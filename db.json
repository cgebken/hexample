{"meta":{"version":1,"warehouse":"2.2.0"},"models":{"Asset":[{"_id":"themes/landscape/source/css/style.styl","path":"css/style.styl","modified":1,"renderable":1},{"_id":"themes/landscape/source/fancybox/blank.gif","path":"fancybox/blank.gif","modified":1,"renderable":1},{"_id":"themes/landscape/source/fancybox/fancybox_loading.gif","path":"fancybox/fancybox_loading.gif","modified":1,"renderable":1},{"_id":"themes/landscape/source/fancybox/fancybox_loading@2x.gif","path":"fancybox/fancybox_loading@2x.gif","modified":1,"renderable":1},{"_id":"themes/landscape/source/fancybox/fancybox_sprite.png","path":"fancybox/fancybox_sprite.png","modified":1,"renderable":1},{"_id":"themes/landscape/source/fancybox/fancybox_overlay.png","path":"fancybox/fancybox_overlay.png","modified":1,"renderable":1},{"_id":"themes/landscape/source/fancybox/fancybox_sprite@2x.png","path":"fancybox/fancybox_sprite@2x.png","modified":1,"renderable":1},{"_id":"themes/landscape/source/fancybox/jquery.fancybox.css","path":"fancybox/jquery.fancybox.css","modified":1,"renderable":1},{"_id":"themes/landscape/source/js/script.js","path":"js/script.js","modified":1,"renderable":1},{"_id":"themes/landscape/source/fancybox/jquery.fancybox.pack.js","path":"fancybox/jquery.fancybox.pack.js","modified":1,"renderable":1},{"_id":"themes/landscape/source/fancybox/jquery.fancybox.js","path":"fancybox/jquery.fancybox.js","modified":1,"renderable":1},{"_id":"themes/landscape/source/css/fonts/FontAwesome.otf","path":"css/fonts/FontAwesome.otf","modified":1,"renderable":1},{"_id":"themes/landscape/source/css/fonts/fontawesome-webfont.eot","path":"css/fonts/fontawesome-webfont.eot","modified":1,"renderable":1},{"_id":"themes/landscape/source/fancybox/helpers/fancybox_buttons.png","path":"fancybox/helpers/fancybox_buttons.png","modified":1,"renderable":1},{"_id":"themes/landscape/source/fancybox/helpers/jquery.fancybox-buttons.css","path":"fancybox/helpers/jquery.fancybox-buttons.css","modified":1,"renderable":1},{"_id":"themes/landscape/source/fancybox/helpers/jquery.fancybox-buttons.js","path":"fancybox/helpers/jquery.fancybox-buttons.js","modified":1,"renderable":1},{"_id":"themes/landscape/source/fancybox/helpers/jquery.fancybox-media.js","path":"fancybox/helpers/jquery.fancybox-media.js","modified":1,"renderable":1},{"_id":"themes/landscape/source/css/fonts/fontawesome-webfont.woff","path":"css/fonts/fontawesome-webfont.woff","modified":1,"renderable":1},{"_id":"themes/landscape/source/fancybox/helpers/jquery.fancybox-thumbs.css","path":"fancybox/helpers/jquery.fancybox-thumbs.css","modified":1,"renderable":1},{"_id":"themes/landscape/source/fancybox/helpers/jquery.fancybox-thumbs.js","path":"fancybox/helpers/jquery.fancybox-thumbs.js","modified":1,"renderable":1},{"_id":"themes/landscape/source/css/fonts/fontawesome-webfont.svg","path":"css/fonts/fontawesome-webfont.svg","modified":1,"renderable":1},{"_id":"themes/landscape/source/css/fonts/fontawesome-webfont.ttf","path":"css/fonts/fontawesome-webfont.ttf","modified":1,"renderable":1},{"_id":"themes/landscape/source/css/images/banner.jpg","path":"css/images/banner.jpg","modified":1,"renderable":1}],"Cache":[{"_id":"themes/landscape/LICENSE","hash":"c480fce396b23997ee23cc535518ffaaf7f458f8","modified":1474373361000},{"_id":"themes/landscape/README.md","hash":"c7e83cfe8f2c724fc9cac32bd71bb5faf9ceeddb","modified":1474373361000},{"_id":"themes/landscape/package.json","hash":"85358dc34311c6662e841584e206a4679183943f","modified":1474373361000},{"_id":"themes/landscape/.gitignore","hash":"58d26d4b5f2f94c2d02a4e4a448088e4a2527c77","modified":1474373361000},{"_id":"themes/landscape/Gruntfile.js","hash":"71adaeaac1f3cc56e36c49d549b8d8a72235c9b9","modified":1474373361000},{"_id":"themes/landscape/_config.yml","hash":"fb8c98a0f6ff9f962637f329c22699721854cd73","modified":1474373361000},{"_id":"themes/landscape/languages/default.yml","hash":"3083f319b352d21d80fc5e20113ddf27889c9d11","modified":1474373361000},{"_id":"themes/landscape/languages/fr.yml","hash":"84ab164b37c6abf625473e9a0c18f6f815dd5fd9","modified":1474373361000},{"_id":"themes/landscape/languages/nl.yml","hash":"12ed59faba1fc4e8cdd1d42ab55ef518dde8039c","modified":1474373361000},{"_id":"themes/landscape/languages/no.yml","hash":"965a171e70347215ec726952e63f5b47930931ef","modified":1474373361000},{"_id":"themes/landscape/languages/ru.yml","hash":"4fda301bbd8b39f2c714e2c934eccc4b27c0a2b0","modified":1474373361000},{"_id":"themes/landscape/languages/zh-CN.yml","hash":"ca40697097ab0b3672a80b455d3f4081292d1eed","modified":1474373361000},{"_id":"themes/landscape/languages/zh-TW.yml","hash":"53ce3000c5f767759c7d2c4efcaa9049788599c3","modified":1474373361000},{"_id":"themes/landscape/layout/archive.ejs","hash":"2703b07cc8ac64ae46d1d263f4653013c7e1666b","modified":1474373361000},{"_id":"themes/landscape/layout/category.ejs","hash":"765426a9c8236828dc34759e604cc2c52292835a","modified":1474373361000},{"_id":"themes/landscape/layout/index.ejs","hash":"aa1b4456907bdb43e629be3931547e2d29ac58c8","modified":1474373361000},{"_id":"themes/landscape/layout/layout.ejs","hash":"f155824ca6130080bb057fa3e868a743c69c4cf5","modified":1474373361000},{"_id":"themes/landscape/scripts/fancybox.js","hash":"aa411cd072399df1ddc8e2181a3204678a5177d9","modified":1474373361000},{"_id":"themes/landscape/layout/post.ejs","hash":"7d80e4e36b14d30a7cd2ac1f61376d9ebf264e8b","modified":1474373361000},{"_id":"themes/landscape/layout/page.ejs","hash":"7d80e4e36b14d30a7cd2ac1f61376d9ebf264e8b","modified":1474373361000},{"_id":"themes/landscape/layout/tag.ejs","hash":"eaa7b4ccb2ca7befb90142e4e68995fb1ea68b2e","modified":1474373361000},{"_id":"source/_posts/2015-04-01-the-first-epages-hackathon-is-over.md","hash":"6e18ebf4321aea2a7e9598ffc0eb878c704841fa","modified":1474381162000},{"_id":"source/_posts/2015-04-02-epages-talks-code.md","hash":"09440efb7097745dc46a4095a3dcf97460bcc9d6","modified":1474381162000},{"_id":"source/_posts/2015-04-16-does-your-heart-beat-for-code.md","hash":"d365b47050285c32dce49a9ab0299ff1e4eec9d3","modified":1474381162000},{"_id":"source/_posts/2015-04-29-js-unconf-2015-retrospective.md","hash":"3965ff7456b6891ab953e0fb19ea5b499ee6b8a7","modified":1474381162000},{"_id":"source/_posts/2015-05-26-hamburg-hackathon.md","hash":"884f770164f1e64833d1c021fb136696ec6ac77d","modified":1474381162000},{"_id":"source/_posts/2015-05-29-techwriter-experience-report.md","hash":"7a21bc4865af1946afc993ca878e728302981748","modified":1474381162000},{"_id":"source/_posts/2015-06-04-team-offsite.md","hash":"b8d17b7f7d3e8c2d8e522d319dbbe67116347c96","modified":1474381162000},{"_id":"source/_posts/2015-06-21-guest-post-shippo-integation.md","hash":"5fc6da36df5e9fbfaab5a8a4a8d0a9265c97a27d","modified":1474381162000},{"_id":"source/_posts/2015-06-25-infrastructure-as-code.md","hash":"a41664bd07a7150a66724e46b3abfb1f6f413e70","modified":1474381162000},{"_id":"source/_posts/2015-06-30-company-cup-jena.md","hash":"e81db3de4754bb340dca751cb603902683c7e6b0","modified":1474381162000},{"_id":"source/_posts/2015-07-07-employee-induction-programme.md","hash":"8e55f4f7d75ee62c52b00fd543857b1c32da8273","modified":1474381162000},{"_id":"source/_posts/2015-07-17-tough-mudder-event.md","hash":"9b0aa5668f9914edc6c8a13281a98771602f5e66","modified":1474381162000},{"_id":"source/_posts/2015-07-20-third-party-integration.md","hash":"4a6e1b03bb1f9ddfef9727ace23573ea4d7c45a6","modified":1474381162000},{"_id":"source/_posts/2015-08-03-creating-systems-with-pipelining.md","hash":"cbc286cbd3286ed89f57710ce90151ffb067c4aa","modified":1474381162000},{"_id":"source/_posts/2015-09-02-barcamp-kiel-2015.md","hash":"088c921bbc79a1ef3b68125e58da5190ab2bdc77","modified":1474381162000},{"_id":"source/_posts/2015-09-04-survey-improve-api-docu.md","hash":"f46efd9e878fec5d316c382fd1677adb9784428c","modified":1474381162000},{"_id":"source/_posts/2015-09-08-code-talks.md","hash":"068ff57aa9b982d57a4051e136784566b18d4e85","modified":1474381162000},{"_id":"source/_posts/2015-09-15-rnd-day-2015.md","hash":"fbe958c6f5743f5bd761ab0c00f90db4bdf543f4","modified":1474381162000},{"_id":"source/_posts/2015-09-21-epages-you-2015.md","hash":"e12c49ba81e4aef392c9899fefd9d39f244740c3","modified":1474381162000},{"_id":"source/_posts/2015-09-24-agile-fluency.md","hash":"cce72012692a9919a4e27e14e166a3a6ad54b558","modified":1474381162000},{"_id":"source/_posts/2015-09-28-service-discovery.md","hash":"3be739cf89957566ee4cd386af877b96814280c7","modified":1474381162000},{"_id":"source/_posts/2015-10-07-code-talks-2015-retrospective.md","hash":"891c654ccb61173d4449f228502ec7b5529c4442","modified":1474381162000},{"_id":"source/_posts/2015-10-27-refugeehackathon.md","hash":"1010fc9a6a5a46f4c381ee967361951cf3805559","modified":1474381162000},{"_id":"source/_posts/2015-10-28-code-talks-java.md","hash":"df6bb919ad4bb7914544873512443259ad72d456","modified":1474381162000},{"_id":"source/_posts/2015-11-19-scrum-basics-2.md","hash":"4e2785723f1fadd378cc53a7c2e3a37cb95e27b3","modified":1474381162000},{"_id":"source/_posts/2015-10-13-scrum-basics-1.md","hash":"e212fcbe3770205595a9cd958dc60abcafd5592b","modified":1474381684000},{"_id":"source/_posts/2015-11-27-seokomm-2015.md","hash":"5dec0b7757e6160e4c497b890a2a60e0249c1eb7","modified":1474381162000},{"_id":"source/_posts/2015-12-07-global-scrum-gathering-2015-prague.md","hash":"77cd8db6e5e2467dd033efdc26ba7073d6e344a0","modified":1474381162000},{"_id":"source/_posts/2015-12-08-wjax2015-microservices.md","hash":"11857e69a72b583715b03b35c64511a94a5556de","modified":1474381162000},{"_id":"source/_posts/2016-02-09-microservice-meetup.md","hash":"1420eb77aff67e0eca972c321a739842ebadf504","modified":1474381908000},{"_id":"source/_posts/2016-02-11-pipeline-elk-test-evaluation-1.md","hash":"2c80befbb7dd6d61d2a144c7915750ecd1cd2040","modified":1474382540000},{"_id":"source/_posts/2015-12-15-scrum-basics-3.md","hash":"8a97dcf47ed4bb94e14466a8e26f374f0f7f41b3","modified":1474381162000},{"_id":"source/_posts/2016-02-17-agile-meetup.md","hash":"97f23b003d7ddf8d80cd5f726a30f037c7f85b0b","modified":1474381908000},{"_id":"source/_posts/2016-02-25-scrum-basics-5.md","hash":"da2e76f21831714fc282cb551c2a8639bb517528","modified":1474381908000},{"_id":"source/_posts/2016-03-08-online-schema-updates.md","hash":"85a94e872fdc0e54b11827019660147a663aeb07","modified":1474382540000},{"_id":"source/_posts/2016-03-31-ecommerce-barcamp-jena.md","hash":"0a0b39b818fff248d903e9e2c0037d71d57229d1","modified":1474382540000},{"_id":"source/_posts/2016-01-21-announce-rest-api.md","hash":"80be236e859a0427bf8fda85cbdabde52e60bc91","modified":1474381908000},{"_id":"source/_posts/2016-01-26-scrum-basics-4.md","hash":"b61edbfe84db9c5c3b8e9e97688b09bf7ee6a5a8","modified":1474381908000},{"_id":"source/_posts/2016-04-20-agile-hackathon.md","hash":"11f796a4d1344ffb4f51f10cb535c47dfe75fab2","modified":1474382540000},{"_id":"source/_posts/2016-04-21-jenadevs-docker-party.md","hash":"b0f7a144aed65fa4c1b0a2f99672fdd6d025e6d0","modified":1474382540000},{"_id":"source/_posts/2016-05-18-offsite-consulting.md","hash":"9be0aa039830847b4f962dea362d97c618e35188","modified":1474381908000},{"_id":"source/_posts/2016-03-17-team-orange-mallorca.md","hash":"ff9c04fdbaf7097b449962dbd03fdf8f53558285","modified":1474381908000},{"_id":"source/_posts/2016-04-01-partner-training.md","hash":"3e71ecf14b221ebcdb68b5000979722a9d905864","modified":1474381908000},{"_id":"source/_posts/2016-04-05-tdd-with-java.md","hash":"702e38dcaecc873f06f67baaa2a6b5b4d4935709","modified":1474381908000},{"_id":"source/_posts/2016-05-26-magdeburger-developer-days.md","hash":"960f00935faf2565ec91b0692460ab7ae9d9c35b","modified":1474381908000},{"_id":"source/_posts/2016-06-16-ux-tw-cooperation.md","hash":"d3b3f84d68cad28d8a3afa83dd6ebe8c8c42204b","modified":1474381908000},{"_id":"source/_posts/2016-07-04-ep6-offsite.md","hash":"1337ebf8ee0d0184647327d5f0a92010eb4bd3ad","modified":1474381908000},{"_id":"source/_posts/2016-07-05-containerdays.md","hash":"dc0f1256e4cf116e0b26dcbae5715f313a66acff","modified":1474381908000},{"_id":"source/_posts/2016-07-14-wiremock.md","hash":"41aa49f1f2a50464f997c041e7d7db7097fab9e2","modified":1474381908000},{"_id":"source/_posts/2016-07-26-xconf-2016.md","hash":"ab127247b871d56f21cfcc807c14d64b0faeb12a","modified":1474381908000},{"_id":"source/_posts/2016-08-04-dev-onboarding.md","hash":"1a6f42868b60c79b545772573d5c7bfa9b17c99d","modified":1474381908000},{"_id":"source/_posts/2016-07-07-elastic-meetup.md","hash":"b89c257ecdab59e91a636885db64d114eda24fa1","modified":1474381908000},{"_id":"source/_posts/2016-08-02-next-gen-webservices.md","hash":"7f73aab1bade6297ca313d75ce426cce98c21bfd","modified":1474381908000},{"_id":"source/_posts/2016-08-12-sageone-approach.md","hash":"4efe8572a9c6a73f8919cf8d8ebb528f0f78b00f","modified":1474381908000},{"_id":"source/_posts/2016-08-23-api-target-group.md","hash":"fe2ec1f5b492748219c3064144bdbe62351a45ec","modified":1474381908000},{"_id":"source/_posts/2016-08-30-partner-training.md","hash":"8d10ecb52b1458b43522279882de7de2f70e1b10","modified":1474381908000},{"_id":"source/_posts/2016-09-01-socrates.md","hash":"1278d1a85f213e67b000a1c8a9314f52d647ce7c","modified":1474381908000},{"_id":"themes/landscape/layout/_partial/after-footer.ejs","hash":"82a30f81c0e8ba4a8af17acd6cc99e93834e4d5e","modified":1474373361000},{"_id":"themes/landscape/layout/_partial/article.ejs","hash":"c9688f08242895989a5c02de27a9a82f44e3dac7","modified":1474384097000},{"_id":"themes/landscape/layout/_partial/archive-post.ejs","hash":"c7a71425a946d05414c069ec91811b5c09a92c47","modified":1474373361000},{"_id":"themes/landscape/layout/_partial/archive.ejs","hash":"931aaaffa0910a48199388ede576184ff15793ee","modified":1474373361000},{"_id":"themes/landscape/layout/_partial/footer.ejs","hash":"93518893cf91287e797ebac543c560e2a63b8d0e","modified":1474373361000},{"_id":"themes/landscape/layout/_partial/head.ejs","hash":"4fe8853e864d192701c03e5cd3a5390287b90612","modified":1474373361000},{"_id":"themes/landscape/layout/_partial/google-analytics.ejs","hash":"f921e7f9223d7c95165e0f835f353b2938e40c45","modified":1474373361000},{"_id":"themes/landscape/layout/_partial/header.ejs","hash":"c21ca56f419d01a9f49c27b6be9f4a98402b2aa3","modified":1474373361000},{"_id":"themes/landscape/layout/_partial/mobile-nav.ejs","hash":"e952a532dfc583930a666b9d4479c32d4a84b44e","modified":1474373361000},{"_id":"themes/landscape/layout/_partial/sidebar.ejs","hash":"930da35cc2d447a92e5ee8f835735e6fd2232469","modified":1474373361000},{"_id":"themes/landscape/layout/_widget/archive.ejs","hash":"beb4a86fcc82a9bdda9289b59db5a1988918bec3","modified":1474373361000},{"_id":"themes/landscape/layout/_widget/category.ejs","hash":"dd1e5af3c6af3f5d6c85dfd5ca1766faed6a0b05","modified":1474373361000},{"_id":"themes/landscape/layout/_widget/recent_posts.ejs","hash":"0d4f064733f8b9e45c0ce131fe4a689d570c883a","modified":1474373361000},{"_id":"themes/landscape/layout/_widget/tag.ejs","hash":"2de380865df9ab5f577f7d3bcadf44261eb5faae","modified":1474373361000},{"_id":"themes/landscape/layout/_widget/tagcloud.ejs","hash":"b4a2079101643f63993dcdb32925c9b071763b46","modified":1474373361000},{"_id":"themes/landscape/source/css/_extend.styl","hash":"222fbe6d222531d61c1ef0f868c90f747b1c2ced","modified":1474373361000},{"_id":"themes/landscape/source/css/_variables.styl","hash":"5e37a6571caf87149af83ac1cc0cdef99f117350","modified":1474373361000},{"_id":"themes/landscape/source/css/style.styl","hash":"a70d9c44dac348d742702f6ba87e5bb3084d65db","modified":1474373361000},{"_id":"themes/landscape/source/fancybox/blank.gif","hash":"2daeaa8b5f19f0bc209d976c02bd6acb51b00b0a","modified":1474373361000},{"_id":"themes/landscape/source/fancybox/fancybox_loading.gif","hash":"1a755fb2599f3a313cc6cfdb14df043f8c14a99c","modified":1474373361000},{"_id":"themes/landscape/source/fancybox/fancybox_loading@2x.gif","hash":"273b123496a42ba45c3416adb027cd99745058b0","modified":1474373361000},{"_id":"themes/landscape/source/fancybox/fancybox_sprite.png","hash":"17df19f97628e77be09c352bf27425faea248251","modified":1474373361000},{"_id":"themes/landscape/source/fancybox/fancybox_overlay.png","hash":"b3a4ee645ba494f52840ef8412015ba0f465dbe0","modified":1474373361000},{"_id":"themes/landscape/source/fancybox/fancybox_sprite@2x.png","hash":"30c58913f327e28f466a00f4c1ac8001b560aed8","modified":1474373361000},{"_id":"themes/landscape/source/fancybox/jquery.fancybox.css","hash":"aaa582fb9eb4b7092dc69fcb2d5b1c20cca58ab6","modified":1474373361000},{"_id":"themes/landscape/source/js/script.js","hash":"2876e0b19ce557fca38d7c6f49ca55922ab666a1","modified":1474373361000},{"_id":"themes/landscape/source/fancybox/jquery.fancybox.pack.js","hash":"9e0d51ca1dbe66f6c0c7aefd552dc8122e694a6e","modified":1474373361000},{"_id":"themes/landscape/source/fancybox/jquery.fancybox.js","hash":"d08b03a42d5c4ba456ef8ba33116fdbb7a9cabed","modified":1474373361000},{"_id":"themes/landscape/layout/_partial/post/category.ejs","hash":"c6bcd0e04271ffca81da25bcff5adf3d46f02fc0","modified":1474373361000},{"_id":"themes/landscape/layout/_partial/post/date.ejs","hash":"6197802873157656e3077c5099a7dda3d3b01c29","modified":1474373361000},{"_id":"themes/landscape/layout/_partial/post/nav.ejs","hash":"16a904de7bceccbb36b4267565f2215704db2880","modified":1474373361000},{"_id":"themes/landscape/layout/_partial/post/gallery.ejs","hash":"3d9d81a3c693ff2378ef06ddb6810254e509de5b","modified":1474373361000},{"_id":"themes/landscape/layout/_partial/post/title.ejs","hash":"635ee5db499fe6f1099ee788488b32472b6d63bc","modified":1474384083000},{"_id":"themes/landscape/layout/_partial/post/tag.ejs","hash":"2fcb0bf9c8847a644167a27824c9bb19ac74dd14","modified":1474373361000},{"_id":"themes/landscape/source/css/_util/grid.styl","hash":"0bf55ee5d09f193e249083602ac5fcdb1e571aed","modified":1474373361000},{"_id":"themes/landscape/source/css/_util/mixin.styl","hash":"44f32767d9fd3c1c08a60d91f181ee53c8f0dbb3","modified":1474373361000},{"_id":"themes/landscape/source/css/_partial/archive.styl","hash":"db15f5677dc68f1730e82190bab69c24611ca292","modified":1474373361000},{"_id":"themes/landscape/source/css/_partial/article.styl","hash":"10685f8787a79f79c9a26c2f943253450c498e3e","modified":1474373361000},{"_id":"themes/landscape/source/css/_partial/comment.styl","hash":"79d280d8d203abb3bd933ca9b8e38c78ec684987","modified":1474373361000},{"_id":"themes/landscape/source/css/_partial/footer.styl","hash":"e35a060b8512031048919709a8e7b1ec0e40bc1b","modified":1474373361000},{"_id":"themes/landscape/source/css/_partial/header.styl","hash":"85ab11e082f4dd86dde72bed653d57ec5381f30c","modified":1474373361000},{"_id":"themes/landscape/source/css/_partial/highlight.styl","hash":"bf4e7be1968dad495b04e83c95eac14c4d0ad7c0","modified":1474373361000},{"_id":"themes/landscape/source/css/_partial/mobile.styl","hash":"a399cf9e1e1cec3e4269066e2948d7ae5854d745","modified":1474373361000},{"_id":"themes/landscape/source/css/_partial/sidebar-aside.styl","hash":"890349df5145abf46ce7712010c89237900b3713","modified":1474373361000},{"_id":"themes/landscape/source/css/_partial/sidebar-bottom.styl","hash":"8fd4f30d319542babfd31f087ddbac550f000a8a","modified":1474373361000},{"_id":"themes/landscape/source/css/_partial/sidebar.styl","hash":"404ec059dc674a48b9ab89cd83f258dec4dcb24d","modified":1474373361000},{"_id":"themes/landscape/source/css/fonts/FontAwesome.otf","hash":"b5b4f9be85f91f10799e87a083da1d050f842734","modified":1474373361000},{"_id":"themes/landscape/source/css/fonts/fontawesome-webfont.eot","hash":"7619748fe34c64fb157a57f6d4ef3678f63a8f5e","modified":1474373361000},{"_id":"themes/landscape/source/fancybox/helpers/fancybox_buttons.png","hash":"e385b139516c6813dcd64b8fc431c364ceafe5f3","modified":1474373361000},{"_id":"themes/landscape/source/fancybox/helpers/jquery.fancybox-buttons.css","hash":"1a9d8e5c22b371fcc69d4dbbb823d9c39f04c0c8","modified":1474373361000},{"_id":"themes/landscape/source/fancybox/helpers/jquery.fancybox-buttons.js","hash":"dc3645529a4bf72983a39fa34c1eb9146e082019","modified":1474373361000},{"_id":"themes/landscape/source/fancybox/helpers/jquery.fancybox-media.js","hash":"294420f9ff20f4e3584d212b0c262a00a96ecdb3","modified":1474373361000},{"_id":"themes/landscape/source/css/fonts/fontawesome-webfont.woff","hash":"04c3bf56d87a0828935bd6b4aee859995f321693","modified":1474373361000},{"_id":"themes/landscape/source/fancybox/helpers/jquery.fancybox-thumbs.css","hash":"4ac329c16a5277592fc12a37cca3d72ca4ec292f","modified":1474373361000},{"_id":"themes/landscape/source/fancybox/helpers/jquery.fancybox-thumbs.js","hash":"47da1ae5401c24b5c17cc18e2730780f5c1a7a0c","modified":1474373361000},{"_id":"themes/landscape/source/css/fonts/fontawesome-webfont.svg","hash":"46fcc0194d75a0ddac0a038aee41b23456784814","modified":1474373361000},{"_id":"themes/landscape/source/css/fonts/fontawesome-webfont.ttf","hash":"7f09c97f333917034ad08fa7295e916c9f72fd3f","modified":1474373361000},{"_id":"themes/landscape/source/css/images/banner.jpg","hash":"f44aa591089fcb3ec79770a1e102fd3289a7c6a6","modified":1474373361000}],"Category":[{"name":"events","_id":"ciu6nuh7q0002hqyx4znd0t21"},{"name":"working-at-epages","_id":"ciu6nuh82000ahqyxa8dkw4b8"},{"name":"api","_id":"ciu6nuh86000fhqyxiud5memz"},{"name":"tech-stories","_id":"ciu6nuh8a000khqyxf8x9xhmi"},{"name":"agile","_id":"ciu6nuh8y0016hqyxlgmotg25"}],"Data":[],"Page":[],"Post":[{"layout":"post","title":"The first ePages hackathon is over","date":"2015-04-01T10:00:00.000Z","authors":["Anja","Birgit"],"_content":"\n**2 days - 50 ePagees - 8 teams.** On March 24 and 25, 2015 all signs in the ePages Jena office pointed to exploratory programming.\n\nThe rules were simple:\n\n<ul class=\"fa-ul\">\n  <li><i class=\"fa-li fa fa-thumb-tack\"></i>Work on a solution for something that bothers in daily work, is time consuming or even would make our work life easier.</li>\n  <li><i class=\"fa-li fa fa-thumb-tack\"></i>Achievable in two days.</li>\n  <li><i class=\"fa-li fa fa-thumb-tack\"></i>Developed in cross-functional teams.</li>\n</ul>\n\nAfter two days of \"blood, sweat, tears\" and lots of fun, we had awesome results:\n\n* Team 1 - Prototype for an interactive administration area guide:\nIn order to develop a prototype for an interactive administration area guide, the team first tested two different frameworks. After finishing the tests, they came up with a pretty good solution guiding a customer through the administration area to create a product.\n\n* Team 2 - Help yourself with Sublime Editor:\nMany team members use Sublime Editor in their daily business. But as the support for Windows has been cut off, the team developed timesaving extensions and plugins itself.\n\n* Team 3 - Replace ArgoUML with an easier tool:\nArgoUML is hard and time-consuming to use. The team's goal was to find an easier tool for creating database models. Split up in two groups, one group fixed the erros in the existing database models and remodeled them in a new modelling language. The other group pushed the results in an eclipse update site/repository and created an eclipse plugin. Every ePages developer can use this solution in future for database modelling.\n\n* Team 4 - Implement Circuit Breaker software:\nePages applications become more and more distributed, but currently highly depend from each other. It's like a house with several rooms: if one room has an energy overload, the circuit breaker trips, shuts down the energy for this room, but keeps the rest of the house safe and running. At ePages, currently a problem in one \"room\" could shut down the whole \"house\".\nThe team implemented an existing Circuit Breaker software to avoid that a problem of one applicaton affects the rest of the software.\n\n* Team 5 - Increase company culture:\nThis team used the hackathon to build a Pong Game. A game takes only two minutes and is ideal for a short pause for reflection. The team members not only achieved to build the game, but learned a lot from each other during the project.\n\n* Team 6 - Hush! Top secret stuff.\n\n* Team 7 - Evaluate Gradle as professional Build-Management-System:\nThe old language pack build process was quite time-consuming and required lots of manual work. The team managed to proof that Gradle would work for ePages and could save a lot of time. Some manual steps of the language pack build process have already been automated.\n\n* Team 8 - Evaluating Docker to optimise resource consumption:\nePages runs automated acceptance tests with a Selenium Framework against a great number of ePages installations. This requires a significant amount of server resources. The team had to face quite some challenges and worked hard to solve them. But at the end, they managed to run the tests with Docker. Yay!\n\nThe team spirit throughout R&D was fantastic. ePagees from Hamburg, Jena, Barcelona (and even New York participated via Skype) worked in crossfunctional teams and had a great time together!\n\nLooking forward to the next ePages hackathon!\n","source":"_posts/2015-04-01-the-first-epages-hackathon-is-over.md","raw":"---\nlayout: post\ntitle: \"The first ePages hackathon is over\"\ndate: \"2015-04-01 12:00:00\"\ncategories: events\nauthors: [\"Anja\", \"Birgit\"]\n---\n\n**2 days - 50 ePagees - 8 teams.** On March 24 and 25, 2015 all signs in the ePages Jena office pointed to exploratory programming.\n\nThe rules were simple:\n\n<ul class=\"fa-ul\">\n  <li><i class=\"fa-li fa fa-thumb-tack\"></i>Work on a solution for something that bothers in daily work, is time consuming or even would make our work life easier.</li>\n  <li><i class=\"fa-li fa fa-thumb-tack\"></i>Achievable in two days.</li>\n  <li><i class=\"fa-li fa fa-thumb-tack\"></i>Developed in cross-functional teams.</li>\n</ul>\n\nAfter two days of \"blood, sweat, tears\" and lots of fun, we had awesome results:\n\n* Team 1 - Prototype for an interactive administration area guide:\nIn order to develop a prototype for an interactive administration area guide, the team first tested two different frameworks. After finishing the tests, they came up with a pretty good solution guiding a customer through the administration area to create a product.\n\n* Team 2 - Help yourself with Sublime Editor:\nMany team members use Sublime Editor in their daily business. But as the support for Windows has been cut off, the team developed timesaving extensions and plugins itself.\n\n* Team 3 - Replace ArgoUML with an easier tool:\nArgoUML is hard and time-consuming to use. The team's goal was to find an easier tool for creating database models. Split up in two groups, one group fixed the erros in the existing database models and remodeled them in a new modelling language. The other group pushed the results in an eclipse update site/repository and created an eclipse plugin. Every ePages developer can use this solution in future for database modelling.\n\n* Team 4 - Implement Circuit Breaker software:\nePages applications become more and more distributed, but currently highly depend from each other. It's like a house with several rooms: if one room has an energy overload, the circuit breaker trips, shuts down the energy for this room, but keeps the rest of the house safe and running. At ePages, currently a problem in one \"room\" could shut down the whole \"house\".\nThe team implemented an existing Circuit Breaker software to avoid that a problem of one applicaton affects the rest of the software.\n\n* Team 5 - Increase company culture:\nThis team used the hackathon to build a Pong Game. A game takes only two minutes and is ideal for a short pause for reflection. The team members not only achieved to build the game, but learned a lot from each other during the project.\n\n* Team 6 - Hush! Top secret stuff.\n\n* Team 7 - Evaluate Gradle as professional Build-Management-System:\nThe old language pack build process was quite time-consuming and required lots of manual work. The team managed to proof that Gradle would work for ePages and could save a lot of time. Some manual steps of the language pack build process have already been automated.\n\n* Team 8 - Evaluating Docker to optimise resource consumption:\nePages runs automated acceptance tests with a Selenium Framework against a great number of ePages installations. This requires a significant amount of server resources. The team had to face quite some challenges and worked hard to solve them. But at the end, they managed to run the tests with Docker. Yay!\n\nThe team spirit throughout R&D was fantastic. ePagees from Hamburg, Jena, Barcelona (and even New York participated via Skype) worked in crossfunctional teams and had a great time together!\n\nLooking forward to the next ePages hackathon!\n","slug":"2015-04-01-the-first-epages-hackathon-is-over","published":1,"updated":"2016-09-20T14:19:22.000Z","comments":1,"photos":[],"link":"","_id":"ciu6nuh7i0000hqyx0ay5hen4","content":"<p><strong>2 days - 50 ePagees - 8 teams.</strong> On March 24 and 25, 2015 all signs in the ePages Jena office pointed to exploratory programming.</p>\n<p>The rules were simple:</p>\n<ul class=\"fa-ul\"><br>  <li><i class=\"fa-li fa fa-thumb-tack\"></i>Work on a solution for something that bothers in daily work, is time consuming or even would make our work life easier.</li><br>  <li><i class=\"fa-li fa fa-thumb-tack\"></i>Achievable in two days.</li><br>  <li><i class=\"fa-li fa fa-thumb-tack\"></i>Developed in cross-functional teams.</li><br></ul>\n\n<p>After two days of “blood, sweat, tears” and lots of fun, we had awesome results:</p>\n<ul>\n<li><p>Team 1 - Prototype for an interactive administration area guide:<br>In order to develop a prototype for an interactive administration area guide, the team first tested two different frameworks. After finishing the tests, they came up with a pretty good solution guiding a customer through the administration area to create a product.</p>\n</li>\n<li><p>Team 2 - Help yourself with Sublime Editor:<br>Many team members use Sublime Editor in their daily business. But as the support for Windows has been cut off, the team developed timesaving extensions and plugins itself.</p>\n</li>\n<li><p>Team 3 - Replace ArgoUML with an easier tool:<br>ArgoUML is hard and time-consuming to use. The team’s goal was to find an easier tool for creating database models. Split up in two groups, one group fixed the erros in the existing database models and remodeled them in a new modelling language. The other group pushed the results in an eclipse update site/repository and created an eclipse plugin. Every ePages developer can use this solution in future for database modelling.</p>\n</li>\n<li><p>Team 4 - Implement Circuit Breaker software:<br>ePages applications become more and more distributed, but currently highly depend from each other. It’s like a house with several rooms: if one room has an energy overload, the circuit breaker trips, shuts down the energy for this room, but keeps the rest of the house safe and running. At ePages, currently a problem in one “room” could shut down the whole “house”.<br>The team implemented an existing Circuit Breaker software to avoid that a problem of one applicaton affects the rest of the software.</p>\n</li>\n<li><p>Team 5 - Increase company culture:<br>This team used the hackathon to build a Pong Game. A game takes only two minutes and is ideal for a short pause for reflection. The team members not only achieved to build the game, but learned a lot from each other during the project.</p>\n</li>\n<li><p>Team 6 - Hush! Top secret stuff.</p>\n</li>\n<li><p>Team 7 - Evaluate Gradle as professional Build-Management-System:<br>The old language pack build process was quite time-consuming and required lots of manual work. The team managed to proof that Gradle would work for ePages and could save a lot of time. Some manual steps of the language pack build process have already been automated.</p>\n</li>\n<li><p>Team 8 - Evaluating Docker to optimise resource consumption:<br>ePages runs automated acceptance tests with a Selenium Framework against a great number of ePages installations. This requires a significant amount of server resources. The team had to face quite some challenges and worked hard to solve them. But at the end, they managed to run the tests with Docker. Yay!</p>\n</li>\n</ul>\n<p>The team spirit throughout R&amp;D was fantastic. ePagees from Hamburg, Jena, Barcelona (and even New York participated via Skype) worked in crossfunctional teams and had a great time together!</p>\n<p>Looking forward to the next ePages hackathon!</p>\n","excerpt":"","more":"<p><strong>2 days - 50 ePagees - 8 teams.</strong> On March 24 and 25, 2015 all signs in the ePages Jena office pointed to exploratory programming.</p>\n<p>The rules were simple:</p>\n<ul class=\"fa-ul\"><br>  <li><i class=\"fa-li fa fa-thumb-tack\"></i>Work on a solution for something that bothers in daily work, is time consuming or even would make our work life easier.</li><br>  <li><i class=\"fa-li fa fa-thumb-tack\"></i>Achievable in two days.</li><br>  <li><i class=\"fa-li fa fa-thumb-tack\"></i>Developed in cross-functional teams.</li><br></ul>\n\n<p>After two days of “blood, sweat, tears” and lots of fun, we had awesome results:</p>\n<ul>\n<li><p>Team 1 - Prototype for an interactive administration area guide:<br>In order to develop a prototype for an interactive administration area guide, the team first tested two different frameworks. After finishing the tests, they came up with a pretty good solution guiding a customer through the administration area to create a product.</p>\n</li>\n<li><p>Team 2 - Help yourself with Sublime Editor:<br>Many team members use Sublime Editor in their daily business. But as the support for Windows has been cut off, the team developed timesaving extensions and plugins itself.</p>\n</li>\n<li><p>Team 3 - Replace ArgoUML with an easier tool:<br>ArgoUML is hard and time-consuming to use. The team’s goal was to find an easier tool for creating database models. Split up in two groups, one group fixed the erros in the existing database models and remodeled them in a new modelling language. The other group pushed the results in an eclipse update site/repository and created an eclipse plugin. Every ePages developer can use this solution in future for database modelling.</p>\n</li>\n<li><p>Team 4 - Implement Circuit Breaker software:<br>ePages applications become more and more distributed, but currently highly depend from each other. It’s like a house with several rooms: if one room has an energy overload, the circuit breaker trips, shuts down the energy for this room, but keeps the rest of the house safe and running. At ePages, currently a problem in one “room” could shut down the whole “house”.<br>The team implemented an existing Circuit Breaker software to avoid that a problem of one applicaton affects the rest of the software.</p>\n</li>\n<li><p>Team 5 - Increase company culture:<br>This team used the hackathon to build a Pong Game. A game takes only two minutes and is ideal for a short pause for reflection. The team members not only achieved to build the game, but learned a lot from each other during the project.</p>\n</li>\n<li><p>Team 6 - Hush! Top secret stuff.</p>\n</li>\n<li><p>Team 7 - Evaluate Gradle as professional Build-Management-System:<br>The old language pack build process was quite time-consuming and required lots of manual work. The team managed to proof that Gradle would work for ePages and could save a lot of time. Some manual steps of the language pack build process have already been automated.</p>\n</li>\n<li><p>Team 8 - Evaluating Docker to optimise resource consumption:<br>ePages runs automated acceptance tests with a Selenium Framework against a great number of ePages installations. This requires a significant amount of server resources. The team had to face quite some challenges and worked hard to solve them. But at the end, they managed to run the tests with Docker. Yay!</p>\n</li>\n</ul>\n<p>The team spirit throughout R&amp;D was fantastic. ePagees from Hamburg, Jena, Barcelona (and even New York participated via Skype) worked in crossfunctional teams and had a great time together!</p>\n<p>Looking forward to the next ePages hackathon!</p>\n"},{"layout":"post","title":"ePages talks code","date":"2015-04-02T10:00:00.000Z","image":"blog-header/code.jpg","authors":["Birgit"],"_content":"\n**Come and meet us in real life @ code.talks, Hamburg!**\nWe are Java Track Sponsor for one of the largest developer conferences in Europe.\nSign up for `code.talks` on September 29 and 30, 2015 to meet with ePages developers and designers. This will be a great chance to network, exchange experience and discuss best practices.\n\nThe conference thrives on a variety of interesting topics in the field of web development, exciting talks and of course lots of fun.\nePages developers will participate actively in the conference and give interesting talks and insights into their field of work.\nAs soon as there's more detailed information on the topics, you will of course read it here.\n\nHope to see you all!\n","source":"_posts/2015-04-02-epages-talks-code.md","raw":"---\nlayout: post\ntitle: \"ePages talks code\"\ndate: \"2015-04-02 12:00:00\"\nimage: blog-header/code.jpg\ncategories: events\nauthors: [\"Birgit\"]\n---\n\n**Come and meet us in real life @ code.talks, Hamburg!**\nWe are Java Track Sponsor for one of the largest developer conferences in Europe.\nSign up for `code.talks` on September 29 and 30, 2015 to meet with ePages developers and designers. This will be a great chance to network, exchange experience and discuss best practices.\n\nThe conference thrives on a variety of interesting topics in the field of web development, exciting talks and of course lots of fun.\nePages developers will participate actively in the conference and give interesting talks and insights into their field of work.\nAs soon as there's more detailed information on the topics, you will of course read it here.\n\nHope to see you all!\n","slug":"2015-04-02-epages-talks-code","published":1,"updated":"2016-09-20T14:19:22.000Z","comments":1,"photos":[],"link":"","_id":"ciu6nuh7m0001hqyxg6k06pvg","content":"<p><strong>Come and meet us in real life @ code.talks, Hamburg!</strong><br>We are Java Track Sponsor for one of the largest developer conferences in Europe.<br>Sign up for <code>code.talks</code> on September 29 and 30, 2015 to meet with ePages developers and designers. This will be a great chance to network, exchange experience and discuss best practices.</p>\n<p>The conference thrives on a variety of interesting topics in the field of web development, exciting talks and of course lots of fun.<br>ePages developers will participate actively in the conference and give interesting talks and insights into their field of work.<br>As soon as there’s more detailed information on the topics, you will of course read it here.</p>\n<p>Hope to see you all!</p>\n","excerpt":"","more":"<p><strong>Come and meet us in real life @ code.talks, Hamburg!</strong><br>We are Java Track Sponsor for one of the largest developer conferences in Europe.<br>Sign up for <code>code.talks</code> on September 29 and 30, 2015 to meet with ePages developers and designers. This will be a great chance to network, exchange experience and discuss best practices.</p>\n<p>The conference thrives on a variety of interesting topics in the field of web development, exciting talks and of course lots of fun.<br>ePages developers will participate actively in the conference and give interesting talks and insights into their field of work.<br>As soon as there’s more detailed information on the topics, you will of course read it here.</p>\n<p>Hope to see you all!</p>\n"},{"layout":"post","title":"Does your heart beat for {code}?","date":"2015-04-16T10:00:00.000Z","image":"blog-header/heartbeat.jpg","authors":["Birgit"],"_content":"\nDo you love coding?\nAre you keen for a new challenge?\nJoin the Force developing the next generation commerce platform.\nHave a look @ our [job openings](http://www.epages.com/en/career/devjobs/) or let's meet in person @ events like the `JS Unconf`, the `Hamburg Geekettes Hackathon` or the `Career Days` in Weimar or Hamburg!\n\nGet in touch with us!\nWe look forward to meeting you.\n","source":"_posts/2015-04-16-does-your-heart-beat-for-code.md","raw":"---\nlayout: post\ntitle: \"Does your heart beat for {code}?\"\ndate: \"2015-04-16 12:00:00\"\nimage: blog-header/heartbeat.jpg\ncategories: working-at-epages\nauthors: [\"Birgit\"]\n---\n\nDo you love coding?\nAre you keen for a new challenge?\nJoin the Force developing the next generation commerce platform.\nHave a look @ our [job openings](http://www.epages.com/en/career/devjobs/) or let's meet in person @ events like the `JS Unconf`, the `Hamburg Geekettes Hackathon` or the `Career Days` in Weimar or Hamburg!\n\nGet in touch with us!\nWe look forward to meeting you.\n","slug":"2015-04-16-does-your-heart-beat-for-code","published":1,"updated":"2016-09-20T14:19:22.000Z","comments":1,"photos":[],"link":"","_id":"ciu6nuh7s0003hqyxg45kkos5","content":"<p>Do you love coding?<br>Are you keen for a new challenge?<br>Join the Force developing the next generation commerce platform.<br>Have a look @ our <a href=\"http://www.epages.com/en/career/devjobs/\" target=\"_blank\" rel=\"external\">job openings</a> or let’s meet in person @ events like the <code>JS Unconf</code>, the <code>Hamburg Geekettes Hackathon</code> or the <code>Career Days</code> in Weimar or Hamburg!</p>\n<p>Get in touch with us!<br>We look forward to meeting you.</p>\n","excerpt":"","more":"<p>Do you love coding?<br>Are you keen for a new challenge?<br>Join the Force developing the next generation commerce platform.<br>Have a look @ our <a href=\"http://www.epages.com/en/career/devjobs/\">job openings</a> or let’s meet in person @ events like the <code>JS Unconf</code>, the <code>Hamburg Geekettes Hackathon</code> or the <code>Career Days</code> in Weimar or Hamburg!</p>\n<p>Get in touch with us!<br>We look forward to meeting you.</p>\n"},{"layout":"post","title":"JS Unconf 2015 Retrospective","date":"2015-04-29T10:00:00.000Z","image":"blog-header/javascript.png","authors":["Paolo"],"_content":"\n**A whole weekend full of JavaScript!** Last weekend I had the chance of attending the `JS Unconf` in Hamburg to gather the latest information on JavaScript. Here is a summary of what it was all about:\n\nIt started with the `Pre JS Unconf code retreat` on Friday, an intense workshop to improve one's coding skills. In code katas based on \"Conway's Game of Life\" and using ECMAScript 6, we were challenged to find elegant coding solutions for a predefined scope. Pair programming with changing partners and varying constraints was the perfect environment to get inspired and develop new ideas. Each coding session followed a small retrospective to sum up the results. **The journey is the reward** pretty much sums up this inspiring and fruitful day. Coding without delivering anything. Cool!\n\nThe next two days focused on awesome talks, of course all related to JavaScript. Rather than following a conventionally structured programme, the audience at the `JS Unconf` is asked to propose talks and also votes for the talks. Here are some of my favourites:\n\n<i class=\"fa fa-pencil\"></i> [Optimize continuous delivery with docker](http://lowsky.github.io/dockerMeetupSlides/#1)\n\n<i class=\"fa fa-pencil\"></i> [Creative coding](https://speakerdeck.com/aemkei/creative-coding)\n\n<i class=\"fa fa-pencil\"></i> [Hacking an intentionally insecure JavaScript Web Application](https://github.com/bkimminich/juice-shop)\n\n<i class=\"fa fa-pencil\"></i> Functional reactive programming with [Bacon.js](https://baconjs.github.io/)\n\nThe breaks between the presentations allowed plenty of time for questions and discussion as well as networking, even with international participants.\n","source":"_posts/2015-04-29-js-unconf-2015-retrospective.md","raw":"---\nlayout: post\ntitle: \"JS Unconf 2015 Retrospective\"\ndate: \"2015-04-29 12:00:00\"\nimage: blog-header/javascript.png\ncategories: events\nauthors: [\"Paolo\"]\n---\n\n**A whole weekend full of JavaScript!** Last weekend I had the chance of attending the `JS Unconf` in Hamburg to gather the latest information on JavaScript. Here is a summary of what it was all about:\n\nIt started with the `Pre JS Unconf code retreat` on Friday, an intense workshop to improve one's coding skills. In code katas based on \"Conway's Game of Life\" and using ECMAScript 6, we were challenged to find elegant coding solutions for a predefined scope. Pair programming with changing partners and varying constraints was the perfect environment to get inspired and develop new ideas. Each coding session followed a small retrospective to sum up the results. **The journey is the reward** pretty much sums up this inspiring and fruitful day. Coding without delivering anything. Cool!\n\nThe next two days focused on awesome talks, of course all related to JavaScript. Rather than following a conventionally structured programme, the audience at the `JS Unconf` is asked to propose talks and also votes for the talks. Here are some of my favourites:\n\n<i class=\"fa fa-pencil\"></i> [Optimize continuous delivery with docker](http://lowsky.github.io/dockerMeetupSlides/#1)\n\n<i class=\"fa fa-pencil\"></i> [Creative coding](https://speakerdeck.com/aemkei/creative-coding)\n\n<i class=\"fa fa-pencil\"></i> [Hacking an intentionally insecure JavaScript Web Application](https://github.com/bkimminich/juice-shop)\n\n<i class=\"fa fa-pencil\"></i> Functional reactive programming with [Bacon.js](https://baconjs.github.io/)\n\nThe breaks between the presentations allowed plenty of time for questions and discussion as well as networking, even with international participants.\n","slug":"2015-04-29-js-unconf-2015-retrospective","published":1,"updated":"2016-09-20T14:19:22.000Z","comments":1,"photos":[],"link":"","_id":"ciu6nuh7u0004hqyx5k293zvd","content":"<p><strong>A whole weekend full of JavaScript!</strong> Last weekend I had the chance of attending the <code>JS Unconf</code> in Hamburg to gather the latest information on JavaScript. Here is a summary of what it was all about:</p>\n<p>It started with the <code>Pre JS Unconf code retreat</code> on Friday, an intense workshop to improve one’s coding skills. In code katas based on “Conway’s Game of Life” and using ECMAScript 6, we were challenged to find elegant coding solutions for a predefined scope. Pair programming with changing partners and varying constraints was the perfect environment to get inspired and develop new ideas. Each coding session followed a small retrospective to sum up the results. <strong>The journey is the reward</strong> pretty much sums up this inspiring and fruitful day. Coding without delivering anything. Cool!</p>\n<p>The next two days focused on awesome talks, of course all related to JavaScript. Rather than following a conventionally structured programme, the audience at the <code>JS Unconf</code> is asked to propose talks and also votes for the talks. Here are some of my favourites:</p>\n<p><i class=\"fa fa-pencil\"></i> <a href=\"http://lowsky.github.io/dockerMeetupSlides/#1\" target=\"_blank\" rel=\"external\">Optimize continuous delivery with docker</a></p>\n<p><i class=\"fa fa-pencil\"></i> <a href=\"https://speakerdeck.com/aemkei/creative-coding\" target=\"_blank\" rel=\"external\">Creative coding</a></p>\n<p><i class=\"fa fa-pencil\"></i> <a href=\"https://github.com/bkimminich/juice-shop\" target=\"_blank\" rel=\"external\">Hacking an intentionally insecure JavaScript Web Application</a></p>\n<p><i class=\"fa fa-pencil\"></i> Functional reactive programming with <a href=\"https://baconjs.github.io/\" target=\"_blank\" rel=\"external\">Bacon.js</a></p>\n<p>The breaks between the presentations allowed plenty of time for questions and discussion as well as networking, even with international participants.</p>\n","excerpt":"","more":"<p><strong>A whole weekend full of JavaScript!</strong> Last weekend I had the chance of attending the <code>JS Unconf</code> in Hamburg to gather the latest information on JavaScript. Here is a summary of what it was all about:</p>\n<p>It started with the <code>Pre JS Unconf code retreat</code> on Friday, an intense workshop to improve one’s coding skills. In code katas based on “Conway’s Game of Life” and using ECMAScript 6, we were challenged to find elegant coding solutions for a predefined scope. Pair programming with changing partners and varying constraints was the perfect environment to get inspired and develop new ideas. Each coding session followed a small retrospective to sum up the results. <strong>The journey is the reward</strong> pretty much sums up this inspiring and fruitful day. Coding without delivering anything. Cool!</p>\n<p>The next two days focused on awesome talks, of course all related to JavaScript. Rather than following a conventionally structured programme, the audience at the <code>JS Unconf</code> is asked to propose talks and also votes for the talks. Here are some of my favourites:</p>\n<p><i class=\"fa fa-pencil\"></i> <a href=\"http://lowsky.github.io/dockerMeetupSlides/#1\">Optimize continuous delivery with docker</a></p>\n<p><i class=\"fa fa-pencil\"></i> <a href=\"https://speakerdeck.com/aemkei/creative-coding\">Creative coding</a></p>\n<p><i class=\"fa fa-pencil\"></i> <a href=\"https://github.com/bkimminich/juice-shop\">Hacking an intentionally insecure JavaScript Web Application</a></p>\n<p><i class=\"fa fa-pencil\"></i> Functional reactive programming with <a href=\"https://baconjs.github.io/\">Bacon.js</a></p>\n<p>The breaks between the presentations allowed plenty of time for questions and discussion as well as networking, even with international participants.</p>\n"},{"layout":"post","title":"Transform creative visions into reality @Geekettes Hamburg Hackathon","date":"2015-05-28T08:30:00.000Z","image":"blog-header/geekettes-2015.png","authors":["Andreas"],"_content":"\nLie-in on the long weekend?!\nNo way!\nLast weekend I was attending the 2nd Hamburg Hackathon organised by Hamburg Geekettes and App Camps. It was all about awesome - and not to forget - pitching (!) ideas, creativity, motivated people and fantastic final presentations in a great atmosphere and cool setting.\nCurious for more?\n\nThe event started with API presentations of well-known companies such as XING, Twitter, Braintree/PayPal, SoundCloud or Sony.\nEven though it was on short notice, I was given a time slot to also present the ePages REST API.\n\nWhen it came to pitching our ideas, I pulled out mine: build a simple ePages Android app using the Ionic framework and AngularJS.\nBut as there were so many pitches, there weren't enough supporters for mine.\nCould be worse!\nI was ready to hack!\nI joined the \"Runanas\" pitch, that matched my interest and I thought would be much fun developing. The goal was to build an app that uses the Sony LifeLog API to find a matching jogging partner.\n\n{% image blog/blog-geekettes-runanas-app.png %}\n\nWithin 24 hours (Honestly! Some team members survived without even a snatch of sleep) we worked with 8 team members to create the \"Runanas App\" using the Sony SmartWatch 3.\nOne part of the team concentrated on the backend part (realised with Django and SQLite), that connects to the Sony API as well as on the prototype development using Android Studio.\nThe other part of the team focused on the business case and the graphics.\nWe actually managed to create a running prototype!  Yay!\n\nWe established a real data exchange\n\n* between the \"Runanas\" app and the Sony API to our backend\n* from the app to our backend\n* from the app to the Sony SmartWatch 3.\n\n{% image blog/blog-geekettes-present-runanas-app.jpg %}\n\nWhen the presentations started, we had 2.5 minutes to present our results to the audience.\nWe were very excited!\nTo achieve our goal, it was all about producing a good mood in the audience, presenting the API that we've used and doing a short demo.\n\nAnd then....**Drum roll**... We impressed Sony with our solution and won the Sony SmartWatch 3!\n\n{% image blog/blog-geekettes-price.jpg %}\n\nIt has been an inspiring and cool weekend with many new ideas and impulses.\nOn my way home, I have not only lots of new experience in my luggage, but also good learnings I can pass on to my colleagues here at ePages.\nNever stop learning...\nWe are definitely ready for the next hackathon.\nStay tuned!\n","source":"_posts/2015-05-26-hamburg-hackathon.md","raw":"---\nlayout: post\ntitle: \"Transform creative visions into reality @Geekettes Hamburg Hackathon\"\ndate: \"2015-05-28 10:30:00\"\nimage: blog-header/geekettes-2015.png\ncategories: events\nauthors: [\"Andreas\"]\n---\n\nLie-in on the long weekend?!\nNo way!\nLast weekend I was attending the 2nd Hamburg Hackathon organised by Hamburg Geekettes and App Camps. It was all about awesome - and not to forget - pitching (!) ideas, creativity, motivated people and fantastic final presentations in a great atmosphere and cool setting.\nCurious for more?\n\nThe event started with API presentations of well-known companies such as XING, Twitter, Braintree/PayPal, SoundCloud or Sony.\nEven though it was on short notice, I was given a time slot to also present the ePages REST API.\n\nWhen it came to pitching our ideas, I pulled out mine: build a simple ePages Android app using the Ionic framework and AngularJS.\nBut as there were so many pitches, there weren't enough supporters for mine.\nCould be worse!\nI was ready to hack!\nI joined the \"Runanas\" pitch, that matched my interest and I thought would be much fun developing. The goal was to build an app that uses the Sony LifeLog API to find a matching jogging partner.\n\n{% image blog/blog-geekettes-runanas-app.png %}\n\nWithin 24 hours (Honestly! Some team members survived without even a snatch of sleep) we worked with 8 team members to create the \"Runanas App\" using the Sony SmartWatch 3.\nOne part of the team concentrated on the backend part (realised with Django and SQLite), that connects to the Sony API as well as on the prototype development using Android Studio.\nThe other part of the team focused on the business case and the graphics.\nWe actually managed to create a running prototype!  Yay!\n\nWe established a real data exchange\n\n* between the \"Runanas\" app and the Sony API to our backend\n* from the app to our backend\n* from the app to the Sony SmartWatch 3.\n\n{% image blog/blog-geekettes-present-runanas-app.jpg %}\n\nWhen the presentations started, we had 2.5 minutes to present our results to the audience.\nWe were very excited!\nTo achieve our goal, it was all about producing a good mood in the audience, presenting the API that we've used and doing a short demo.\n\nAnd then....**Drum roll**... We impressed Sony with our solution and won the Sony SmartWatch 3!\n\n{% image blog/blog-geekettes-price.jpg %}\n\nIt has been an inspiring and cool weekend with many new ideas and impulses.\nOn my way home, I have not only lots of new experience in my luggage, but also good learnings I can pass on to my colleagues here at ePages.\nNever stop learning...\nWe are definitely ready for the next hackathon.\nStay tuned!\n","slug":"2015-05-26-hamburg-hackathon","published":1,"updated":"2016-09-20T14:19:22.000Z","comments":1,"photos":[],"link":"","_id":"ciu6nuh7x0005hqyx7r6s5r5d","content":"<p>Lie-in on the long weekend?!<br>No way!<br>Last weekend I was attending the 2nd Hamburg Hackathon organised by Hamburg Geekettes and App Camps. It was all about awesome - and not to forget - pitching (!) ideas, creativity, motivated people and fantastic final presentations in a great atmosphere and cool setting.<br>Curious for more?</p>\n<p>The event started with API presentations of well-known companies such as XING, Twitter, Braintree/PayPal, SoundCloud or Sony.<br>Even though it was on short notice, I was given a time slot to also present the ePages REST API.</p>\n<p>When it came to pitching our ideas, I pulled out mine: build a simple ePages Android app using the Ionic framework and AngularJS.<br>But as there were so many pitches, there weren’t enough supporters for mine.<br>Could be worse!<br>I was ready to hack!<br>I joined the “Runanas” pitch, that matched my interest and I thought would be much fun developing. The goal was to build an app that uses the Sony LifeLog API to find a matching jogging partner.</p>\n<img class=\"blog/blog-geekettes-runanas-app.png\">\n<p>Within 24 hours (Honestly! Some team members survived without even a snatch of sleep) we worked with 8 team members to create the “Runanas App” using the Sony SmartWatch 3.<br>One part of the team concentrated on the backend part (realised with Django and SQLite), that connects to the Sony API as well as on the prototype development using Android Studio.<br>The other part of the team focused on the business case and the graphics.<br>We actually managed to create a running prototype!  Yay!</p>\n<p>We established a real data exchange</p>\n<ul>\n<li>between the “Runanas” app and the Sony API to our backend</li>\n<li>from the app to our backend</li>\n<li>from the app to the Sony SmartWatch 3.</li>\n</ul>\n<img class=\"blog/blog-geekettes-present-runanas-app.jpg\">\n<p>When the presentations started, we had 2.5 minutes to present our results to the audience.<br>We were very excited!<br>To achieve our goal, it was all about producing a good mood in the audience, presenting the API that we’ve used and doing a short demo.</p>\n<p>And then….<strong>Drum roll</strong>… We impressed Sony with our solution and won the Sony SmartWatch 3!</p>\n<img class=\"blog/blog-geekettes-price.jpg\">\n<p>It has been an inspiring and cool weekend with many new ideas and impulses.<br>On my way home, I have not only lots of new experience in my luggage, but also good learnings I can pass on to my colleagues here at ePages.<br>Never stop learning…<br>We are definitely ready for the next hackathon.<br>Stay tuned!</p>\n","excerpt":"","more":"<p>Lie-in on the long weekend?!<br>No way!<br>Last weekend I was attending the 2nd Hamburg Hackathon organised by Hamburg Geekettes and App Camps. It was all about awesome - and not to forget - pitching (!) ideas, creativity, motivated people and fantastic final presentations in a great atmosphere and cool setting.<br>Curious for more?</p>\n<p>The event started with API presentations of well-known companies such as XING, Twitter, Braintree/PayPal, SoundCloud or Sony.<br>Even though it was on short notice, I was given a time slot to also present the ePages REST API.</p>\n<p>When it came to pitching our ideas, I pulled out mine: build a simple ePages Android app using the Ionic framework and AngularJS.<br>But as there were so many pitches, there weren’t enough supporters for mine.<br>Could be worse!<br>I was ready to hack!<br>I joined the “Runanas” pitch, that matched my interest and I thought would be much fun developing. The goal was to build an app that uses the Sony LifeLog API to find a matching jogging partner.</p>\n<img class=\"blog/blog-geekettes-runanas-app.png\">\n<p>Within 24 hours (Honestly! Some team members survived without even a snatch of sleep) we worked with 8 team members to create the “Runanas App” using the Sony SmartWatch 3.<br>One part of the team concentrated on the backend part (realised with Django and SQLite), that connects to the Sony API as well as on the prototype development using Android Studio.<br>The other part of the team focused on the business case and the graphics.<br>We actually managed to create a running prototype!  Yay!</p>\n<p>We established a real data exchange</p>\n<ul>\n<li>between the “Runanas” app and the Sony API to our backend</li>\n<li>from the app to our backend</li>\n<li>from the app to the Sony SmartWatch 3.</li>\n</ul>\n<img class=\"blog/blog-geekettes-present-runanas-app.jpg\">\n<p>When the presentations started, we had 2.5 minutes to present our results to the audience.<br>We were very excited!<br>To achieve our goal, it was all about producing a good mood in the audience, presenting the API that we’ve used and doing a short demo.</p>\n<p>And then….<strong>Drum roll</strong>… We impressed Sony with our solution and won the Sony SmartWatch 3!</p>\n<img class=\"blog/blog-geekettes-price.jpg\">\n<p>It has been an inspiring and cool weekend with many new ideas and impulses.<br>On my way home, I have not only lots of new experience in my luggage, but also good learnings I can pass on to my colleagues here at ePages.<br>Never stop learning…<br>We are definitely ready for the next hackathon.<br>Stay tuned!</p>\n"},{"layout":"post","title":"RESTful API documentation @ePages","date":"2015-05-28T11:35:00.000Z","image":"blog-header/compass.jpg","authors":["Birgit"],"_content":"\nI was a real newbie in the field of software development, with a career background as a Technical Writer mainly in mechanical/electrical engineering and consumer goods businesses. I took this fresh challenge and find myself now right in the middle of an exciting path to a state-of-the-art RESTful API documentation. Interested in my story how ePages tackled this? Read on!\n\nDeveloping a REST API based on JSON to simply connect third party applications to the ePages software, this REST API also needed proper documentation. To realise this, I needed to work closely together with the developers and find a way to connect with their favourite working environment. And there was no way around [GitHub](https://github.com/). It was all about **Fetch**ing, **Pull**ing, **Commit**ting and making **Pull Requests** to familiarise myself with the GitHub workflow. To do so, [Source Tree](https://www.atlassian.com/software/sourcetree/overview) and [Sublime Text](http://www.sublimetext.com/) became part of my daily working environment.\n\nWe wanted to publish the API documentation online - no sooner said than done: one of our developers was very committed to support this project. He built a Jekyll-based static html generation tool, to create documentation from Markdown files.\n\nOne of the main requirements for our API documentation was to automatically import RAML files into the documentation tool, to easily bridge development and documentation and to avoid double work. To achieve this, he developed a Ruby-based open source library, the [raml_parser](https://github.com/ePages-de/raml_parser). The raml_parser reads RAML files and returns the respective information.\n\nMeanwhile, I made myself familiar with RAML (RESTful API Modeling Language), which is a useful tool to describe RESTful APIs in a structured and simple way.\nRAML allows to define simple patterns that help reduce repetitions in an API. Resources and methods can be displayed easily and filled with custom details. It also allows to include markdown-formatted descriptions or entire markdown documentation sections.\n\nI’ve never come across all this in my previous TechWriter life, but noticed very soon that our inhouse documentation tool compared with simply editing markdown and raml files enriches my knowledge and makes my work far easier.\n\nIt really is a challenge to cope with so much new stuff, but I can totally recommend this way of working to every TechWriter.\n","source":"_posts/2015-05-29-techwriter-experience-report.md","raw":"---\nlayout: post\ntitle: \"RESTful API documentation @ePages\"\ndate: \"2015-05-28 13:35:00\"\nimage: blog-header/compass.jpg\ncategories: api\nauthors: [\"Birgit\"]\n---\n\nI was a real newbie in the field of software development, with a career background as a Technical Writer mainly in mechanical/electrical engineering and consumer goods businesses. I took this fresh challenge and find myself now right in the middle of an exciting path to a state-of-the-art RESTful API documentation. Interested in my story how ePages tackled this? Read on!\n\nDeveloping a REST API based on JSON to simply connect third party applications to the ePages software, this REST API also needed proper documentation. To realise this, I needed to work closely together with the developers and find a way to connect with their favourite working environment. And there was no way around [GitHub](https://github.com/). It was all about **Fetch**ing, **Pull**ing, **Commit**ting and making **Pull Requests** to familiarise myself with the GitHub workflow. To do so, [Source Tree](https://www.atlassian.com/software/sourcetree/overview) and [Sublime Text](http://www.sublimetext.com/) became part of my daily working environment.\n\nWe wanted to publish the API documentation online - no sooner said than done: one of our developers was very committed to support this project. He built a Jekyll-based static html generation tool, to create documentation from Markdown files.\n\nOne of the main requirements for our API documentation was to automatically import RAML files into the documentation tool, to easily bridge development and documentation and to avoid double work. To achieve this, he developed a Ruby-based open source library, the [raml_parser](https://github.com/ePages-de/raml_parser). The raml_parser reads RAML files and returns the respective information.\n\nMeanwhile, I made myself familiar with RAML (RESTful API Modeling Language), which is a useful tool to describe RESTful APIs in a structured and simple way.\nRAML allows to define simple patterns that help reduce repetitions in an API. Resources and methods can be displayed easily and filled with custom details. It also allows to include markdown-formatted descriptions or entire markdown documentation sections.\n\nI’ve never come across all this in my previous TechWriter life, but noticed very soon that our inhouse documentation tool compared with simply editing markdown and raml files enriches my knowledge and makes my work far easier.\n\nIt really is a challenge to cope with so much new stuff, but I can totally recommend this way of working to every TechWriter.\n","slug":"2015-05-29-techwriter-experience-report","published":1,"updated":"2016-09-20T14:19:22.000Z","comments":1,"photos":[],"link":"","_id":"ciu6nuh7z0007hqyxtjv269xl","content":"<p>I was a real newbie in the field of software development, with a career background as a Technical Writer mainly in mechanical/electrical engineering and consumer goods businesses. I took this fresh challenge and find myself now right in the middle of an exciting path to a state-of-the-art RESTful API documentation. Interested in my story how ePages tackled this? Read on!</p>\n<p>Developing a REST API based on JSON to simply connect third party applications to the ePages software, this REST API also needed proper documentation. To realise this, I needed to work closely together with the developers and find a way to connect with their favourite working environment. And there was no way around <a href=\"https://github.com/\" target=\"_blank\" rel=\"external\">GitHub</a>. It was all about <strong>Fetch</strong>ing, <strong>Pull</strong>ing, <strong>Commit</strong>ting and making <strong>Pull Requests</strong> to familiarise myself with the GitHub workflow. To do so, <a href=\"https://www.atlassian.com/software/sourcetree/overview\" target=\"_blank\" rel=\"external\">Source Tree</a> and <a href=\"http://www.sublimetext.com/\" target=\"_blank\" rel=\"external\">Sublime Text</a> became part of my daily working environment.</p>\n<p>We wanted to publish the API documentation online - no sooner said than done: one of our developers was very committed to support this project. He built a Jekyll-based static html generation tool, to create documentation from Markdown files.</p>\n<p>One of the main requirements for our API documentation was to automatically import RAML files into the documentation tool, to easily bridge development and documentation and to avoid double work. To achieve this, he developed a Ruby-based open source library, the <a href=\"https://github.com/ePages-de/raml_parser\" target=\"_blank\" rel=\"external\">raml_parser</a>. The raml_parser reads RAML files and returns the respective information.</p>\n<p>Meanwhile, I made myself familiar with RAML (RESTful API Modeling Language), which is a useful tool to describe RESTful APIs in a structured and simple way.<br>RAML allows to define simple patterns that help reduce repetitions in an API. Resources and methods can be displayed easily and filled with custom details. It also allows to include markdown-formatted descriptions or entire markdown documentation sections.</p>\n<p>I’ve never come across all this in my previous TechWriter life, but noticed very soon that our inhouse documentation tool compared with simply editing markdown and raml files enriches my knowledge and makes my work far easier.</p>\n<p>It really is a challenge to cope with so much new stuff, but I can totally recommend this way of working to every TechWriter.</p>\n","excerpt":"","more":"<p>I was a real newbie in the field of software development, with a career background as a Technical Writer mainly in mechanical/electrical engineering and consumer goods businesses. I took this fresh challenge and find myself now right in the middle of an exciting path to a state-of-the-art RESTful API documentation. Interested in my story how ePages tackled this? Read on!</p>\n<p>Developing a REST API based on JSON to simply connect third party applications to the ePages software, this REST API also needed proper documentation. To realise this, I needed to work closely together with the developers and find a way to connect with their favourite working environment. And there was no way around <a href=\"https://github.com/\">GitHub</a>. It was all about <strong>Fetch</strong>ing, <strong>Pull</strong>ing, <strong>Commit</strong>ting and making <strong>Pull Requests</strong> to familiarise myself with the GitHub workflow. To do so, <a href=\"https://www.atlassian.com/software/sourcetree/overview\">Source Tree</a> and <a href=\"http://www.sublimetext.com/\">Sublime Text</a> became part of my daily working environment.</p>\n<p>We wanted to publish the API documentation online - no sooner said than done: one of our developers was very committed to support this project. He built a Jekyll-based static html generation tool, to create documentation from Markdown files.</p>\n<p>One of the main requirements for our API documentation was to automatically import RAML files into the documentation tool, to easily bridge development and documentation and to avoid double work. To achieve this, he developed a Ruby-based open source library, the <a href=\"https://github.com/ePages-de/raml_parser\">raml_parser</a>. The raml_parser reads RAML files and returns the respective information.</p>\n<p>Meanwhile, I made myself familiar with RAML (RESTful API Modeling Language), which is a useful tool to describe RESTful APIs in a structured and simple way.<br>RAML allows to define simple patterns that help reduce repetitions in an API. Resources and methods can be displayed easily and filled with custom details. It also allows to include markdown-formatted descriptions or entire markdown documentation sections.</p>\n<p>I’ve never come across all this in my previous TechWriter life, but noticed very soon that our inhouse documentation tool compared with simply editing markdown and raml files enriches my knowledge and makes my work far easier.</p>\n<p>It really is a challenge to cope with so much new stuff, but I can totally recommend this way of working to every TechWriter.</p>\n"},{"layout":"post","title":"ePages scrum team goes offsite","date":"2015-06-04T08:49:00.000Z","authors":["Fouad-Steffen"],"_content":"\nWorking hard and embracing the nature? How does that fit together? One of our ePages scrum teams organised an offsite event and convened in a lovely castle to focus on knowledge transfer. What did they do? Read on!\n\nWe resided in a lovely place called \"Die Burg Schöna\" right in the last corner of Saxon Switzerland, Germany to come together some hours away from the office to approach a tight agenda of topics in our team.\nSurrounded by nature...\n\n{% image blog/blog-offsite-landscape.jpg %}\n\n...we had to utilise and build upon our team work on more than one occasion, in order to overcome some obstacles, steep mountains as well as find some hidden geo caches. This pulled us together as a unit even more than previously.\n\n{% image blog/blog-offsite-work.jpg %}\n\nWe pulled back the curtains and went deep into several technical topics, in order to give all team members an in-depth understanding concerning all development areas.\n\nIn order to mix up the day of mind-boggling workshops, we went hiking and filled our lungs with oxygen. This gave our brains a breather for a while and allowed us to hone in on our teamwork.\n\n{% image blog/blog-offsite-hiking.jpg %}\n\nWe also prepared dinner together and celebrated a very healthy living with lots of salad (let's not talk about all the sweets that were consumed nor about BBQ).\n\nTo sum it up: these offsite days were fun, productive, effective and brought the team together even more!\n","source":"_posts/2015-06-04-team-offsite.md","raw":"---\nlayout: post\ntitle: \"ePages scrum team goes offsite\"\ndate: \"2015-06-04 10:49:00\"\ncategories: events\nauthors: [\"Fouad-Steffen\"]\n---\n\nWorking hard and embracing the nature? How does that fit together? One of our ePages scrum teams organised an offsite event and convened in a lovely castle to focus on knowledge transfer. What did they do? Read on!\n\nWe resided in a lovely place called \"Die Burg Schöna\" right in the last corner of Saxon Switzerland, Germany to come together some hours away from the office to approach a tight agenda of topics in our team.\nSurrounded by nature...\n\n{% image blog/blog-offsite-landscape.jpg %}\n\n...we had to utilise and build upon our team work on more than one occasion, in order to overcome some obstacles, steep mountains as well as find some hidden geo caches. This pulled us together as a unit even more than previously.\n\n{% image blog/blog-offsite-work.jpg %}\n\nWe pulled back the curtains and went deep into several technical topics, in order to give all team members an in-depth understanding concerning all development areas.\n\nIn order to mix up the day of mind-boggling workshops, we went hiking and filled our lungs with oxygen. This gave our brains a breather for a while and allowed us to hone in on our teamwork.\n\n{% image blog/blog-offsite-hiking.jpg %}\n\nWe also prepared dinner together and celebrated a very healthy living with lots of salad (let's not talk about all the sweets that were consumed nor about BBQ).\n\nTo sum it up: these offsite days were fun, productive, effective and brought the team together even more!\n","slug":"2015-06-04-team-offsite","published":1,"updated":"2016-09-20T14:19:22.000Z","comments":1,"photos":[],"link":"","_id":"ciu6nuh810009hqyxzxk3d8e6","content":"<p>Working hard and embracing the nature? How does that fit together? One of our ePages scrum teams organised an offsite event and convened in a lovely castle to focus on knowledge transfer. What did they do? Read on!</p>\n<p>We resided in a lovely place called “Die Burg Schöna” right in the last corner of Saxon Switzerland, Germany to come together some hours away from the office to approach a tight agenda of topics in our team.<br>Surrounded by nature…</p>\n<img class=\"blog/blog-offsite-landscape.jpg\">\n<p>…we had to utilise and build upon our team work on more than one occasion, in order to overcome some obstacles, steep mountains as well as find some hidden geo caches. This pulled us together as a unit even more than previously.</p>\n<img class=\"blog/blog-offsite-work.jpg\">\n<p>We pulled back the curtains and went deep into several technical topics, in order to give all team members an in-depth understanding concerning all development areas.</p>\n<p>In order to mix up the day of mind-boggling workshops, we went hiking and filled our lungs with oxygen. This gave our brains a breather for a while and allowed us to hone in on our teamwork.</p>\n<img class=\"blog/blog-offsite-hiking.jpg\">\n<p>We also prepared dinner together and celebrated a very healthy living with lots of salad (let’s not talk about all the sweets that were consumed nor about BBQ).</p>\n<p>To sum it up: these offsite days were fun, productive, effective and brought the team together even more!</p>\n","excerpt":"","more":"<p>Working hard and embracing the nature? How does that fit together? One of our ePages scrum teams organised an offsite event and convened in a lovely castle to focus on knowledge transfer. What did they do? Read on!</p>\n<p>We resided in a lovely place called “Die Burg Schöna” right in the last corner of Saxon Switzerland, Germany to come together some hours away from the office to approach a tight agenda of topics in our team.<br>Surrounded by nature…</p>\n<img class=\"blog/blog-offsite-landscape.jpg\">\n<p>…we had to utilise and build upon our team work on more than one occasion, in order to overcome some obstacles, steep mountains as well as find some hidden geo caches. This pulled us together as a unit even more than previously.</p>\n<img class=\"blog/blog-offsite-work.jpg\">\n<p>We pulled back the curtains and went deep into several technical topics, in order to give all team members an in-depth understanding concerning all development areas.</p>\n<p>In order to mix up the day of mind-boggling workshops, we went hiking and filled our lungs with oxygen. This gave our brains a breather for a while and allowed us to hone in on our teamwork.</p>\n<img class=\"blog/blog-offsite-hiking.jpg\">\n<p>We also prepared dinner together and celebrated a very healthy living with lots of salad (let’s not talk about all the sweets that were consumed nor about BBQ).</p>\n<p>To sum it up: these offsite days were fun, productive, effective and brought the team together even more!</p>\n"},{"layout":"post","title":"Guest post: A Shippo developer gives an insight on the technical integration into ePages","date":"2015-06-21T21:59:25.000Z","image":"blog-header/puzzle.jpg","authors":["Shippo"],"_content":"\nShippo is excited to support ePages merchants thanks to a new partnership.\nePages helps businesses set up their online shop via channel partners and offers them tools like Shippo to simplify the e-commerce experience.\nThis collaboration benefits the ePages channel partners because they need not build carrier shipping integrations themselves, trusting in companies like Shippo to provide the technology, service, and expertise in complicated markets like shipping.\n\nBy integrating Shippo with ePages stores, merchants will save time and money on their shipping.\nThey use Shippo’s simple, frictionless dashboard to create shipping labels in a few steps across 14 different shipping carriers.\nMerchants track packages, send notification emails, print packing slips, and much more.\n\nHere is insight into the technical aspect of this integration from one of our developers:\n\nWith this ePages integration, the need to refactor our abstraction layer for shop integrations became necessary.\nWe previously integrated with third-party e-commerce platforms using an interface that worked flawlessly.\nHowever, the previous abstraction was susceptible to schema changes in the database, which, on occasion, meant a database migration.\nWe decided to design a more flexible layer to streamline our integrations and, at the same time, create an interface that is also independent of any common schema or data migrations.\n\nThe safest approach for this project was to *test - refactor - repeat*.\nThis process was tedious and extremely slow, but it guaranteed that existing shop integrations remained fully functional.\nDigging into the existing design revealed some problems, which could have been avoided had we thought more deeply about the design requirements.\nFortunately, we addressed this before our technical debt started to pile up.\n\nThe biggest challenge during this process was to not repeat common functionality of the design, such as order update, validation, and serialisation.\nThis meant that changes to common methods would not require updating more than one piece of code, which translates to less maintenance and fewer bugs.\nIt also made obscure dependencies easier to spot and the code easier to debug.\n\nThe advantage from this change is tremendous: **we can integrate with third-party platforms much more rapidly.**\nThe actual ePages integration took roughly one week of development time, while the large majority was spent on refactoring the existing codebase.\n\nRefactoring can usually be avoided, if all of the design requirements are taken into consideration.\nIf you expect some logic will become more complex, then it’s better to address it early on and not wait until the change is needed.\nBy then, a minor change to the codebase could cause it to break, or worse, it could introduce a bug to production.\n\nThis type of project is not usually influenced by customer feedback, however, thanks to all the real-time constructive criticism and suggestions, we were able to pinpoint and resolve some user experience difficulties during the integration process.\nThis included improving our order update process and preventing duplicate items/orders due to user error.\nWe’re now excited to bring Shippo to the ePages community! To learn more about Shippo, visit [goshippo.com](https://goshippo.com/).\n","source":"_posts/2015-06-21-guest-post-shippo-integation.md","raw":"---\nlayout: post\ntitle: \"Guest post: A Shippo developer gives an insight on the technical integration into ePages\"\ndate: \"2015-06-21 23:59:25\"\nimage: blog-header/puzzle.jpg\ncategories: tech-stories\nauthors: [\"Shippo\"]\n---\n\nShippo is excited to support ePages merchants thanks to a new partnership.\nePages helps businesses set up their online shop via channel partners and offers them tools like Shippo to simplify the e-commerce experience.\nThis collaboration benefits the ePages channel partners because they need not build carrier shipping integrations themselves, trusting in companies like Shippo to provide the technology, service, and expertise in complicated markets like shipping.\n\nBy integrating Shippo with ePages stores, merchants will save time and money on their shipping.\nThey use Shippo’s simple, frictionless dashboard to create shipping labels in a few steps across 14 different shipping carriers.\nMerchants track packages, send notification emails, print packing slips, and much more.\n\nHere is insight into the technical aspect of this integration from one of our developers:\n\nWith this ePages integration, the need to refactor our abstraction layer for shop integrations became necessary.\nWe previously integrated with third-party e-commerce platforms using an interface that worked flawlessly.\nHowever, the previous abstraction was susceptible to schema changes in the database, which, on occasion, meant a database migration.\nWe decided to design a more flexible layer to streamline our integrations and, at the same time, create an interface that is also independent of any common schema or data migrations.\n\nThe safest approach for this project was to *test - refactor - repeat*.\nThis process was tedious and extremely slow, but it guaranteed that existing shop integrations remained fully functional.\nDigging into the existing design revealed some problems, which could have been avoided had we thought more deeply about the design requirements.\nFortunately, we addressed this before our technical debt started to pile up.\n\nThe biggest challenge during this process was to not repeat common functionality of the design, such as order update, validation, and serialisation.\nThis meant that changes to common methods would not require updating more than one piece of code, which translates to less maintenance and fewer bugs.\nIt also made obscure dependencies easier to spot and the code easier to debug.\n\nThe advantage from this change is tremendous: **we can integrate with third-party platforms much more rapidly.**\nThe actual ePages integration took roughly one week of development time, while the large majority was spent on refactoring the existing codebase.\n\nRefactoring can usually be avoided, if all of the design requirements are taken into consideration.\nIf you expect some logic will become more complex, then it’s better to address it early on and not wait until the change is needed.\nBy then, a minor change to the codebase could cause it to break, or worse, it could introduce a bug to production.\n\nThis type of project is not usually influenced by customer feedback, however, thanks to all the real-time constructive criticism and suggestions, we were able to pinpoint and resolve some user experience difficulties during the integration process.\nThis included improving our order update process and preventing duplicate items/orders due to user error.\nWe’re now excited to bring Shippo to the ePages community! To learn more about Shippo, visit [goshippo.com](https://goshippo.com/).\n","slug":"2015-06-21-guest-post-shippo-integation","published":1,"updated":"2016-09-20T14:19:22.000Z","comments":1,"photos":[],"link":"","_id":"ciu6nuh82000chqyx4sxqlplz","content":"<p>Shippo is excited to support ePages merchants thanks to a new partnership.<br>ePages helps businesses set up their online shop via channel partners and offers them tools like Shippo to simplify the e-commerce experience.<br>This collaboration benefits the ePages channel partners because they need not build carrier shipping integrations themselves, trusting in companies like Shippo to provide the technology, service, and expertise in complicated markets like shipping.</p>\n<p>By integrating Shippo with ePages stores, merchants will save time and money on their shipping.<br>They use Shippo’s simple, frictionless dashboard to create shipping labels in a few steps across 14 different shipping carriers.<br>Merchants track packages, send notification emails, print packing slips, and much more.</p>\n<p>Here is insight into the technical aspect of this integration from one of our developers:</p>\n<p>With this ePages integration, the need to refactor our abstraction layer for shop integrations became necessary.<br>We previously integrated with third-party e-commerce platforms using an interface that worked flawlessly.<br>However, the previous abstraction was susceptible to schema changes in the database, which, on occasion, meant a database migration.<br>We decided to design a more flexible layer to streamline our integrations and, at the same time, create an interface that is also independent of any common schema or data migrations.</p>\n<p>The safest approach for this project was to <em>test - refactor - repeat</em>.<br>This process was tedious and extremely slow, but it guaranteed that existing shop integrations remained fully functional.<br>Digging into the existing design revealed some problems, which could have been avoided had we thought more deeply about the design requirements.<br>Fortunately, we addressed this before our technical debt started to pile up.</p>\n<p>The biggest challenge during this process was to not repeat common functionality of the design, such as order update, validation, and serialisation.<br>This meant that changes to common methods would not require updating more than one piece of code, which translates to less maintenance and fewer bugs.<br>It also made obscure dependencies easier to spot and the code easier to debug.</p>\n<p>The advantage from this change is tremendous: <strong>we can integrate with third-party platforms much more rapidly.</strong><br>The actual ePages integration took roughly one week of development time, while the large majority was spent on refactoring the existing codebase.</p>\n<p>Refactoring can usually be avoided, if all of the design requirements are taken into consideration.<br>If you expect some logic will become more complex, then it’s better to address it early on and not wait until the change is needed.<br>By then, a minor change to the codebase could cause it to break, or worse, it could introduce a bug to production.</p>\n<p>This type of project is not usually influenced by customer feedback, however, thanks to all the real-time constructive criticism and suggestions, we were able to pinpoint and resolve some user experience difficulties during the integration process.<br>This included improving our order update process and preventing duplicate items/orders due to user error.<br>We’re now excited to bring Shippo to the ePages community! To learn more about Shippo, visit <a href=\"https://goshippo.com/\" target=\"_blank\" rel=\"external\">goshippo.com</a>.</p>\n","excerpt":"","more":"<p>Shippo is excited to support ePages merchants thanks to a new partnership.<br>ePages helps businesses set up their online shop via channel partners and offers them tools like Shippo to simplify the e-commerce experience.<br>This collaboration benefits the ePages channel partners because they need not build carrier shipping integrations themselves, trusting in companies like Shippo to provide the technology, service, and expertise in complicated markets like shipping.</p>\n<p>By integrating Shippo with ePages stores, merchants will save time and money on their shipping.<br>They use Shippo’s simple, frictionless dashboard to create shipping labels in a few steps across 14 different shipping carriers.<br>Merchants track packages, send notification emails, print packing slips, and much more.</p>\n<p>Here is insight into the technical aspect of this integration from one of our developers:</p>\n<p>With this ePages integration, the need to refactor our abstraction layer for shop integrations became necessary.<br>We previously integrated with third-party e-commerce platforms using an interface that worked flawlessly.<br>However, the previous abstraction was susceptible to schema changes in the database, which, on occasion, meant a database migration.<br>We decided to design a more flexible layer to streamline our integrations and, at the same time, create an interface that is also independent of any common schema or data migrations.</p>\n<p>The safest approach for this project was to <em>test - refactor - repeat</em>.<br>This process was tedious and extremely slow, but it guaranteed that existing shop integrations remained fully functional.<br>Digging into the existing design revealed some problems, which could have been avoided had we thought more deeply about the design requirements.<br>Fortunately, we addressed this before our technical debt started to pile up.</p>\n<p>The biggest challenge during this process was to not repeat common functionality of the design, such as order update, validation, and serialisation.<br>This meant that changes to common methods would not require updating more than one piece of code, which translates to less maintenance and fewer bugs.<br>It also made obscure dependencies easier to spot and the code easier to debug.</p>\n<p>The advantage from this change is tremendous: <strong>we can integrate with third-party platforms much more rapidly.</strong><br>The actual ePages integration took roughly one week of development time, while the large majority was spent on refactoring the existing codebase.</p>\n<p>Refactoring can usually be avoided, if all of the design requirements are taken into consideration.<br>If you expect some logic will become more complex, then it’s better to address it early on and not wait until the change is needed.<br>By then, a minor change to the codebase could cause it to break, or worse, it could introduce a bug to production.</p>\n<p>This type of project is not usually influenced by customer feedback, however, thanks to all the real-time constructive criticism and suggestions, we were able to pinpoint and resolve some user experience difficulties during the integration process.<br>This included improving our order update process and preventing duplicate items/orders due to user error.<br>We’re now excited to bring Shippo to the ePages community! To learn more about Shippo, visit <a href=\"https://goshippo.com/\">goshippo.com</a>.</p>\n"},{"layout":"post","title":"Infrastructure as code: automating Jenkins","date":"2015-06-25T07:00:00.000Z","authors":["Jens","Dirk"],"_content":"\nHere at ePages we heavily rely on [Continuous Integration (CI)](http://www.martinfowler.com/articles/continuousIntegration.html) to make sure our code is always in a good shape.\n[Jenkins](https://jenkins-ci.org/) is the software we use as our CI tool.\nA mixed language stack mainly composed of `Java`, `JavaScript` and `Perl` spread over multiple teams brings in different build processes and toolings needed to produce the artifacts our software is composed of, e.g. `gradle`, `grunt` and `make`.\nWe do not run all build jobs on a single Jenkins instance, but already spread out different jobs to dedicated Jenkins servers.\nNevertheless some teams still share their build infrastructure, thus lacking independence e.g. when it comes to introducing new Jenkins plugins or other tools needed for their build process.\n\n{% image blog/blog-jenkins-polyglot.png %}\n\n## Jenkins configuration\n\nJenkins makes it very easy to introduce new functionality by installing one of the [many available plugins](https://wiki.jenkins-ci.org/display/JENKINS/Plugins).\nUnfortunately not every plugin turns out to work as expected or in the worst case can potentially bring down the whole Jenkins instance.\nTo evaluate unknown plugins by installing them into your production CI infrastructure bears problems, since they often leave unwanted traces behind, even after uninstallation.\nEven making changes to a job configuration without adding any new plugins can lead to broken build jobs, negatively affecting the productivity of whole teams.\n\n### The solution\n\nWe were looking for ways to make it safe and easy to improve our build infrastructure.\nUsing version control like [GitHub](https://github.com/) for all of our source code, it was natural to treat our infrastructure the same way and be able to roll back to a previous version without any hassle.\nVersioning whole images of Jenkins virtual servers didn't seem feasible and plugins like [JobConfigHistory](https://wiki.jenkins-ci.org/display/JENKINS/JobConfigHistory+Plugin) did not cover managing plugin versions as well.\n\n### Server provisioning using Ansible and Vagrant\n\nWe started by automating the installation of Jenkins, including all required plugins.\nThe idea is to set up a Jenkins server from scratch by running just a single command, while still being able to use the same facilities to update the installation, e.g. with new plugins, using the same technology.\nTo achieve this, we decided to use [Ansible](http://www.ansible.com/home), mainly due to existing know-how.\n\nOnce the basic installation of Jenkins and its prerequisites is done, the interesting part begins: installing and configuring plugins.\nThe installation of additional plugins is done by utilising the [Jenkins Command Line Interpreter (CLI)](https://wiki.jenkins-ci.org/display/JENKINS/Jenkins+CLI).\nThis allows us to provide plugin names and explicit versions to be installed.\nThe tricky part is getting the global configuration of Jenkins right.\nThe pragmatic solution we chose was to create the `config.xml` locally (but templated) and copy it over to Jenkins using the according Ansible task.\n\nWith the toolset described so far, the basic setup can be easily recreated any time.\nAnd since this is so easy now, we usually test our setup scripts by installing them to local [Vagrant](https://www.vagrantup.com/) machines.\nEspecially for the global Jenkins configuration this is an essential step, which is even easier and faster due to Ansible's smart way of tracking installation state.\nJust rerun the Ansible playbook and changes in the configuration are automatically applied; then you can be sure, that they are based on your version-managed infrastructure code!\n\n### Job provisioning using Job DSL\n\nUsually, Jenkins jobs are created manually using the web UI and are stored in XML configuration files.\nThese files are quite verbose, and are not nice to edit directly.\nIf you want to create a new job based on an existing one, you should do this in an automated fashion.\nHere a very nice plugin comes to help: the [Job DSL Plugin](https://wiki.jenkins-ci.org/display/JENKINS/Job+DSL+Plugin) allows the creation of jobs from simplified DSL ([Domain Specific Language](http://martinfowler.com/books/dsl.html)) descriptions, which are much nicer to read and write than the XML configuration files.\nAll you need to create your jobs is a single so-called _seed_ job, which (in our case) pulls the job definitions as Groovy DSL scripts from Git to generate the desired jobs.\n\nThe _seed_ job can be run whenever there are changes in the DSL scripts for the jobs, and updates the configuration of changed jobs accordingly.\nExisting build metadata, like next build number files, is not touched by such an update.\n\n### Handling of job metadata\n\nManaging the job metadata, e.g. the `nextBuildNumber` file, the workspace and the results of the last builds, is still a tricky topic.\nAs these files are created or updated by the actual build executions, they are not easily recreated.\nTherefore, we stick to doing some plain old backup task to save the relevant parts.\nFor us, these are the `nextBuildNumber` files and the `builds` directory.\nAll other job metadata is either not really important, like symbolic links to the last successful build directory, or will automatically be recreated with the next build, e.g. the workspace.\n\n### Running Jenkins slaves on developer machines\n\nBeing able to run lots of build jobs in parallel is key to receiving fast feedback from our CI infrastructure.\nWith modern desktops and laptops there is enough idle CPU and RAM resources available in our offices most of the time, which we want to use for this purpose by running [Jenkins slaves](https://wiki.jenkins-ci.org/display/JENKINS/Step+by+step+guide+to+set+up+master+and+slave+machines).\nIn order not to interfere with the operating system and tools installation on each developer's machine, we create virtual images (or maybe even [Docker](https://www.docker.com/) containers in the future) containing all the components needed for a Jenkins slave to execute build jobs.\nUsing the [Jenkins Swarm Plugin](https://wiki.jenkins-ci.org/display/JENKINS/Swarm+Plugin) each slave registers itself at its central master, which delegates build job execution to idle slave nodes.\nEach build job is configured to carry one or more _labels_, which control that they get only executed on slaves which can support these kind of jobs.\nThis way we can separate e.g. [Selenium](http://www.seleniumhq.org/) integration tests from unit tests.\n\n## Outlook\n\nWe want to offer each team an easy way to setup and manage their own dedicated CI infrastructure and tweak it to their specific needs.\nBy spreading the load of executing build jobs to various developer's machine we can further shorten the time a team needs to wait for the [GitHub pull request builder plugin](https://wiki.jenkins-ci.org/display/JENKINS/GitHub+pull+request+builder+plugin) to check if a pull request is safe to merge into the main development line, thus preventing stale pull requests and merge hell later.\nWe could also offload more slaves to e.g. [Amazon EC2](https://aws.amazon.com/ec2/), if we really need the compute power.\nThe process of moving our custom Jenkins installations and job configurations to this new CI infrastructure has just started and we are eager to learn how this will turn out in the future.\n","source":"_posts/2015-06-25-infrastructure-as-code.md","raw":"---\nlayout: post\ntitle: \"Infrastructure as code: automating Jenkins\"\ndate: \"2015-06-25 09:00:00\"\ncategories: tech-stories\nauthors: [\"Jens\", \"Dirk\"]\n---\n\nHere at ePages we heavily rely on [Continuous Integration (CI)](http://www.martinfowler.com/articles/continuousIntegration.html) to make sure our code is always in a good shape.\n[Jenkins](https://jenkins-ci.org/) is the software we use as our CI tool.\nA mixed language stack mainly composed of `Java`, `JavaScript` and `Perl` spread over multiple teams brings in different build processes and toolings needed to produce the artifacts our software is composed of, e.g. `gradle`, `grunt` and `make`.\nWe do not run all build jobs on a single Jenkins instance, but already spread out different jobs to dedicated Jenkins servers.\nNevertheless some teams still share their build infrastructure, thus lacking independence e.g. when it comes to introducing new Jenkins plugins or other tools needed for their build process.\n\n{% image blog/blog-jenkins-polyglot.png %}\n\n## Jenkins configuration\n\nJenkins makes it very easy to introduce new functionality by installing one of the [many available plugins](https://wiki.jenkins-ci.org/display/JENKINS/Plugins).\nUnfortunately not every plugin turns out to work as expected or in the worst case can potentially bring down the whole Jenkins instance.\nTo evaluate unknown plugins by installing them into your production CI infrastructure bears problems, since they often leave unwanted traces behind, even after uninstallation.\nEven making changes to a job configuration without adding any new plugins can lead to broken build jobs, negatively affecting the productivity of whole teams.\n\n### The solution\n\nWe were looking for ways to make it safe and easy to improve our build infrastructure.\nUsing version control like [GitHub](https://github.com/) for all of our source code, it was natural to treat our infrastructure the same way and be able to roll back to a previous version without any hassle.\nVersioning whole images of Jenkins virtual servers didn't seem feasible and plugins like [JobConfigHistory](https://wiki.jenkins-ci.org/display/JENKINS/JobConfigHistory+Plugin) did not cover managing plugin versions as well.\n\n### Server provisioning using Ansible and Vagrant\n\nWe started by automating the installation of Jenkins, including all required plugins.\nThe idea is to set up a Jenkins server from scratch by running just a single command, while still being able to use the same facilities to update the installation, e.g. with new plugins, using the same technology.\nTo achieve this, we decided to use [Ansible](http://www.ansible.com/home), mainly due to existing know-how.\n\nOnce the basic installation of Jenkins and its prerequisites is done, the interesting part begins: installing and configuring plugins.\nThe installation of additional plugins is done by utilising the [Jenkins Command Line Interpreter (CLI)](https://wiki.jenkins-ci.org/display/JENKINS/Jenkins+CLI).\nThis allows us to provide plugin names and explicit versions to be installed.\nThe tricky part is getting the global configuration of Jenkins right.\nThe pragmatic solution we chose was to create the `config.xml` locally (but templated) and copy it over to Jenkins using the according Ansible task.\n\nWith the toolset described so far, the basic setup can be easily recreated any time.\nAnd since this is so easy now, we usually test our setup scripts by installing them to local [Vagrant](https://www.vagrantup.com/) machines.\nEspecially for the global Jenkins configuration this is an essential step, which is even easier and faster due to Ansible's smart way of tracking installation state.\nJust rerun the Ansible playbook and changes in the configuration are automatically applied; then you can be sure, that they are based on your version-managed infrastructure code!\n\n### Job provisioning using Job DSL\n\nUsually, Jenkins jobs are created manually using the web UI and are stored in XML configuration files.\nThese files are quite verbose, and are not nice to edit directly.\nIf you want to create a new job based on an existing one, you should do this in an automated fashion.\nHere a very nice plugin comes to help: the [Job DSL Plugin](https://wiki.jenkins-ci.org/display/JENKINS/Job+DSL+Plugin) allows the creation of jobs from simplified DSL ([Domain Specific Language](http://martinfowler.com/books/dsl.html)) descriptions, which are much nicer to read and write than the XML configuration files.\nAll you need to create your jobs is a single so-called _seed_ job, which (in our case) pulls the job definitions as Groovy DSL scripts from Git to generate the desired jobs.\n\nThe _seed_ job can be run whenever there are changes in the DSL scripts for the jobs, and updates the configuration of changed jobs accordingly.\nExisting build metadata, like next build number files, is not touched by such an update.\n\n### Handling of job metadata\n\nManaging the job metadata, e.g. the `nextBuildNumber` file, the workspace and the results of the last builds, is still a tricky topic.\nAs these files are created or updated by the actual build executions, they are not easily recreated.\nTherefore, we stick to doing some plain old backup task to save the relevant parts.\nFor us, these are the `nextBuildNumber` files and the `builds` directory.\nAll other job metadata is either not really important, like symbolic links to the last successful build directory, or will automatically be recreated with the next build, e.g. the workspace.\n\n### Running Jenkins slaves on developer machines\n\nBeing able to run lots of build jobs in parallel is key to receiving fast feedback from our CI infrastructure.\nWith modern desktops and laptops there is enough idle CPU and RAM resources available in our offices most of the time, which we want to use for this purpose by running [Jenkins slaves](https://wiki.jenkins-ci.org/display/JENKINS/Step+by+step+guide+to+set+up+master+and+slave+machines).\nIn order not to interfere with the operating system and tools installation on each developer's machine, we create virtual images (or maybe even [Docker](https://www.docker.com/) containers in the future) containing all the components needed for a Jenkins slave to execute build jobs.\nUsing the [Jenkins Swarm Plugin](https://wiki.jenkins-ci.org/display/JENKINS/Swarm+Plugin) each slave registers itself at its central master, which delegates build job execution to idle slave nodes.\nEach build job is configured to carry one or more _labels_, which control that they get only executed on slaves which can support these kind of jobs.\nThis way we can separate e.g. [Selenium](http://www.seleniumhq.org/) integration tests from unit tests.\n\n## Outlook\n\nWe want to offer each team an easy way to setup and manage their own dedicated CI infrastructure and tweak it to their specific needs.\nBy spreading the load of executing build jobs to various developer's machine we can further shorten the time a team needs to wait for the [GitHub pull request builder plugin](https://wiki.jenkins-ci.org/display/JENKINS/GitHub+pull+request+builder+plugin) to check if a pull request is safe to merge into the main development line, thus preventing stale pull requests and merge hell later.\nWe could also offload more slaves to e.g. [Amazon EC2](https://aws.amazon.com/ec2/), if we really need the compute power.\nThe process of moving our custom Jenkins installations and job configurations to this new CI infrastructure has just started and we are eager to learn how this will turn out in the future.\n","slug":"2015-06-25-infrastructure-as-code","published":1,"updated":"2016-09-20T14:19:22.000Z","comments":1,"photos":[],"link":"","_id":"ciu6nuh84000ehqyxmldl8y4y","content":"<p>Here at ePages we heavily rely on <a href=\"http://www.martinfowler.com/articles/continuousIntegration.html\" target=\"_blank\" rel=\"external\">Continuous Integration (CI)</a> to make sure our code is always in a good shape.<br><a href=\"https://jenkins-ci.org/\" target=\"_blank\" rel=\"external\">Jenkins</a> is the software we use as our CI tool.<br>A mixed language stack mainly composed of <code>Java</code>, <code>JavaScript</code> and <code>Perl</code> spread over multiple teams brings in different build processes and toolings needed to produce the artifacts our software is composed of, e.g. <code>gradle</code>, <code>grunt</code> and <code>make</code>.<br>We do not run all build jobs on a single Jenkins instance, but already spread out different jobs to dedicated Jenkins servers.<br>Nevertheless some teams still share their build infrastructure, thus lacking independence e.g. when it comes to introducing new Jenkins plugins or other tools needed for their build process.</p>\n<img class=\"blog/blog-jenkins-polyglot.png\">\n<h2 id=\"Jenkins-configuration\"><a href=\"#Jenkins-configuration\" class=\"headerlink\" title=\"Jenkins configuration\"></a>Jenkins configuration</h2><p>Jenkins makes it very easy to introduce new functionality by installing one of the <a href=\"https://wiki.jenkins-ci.org/display/JENKINS/Plugins\" target=\"_blank\" rel=\"external\">many available plugins</a>.<br>Unfortunately not every plugin turns out to work as expected or in the worst case can potentially bring down the whole Jenkins instance.<br>To evaluate unknown plugins by installing them into your production CI infrastructure bears problems, since they often leave unwanted traces behind, even after uninstallation.<br>Even making changes to a job configuration without adding any new plugins can lead to broken build jobs, negatively affecting the productivity of whole teams.</p>\n<h3 id=\"The-solution\"><a href=\"#The-solution\" class=\"headerlink\" title=\"The solution\"></a>The solution</h3><p>We were looking for ways to make it safe and easy to improve our build infrastructure.<br>Using version control like <a href=\"https://github.com/\" target=\"_blank\" rel=\"external\">GitHub</a> for all of our source code, it was natural to treat our infrastructure the same way and be able to roll back to a previous version without any hassle.<br>Versioning whole images of Jenkins virtual servers didn’t seem feasible and plugins like <a href=\"https://wiki.jenkins-ci.org/display/JENKINS/JobConfigHistory+Plugin\" target=\"_blank\" rel=\"external\">JobConfigHistory</a> did not cover managing plugin versions as well.</p>\n<h3 id=\"Server-provisioning-using-Ansible-and-Vagrant\"><a href=\"#Server-provisioning-using-Ansible-and-Vagrant\" class=\"headerlink\" title=\"Server provisioning using Ansible and Vagrant\"></a>Server provisioning using Ansible and Vagrant</h3><p>We started by automating the installation of Jenkins, including all required plugins.<br>The idea is to set up a Jenkins server from scratch by running just a single command, while still being able to use the same facilities to update the installation, e.g. with new plugins, using the same technology.<br>To achieve this, we decided to use <a href=\"http://www.ansible.com/home\" target=\"_blank\" rel=\"external\">Ansible</a>, mainly due to existing know-how.</p>\n<p>Once the basic installation of Jenkins and its prerequisites is done, the interesting part begins: installing and configuring plugins.<br>The installation of additional plugins is done by utilising the <a href=\"https://wiki.jenkins-ci.org/display/JENKINS/Jenkins+CLI\" target=\"_blank\" rel=\"external\">Jenkins Command Line Interpreter (CLI)</a>.<br>This allows us to provide plugin names and explicit versions to be installed.<br>The tricky part is getting the global configuration of Jenkins right.<br>The pragmatic solution we chose was to create the <code>config.xml</code> locally (but templated) and copy it over to Jenkins using the according Ansible task.</p>\n<p>With the toolset described so far, the basic setup can be easily recreated any time.<br>And since this is so easy now, we usually test our setup scripts by installing them to local <a href=\"https://www.vagrantup.com/\" target=\"_blank\" rel=\"external\">Vagrant</a> machines.<br>Especially for the global Jenkins configuration this is an essential step, which is even easier and faster due to Ansible’s smart way of tracking installation state.<br>Just rerun the Ansible playbook and changes in the configuration are automatically applied; then you can be sure, that they are based on your version-managed infrastructure code!</p>\n<h3 id=\"Job-provisioning-using-Job-DSL\"><a href=\"#Job-provisioning-using-Job-DSL\" class=\"headerlink\" title=\"Job provisioning using Job DSL\"></a>Job provisioning using Job DSL</h3><p>Usually, Jenkins jobs are created manually using the web UI and are stored in XML configuration files.<br>These files are quite verbose, and are not nice to edit directly.<br>If you want to create a new job based on an existing one, you should do this in an automated fashion.<br>Here a very nice plugin comes to help: the <a href=\"https://wiki.jenkins-ci.org/display/JENKINS/Job+DSL+Plugin\" target=\"_blank\" rel=\"external\">Job DSL Plugin</a> allows the creation of jobs from simplified DSL (<a href=\"http://martinfowler.com/books/dsl.html\" target=\"_blank\" rel=\"external\">Domain Specific Language</a>) descriptions, which are much nicer to read and write than the XML configuration files.<br>All you need to create your jobs is a single so-called <em>seed</em> job, which (in our case) pulls the job definitions as Groovy DSL scripts from Git to generate the desired jobs.</p>\n<p>The <em>seed</em> job can be run whenever there are changes in the DSL scripts for the jobs, and updates the configuration of changed jobs accordingly.<br>Existing build metadata, like next build number files, is not touched by such an update.</p>\n<h3 id=\"Handling-of-job-metadata\"><a href=\"#Handling-of-job-metadata\" class=\"headerlink\" title=\"Handling of job metadata\"></a>Handling of job metadata</h3><p>Managing the job metadata, e.g. the <code>nextBuildNumber</code> file, the workspace and the results of the last builds, is still a tricky topic.<br>As these files are created or updated by the actual build executions, they are not easily recreated.<br>Therefore, we stick to doing some plain old backup task to save the relevant parts.<br>For us, these are the <code>nextBuildNumber</code> files and the <code>builds</code> directory.<br>All other job metadata is either not really important, like symbolic links to the last successful build directory, or will automatically be recreated with the next build, e.g. the workspace.</p>\n<h3 id=\"Running-Jenkins-slaves-on-developer-machines\"><a href=\"#Running-Jenkins-slaves-on-developer-machines\" class=\"headerlink\" title=\"Running Jenkins slaves on developer machines\"></a>Running Jenkins slaves on developer machines</h3><p>Being able to run lots of build jobs in parallel is key to receiving fast feedback from our CI infrastructure.<br>With modern desktops and laptops there is enough idle CPU and RAM resources available in our offices most of the time, which we want to use for this purpose by running <a href=\"https://wiki.jenkins-ci.org/display/JENKINS/Step+by+step+guide+to+set+up+master+and+slave+machines\" target=\"_blank\" rel=\"external\">Jenkins slaves</a>.<br>In order not to interfere with the operating system and tools installation on each developer’s machine, we create virtual images (or maybe even <a href=\"https://www.docker.com/\" target=\"_blank\" rel=\"external\">Docker</a> containers in the future) containing all the components needed for a Jenkins slave to execute build jobs.<br>Using the <a href=\"https://wiki.jenkins-ci.org/display/JENKINS/Swarm+Plugin\" target=\"_blank\" rel=\"external\">Jenkins Swarm Plugin</a> each slave registers itself at its central master, which delegates build job execution to idle slave nodes.<br>Each build job is configured to carry one or more <em>labels</em>, which control that they get only executed on slaves which can support these kind of jobs.<br>This way we can separate e.g. <a href=\"http://www.seleniumhq.org/\" target=\"_blank\" rel=\"external\">Selenium</a> integration tests from unit tests.</p>\n<h2 id=\"Outlook\"><a href=\"#Outlook\" class=\"headerlink\" title=\"Outlook\"></a>Outlook</h2><p>We want to offer each team an easy way to setup and manage their own dedicated CI infrastructure and tweak it to their specific needs.<br>By spreading the load of executing build jobs to various developer’s machine we can further shorten the time a team needs to wait for the <a href=\"https://wiki.jenkins-ci.org/display/JENKINS/GitHub+pull+request+builder+plugin\" target=\"_blank\" rel=\"external\">GitHub pull request builder plugin</a> to check if a pull request is safe to merge into the main development line, thus preventing stale pull requests and merge hell later.<br>We could also offload more slaves to e.g. <a href=\"https://aws.amazon.com/ec2/\" target=\"_blank\" rel=\"external\">Amazon EC2</a>, if we really need the compute power.<br>The process of moving our custom Jenkins installations and job configurations to this new CI infrastructure has just started and we are eager to learn how this will turn out in the future.</p>\n","excerpt":"","more":"<p>Here at ePages we heavily rely on <a href=\"http://www.martinfowler.com/articles/continuousIntegration.html\">Continuous Integration (CI)</a> to make sure our code is always in a good shape.<br><a href=\"https://jenkins-ci.org/\">Jenkins</a> is the software we use as our CI tool.<br>A mixed language stack mainly composed of <code>Java</code>, <code>JavaScript</code> and <code>Perl</code> spread over multiple teams brings in different build processes and toolings needed to produce the artifacts our software is composed of, e.g. <code>gradle</code>, <code>grunt</code> and <code>make</code>.<br>We do not run all build jobs on a single Jenkins instance, but already spread out different jobs to dedicated Jenkins servers.<br>Nevertheless some teams still share their build infrastructure, thus lacking independence e.g. when it comes to introducing new Jenkins plugins or other tools needed for their build process.</p>\n<img class=\"blog/blog-jenkins-polyglot.png\">\n<h2 id=\"Jenkins-configuration\"><a href=\"#Jenkins-configuration\" class=\"headerlink\" title=\"Jenkins configuration\"></a>Jenkins configuration</h2><p>Jenkins makes it very easy to introduce new functionality by installing one of the <a href=\"https://wiki.jenkins-ci.org/display/JENKINS/Plugins\">many available plugins</a>.<br>Unfortunately not every plugin turns out to work as expected or in the worst case can potentially bring down the whole Jenkins instance.<br>To evaluate unknown plugins by installing them into your production CI infrastructure bears problems, since they often leave unwanted traces behind, even after uninstallation.<br>Even making changes to a job configuration without adding any new plugins can lead to broken build jobs, negatively affecting the productivity of whole teams.</p>\n<h3 id=\"The-solution\"><a href=\"#The-solution\" class=\"headerlink\" title=\"The solution\"></a>The solution</h3><p>We were looking for ways to make it safe and easy to improve our build infrastructure.<br>Using version control like <a href=\"https://github.com/\">GitHub</a> for all of our source code, it was natural to treat our infrastructure the same way and be able to roll back to a previous version without any hassle.<br>Versioning whole images of Jenkins virtual servers didn’t seem feasible and plugins like <a href=\"https://wiki.jenkins-ci.org/display/JENKINS/JobConfigHistory+Plugin\">JobConfigHistory</a> did not cover managing plugin versions as well.</p>\n<h3 id=\"Server-provisioning-using-Ansible-and-Vagrant\"><a href=\"#Server-provisioning-using-Ansible-and-Vagrant\" class=\"headerlink\" title=\"Server provisioning using Ansible and Vagrant\"></a>Server provisioning using Ansible and Vagrant</h3><p>We started by automating the installation of Jenkins, including all required plugins.<br>The idea is to set up a Jenkins server from scratch by running just a single command, while still being able to use the same facilities to update the installation, e.g. with new plugins, using the same technology.<br>To achieve this, we decided to use <a href=\"http://www.ansible.com/home\">Ansible</a>, mainly due to existing know-how.</p>\n<p>Once the basic installation of Jenkins and its prerequisites is done, the interesting part begins: installing and configuring plugins.<br>The installation of additional plugins is done by utilising the <a href=\"https://wiki.jenkins-ci.org/display/JENKINS/Jenkins+CLI\">Jenkins Command Line Interpreter (CLI)</a>.<br>This allows us to provide plugin names and explicit versions to be installed.<br>The tricky part is getting the global configuration of Jenkins right.<br>The pragmatic solution we chose was to create the <code>config.xml</code> locally (but templated) and copy it over to Jenkins using the according Ansible task.</p>\n<p>With the toolset described so far, the basic setup can be easily recreated any time.<br>And since this is so easy now, we usually test our setup scripts by installing them to local <a href=\"https://www.vagrantup.com/\">Vagrant</a> machines.<br>Especially for the global Jenkins configuration this is an essential step, which is even easier and faster due to Ansible’s smart way of tracking installation state.<br>Just rerun the Ansible playbook and changes in the configuration are automatically applied; then you can be sure, that they are based on your version-managed infrastructure code!</p>\n<h3 id=\"Job-provisioning-using-Job-DSL\"><a href=\"#Job-provisioning-using-Job-DSL\" class=\"headerlink\" title=\"Job provisioning using Job DSL\"></a>Job provisioning using Job DSL</h3><p>Usually, Jenkins jobs are created manually using the web UI and are stored in XML configuration files.<br>These files are quite verbose, and are not nice to edit directly.<br>If you want to create a new job based on an existing one, you should do this in an automated fashion.<br>Here a very nice plugin comes to help: the <a href=\"https://wiki.jenkins-ci.org/display/JENKINS/Job+DSL+Plugin\">Job DSL Plugin</a> allows the creation of jobs from simplified DSL (<a href=\"http://martinfowler.com/books/dsl.html\">Domain Specific Language</a>) descriptions, which are much nicer to read and write than the XML configuration files.<br>All you need to create your jobs is a single so-called <em>seed</em> job, which (in our case) pulls the job definitions as Groovy DSL scripts from Git to generate the desired jobs.</p>\n<p>The <em>seed</em> job can be run whenever there are changes in the DSL scripts for the jobs, and updates the configuration of changed jobs accordingly.<br>Existing build metadata, like next build number files, is not touched by such an update.</p>\n<h3 id=\"Handling-of-job-metadata\"><a href=\"#Handling-of-job-metadata\" class=\"headerlink\" title=\"Handling of job metadata\"></a>Handling of job metadata</h3><p>Managing the job metadata, e.g. the <code>nextBuildNumber</code> file, the workspace and the results of the last builds, is still a tricky topic.<br>As these files are created or updated by the actual build executions, they are not easily recreated.<br>Therefore, we stick to doing some plain old backup task to save the relevant parts.<br>For us, these are the <code>nextBuildNumber</code> files and the <code>builds</code> directory.<br>All other job metadata is either not really important, like symbolic links to the last successful build directory, or will automatically be recreated with the next build, e.g. the workspace.</p>\n<h3 id=\"Running-Jenkins-slaves-on-developer-machines\"><a href=\"#Running-Jenkins-slaves-on-developer-machines\" class=\"headerlink\" title=\"Running Jenkins slaves on developer machines\"></a>Running Jenkins slaves on developer machines</h3><p>Being able to run lots of build jobs in parallel is key to receiving fast feedback from our CI infrastructure.<br>With modern desktops and laptops there is enough idle CPU and RAM resources available in our offices most of the time, which we want to use for this purpose by running <a href=\"https://wiki.jenkins-ci.org/display/JENKINS/Step+by+step+guide+to+set+up+master+and+slave+machines\">Jenkins slaves</a>.<br>In order not to interfere with the operating system and tools installation on each developer’s machine, we create virtual images (or maybe even <a href=\"https://www.docker.com/\">Docker</a> containers in the future) containing all the components needed for a Jenkins slave to execute build jobs.<br>Using the <a href=\"https://wiki.jenkins-ci.org/display/JENKINS/Swarm+Plugin\">Jenkins Swarm Plugin</a> each slave registers itself at its central master, which delegates build job execution to idle slave nodes.<br>Each build job is configured to carry one or more <em>labels</em>, which control that they get only executed on slaves which can support these kind of jobs.<br>This way we can separate e.g. <a href=\"http://www.seleniumhq.org/\">Selenium</a> integration tests from unit tests.</p>\n<h2 id=\"Outlook\"><a href=\"#Outlook\" class=\"headerlink\" title=\"Outlook\"></a>Outlook</h2><p>We want to offer each team an easy way to setup and manage their own dedicated CI infrastructure and tweak it to their specific needs.<br>By spreading the load of executing build jobs to various developer’s machine we can further shorten the time a team needs to wait for the <a href=\"https://wiki.jenkins-ci.org/display/JENKINS/GitHub+pull+request+builder+plugin\">GitHub pull request builder plugin</a> to check if a pull request is safe to merge into the main development line, thus preventing stale pull requests and merge hell later.<br>We could also offload more slaves to e.g. <a href=\"https://aws.amazon.com/ec2/\">Amazon EC2</a>, if we really need the compute power.<br>The process of moving our custom Jenkins installations and job configurations to this new CI infrastructure has just started and we are eager to learn how this will turn out in the future.</p>\n"},{"layout":"post","title":"ePages participates in Jena Company Cup","date":"2015-06-30T06:00:00.000Z","image":"blog-header/company-cup-2015.jpg","authors":["Björn"],"_content":"On Friday the 19th of June 2015, the first “Jenaer Unternehmenscup” (Jena Company Cup) took place.\nIt was a one-day football tournament for organisations and companies in and around Jena.\n\nSome brave and ambitious men accepted the challenge and without further ado founded the “ePages Football Club”.\nThere was some work to do on convincing our team, but after some weeks of hard training and many instructions eight players were ready to go for the cup!\n\n{% image blog/blog-company-cup-2.jpg %}\n\nWe ran.\n\n{% image blog/blog-company-cup-3.jpg %}\n\nWe fought.\n\n{% image blog/blog-company-cup-4.jpg %}\n\nWe shot.\n\n{% image blog/blog-company-cup-5.jpg %}\n\nWe did our best...\n\n{% image blog/blog-company-cup-6.jpg %}\n\n... but unfortunately the other teams had too.\n\n{% image blog/blog-company-cup-7.jpg %}\n\nOur team showed a lot of commitment, passion, team spirit and fun in thrilling matches and also was not frightened of full physical involvement. In the end we won a cup, a cup that we don’t want to win again next time - the \"red lantern\" challenge cup for the last place:\n\n{% image blog/blog-company-cup-8.jpg %}\n\nBut at the end of the day only one thing really counts: we had a lot of fun!\n\n{% image blog/blog-company-cup-9.jpg %}\n","source":"_posts/2015-06-30-company-cup-jena.md","raw":"---\nlayout: post\ntitle: \"ePages participates in Jena Company Cup\"\ndate: \"2015-06-30 08:00:00\"\nimage: blog-header/company-cup-2015.jpg\ncategories: events\nauthors: [\"Björn\"]\n---\nOn Friday the 19th of June 2015, the first “Jenaer Unternehmenscup” (Jena Company Cup) took place.\nIt was a one-day football tournament for organisations and companies in and around Jena.\n\nSome brave and ambitious men accepted the challenge and without further ado founded the “ePages Football Club”.\nThere was some work to do on convincing our team, but after some weeks of hard training and many instructions eight players were ready to go for the cup!\n\n{% image blog/blog-company-cup-2.jpg %}\n\nWe ran.\n\n{% image blog/blog-company-cup-3.jpg %}\n\nWe fought.\n\n{% image blog/blog-company-cup-4.jpg %}\n\nWe shot.\n\n{% image blog/blog-company-cup-5.jpg %}\n\nWe did our best...\n\n{% image blog/blog-company-cup-6.jpg %}\n\n... but unfortunately the other teams had too.\n\n{% image blog/blog-company-cup-7.jpg %}\n\nOur team showed a lot of commitment, passion, team spirit and fun in thrilling matches and also was not frightened of full physical involvement. In the end we won a cup, a cup that we don’t want to win again next time - the \"red lantern\" challenge cup for the last place:\n\n{% image blog/blog-company-cup-8.jpg %}\n\nBut at the end of the day only one thing really counts: we had a lot of fun!\n\n{% image blog/blog-company-cup-9.jpg %}\n","slug":"2015-06-30-company-cup-jena","published":1,"updated":"2016-09-20T14:19:22.000Z","comments":1,"photos":[],"link":"","_id":"ciu6nuh87000hhqyxghnojy30","content":"<p>On Friday the 19th of June 2015, the first “Jenaer Unternehmenscup” (Jena Company Cup) took place.<br>It was a one-day football tournament for organisations and companies in and around Jena.</p>\n<p>Some brave and ambitious men accepted the challenge and without further ado founded the “ePages Football Club”.<br>There was some work to do on convincing our team, but after some weeks of hard training and many instructions eight players were ready to go for the cup!</p>\n<img class=\"blog/blog-company-cup-2.jpg\">\n<p>We ran.</p>\n<img class=\"blog/blog-company-cup-3.jpg\">\n<p>We fought.</p>\n<img class=\"blog/blog-company-cup-4.jpg\">\n<p>We shot.</p>\n<img class=\"blog/blog-company-cup-5.jpg\">\n<p>We did our best…</p>\n<img class=\"blog/blog-company-cup-6.jpg\">\n<p>… but unfortunately the other teams had too.</p>\n<img class=\"blog/blog-company-cup-7.jpg\">\n<p>Our team showed a lot of commitment, passion, team spirit and fun in thrilling matches and also was not frightened of full physical involvement. In the end we won a cup, a cup that we don’t want to win again next time - the “red lantern” challenge cup for the last place:</p>\n<img class=\"blog/blog-company-cup-8.jpg\">\n<p>But at the end of the day only one thing really counts: we had a lot of fun!</p>\n<img class=\"blog/blog-company-cup-9.jpg\">\n","excerpt":"","more":"<p>On Friday the 19th of June 2015, the first “Jenaer Unternehmenscup” (Jena Company Cup) took place.<br>It was a one-day football tournament for organisations and companies in and around Jena.</p>\n<p>Some brave and ambitious men accepted the challenge and without further ado founded the “ePages Football Club”.<br>There was some work to do on convincing our team, but after some weeks of hard training and many instructions eight players were ready to go for the cup!</p>\n<img class=\"blog/blog-company-cup-2.jpg\">\n<p>We ran.</p>\n<img class=\"blog/blog-company-cup-3.jpg\">\n<p>We fought.</p>\n<img class=\"blog/blog-company-cup-4.jpg\">\n<p>We shot.</p>\n<img class=\"blog/blog-company-cup-5.jpg\">\n<p>We did our best…</p>\n<img class=\"blog/blog-company-cup-6.jpg\">\n<p>… but unfortunately the other teams had too.</p>\n<img class=\"blog/blog-company-cup-7.jpg\">\n<p>Our team showed a lot of commitment, passion, team spirit and fun in thrilling matches and also was not frightened of full physical involvement. In the end we won a cup, a cup that we don’t want to win again next time - the “red lantern” challenge cup for the last place:</p>\n<img class=\"blog/blog-company-cup-8.jpg\">\n<p>But at the end of the day only one thing really counts: we had a lot of fun!</p>\n<img class=\"blog/blog-company-cup-9.jpg\">\n"},{"layout":"post","title":"How ePages gives new developers a great start","date":"2015-07-07T05:32:32.000Z","authors":["Birgit"],"_content":"\nMost likely, everyone reading this has already had the experience of starting at a new company.\nSome might tell stories about the best first workday they have ever had, others might have just repressed the thoughts about a scaring introductory day.\nIn the first week of July, a bunch of new developers started at ePages.\nFind out what we did to help them get off on the right foot and give them a positive start.\n\n{% image blog/blog-employee-induction-cto.jpg %}\n\n## 1. Welcome employee before employment even begins\n\nAll new employees receive a welcome letter that includes:\n\n* information about the starting date and time of their first day of work\n* an induction programme giving some indication of what will happen during their first days at ePages\n* a personnel record that's to be completed by the employee by their first day\n\n## 2. Involve teams and organise buddies\n\nIt makes sense to involve teams and organise buddies, after all, a new developer will be part of a development team.\nWe circulate the induction plan to the team to ensure they are informed about the new colleague and aware of what training they are in, why and when.\nThis allows the team to organise and plan their tasks accordingly and coordinate the induction sessions and pair programming with the new team member upfront.\nOf course, this also includes setting up the workspace and ordering IT equipment.\nWe further involve colleagues from other departments to volunteer as mentors for the new employees.\nHere at ePages we call them \"buddies\".\n\n## 3. First work day: Meet with new employees right away\n\nWhen having arrived at the office, our human resources coordinator welcomes the new employees, a round of introductions follows and the further course of the day will be explained.\n\nOur CTO gives a brief introduction including:\n\n* Development teams and their tasks\n* Goals and targets\n* Software architecture\n* Benefits for our merchants\n\n## 4. Buddy time!\n\n{% image blog/blog-employee-induction-welcome.jpg 45% right %}\n\nNext we get the newbies into contact with their buddies and off they go exploring the office.\nThis is all about settling-in and clarifying feel-good issues such as:\n\n* Coffee machine\n* Rest rooms\n* Kitchen use\n* Storage areas\n* Office systems\n* Social rooms\n\nBuddies show the layout of the offices and the new workplace, introduce the new employees to staff of other departments and may answer any questions that the employee is not comfortable posing to the team or supervisor.\nThey'll be shown their workplaces as well as important contact points.\n\n## 5. Introduction session with HR\n\nOur HR team then hands out the office keys and local transport tickets and helps to familiarise our new employees.\nThis includes:\n\n* Org chart\n* Company values\n* Benefits\n* Documents to be submitted\n* Travel guidelines\n* Target agreement discussions\n* Company events and holidays\n* Applications for leave and sick leave\n\n{% image blog/blog-employee-induction-agenda.png 40% left %}\n\n## 6. Team lunch\n\nPhew! It's definitely time for a break and a great chance to get to know the team members during the lunch.\n\n## 7. At the desk with the team\n\nNow it's team time: Setting up the workplace, configuring the laptop, collecting office materials and receiving more \"getting started\" information from the team.\n\n## And what's next?\n\nThe first day is over and the new colleagues have a lot of new information in their luggage.\nThe agenda for the following days contains some more interesting topics and valuable tips for a great start at ePages.\nCheck out what our typical agenda looks like:\n\nCertainly, it takes plenty of time and coaching to get new employees fully familiar with the company and all work processes.\nWith our induction programme we are laying the groundwork to make this process as quick as possible.\nWe want to ensure that our new colleagues feel integrated into the team right from the start.\n","source":"_posts/2015-07-07-employee-induction-programme.md","raw":"---\nlayout: post\ntitle: \"How ePages gives new developers a great start\"\ndate: \"2015-07-07 07:32:32\"\ncategories: working-at-epages\nauthors: [\"Birgit\"]\n---\n\nMost likely, everyone reading this has already had the experience of starting at a new company.\nSome might tell stories about the best first workday they have ever had, others might have just repressed the thoughts about a scaring introductory day.\nIn the first week of July, a bunch of new developers started at ePages.\nFind out what we did to help them get off on the right foot and give them a positive start.\n\n{% image blog/blog-employee-induction-cto.jpg %}\n\n## 1. Welcome employee before employment even begins\n\nAll new employees receive a welcome letter that includes:\n\n* information about the starting date and time of their first day of work\n* an induction programme giving some indication of what will happen during their first days at ePages\n* a personnel record that's to be completed by the employee by their first day\n\n## 2. Involve teams and organise buddies\n\nIt makes sense to involve teams and organise buddies, after all, a new developer will be part of a development team.\nWe circulate the induction plan to the team to ensure they are informed about the new colleague and aware of what training they are in, why and when.\nThis allows the team to organise and plan their tasks accordingly and coordinate the induction sessions and pair programming with the new team member upfront.\nOf course, this also includes setting up the workspace and ordering IT equipment.\nWe further involve colleagues from other departments to volunteer as mentors for the new employees.\nHere at ePages we call them \"buddies\".\n\n## 3. First work day: Meet with new employees right away\n\nWhen having arrived at the office, our human resources coordinator welcomes the new employees, a round of introductions follows and the further course of the day will be explained.\n\nOur CTO gives a brief introduction including:\n\n* Development teams and their tasks\n* Goals and targets\n* Software architecture\n* Benefits for our merchants\n\n## 4. Buddy time!\n\n{% image blog/blog-employee-induction-welcome.jpg 45% right %}\n\nNext we get the newbies into contact with their buddies and off they go exploring the office.\nThis is all about settling-in and clarifying feel-good issues such as:\n\n* Coffee machine\n* Rest rooms\n* Kitchen use\n* Storage areas\n* Office systems\n* Social rooms\n\nBuddies show the layout of the offices and the new workplace, introduce the new employees to staff of other departments and may answer any questions that the employee is not comfortable posing to the team or supervisor.\nThey'll be shown their workplaces as well as important contact points.\n\n## 5. Introduction session with HR\n\nOur HR team then hands out the office keys and local transport tickets and helps to familiarise our new employees.\nThis includes:\n\n* Org chart\n* Company values\n* Benefits\n* Documents to be submitted\n* Travel guidelines\n* Target agreement discussions\n* Company events and holidays\n* Applications for leave and sick leave\n\n{% image blog/blog-employee-induction-agenda.png 40% left %}\n\n## 6. Team lunch\n\nPhew! It's definitely time for a break and a great chance to get to know the team members during the lunch.\n\n## 7. At the desk with the team\n\nNow it's team time: Setting up the workplace, configuring the laptop, collecting office materials and receiving more \"getting started\" information from the team.\n\n## And what's next?\n\nThe first day is over and the new colleagues have a lot of new information in their luggage.\nThe agenda for the following days contains some more interesting topics and valuable tips for a great start at ePages.\nCheck out what our typical agenda looks like:\n\nCertainly, it takes plenty of time and coaching to get new employees fully familiar with the company and all work processes.\nWith our induction programme we are laying the groundwork to make this process as quick as possible.\nWe want to ensure that our new colleagues feel integrated into the team right from the start.\n","slug":"2015-07-07-employee-induction-programme","published":1,"updated":"2016-09-20T14:19:22.000Z","comments":1,"photos":[],"link":"","_id":"ciu6nuh88000jhqyx9hab5vcq","content":"<p>Most likely, everyone reading this has already had the experience of starting at a new company.<br>Some might tell stories about the best first workday they have ever had, others might have just repressed the thoughts about a scaring introductory day.<br>In the first week of July, a bunch of new developers started at ePages.<br>Find out what we did to help them get off on the right foot and give them a positive start.</p>\n<img class=\"blog/blog-employee-induction-cto.jpg\">\n<h2 id=\"1-Welcome-employee-before-employment-even-begins\"><a href=\"#1-Welcome-employee-before-employment-even-begins\" class=\"headerlink\" title=\"1. Welcome employee before employment even begins\"></a>1. Welcome employee before employment even begins</h2><p>All new employees receive a welcome letter that includes:</p>\n<ul>\n<li>information about the starting date and time of their first day of work</li>\n<li>an induction programme giving some indication of what will happen during their first days at ePages</li>\n<li>a personnel record that’s to be completed by the employee by their first day</li>\n</ul>\n<h2 id=\"2-Involve-teams-and-organise-buddies\"><a href=\"#2-Involve-teams-and-organise-buddies\" class=\"headerlink\" title=\"2. Involve teams and organise buddies\"></a>2. Involve teams and organise buddies</h2><p>It makes sense to involve teams and organise buddies, after all, a new developer will be part of a development team.<br>We circulate the induction plan to the team to ensure they are informed about the new colleague and aware of what training they are in, why and when.<br>This allows the team to organise and plan their tasks accordingly and coordinate the induction sessions and pair programming with the new team member upfront.<br>Of course, this also includes setting up the workspace and ordering IT equipment.<br>We further involve colleagues from other departments to volunteer as mentors for the new employees.<br>Here at ePages we call them “buddies”.</p>\n<h2 id=\"3-First-work-day-Meet-with-new-employees-right-away\"><a href=\"#3-First-work-day-Meet-with-new-employees-right-away\" class=\"headerlink\" title=\"3. First work day: Meet with new employees right away\"></a>3. First work day: Meet with new employees right away</h2><p>When having arrived at the office, our human resources coordinator welcomes the new employees, a round of introductions follows and the further course of the day will be explained.</p>\n<p>Our CTO gives a brief introduction including:</p>\n<ul>\n<li>Development teams and their tasks</li>\n<li>Goals and targets</li>\n<li>Software architecture</li>\n<li>Benefits for our merchants</li>\n</ul>\n<h2 id=\"4-Buddy-time\"><a href=\"#4-Buddy-time\" class=\"headerlink\" title=\"4. Buddy time!\"></a>4. Buddy time!</h2><img class=\"blog/blog-employee-induction-welcome.jpg 45% right\">\n<p>Next we get the newbies into contact with their buddies and off they go exploring the office.<br>This is all about settling-in and clarifying feel-good issues such as:</p>\n<ul>\n<li>Coffee machine</li>\n<li>Rest rooms</li>\n<li>Kitchen use</li>\n<li>Storage areas</li>\n<li>Office systems</li>\n<li>Social rooms</li>\n</ul>\n<p>Buddies show the layout of the offices and the new workplace, introduce the new employees to staff of other departments and may answer any questions that the employee is not comfortable posing to the team or supervisor.<br>They’ll be shown their workplaces as well as important contact points.</p>\n<h2 id=\"5-Introduction-session-with-HR\"><a href=\"#5-Introduction-session-with-HR\" class=\"headerlink\" title=\"5. Introduction session with HR\"></a>5. Introduction session with HR</h2><p>Our HR team then hands out the office keys and local transport tickets and helps to familiarise our new employees.<br>This includes:</p>\n<ul>\n<li>Org chart</li>\n<li>Company values</li>\n<li>Benefits</li>\n<li>Documents to be submitted</li>\n<li>Travel guidelines</li>\n<li>Target agreement discussions</li>\n<li>Company events and holidays</li>\n<li>Applications for leave and sick leave</li>\n</ul>\n<img class=\"blog/blog-employee-induction-agenda.png 40% left\">\n<h2 id=\"6-Team-lunch\"><a href=\"#6-Team-lunch\" class=\"headerlink\" title=\"6. Team lunch\"></a>6. Team lunch</h2><p>Phew! It’s definitely time for a break and a great chance to get to know the team members during the lunch.</p>\n<h2 id=\"7-At-the-desk-with-the-team\"><a href=\"#7-At-the-desk-with-the-team\" class=\"headerlink\" title=\"7. At the desk with the team\"></a>7. At the desk with the team</h2><p>Now it’s team time: Setting up the workplace, configuring the laptop, collecting office materials and receiving more “getting started” information from the team.</p>\n<h2 id=\"And-what’s-next\"><a href=\"#And-what’s-next\" class=\"headerlink\" title=\"And what’s next?\"></a>And what’s next?</h2><p>The first day is over and the new colleagues have a lot of new information in their luggage.<br>The agenda for the following days contains some more interesting topics and valuable tips for a great start at ePages.<br>Check out what our typical agenda looks like:</p>\n<p>Certainly, it takes plenty of time and coaching to get new employees fully familiar with the company and all work processes.<br>With our induction programme we are laying the groundwork to make this process as quick as possible.<br>We want to ensure that our new colleagues feel integrated into the team right from the start.</p>\n","excerpt":"","more":"<p>Most likely, everyone reading this has already had the experience of starting at a new company.<br>Some might tell stories about the best first workday they have ever had, others might have just repressed the thoughts about a scaring introductory day.<br>In the first week of July, a bunch of new developers started at ePages.<br>Find out what we did to help them get off on the right foot and give them a positive start.</p>\n<img class=\"blog/blog-employee-induction-cto.jpg\">\n<h2 id=\"1-Welcome-employee-before-employment-even-begins\"><a href=\"#1-Welcome-employee-before-employment-even-begins\" class=\"headerlink\" title=\"1. Welcome employee before employment even begins\"></a>1. Welcome employee before employment even begins</h2><p>All new employees receive a welcome letter that includes:</p>\n<ul>\n<li>information about the starting date and time of their first day of work</li>\n<li>an induction programme giving some indication of what will happen during their first days at ePages</li>\n<li>a personnel record that’s to be completed by the employee by their first day</li>\n</ul>\n<h2 id=\"2-Involve-teams-and-organise-buddies\"><a href=\"#2-Involve-teams-and-organise-buddies\" class=\"headerlink\" title=\"2. Involve teams and organise buddies\"></a>2. Involve teams and organise buddies</h2><p>It makes sense to involve teams and organise buddies, after all, a new developer will be part of a development team.<br>We circulate the induction plan to the team to ensure they are informed about the new colleague and aware of what training they are in, why and when.<br>This allows the team to organise and plan their tasks accordingly and coordinate the induction sessions and pair programming with the new team member upfront.<br>Of course, this also includes setting up the workspace and ordering IT equipment.<br>We further involve colleagues from other departments to volunteer as mentors for the new employees.<br>Here at ePages we call them “buddies”.</p>\n<h2 id=\"3-First-work-day-Meet-with-new-employees-right-away\"><a href=\"#3-First-work-day-Meet-with-new-employees-right-away\" class=\"headerlink\" title=\"3. First work day: Meet with new employees right away\"></a>3. First work day: Meet with new employees right away</h2><p>When having arrived at the office, our human resources coordinator welcomes the new employees, a round of introductions follows and the further course of the day will be explained.</p>\n<p>Our CTO gives a brief introduction including:</p>\n<ul>\n<li>Development teams and their tasks</li>\n<li>Goals and targets</li>\n<li>Software architecture</li>\n<li>Benefits for our merchants</li>\n</ul>\n<h2 id=\"4-Buddy-time\"><a href=\"#4-Buddy-time\" class=\"headerlink\" title=\"4. Buddy time!\"></a>4. Buddy time!</h2><img class=\"blog/blog-employee-induction-welcome.jpg 45% right\">\n<p>Next we get the newbies into contact with their buddies and off they go exploring the office.<br>This is all about settling-in and clarifying feel-good issues such as:</p>\n<ul>\n<li>Coffee machine</li>\n<li>Rest rooms</li>\n<li>Kitchen use</li>\n<li>Storage areas</li>\n<li>Office systems</li>\n<li>Social rooms</li>\n</ul>\n<p>Buddies show the layout of the offices and the new workplace, introduce the new employees to staff of other departments and may answer any questions that the employee is not comfortable posing to the team or supervisor.<br>They’ll be shown their workplaces as well as important contact points.</p>\n<h2 id=\"5-Introduction-session-with-HR\"><a href=\"#5-Introduction-session-with-HR\" class=\"headerlink\" title=\"5. Introduction session with HR\"></a>5. Introduction session with HR</h2><p>Our HR team then hands out the office keys and local transport tickets and helps to familiarise our new employees.<br>This includes:</p>\n<ul>\n<li>Org chart</li>\n<li>Company values</li>\n<li>Benefits</li>\n<li>Documents to be submitted</li>\n<li>Travel guidelines</li>\n<li>Target agreement discussions</li>\n<li>Company events and holidays</li>\n<li>Applications for leave and sick leave</li>\n</ul>\n<img class=\"blog/blog-employee-induction-agenda.png 40% left\">\n<h2 id=\"6-Team-lunch\"><a href=\"#6-Team-lunch\" class=\"headerlink\" title=\"6. Team lunch\"></a>6. Team lunch</h2><p>Phew! It’s definitely time for a break and a great chance to get to know the team members during the lunch.</p>\n<h2 id=\"7-At-the-desk-with-the-team\"><a href=\"#7-At-the-desk-with-the-team\" class=\"headerlink\" title=\"7. At the desk with the team\"></a>7. At the desk with the team</h2><p>Now it’s team time: Setting up the workplace, configuring the laptop, collecting office materials and receiving more “getting started” information from the team.</p>\n<h2 id=\"And-what’s-next\"><a href=\"#And-what’s-next\" class=\"headerlink\" title=\"And what’s next?\"></a>And what’s next?</h2><p>The first day is over and the new colleagues have a lot of new information in their luggage.<br>The agenda for the following days contains some more interesting topics and valuable tips for a great start at ePages.<br>Check out what our typical agenda looks like:</p>\n<p>Certainly, it takes plenty of time and coaching to get new employees fully familiar with the company and all work processes.<br>With our induction programme we are laying the groundwork to make this process as quick as possible.<br>We want to ensure that our new colleagues feel integrated into the team right from the start.</p>\n"},{"layout":"post","title":"ePagees face the Tough Mudder challenge","date":"2015-07-17T06:14:03.000Z","image":"blog-header/tough-mudder.jpg","authors":["Ludger"],"_content":"\nWeeks of preparation.\nRunning to and around the Alster during lunch breaks.\nAthletics exercises. A lot of training sessions and sweat.\nFocussing on that one goal: participating in the [Tough Mudder](https://toughmudder.com/) obstacle course!\nFind out more how we fought through the mud.\n\nWe were well prepared to do the Tough Mudder challenge in the Lüneburg Heath, a muddy and marshy area in Northern Germany.\nIt was raining throughout the day, so it was really slimy and muddy, that means perfect conditions for this great challenge.\n\nThe Tough Mudder is a 16 to 18km Cross-Country Run through the wilderness with about 15 different obstacles.\nSix of these obstacles were tougher ones such as the Birth Canal, Berlin Walls ...\n\n{% image blog/blog-tough-mudder-5.jpg %}\n\n...Hangin' Tough...\n\n{% image blog/blog-tough-mudder-1.jpg %}\n\n...Arctic Enema (diving into 4-degree-cold water) and Kiss of Mud (tasty!).\n\nTough Mudder is not a competition or a race. It's a challenge without time measurement and a great team event.\nThe ePagees participating in this event showed great team spirit.\nThe team consisted of six colleagues from four different departments.\n\n{% image blog/blog-tough-mudder-2.jpg %}\n\nSome of these colleagues had never ran that far before, especially on muddy ground - making it an even more spectacular performance!\n\n{% image blog/blog-tough-mudder-4.jpg %}\n\nStarting from the very back row we were all running fast and overtaking quite a few of the other attendees, but still supporting each other until the very last obstacle.\nIt was called Electroshock therapy which we all ran through arm in arm together.\n\n{% image blog/blog-tough-mudder-3.jpg %}\n","source":"_posts/2015-07-17-tough-mudder-event.md","raw":"---\nlayout: post\ntitle: \"ePagees face the Tough Mudder challenge\"\ndate: \"2015-07-17 08:14:03\"\nimage: blog-header/tough-mudder.jpg\ncategories: events\nauthors: [\"Ludger\"]\n---\n\nWeeks of preparation.\nRunning to and around the Alster during lunch breaks.\nAthletics exercises. A lot of training sessions and sweat.\nFocussing on that one goal: participating in the [Tough Mudder](https://toughmudder.com/) obstacle course!\nFind out more how we fought through the mud.\n\nWe were well prepared to do the Tough Mudder challenge in the Lüneburg Heath, a muddy and marshy area in Northern Germany.\nIt was raining throughout the day, so it was really slimy and muddy, that means perfect conditions for this great challenge.\n\nThe Tough Mudder is a 16 to 18km Cross-Country Run through the wilderness with about 15 different obstacles.\nSix of these obstacles were tougher ones such as the Birth Canal, Berlin Walls ...\n\n{% image blog/blog-tough-mudder-5.jpg %}\n\n...Hangin' Tough...\n\n{% image blog/blog-tough-mudder-1.jpg %}\n\n...Arctic Enema (diving into 4-degree-cold water) and Kiss of Mud (tasty!).\n\nTough Mudder is not a competition or a race. It's a challenge without time measurement and a great team event.\nThe ePagees participating in this event showed great team spirit.\nThe team consisted of six colleagues from four different departments.\n\n{% image blog/blog-tough-mudder-2.jpg %}\n\nSome of these colleagues had never ran that far before, especially on muddy ground - making it an even more spectacular performance!\n\n{% image blog/blog-tough-mudder-4.jpg %}\n\nStarting from the very back row we were all running fast and overtaking quite a few of the other attendees, but still supporting each other until the very last obstacle.\nIt was called Electroshock therapy which we all ran through arm in arm together.\n\n{% image blog/blog-tough-mudder-3.jpg %}\n","slug":"2015-07-17-tough-mudder-event","published":1,"updated":"2016-09-20T14:19:22.000Z","comments":1,"photos":[],"link":"","_id":"ciu6nuh8a000mhqyxi8fghv1s","content":"<p>Weeks of preparation.<br>Running to and around the Alster during lunch breaks.<br>Athletics exercises. A lot of training sessions and sweat.<br>Focussing on that one goal: participating in the <a href=\"https://toughmudder.com/\" target=\"_blank\" rel=\"external\">Tough Mudder</a> obstacle course!<br>Find out more how we fought through the mud.</p>\n<p>We were well prepared to do the Tough Mudder challenge in the Lüneburg Heath, a muddy and marshy area in Northern Germany.<br>It was raining throughout the day, so it was really slimy and muddy, that means perfect conditions for this great challenge.</p>\n<p>The Tough Mudder is a 16 to 18km Cross-Country Run through the wilderness with about 15 different obstacles.<br>Six of these obstacles were tougher ones such as the Birth Canal, Berlin Walls …</p>\n<img class=\"blog/blog-tough-mudder-5.jpg\">\n<p>…Hangin’ Tough…</p>\n<img class=\"blog/blog-tough-mudder-1.jpg\">\n<p>…Arctic Enema (diving into 4-degree-cold water) and Kiss of Mud (tasty!).</p>\n<p>Tough Mudder is not a competition or a race. It’s a challenge without time measurement and a great team event.<br>The ePagees participating in this event showed great team spirit.<br>The team consisted of six colleagues from four different departments.</p>\n<img class=\"blog/blog-tough-mudder-2.jpg\">\n<p>Some of these colleagues had never ran that far before, especially on muddy ground - making it an even more spectacular performance!</p>\n<img class=\"blog/blog-tough-mudder-4.jpg\">\n<p>Starting from the very back row we were all running fast and overtaking quite a few of the other attendees, but still supporting each other until the very last obstacle.<br>It was called Electroshock therapy which we all ran through arm in arm together.</p>\n<img class=\"blog/blog-tough-mudder-3.jpg\">\n","excerpt":"","more":"<p>Weeks of preparation.<br>Running to and around the Alster during lunch breaks.<br>Athletics exercises. A lot of training sessions and sweat.<br>Focussing on that one goal: participating in the <a href=\"https://toughmudder.com/\">Tough Mudder</a> obstacle course!<br>Find out more how we fought through the mud.</p>\n<p>We were well prepared to do the Tough Mudder challenge in the Lüneburg Heath, a muddy and marshy area in Northern Germany.<br>It was raining throughout the day, so it was really slimy and muddy, that means perfect conditions for this great challenge.</p>\n<p>The Tough Mudder is a 16 to 18km Cross-Country Run through the wilderness with about 15 different obstacles.<br>Six of these obstacles were tougher ones such as the Birth Canal, Berlin Walls …</p>\n<img class=\"blog/blog-tough-mudder-5.jpg\">\n<p>…Hangin’ Tough…</p>\n<img class=\"blog/blog-tough-mudder-1.jpg\">\n<p>…Arctic Enema (diving into 4-degree-cold water) and Kiss of Mud (tasty!).</p>\n<p>Tough Mudder is not a competition or a race. It’s a challenge without time measurement and a great team event.<br>The ePagees participating in this event showed great team spirit.<br>The team consisted of six colleagues from four different departments.</p>\n<img class=\"blog/blog-tough-mudder-2.jpg\">\n<p>Some of these colleagues had never ran that far before, especially on muddy ground - making it an even more spectacular performance!</p>\n<img class=\"blog/blog-tough-mudder-4.jpg\">\n<p>Starting from the very back row we were all running fast and overtaking quite a few of the other attendees, but still supporting each other until the very last obstacle.<br>It was called Electroshock therapy which we all ran through arm in arm together.</p>\n<img class=\"blog/blog-tough-mudder-3.jpg\">\n"},{"layout":"post","title":"Challenges of integrating third-parties","date":"2015-07-20T12:26:17.000Z","image":"blog-header/puzzle.jpg","authors":["Ulf B."],"_content":"\nThird-party applications are an important part of the service that ePages offers.\nAs our applications are built on an internal application platform, ePages developers are highly dependent on third-party services.\nRead more to find out why it is not the easiest thing to integrate third-parties and how we tackle this.\n\n## The use case\n\n{% image blog/blog-third-party-overview.png %}\n\nExample: If a customer buys a product in an ePages online shop, they could choose e.g. PayPal as payment method and DHL as delivery method.\nThe customer could also obtain an insurance with Trusted Shops.\n(Read further [here](http://www.epages.com/en/partner/technology-partner/) to get an overview of our technology partners.)\nA checkout alone can easily have three third-party dependencies.\n\nThe merchant, in turn, receives information via server-sided callbacks, if an order has been paid.\nThey can generate shipping labels via the web service of a third-party shipping method or synchronise their online shop with ERP-software.\nThese are just a few examples of third-party integrations at ePages.\nThere are a lot more use cases where both customer and merchant can use third-party services.\n\nPayment, deliveries, market places, marketing and tax calculation - for many applications, specialised services are available that have to be integrated into the platform at various locations.\nIn all of these areas new startup companies are founded that offer new services.\nAt the same time, also existing companies expand their service portfolio in order to not lose the connection in the dynamic e-commerce market.\nThese circumstances keep us busy not only in integrating new services periodically but also by maintaining the existing integrations.\n\nIf companies expand abroad, as is the case at ePages, it might be required to include additional services, to being attractive for the merchants in that specific country.\nWe integrated e.g. USPS and FedEx, since it would not make any sense to enter the US market without an integration of these common US shipping agents.\n\n## Third-party libraries vs Third-party web services\n\nToday's software is mostly based on third-party components, as there are already proven solutions in place that can be easily reused.\nFurthermore, these projects are supported by great communities that continuously develop the software and often are absolute experts in this respective field.\n\nHowever, with regards to third-party components we have to distinguish between third-party libraries and third-party web services.\nThird-party libraries are integrated directly into the code base and remain unchanged until a new library version is included.\n\nWorking with third-party web services is more complex.\nEven if a third-party web service, other than a third-party library, does not directly expand the code base, one must never forget:\nBy integrating a third-party service, this service will be part of your software.\nThe software will be expanded by functionality that is dependent on the availability of the third-party web service and acts as expected.\nThis fact puts special demands on the developers.\n\n## The challenge\n\nUsually the only things we know about the third-party web service is the endpoint URL and a more or less helpful documentation.\nThe problem is, that not only the API itself, but also both the endpoint and the documentation, can change every time.\nYou will only notice the change if something does not work anymore.\nSometimes an SDK exists for the API that should facilitate working with it.\nBut sometimes the SDK does not support the latest API version or the required programming language is not available.\n\nOften the documentation was only produced in the national language of the API developers, making it impossible to understand the content.\nThe result is that integration problems cannot be fixed by our developers in Barcelona if the documentation is e.g. only available in German.\n\n## The approach\n\nIdeally, we are in direct contact with the developers of the respective third-party to clarify any questions or concerns.\nUnfortunately, that is not always the case.\nIn this case we have to find out by ourselves how the web service works using the trial-and-error method or reverse engineering.\n\nWhen working with a SOAP API, the WSDL-file that describes the service, provides many helpful bits of information.\nUsing a tool such as SoapUI, such a file can be analysed easily.\nEven test requests can be sent via the SoapUI.\n\nFor such tests, the third-party provides special test accounts.\nUnfortunately, these are sometimes only valid for a limited period of time.\nThis is only then noticed, if the account is required again, e.g. if after some time problems with an integration arise that have to be fixed on short notice.\n\nTo test our integrations we are writing Unit tests as well as integration and Selenium tests.\nBy carrying out these tests we are alerted to these problems at an early stage.\n\nSome companies even operate special test platforms with a separate endpoint.\nWhat sounds like a very developer-friendly offer, has a major disadvantage: doing the tests on one system and using a different system for production.\nIdeally, the test system should act exactly as the live-system, but that is not always the case.\nThis is especially annoying if after the rollout customers report problems that did not arise on the test platform.\n\n## The conclusion\n\nAll in all one can say that third-party integrations are challenging for developers.\nBut using suitable tools and a high test coverage can definitely help to master these challenges.\nGo for it!\n\nA special thanks to our technology partners for informing us beforehand when they plan to make changes.\n","source":"_posts/2015-07-20-third-party-integration.md","raw":"---\nlayout: post\ntitle: \"Challenges of integrating third-parties\"\ndate: \"2015-07-20 14:26:17\"\nimage: blog-header/puzzle.jpg\ncategories: tech-stories\nauthors: [\"Ulf B.\"]\n---\n\nThird-party applications are an important part of the service that ePages offers.\nAs our applications are built on an internal application platform, ePages developers are highly dependent on third-party services.\nRead more to find out why it is not the easiest thing to integrate third-parties and how we tackle this.\n\n## The use case\n\n{% image blog/blog-third-party-overview.png %}\n\nExample: If a customer buys a product in an ePages online shop, they could choose e.g. PayPal as payment method and DHL as delivery method.\nThe customer could also obtain an insurance with Trusted Shops.\n(Read further [here](http://www.epages.com/en/partner/technology-partner/) to get an overview of our technology partners.)\nA checkout alone can easily have three third-party dependencies.\n\nThe merchant, in turn, receives information via server-sided callbacks, if an order has been paid.\nThey can generate shipping labels via the web service of a third-party shipping method or synchronise their online shop with ERP-software.\nThese are just a few examples of third-party integrations at ePages.\nThere are a lot more use cases where both customer and merchant can use third-party services.\n\nPayment, deliveries, market places, marketing and tax calculation - for many applications, specialised services are available that have to be integrated into the platform at various locations.\nIn all of these areas new startup companies are founded that offer new services.\nAt the same time, also existing companies expand their service portfolio in order to not lose the connection in the dynamic e-commerce market.\nThese circumstances keep us busy not only in integrating new services periodically but also by maintaining the existing integrations.\n\nIf companies expand abroad, as is the case at ePages, it might be required to include additional services, to being attractive for the merchants in that specific country.\nWe integrated e.g. USPS and FedEx, since it would not make any sense to enter the US market without an integration of these common US shipping agents.\n\n## Third-party libraries vs Third-party web services\n\nToday's software is mostly based on third-party components, as there are already proven solutions in place that can be easily reused.\nFurthermore, these projects are supported by great communities that continuously develop the software and often are absolute experts in this respective field.\n\nHowever, with regards to third-party components we have to distinguish between third-party libraries and third-party web services.\nThird-party libraries are integrated directly into the code base and remain unchanged until a new library version is included.\n\nWorking with third-party web services is more complex.\nEven if a third-party web service, other than a third-party library, does not directly expand the code base, one must never forget:\nBy integrating a third-party service, this service will be part of your software.\nThe software will be expanded by functionality that is dependent on the availability of the third-party web service and acts as expected.\nThis fact puts special demands on the developers.\n\n## The challenge\n\nUsually the only things we know about the third-party web service is the endpoint URL and a more or less helpful documentation.\nThe problem is, that not only the API itself, but also both the endpoint and the documentation, can change every time.\nYou will only notice the change if something does not work anymore.\nSometimes an SDK exists for the API that should facilitate working with it.\nBut sometimes the SDK does not support the latest API version or the required programming language is not available.\n\nOften the documentation was only produced in the national language of the API developers, making it impossible to understand the content.\nThe result is that integration problems cannot be fixed by our developers in Barcelona if the documentation is e.g. only available in German.\n\n## The approach\n\nIdeally, we are in direct contact with the developers of the respective third-party to clarify any questions or concerns.\nUnfortunately, that is not always the case.\nIn this case we have to find out by ourselves how the web service works using the trial-and-error method or reverse engineering.\n\nWhen working with a SOAP API, the WSDL-file that describes the service, provides many helpful bits of information.\nUsing a tool such as SoapUI, such a file can be analysed easily.\nEven test requests can be sent via the SoapUI.\n\nFor such tests, the third-party provides special test accounts.\nUnfortunately, these are sometimes only valid for a limited period of time.\nThis is only then noticed, if the account is required again, e.g. if after some time problems with an integration arise that have to be fixed on short notice.\n\nTo test our integrations we are writing Unit tests as well as integration and Selenium tests.\nBy carrying out these tests we are alerted to these problems at an early stage.\n\nSome companies even operate special test platforms with a separate endpoint.\nWhat sounds like a very developer-friendly offer, has a major disadvantage: doing the tests on one system and using a different system for production.\nIdeally, the test system should act exactly as the live-system, but that is not always the case.\nThis is especially annoying if after the rollout customers report problems that did not arise on the test platform.\n\n## The conclusion\n\nAll in all one can say that third-party integrations are challenging for developers.\nBut using suitable tools and a high test coverage can definitely help to master these challenges.\nGo for it!\n\nA special thanks to our technology partners for informing us beforehand when they plan to make changes.\n","slug":"2015-07-20-third-party-integration","published":1,"updated":"2016-09-20T14:19:22.000Z","comments":1,"photos":[],"link":"","_id":"ciu6nuh8k000ohqyxs76hci8u","content":"<p>Third-party applications are an important part of the service that ePages offers.<br>As our applications are built on an internal application platform, ePages developers are highly dependent on third-party services.<br>Read more to find out why it is not the easiest thing to integrate third-parties and how we tackle this.</p>\n<h2 id=\"The-use-case\"><a href=\"#The-use-case\" class=\"headerlink\" title=\"The use case\"></a>The use case</h2><img class=\"blog/blog-third-party-overview.png\">\n<p>Example: If a customer buys a product in an ePages online shop, they could choose e.g. PayPal as payment method and DHL as delivery method.<br>The customer could also obtain an insurance with Trusted Shops.<br>(Read further <a href=\"http://www.epages.com/en/partner/technology-partner/\" target=\"_blank\" rel=\"external\">here</a> to get an overview of our technology partners.)<br>A checkout alone can easily have three third-party dependencies.</p>\n<p>The merchant, in turn, receives information via server-sided callbacks, if an order has been paid.<br>They can generate shipping labels via the web service of a third-party shipping method or synchronise their online shop with ERP-software.<br>These are just a few examples of third-party integrations at ePages.<br>There are a lot more use cases where both customer and merchant can use third-party services.</p>\n<p>Payment, deliveries, market places, marketing and tax calculation - for many applications, specialised services are available that have to be integrated into the platform at various locations.<br>In all of these areas new startup companies are founded that offer new services.<br>At the same time, also existing companies expand their service portfolio in order to not lose the connection in the dynamic e-commerce market.<br>These circumstances keep us busy not only in integrating new services periodically but also by maintaining the existing integrations.</p>\n<p>If companies expand abroad, as is the case at ePages, it might be required to include additional services, to being attractive for the merchants in that specific country.<br>We integrated e.g. USPS and FedEx, since it would not make any sense to enter the US market without an integration of these common US shipping agents.</p>\n<h2 id=\"Third-party-libraries-vs-Third-party-web-services\"><a href=\"#Third-party-libraries-vs-Third-party-web-services\" class=\"headerlink\" title=\"Third-party libraries vs Third-party web services\"></a>Third-party libraries vs Third-party web services</h2><p>Today’s software is mostly based on third-party components, as there are already proven solutions in place that can be easily reused.<br>Furthermore, these projects are supported by great communities that continuously develop the software and often are absolute experts in this respective field.</p>\n<p>However, with regards to third-party components we have to distinguish between third-party libraries and third-party web services.<br>Third-party libraries are integrated directly into the code base and remain unchanged until a new library version is included.</p>\n<p>Working with third-party web services is more complex.<br>Even if a third-party web service, other than a third-party library, does not directly expand the code base, one must never forget:<br>By integrating a third-party service, this service will be part of your software.<br>The software will be expanded by functionality that is dependent on the availability of the third-party web service and acts as expected.<br>This fact puts special demands on the developers.</p>\n<h2 id=\"The-challenge\"><a href=\"#The-challenge\" class=\"headerlink\" title=\"The challenge\"></a>The challenge</h2><p>Usually the only things we know about the third-party web service is the endpoint URL and a more or less helpful documentation.<br>The problem is, that not only the API itself, but also both the endpoint and the documentation, can change every time.<br>You will only notice the change if something does not work anymore.<br>Sometimes an SDK exists for the API that should facilitate working with it.<br>But sometimes the SDK does not support the latest API version or the required programming language is not available.</p>\n<p>Often the documentation was only produced in the national language of the API developers, making it impossible to understand the content.<br>The result is that integration problems cannot be fixed by our developers in Barcelona if the documentation is e.g. only available in German.</p>\n<h2 id=\"The-approach\"><a href=\"#The-approach\" class=\"headerlink\" title=\"The approach\"></a>The approach</h2><p>Ideally, we are in direct contact with the developers of the respective third-party to clarify any questions or concerns.<br>Unfortunately, that is not always the case.<br>In this case we have to find out by ourselves how the web service works using the trial-and-error method or reverse engineering.</p>\n<p>When working with a SOAP API, the WSDL-file that describes the service, provides many helpful bits of information.<br>Using a tool such as SoapUI, such a file can be analysed easily.<br>Even test requests can be sent via the SoapUI.</p>\n<p>For such tests, the third-party provides special test accounts.<br>Unfortunately, these are sometimes only valid for a limited period of time.<br>This is only then noticed, if the account is required again, e.g. if after some time problems with an integration arise that have to be fixed on short notice.</p>\n<p>To test our integrations we are writing Unit tests as well as integration and Selenium tests.<br>By carrying out these tests we are alerted to these problems at an early stage.</p>\n<p>Some companies even operate special test platforms with a separate endpoint.<br>What sounds like a very developer-friendly offer, has a major disadvantage: doing the tests on one system and using a different system for production.<br>Ideally, the test system should act exactly as the live-system, but that is not always the case.<br>This is especially annoying if after the rollout customers report problems that did not arise on the test platform.</p>\n<h2 id=\"The-conclusion\"><a href=\"#The-conclusion\" class=\"headerlink\" title=\"The conclusion\"></a>The conclusion</h2><p>All in all one can say that third-party integrations are challenging for developers.<br>But using suitable tools and a high test coverage can definitely help to master these challenges.<br>Go for it!</p>\n<p>A special thanks to our technology partners for informing us beforehand when they plan to make changes.</p>\n","excerpt":"","more":"<p>Third-party applications are an important part of the service that ePages offers.<br>As our applications are built on an internal application platform, ePages developers are highly dependent on third-party services.<br>Read more to find out why it is not the easiest thing to integrate third-parties and how we tackle this.</p>\n<h2 id=\"The-use-case\"><a href=\"#The-use-case\" class=\"headerlink\" title=\"The use case\"></a>The use case</h2><img class=\"blog/blog-third-party-overview.png\">\n<p>Example: If a customer buys a product in an ePages online shop, they could choose e.g. PayPal as payment method and DHL as delivery method.<br>The customer could also obtain an insurance with Trusted Shops.<br>(Read further <a href=\"http://www.epages.com/en/partner/technology-partner/\">here</a> to get an overview of our technology partners.)<br>A checkout alone can easily have three third-party dependencies.</p>\n<p>The merchant, in turn, receives information via server-sided callbacks, if an order has been paid.<br>They can generate shipping labels via the web service of a third-party shipping method or synchronise their online shop with ERP-software.<br>These are just a few examples of third-party integrations at ePages.<br>There are a lot more use cases where both customer and merchant can use third-party services.</p>\n<p>Payment, deliveries, market places, marketing and tax calculation - for many applications, specialised services are available that have to be integrated into the platform at various locations.<br>In all of these areas new startup companies are founded that offer new services.<br>At the same time, also existing companies expand their service portfolio in order to not lose the connection in the dynamic e-commerce market.<br>These circumstances keep us busy not only in integrating new services periodically but also by maintaining the existing integrations.</p>\n<p>If companies expand abroad, as is the case at ePages, it might be required to include additional services, to being attractive for the merchants in that specific country.<br>We integrated e.g. USPS and FedEx, since it would not make any sense to enter the US market without an integration of these common US shipping agents.</p>\n<h2 id=\"Third-party-libraries-vs-Third-party-web-services\"><a href=\"#Third-party-libraries-vs-Third-party-web-services\" class=\"headerlink\" title=\"Third-party libraries vs Third-party web services\"></a>Third-party libraries vs Third-party web services</h2><p>Today’s software is mostly based on third-party components, as there are already proven solutions in place that can be easily reused.<br>Furthermore, these projects are supported by great communities that continuously develop the software and often are absolute experts in this respective field.</p>\n<p>However, with regards to third-party components we have to distinguish between third-party libraries and third-party web services.<br>Third-party libraries are integrated directly into the code base and remain unchanged until a new library version is included.</p>\n<p>Working with third-party web services is more complex.<br>Even if a third-party web service, other than a third-party library, does not directly expand the code base, one must never forget:<br>By integrating a third-party service, this service will be part of your software.<br>The software will be expanded by functionality that is dependent on the availability of the third-party web service and acts as expected.<br>This fact puts special demands on the developers.</p>\n<h2 id=\"The-challenge\"><a href=\"#The-challenge\" class=\"headerlink\" title=\"The challenge\"></a>The challenge</h2><p>Usually the only things we know about the third-party web service is the endpoint URL and a more or less helpful documentation.<br>The problem is, that not only the API itself, but also both the endpoint and the documentation, can change every time.<br>You will only notice the change if something does not work anymore.<br>Sometimes an SDK exists for the API that should facilitate working with it.<br>But sometimes the SDK does not support the latest API version or the required programming language is not available.</p>\n<p>Often the documentation was only produced in the national language of the API developers, making it impossible to understand the content.<br>The result is that integration problems cannot be fixed by our developers in Barcelona if the documentation is e.g. only available in German.</p>\n<h2 id=\"The-approach\"><a href=\"#The-approach\" class=\"headerlink\" title=\"The approach\"></a>The approach</h2><p>Ideally, we are in direct contact with the developers of the respective third-party to clarify any questions or concerns.<br>Unfortunately, that is not always the case.<br>In this case we have to find out by ourselves how the web service works using the trial-and-error method or reverse engineering.</p>\n<p>When working with a SOAP API, the WSDL-file that describes the service, provides many helpful bits of information.<br>Using a tool such as SoapUI, such a file can be analysed easily.<br>Even test requests can be sent via the SoapUI.</p>\n<p>For such tests, the third-party provides special test accounts.<br>Unfortunately, these are sometimes only valid for a limited period of time.<br>This is only then noticed, if the account is required again, e.g. if after some time problems with an integration arise that have to be fixed on short notice.</p>\n<p>To test our integrations we are writing Unit tests as well as integration and Selenium tests.<br>By carrying out these tests we are alerted to these problems at an early stage.</p>\n<p>Some companies even operate special test platforms with a separate endpoint.<br>What sounds like a very developer-friendly offer, has a major disadvantage: doing the tests on one system and using a different system for production.<br>Ideally, the test system should act exactly as the live-system, but that is not always the case.<br>This is especially annoying if after the rollout customers report problems that did not arise on the test platform.</p>\n<h2 id=\"The-conclusion\"><a href=\"#The-conclusion\" class=\"headerlink\" title=\"The conclusion\"></a>The conclusion</h2><p>All in all one can say that third-party integrations are challenging for developers.<br>But using suitable tools and a high test coverage can definitely help to master these challenges.<br>Go for it!</p>\n<p>A special thanks to our technology partners for informing us beforehand when they plan to make changes.</p>\n"},{"layout":"post","title":"Creating systems with pipelining","date":"2015-08-03T00:00:00.000Z","image":"blog-header/pipelines.jpg","authors":["Carsten","Karsten"],"_content":"\nIf we talk about [pipelining](https://en.wikipedia.org/wiki/Pipeline_(software)) at ePages, we understand it as an automatic workflow.\nWe are integrating many steps using different tools to reach a specific goal: creating a simple way to provide a highly specialised system.\n\nThis system can be used for development purposes, external or even live deployment.\nThe setup used here is a combination of different software and tools.\nOne of them is [vmware](http://www.vmware.com/) with [vCenter](https://www.vmware.com/products/vcenter-server) and some [ESXi](https://www.vmware.com/products/vsphere/features/esxi-hypervisor) servers to offer and manage systems in a virtual environment.\nAnother tool we use is called [i-doit](http://www.i-doit.org/) and is used for creation and documentation of inventories and network related information.\nAs you may have read in a previous [post](https://developer.epages.com/blog/2015/06/25/infrastructure-as-code.html) we often use [Jenkins](https://jenkins-ci.org/) for [Continuous Integration](http://www.martinfowler.com/articles/continuousIntegration.html), so it's one of our favourite tools to automate processes.\nThe key of an automated OS install is the combination of [iPXE](http://ipxe.org/) and kickstart isos, for example preseed values for [Debian](https://wiki.debian.org/DebianInstaller/Preseed) or [Centos/RHEL](http://www.centos.org/docs/4/html/rhel-sag-en-4/s1-kickstart2-file.html).\nLast but not least when it comes to system specialisation [Linux](https://www.linux.com/) itself should be mentioned.\nTo speak with the different interfaces, programming languages like [`Perl`](https://www.perl.org/) and [`Python`](https://www.python.org/) or scripting languages like [`PHP`](https://secure.php.net/) and [`bash`](http://www.gnu.org/software/bash/) are used.\n\n{% image blog/blog-pipeline-tools.png %}\n\nThe basic idea is simple. First thing we need is a system.\n\n## The system\n\nThis is fairly simple, due to the [vSphere Cloud Plugin](https://wiki.jenkins-ci.org/display/JENKINS/vSphere+Cloud+Plugin) for Jenkins, it is easy to construct a job, building a basic virtual machine from a template.\nThese templates are predefined with a set of CPU, RAM, disc space as well as an iPXE kickstart iso file that is specifically OS mounted.\nIf it's needed, you can create and run an additional job changing the values of the machine before the install starts.\nManaging the network environment is a little bit more challenging.\nIn the simplest case a development system should be created, so the system needs an IP with internet access and an R/DNS entry.\nHere we killed two birds with one stone.\nBy using i-doit we provide at first the information about the new system to our documentation system via REST API and in the second step calculate the next free ip in our network.\nThe system is documented and we have all information we need to create a [DHCP](https://en.wikipedia.org/wiki/Dynamic_Host_Configuration_Protocol) and [DNS](https://en.wikipedia.org/wiki/Domain_Name_System) entry.\nUsing the API of i-doit the DHCP and DNS configuration files were generated, tested and deployed to our DHCP and DNS Servers.\n\n## Installation process\n\nNow we can start the virtual machine with our kickstart script installing the predefined OS.\nThe kickstart script uses iPXE boot, loads the configuration and installs the system.\nThe open source boot firmware iPXE allows us to boot an iso file over the network and supports dynamic or static IP configuration depending on your network.\nFor example for networks without DHCP you can hard code a static IP for an installation and change the network configuration after the initial installation has been done.\nThe loaded ISO files are preseed values for the specified OS that include all information the installation process process needs to install the OS.\nAt the moment Centos 6/7 and Debian 7/8 are supported from our side.\nAfter the installation, we have a first simple not very specialised system that could now be used.\nSome magic Jenkins jobs do the trick and specialise the system now.\n\n## Specialisation\n\nHere you can explore your creativity.\nMany jobs are available: from [security related configurations](https://www.linode.com/docs/security/securing-your-server) over installing of different software to installing our full ePages to a system with a specific version or project specific configurations.\nIn our situation it depends on the use case. For example internal development systems have other security related configurations than external systems, or test and live systems can have project specific configurations depending on what our customers need.\n\n## The pipeline\n\nHere is a simplified picture of the whole pipeline.\nThe full process lasts about 10 to 15 minutes but depends on the specific configuration you choose.\n\n{% image blog/blog-pipeline-jenkins.png %}\n\nIn the future we'd like to use the existing build pipelines to create distributed systems with our and other software.\n","source":"_posts/2015-08-03-creating-systems-with-pipelining.md","raw":"---\nlayout: post\ntitle: \"Creating systems with pipelining\"\ndate: \"2015-08-03\"\nimage: blog-header/pipelines.jpg\ncategories: tech-stories\nauthors: [\"Carsten\", \"Karsten\"]\n---\n\nIf we talk about [pipelining](https://en.wikipedia.org/wiki/Pipeline_(software)) at ePages, we understand it as an automatic workflow.\nWe are integrating many steps using different tools to reach a specific goal: creating a simple way to provide a highly specialised system.\n\nThis system can be used for development purposes, external or even live deployment.\nThe setup used here is a combination of different software and tools.\nOne of them is [vmware](http://www.vmware.com/) with [vCenter](https://www.vmware.com/products/vcenter-server) and some [ESXi](https://www.vmware.com/products/vsphere/features/esxi-hypervisor) servers to offer and manage systems in a virtual environment.\nAnother tool we use is called [i-doit](http://www.i-doit.org/) and is used for creation and documentation of inventories and network related information.\nAs you may have read in a previous [post](https://developer.epages.com/blog/2015/06/25/infrastructure-as-code.html) we often use [Jenkins](https://jenkins-ci.org/) for [Continuous Integration](http://www.martinfowler.com/articles/continuousIntegration.html), so it's one of our favourite tools to automate processes.\nThe key of an automated OS install is the combination of [iPXE](http://ipxe.org/) and kickstart isos, for example preseed values for [Debian](https://wiki.debian.org/DebianInstaller/Preseed) or [Centos/RHEL](http://www.centos.org/docs/4/html/rhel-sag-en-4/s1-kickstart2-file.html).\nLast but not least when it comes to system specialisation [Linux](https://www.linux.com/) itself should be mentioned.\nTo speak with the different interfaces, programming languages like [`Perl`](https://www.perl.org/) and [`Python`](https://www.python.org/) or scripting languages like [`PHP`](https://secure.php.net/) and [`bash`](http://www.gnu.org/software/bash/) are used.\n\n{% image blog/blog-pipeline-tools.png %}\n\nThe basic idea is simple. First thing we need is a system.\n\n## The system\n\nThis is fairly simple, due to the [vSphere Cloud Plugin](https://wiki.jenkins-ci.org/display/JENKINS/vSphere+Cloud+Plugin) for Jenkins, it is easy to construct a job, building a basic virtual machine from a template.\nThese templates are predefined with a set of CPU, RAM, disc space as well as an iPXE kickstart iso file that is specifically OS mounted.\nIf it's needed, you can create and run an additional job changing the values of the machine before the install starts.\nManaging the network environment is a little bit more challenging.\nIn the simplest case a development system should be created, so the system needs an IP with internet access and an R/DNS entry.\nHere we killed two birds with one stone.\nBy using i-doit we provide at first the information about the new system to our documentation system via REST API and in the second step calculate the next free ip in our network.\nThe system is documented and we have all information we need to create a [DHCP](https://en.wikipedia.org/wiki/Dynamic_Host_Configuration_Protocol) and [DNS](https://en.wikipedia.org/wiki/Domain_Name_System) entry.\nUsing the API of i-doit the DHCP and DNS configuration files were generated, tested and deployed to our DHCP and DNS Servers.\n\n## Installation process\n\nNow we can start the virtual machine with our kickstart script installing the predefined OS.\nThe kickstart script uses iPXE boot, loads the configuration and installs the system.\nThe open source boot firmware iPXE allows us to boot an iso file over the network and supports dynamic or static IP configuration depending on your network.\nFor example for networks without DHCP you can hard code a static IP for an installation and change the network configuration after the initial installation has been done.\nThe loaded ISO files are preseed values for the specified OS that include all information the installation process process needs to install the OS.\nAt the moment Centos 6/7 and Debian 7/8 are supported from our side.\nAfter the installation, we have a first simple not very specialised system that could now be used.\nSome magic Jenkins jobs do the trick and specialise the system now.\n\n## Specialisation\n\nHere you can explore your creativity.\nMany jobs are available: from [security related configurations](https://www.linode.com/docs/security/securing-your-server) over installing of different software to installing our full ePages to a system with a specific version or project specific configurations.\nIn our situation it depends on the use case. For example internal development systems have other security related configurations than external systems, or test and live systems can have project specific configurations depending on what our customers need.\n\n## The pipeline\n\nHere is a simplified picture of the whole pipeline.\nThe full process lasts about 10 to 15 minutes but depends on the specific configuration you choose.\n\n{% image blog/blog-pipeline-jenkins.png %}\n\nIn the future we'd like to use the existing build pipelines to create distributed systems with our and other software.\n","slug":"2015-08-03-creating-systems-with-pipelining","published":1,"updated":"2016-09-20T14:19:22.000Z","comments":1,"photos":[],"link":"","_id":"ciu6nuh8o000rhqyxpgr9j1uo","content":"<p>If we talk about <a href=\"https://en.wikipedia.org/wiki/Pipeline_(software\" target=\"_blank\" rel=\"external\">pipelining</a>) at ePages, we understand it as an automatic workflow.<br>We are integrating many steps using different tools to reach a specific goal: creating a simple way to provide a highly specialised system.</p>\n<p>This system can be used for development purposes, external or even live deployment.<br>The setup used here is a combination of different software and tools.<br>One of them is <a href=\"http://www.vmware.com/\" target=\"_blank\" rel=\"external\">vmware</a> with <a href=\"https://www.vmware.com/products/vcenter-server\" target=\"_blank\" rel=\"external\">vCenter</a> and some <a href=\"https://www.vmware.com/products/vsphere/features/esxi-hypervisor\" target=\"_blank\" rel=\"external\">ESXi</a> servers to offer and manage systems in a virtual environment.<br>Another tool we use is called <a href=\"http://www.i-doit.org/\" target=\"_blank\" rel=\"external\">i-doit</a> and is used for creation and documentation of inventories and network related information.<br>As you may have read in a previous <a href=\"https://developer.epages.com/blog/2015/06/25/infrastructure-as-code.html\" target=\"_blank\" rel=\"external\">post</a> we often use <a href=\"https://jenkins-ci.org/\" target=\"_blank\" rel=\"external\">Jenkins</a> for <a href=\"http://www.martinfowler.com/articles/continuousIntegration.html\" target=\"_blank\" rel=\"external\">Continuous Integration</a>, so it’s one of our favourite tools to automate processes.<br>The key of an automated OS install is the combination of <a href=\"http://ipxe.org/\" target=\"_blank\" rel=\"external\">iPXE</a> and kickstart isos, for example preseed values for <a href=\"https://wiki.debian.org/DebianInstaller/Preseed\" target=\"_blank\" rel=\"external\">Debian</a> or <a href=\"http://www.centos.org/docs/4/html/rhel-sag-en-4/s1-kickstart2-file.html\" target=\"_blank\" rel=\"external\">Centos/RHEL</a>.<br>Last but not least when it comes to system specialisation <a href=\"https://www.linux.com/\" target=\"_blank\" rel=\"external\">Linux</a> itself should be mentioned.<br>To speak with the different interfaces, programming languages like <a href=\"https://www.perl.org/\" target=\"_blank\" rel=\"external\"><code>Perl</code></a> and <a href=\"https://www.python.org/\" target=\"_blank\" rel=\"external\"><code>Python</code></a> or scripting languages like <a href=\"https://secure.php.net/\" target=\"_blank\" rel=\"external\"><code>PHP</code></a> and <a href=\"http://www.gnu.org/software/bash/\" target=\"_blank\" rel=\"external\"><code>bash</code></a> are used.</p>\n<img class=\"blog/blog-pipeline-tools.png\">\n<p>The basic idea is simple. First thing we need is a system.</p>\n<h2 id=\"The-system\"><a href=\"#The-system\" class=\"headerlink\" title=\"The system\"></a>The system</h2><p>This is fairly simple, due to the <a href=\"https://wiki.jenkins-ci.org/display/JENKINS/vSphere+Cloud+Plugin\" target=\"_blank\" rel=\"external\">vSphere Cloud Plugin</a> for Jenkins, it is easy to construct a job, building a basic virtual machine from a template.<br>These templates are predefined with a set of CPU, RAM, disc space as well as an iPXE kickstart iso file that is specifically OS mounted.<br>If it’s needed, you can create and run an additional job changing the values of the machine before the install starts.<br>Managing the network environment is a little bit more challenging.<br>In the simplest case a development system should be created, so the system needs an IP with internet access and an R/DNS entry.<br>Here we killed two birds with one stone.<br>By using i-doit we provide at first the information about the new system to our documentation system via REST API and in the second step calculate the next free ip in our network.<br>The system is documented and we have all information we need to create a <a href=\"https://en.wikipedia.org/wiki/Dynamic_Host_Configuration_Protocol\" target=\"_blank\" rel=\"external\">DHCP</a> and <a href=\"https://en.wikipedia.org/wiki/Domain_Name_System\" target=\"_blank\" rel=\"external\">DNS</a> entry.<br>Using the API of i-doit the DHCP and DNS configuration files were generated, tested and deployed to our DHCP and DNS Servers.</p>\n<h2 id=\"Installation-process\"><a href=\"#Installation-process\" class=\"headerlink\" title=\"Installation process\"></a>Installation process</h2><p>Now we can start the virtual machine with our kickstart script installing the predefined OS.<br>The kickstart script uses iPXE boot, loads the configuration and installs the system.<br>The open source boot firmware iPXE allows us to boot an iso file over the network and supports dynamic or static IP configuration depending on your network.<br>For example for networks without DHCP you can hard code a static IP for an installation and change the network configuration after the initial installation has been done.<br>The loaded ISO files are preseed values for the specified OS that include all information the installation process process needs to install the OS.<br>At the moment Centos 6/7 and Debian 7/8 are supported from our side.<br>After the installation, we have a first simple not very specialised system that could now be used.<br>Some magic Jenkins jobs do the trick and specialise the system now.</p>\n<h2 id=\"Specialisation\"><a href=\"#Specialisation\" class=\"headerlink\" title=\"Specialisation\"></a>Specialisation</h2><p>Here you can explore your creativity.<br>Many jobs are available: from <a href=\"https://www.linode.com/docs/security/securing-your-server\" target=\"_blank\" rel=\"external\">security related configurations</a> over installing of different software to installing our full ePages to a system with a specific version or project specific configurations.<br>In our situation it depends on the use case. For example internal development systems have other security related configurations than external systems, or test and live systems can have project specific configurations depending on what our customers need.</p>\n<h2 id=\"The-pipeline\"><a href=\"#The-pipeline\" class=\"headerlink\" title=\"The pipeline\"></a>The pipeline</h2><p>Here is a simplified picture of the whole pipeline.<br>The full process lasts about 10 to 15 minutes but depends on the specific configuration you choose.</p>\n<img class=\"blog/blog-pipeline-jenkins.png\">\n<p>In the future we’d like to use the existing build pipelines to create distributed systems with our and other software.</p>\n","excerpt":"","more":"<p>If we talk about <a href=\"https://en.wikipedia.org/wiki/Pipeline_(software\">pipelining</a>) at ePages, we understand it as an automatic workflow.<br>We are integrating many steps using different tools to reach a specific goal: creating a simple way to provide a highly specialised system.</p>\n<p>This system can be used for development purposes, external or even live deployment.<br>The setup used here is a combination of different software and tools.<br>One of them is <a href=\"http://www.vmware.com/\">vmware</a> with <a href=\"https://www.vmware.com/products/vcenter-server\">vCenter</a> and some <a href=\"https://www.vmware.com/products/vsphere/features/esxi-hypervisor\">ESXi</a> servers to offer and manage systems in a virtual environment.<br>Another tool we use is called <a href=\"http://www.i-doit.org/\">i-doit</a> and is used for creation and documentation of inventories and network related information.<br>As you may have read in a previous <a href=\"https://developer.epages.com/blog/2015/06/25/infrastructure-as-code.html\">post</a> we often use <a href=\"https://jenkins-ci.org/\">Jenkins</a> for <a href=\"http://www.martinfowler.com/articles/continuousIntegration.html\">Continuous Integration</a>, so it’s one of our favourite tools to automate processes.<br>The key of an automated OS install is the combination of <a href=\"http://ipxe.org/\">iPXE</a> and kickstart isos, for example preseed values for <a href=\"https://wiki.debian.org/DebianInstaller/Preseed\">Debian</a> or <a href=\"http://www.centos.org/docs/4/html/rhel-sag-en-4/s1-kickstart2-file.html\">Centos/RHEL</a>.<br>Last but not least when it comes to system specialisation <a href=\"https://www.linux.com/\">Linux</a> itself should be mentioned.<br>To speak with the different interfaces, programming languages like <a href=\"https://www.perl.org/\"><code>Perl</code></a> and <a href=\"https://www.python.org/\"><code>Python</code></a> or scripting languages like <a href=\"https://secure.php.net/\"><code>PHP</code></a> and <a href=\"http://www.gnu.org/software/bash/\"><code>bash</code></a> are used.</p>\n<img class=\"blog/blog-pipeline-tools.png\">\n<p>The basic idea is simple. First thing we need is a system.</p>\n<h2 id=\"The-system\"><a href=\"#The-system\" class=\"headerlink\" title=\"The system\"></a>The system</h2><p>This is fairly simple, due to the <a href=\"https://wiki.jenkins-ci.org/display/JENKINS/vSphere+Cloud+Plugin\">vSphere Cloud Plugin</a> for Jenkins, it is easy to construct a job, building a basic virtual machine from a template.<br>These templates are predefined with a set of CPU, RAM, disc space as well as an iPXE kickstart iso file that is specifically OS mounted.<br>If it’s needed, you can create and run an additional job changing the values of the machine before the install starts.<br>Managing the network environment is a little bit more challenging.<br>In the simplest case a development system should be created, so the system needs an IP with internet access and an R/DNS entry.<br>Here we killed two birds with one stone.<br>By using i-doit we provide at first the information about the new system to our documentation system via REST API and in the second step calculate the next free ip in our network.<br>The system is documented and we have all information we need to create a <a href=\"https://en.wikipedia.org/wiki/Dynamic_Host_Configuration_Protocol\">DHCP</a> and <a href=\"https://en.wikipedia.org/wiki/Domain_Name_System\">DNS</a> entry.<br>Using the API of i-doit the DHCP and DNS configuration files were generated, tested and deployed to our DHCP and DNS Servers.</p>\n<h2 id=\"Installation-process\"><a href=\"#Installation-process\" class=\"headerlink\" title=\"Installation process\"></a>Installation process</h2><p>Now we can start the virtual machine with our kickstart script installing the predefined OS.<br>The kickstart script uses iPXE boot, loads the configuration and installs the system.<br>The open source boot firmware iPXE allows us to boot an iso file over the network and supports dynamic or static IP configuration depending on your network.<br>For example for networks without DHCP you can hard code a static IP for an installation and change the network configuration after the initial installation has been done.<br>The loaded ISO files are preseed values for the specified OS that include all information the installation process process needs to install the OS.<br>At the moment Centos 6/7 and Debian 7/8 are supported from our side.<br>After the installation, we have a first simple not very specialised system that could now be used.<br>Some magic Jenkins jobs do the trick and specialise the system now.</p>\n<h2 id=\"Specialisation\"><a href=\"#Specialisation\" class=\"headerlink\" title=\"Specialisation\"></a>Specialisation</h2><p>Here you can explore your creativity.<br>Many jobs are available: from <a href=\"https://www.linode.com/docs/security/securing-your-server\">security related configurations</a> over installing of different software to installing our full ePages to a system with a specific version or project specific configurations.<br>In our situation it depends on the use case. For example internal development systems have other security related configurations than external systems, or test and live systems can have project specific configurations depending on what our customers need.</p>\n<h2 id=\"The-pipeline\"><a href=\"#The-pipeline\" class=\"headerlink\" title=\"The pipeline\"></a>The pipeline</h2><p>Here is a simplified picture of the whole pipeline.<br>The full process lasts about 10 to 15 minutes but depends on the specific configuration you choose.</p>\n<img class=\"blog/blog-pipeline-jenkins.png\">\n<p>In the future we’d like to use the existing build pipelines to create distributed systems with our and other software.</p>\n"},{"layout":"post","title":"BarCamp Kiel 2015 - A short review","date":"2015-09-02T12:51:00.000Z","authors":["David"],"_content":"\nLast weekend, more than 80 developers, designers, bloggers and shop owners participated in the 6. [BarCamp in Kiel](http://barcamp-kiel.de), Germany.\nThey all joined different lectures and discussed several topics.\nThis year, the focus was laid on technology, media and education.\nRead on for a short review on the topics.\n\n## What is a BarCamp?\n\nA BarCamp is an international conference with only user-generated lectures and speeches and no set agenda in advance.\nEvery person interested can join for free and take part in interesting discussions.\nThe main topics are technology and media, but most of the BarCamps focus on special subjects like medicine or social science.\nIf you're interested in participating in a BarCamp, search [online](http://t3n.de/news/grosser-barcamp-ueberblick-alle-488972/) and feel free to join.\n\n## LECTURE: Clean code and testing\n\nOne of the most interesting topics for developers is the challenge to write complex code without losing the focus on a clean and structured architecture.\nAdditionally, this code should be tested and work properly after having changed some lines.\nSeveral tools help to ensure this.\n\nBut how tidy should source code be without losing focus in a fast-weight development?\nAnd which tools can help to optimise code and test it regularly?\n\nA good base can be given by the continuous integration tool [Jenkins](http://jenkins-ci.org/).\nIt's open source and helps to develop any component to a programme.\nOther important software comes with programming in Java.\nThe tool [FindBugs](http://findbugs.sourceforge.net) helps to find errors in code before the software crashes.\nWith [JUnit][junit] you can test your software.\n[Checkstyle](http://checkstyle.sourceforge.net/) is a nice feature to define developing standards like numbers of chars per line.\nAll this software is available as a plugin for the IDE [Eclipse](https://www.eclipse.org/downloads/).\n\nGood books on code standards are: [\"Clean Code\" by Robert Martin](https://www.google.de/search?tbm=bks&hl=de&q=isbn%3A9780132350884) or [\"Writing Effectively with Legacy Code\" by Michael Feathers](https://www.google.de/search?tbm=bks&hl=de&q=isbn%3A9780132931755).\nThe  question about clean code is: how well should the code quality be in relation to the quantity?\n\n## LECTURE: The mBot\n\nA common question is, how early and deep should the education of information technology start at school.\nSchool lessons in computer science give the wrong overview on planning, developing and understanding software principles and their ideas.\nTo educate younger (and maybe also older) people on software development, the Chinese company [Makeblock](http://www.makeblock.cc/) created a robot called [\"mBot\"](http://mblock.cc/mbot/).\nThese projects support children to learn simple software algorithms.\nThey use the graphic user interface [\"Scratch\"][scratch] to let the robot move, see and react with the surrounding.\n\nThere are several other educational concepts for learning informatics at school.\nThe company [Lego](http://www.lego.com/en-gb/technic) hosts the [First Lego League competition](http://www.first-lego-league.org/en/) every year, the network [Roberta](http://roberta-home.de/en) is closely connected with schools to implement this.\n\n## LECTURE: Gamification in projects\n\nOne of the lectures was related to team and project organisation, e.g. how to motivate teams over a long time in discouraging projects.\n\nA concept for the long-time motivation is the Gamification.\nCurrently, Gamification is present in customer software.\nSoftware allures with ranking lists and virtual goods.\nIs it possible to adapt this concept to the team structure?\nAn interesting concept like [ClassCraft](http://www.classcraft.com/) shows that this work.\nThe idea is to motivate younger people with role-playing games.\nThe student gets bonuses for example, one solved question in the next math test for helping other students and doing social things.\n\nIf Gamification should work, two ideas should be considered: the person taking part in the Gamification should not see the real aim, i.e. carrying out a task.\nAnd they should not be aware of all the \"rules\".\nThey should not see what is needed to win the game.\nSome companies try concepts like presenting a list of unpopular tasks.\nIf an employee finishes a defined number of theses tasks, they will receive a day of vacation.\nAlso, an interesting idea is to bet on a team related number after a special time period.\nSome teams in companies bet on the number of tasks solved after a month.\n","source":"_posts/2015-09-02-barcamp-kiel-2015.md","raw":"---\nlayout: post\ntitle: \"BarCamp Kiel 2015 - A short review\"\ndate: \"2015-09-02 14:51:00\"\ncategories: events\nauthors: [\"David\"]\n---\n\nLast weekend, more than 80 developers, designers, bloggers and shop owners participated in the 6. [BarCamp in Kiel](http://barcamp-kiel.de), Germany.\nThey all joined different lectures and discussed several topics.\nThis year, the focus was laid on technology, media and education.\nRead on for a short review on the topics.\n\n## What is a BarCamp?\n\nA BarCamp is an international conference with only user-generated lectures and speeches and no set agenda in advance.\nEvery person interested can join for free and take part in interesting discussions.\nThe main topics are technology and media, but most of the BarCamps focus on special subjects like medicine or social science.\nIf you're interested in participating in a BarCamp, search [online](http://t3n.de/news/grosser-barcamp-ueberblick-alle-488972/) and feel free to join.\n\n## LECTURE: Clean code and testing\n\nOne of the most interesting topics for developers is the challenge to write complex code without losing the focus on a clean and structured architecture.\nAdditionally, this code should be tested and work properly after having changed some lines.\nSeveral tools help to ensure this.\n\nBut how tidy should source code be without losing focus in a fast-weight development?\nAnd which tools can help to optimise code and test it regularly?\n\nA good base can be given by the continuous integration tool [Jenkins](http://jenkins-ci.org/).\nIt's open source and helps to develop any component to a programme.\nOther important software comes with programming in Java.\nThe tool [FindBugs](http://findbugs.sourceforge.net) helps to find errors in code before the software crashes.\nWith [JUnit][junit] you can test your software.\n[Checkstyle](http://checkstyle.sourceforge.net/) is a nice feature to define developing standards like numbers of chars per line.\nAll this software is available as a plugin for the IDE [Eclipse](https://www.eclipse.org/downloads/).\n\nGood books on code standards are: [\"Clean Code\" by Robert Martin](https://www.google.de/search?tbm=bks&hl=de&q=isbn%3A9780132350884) or [\"Writing Effectively with Legacy Code\" by Michael Feathers](https://www.google.de/search?tbm=bks&hl=de&q=isbn%3A9780132931755).\nThe  question about clean code is: how well should the code quality be in relation to the quantity?\n\n## LECTURE: The mBot\n\nA common question is, how early and deep should the education of information technology start at school.\nSchool lessons in computer science give the wrong overview on planning, developing and understanding software principles and their ideas.\nTo educate younger (and maybe also older) people on software development, the Chinese company [Makeblock](http://www.makeblock.cc/) created a robot called [\"mBot\"](http://mblock.cc/mbot/).\nThese projects support children to learn simple software algorithms.\nThey use the graphic user interface [\"Scratch\"][scratch] to let the robot move, see and react with the surrounding.\n\nThere are several other educational concepts for learning informatics at school.\nThe company [Lego](http://www.lego.com/en-gb/technic) hosts the [First Lego League competition](http://www.first-lego-league.org/en/) every year, the network [Roberta](http://roberta-home.de/en) is closely connected with schools to implement this.\n\n## LECTURE: Gamification in projects\n\nOne of the lectures was related to team and project organisation, e.g. how to motivate teams over a long time in discouraging projects.\n\nA concept for the long-time motivation is the Gamification.\nCurrently, Gamification is present in customer software.\nSoftware allures with ranking lists and virtual goods.\nIs it possible to adapt this concept to the team structure?\nAn interesting concept like [ClassCraft](http://www.classcraft.com/) shows that this work.\nThe idea is to motivate younger people with role-playing games.\nThe student gets bonuses for example, one solved question in the next math test for helping other students and doing social things.\n\nIf Gamification should work, two ideas should be considered: the person taking part in the Gamification should not see the real aim, i.e. carrying out a task.\nAnd they should not be aware of all the \"rules\".\nThey should not see what is needed to win the game.\nSome companies try concepts like presenting a list of unpopular tasks.\nIf an employee finishes a defined number of theses tasks, they will receive a day of vacation.\nAlso, an interesting idea is to bet on a team related number after a special time period.\nSome teams in companies bet on the number of tasks solved after a month.\n","slug":"2015-09-02-barcamp-kiel-2015","published":1,"updated":"2016-09-20T14:19:22.000Z","comments":1,"photos":[],"link":"","_id":"ciu6nuh8r000thqyx0vmur6rt","content":"<p>Last weekend, more than 80 developers, designers, bloggers and shop owners participated in the 6. <a href=\"http://barcamp-kiel.de\" target=\"_blank\" rel=\"external\">BarCamp in Kiel</a>, Germany.<br>They all joined different lectures and discussed several topics.<br>This year, the focus was laid on technology, media and education.<br>Read on for a short review on the topics.</p>\n<h2 id=\"What-is-a-BarCamp\"><a href=\"#What-is-a-BarCamp\" class=\"headerlink\" title=\"What is a BarCamp?\"></a>What is a BarCamp?</h2><p>A BarCamp is an international conference with only user-generated lectures and speeches and no set agenda in advance.<br>Every person interested can join for free and take part in interesting discussions.<br>The main topics are technology and media, but most of the BarCamps focus on special subjects like medicine or social science.<br>If you’re interested in participating in a BarCamp, search <a href=\"http://t3n.de/news/grosser-barcamp-ueberblick-alle-488972/\" target=\"_blank\" rel=\"external\">online</a> and feel free to join.</p>\n<h2 id=\"LECTURE-Clean-code-and-testing\"><a href=\"#LECTURE-Clean-code-and-testing\" class=\"headerlink\" title=\"LECTURE: Clean code and testing\"></a>LECTURE: Clean code and testing</h2><p>One of the most interesting topics for developers is the challenge to write complex code without losing the focus on a clean and structured architecture.<br>Additionally, this code should be tested and work properly after having changed some lines.<br>Several tools help to ensure this.</p>\n<p>But how tidy should source code be without losing focus in a fast-weight development?<br>And which tools can help to optimise code and test it regularly?</p>\n<p>A good base can be given by the continuous integration tool <a href=\"http://jenkins-ci.org/\" target=\"_blank\" rel=\"external\">Jenkins</a>.<br>It’s open source and helps to develop any component to a programme.<br>Other important software comes with programming in Java.<br>The tool <a href=\"http://findbugs.sourceforge.net\" target=\"_blank\" rel=\"external\">FindBugs</a> helps to find errors in code before the software crashes.<br>With [JUnit][junit] you can test your software.<br><a href=\"http://checkstyle.sourceforge.net/\" target=\"_blank\" rel=\"external\">Checkstyle</a> is a nice feature to define developing standards like numbers of chars per line.<br>All this software is available as a plugin for the IDE <a href=\"https://www.eclipse.org/downloads/\" target=\"_blank\" rel=\"external\">Eclipse</a>.</p>\n<p>Good books on code standards are: <a href=\"https://www.google.de/search?tbm=bks&amp;hl=de&amp;q=isbn%3A9780132350884\" target=\"_blank\" rel=\"external\">“Clean Code” by Robert Martin</a> or <a href=\"https://www.google.de/search?tbm=bks&amp;hl=de&amp;q=isbn%3A9780132931755\" target=\"_blank\" rel=\"external\">“Writing Effectively with Legacy Code” by Michael Feathers</a>.<br>The  question about clean code is: how well should the code quality be in relation to the quantity?</p>\n<h2 id=\"LECTURE-The-mBot\"><a href=\"#LECTURE-The-mBot\" class=\"headerlink\" title=\"LECTURE: The mBot\"></a>LECTURE: The mBot</h2><p>A common question is, how early and deep should the education of information technology start at school.<br>School lessons in computer science give the wrong overview on planning, developing and understanding software principles and their ideas.<br>To educate younger (and maybe also older) people on software development, the Chinese company <a href=\"http://www.makeblock.cc/\" target=\"_blank\" rel=\"external\">Makeblock</a> created a robot called <a href=\"http://mblock.cc/mbot/\" target=\"_blank\" rel=\"external\">“mBot”</a>.<br>These projects support children to learn simple software algorithms.<br>They use the graphic user interface [“Scratch”][scratch] to let the robot move, see and react with the surrounding.</p>\n<p>There are several other educational concepts for learning informatics at school.<br>The company <a href=\"http://www.lego.com/en-gb/technic\" target=\"_blank\" rel=\"external\">Lego</a> hosts the <a href=\"http://www.first-lego-league.org/en/\" target=\"_blank\" rel=\"external\">First Lego League competition</a> every year, the network <a href=\"http://roberta-home.de/en\" target=\"_blank\" rel=\"external\">Roberta</a> is closely connected with schools to implement this.</p>\n<h2 id=\"LECTURE-Gamification-in-projects\"><a href=\"#LECTURE-Gamification-in-projects\" class=\"headerlink\" title=\"LECTURE: Gamification in projects\"></a>LECTURE: Gamification in projects</h2><p>One of the lectures was related to team and project organisation, e.g. how to motivate teams over a long time in discouraging projects.</p>\n<p>A concept for the long-time motivation is the Gamification.<br>Currently, Gamification is present in customer software.<br>Software allures with ranking lists and virtual goods.<br>Is it possible to adapt this concept to the team structure?<br>An interesting concept like <a href=\"http://www.classcraft.com/\" target=\"_blank\" rel=\"external\">ClassCraft</a> shows that this work.<br>The idea is to motivate younger people with role-playing games.<br>The student gets bonuses for example, one solved question in the next math test for helping other students and doing social things.</p>\n<p>If Gamification should work, two ideas should be considered: the person taking part in the Gamification should not see the real aim, i.e. carrying out a task.<br>And they should not be aware of all the “rules”.<br>They should not see what is needed to win the game.<br>Some companies try concepts like presenting a list of unpopular tasks.<br>If an employee finishes a defined number of theses tasks, they will receive a day of vacation.<br>Also, an interesting idea is to bet on a team related number after a special time period.<br>Some teams in companies bet on the number of tasks solved after a month.</p>\n","excerpt":"","more":"<p>Last weekend, more than 80 developers, designers, bloggers and shop owners participated in the 6. <a href=\"http://barcamp-kiel.de\">BarCamp in Kiel</a>, Germany.<br>They all joined different lectures and discussed several topics.<br>This year, the focus was laid on technology, media and education.<br>Read on for a short review on the topics.</p>\n<h2 id=\"What-is-a-BarCamp\"><a href=\"#What-is-a-BarCamp\" class=\"headerlink\" title=\"What is a BarCamp?\"></a>What is a BarCamp?</h2><p>A BarCamp is an international conference with only user-generated lectures and speeches and no set agenda in advance.<br>Every person interested can join for free and take part in interesting discussions.<br>The main topics are technology and media, but most of the BarCamps focus on special subjects like medicine or social science.<br>If you’re interested in participating in a BarCamp, search <a href=\"http://t3n.de/news/grosser-barcamp-ueberblick-alle-488972/\">online</a> and feel free to join.</p>\n<h2 id=\"LECTURE-Clean-code-and-testing\"><a href=\"#LECTURE-Clean-code-and-testing\" class=\"headerlink\" title=\"LECTURE: Clean code and testing\"></a>LECTURE: Clean code and testing</h2><p>One of the most interesting topics for developers is the challenge to write complex code without losing the focus on a clean and structured architecture.<br>Additionally, this code should be tested and work properly after having changed some lines.<br>Several tools help to ensure this.</p>\n<p>But how tidy should source code be without losing focus in a fast-weight development?<br>And which tools can help to optimise code and test it regularly?</p>\n<p>A good base can be given by the continuous integration tool <a href=\"http://jenkins-ci.org/\">Jenkins</a>.<br>It’s open source and helps to develop any component to a programme.<br>Other important software comes with programming in Java.<br>The tool <a href=\"http://findbugs.sourceforge.net\">FindBugs</a> helps to find errors in code before the software crashes.<br>With [JUnit][junit] you can test your software.<br><a href=\"http://checkstyle.sourceforge.net/\">Checkstyle</a> is a nice feature to define developing standards like numbers of chars per line.<br>All this software is available as a plugin for the IDE <a href=\"https://www.eclipse.org/downloads/\">Eclipse</a>.</p>\n<p>Good books on code standards are: <a href=\"https://www.google.de/search?tbm=bks&amp;hl=de&amp;q=isbn%3A9780132350884\">“Clean Code” by Robert Martin</a> or <a href=\"https://www.google.de/search?tbm=bks&amp;hl=de&amp;q=isbn%3A9780132931755\">“Writing Effectively with Legacy Code” by Michael Feathers</a>.<br>The  question about clean code is: how well should the code quality be in relation to the quantity?</p>\n<h2 id=\"LECTURE-The-mBot\"><a href=\"#LECTURE-The-mBot\" class=\"headerlink\" title=\"LECTURE: The mBot\"></a>LECTURE: The mBot</h2><p>A common question is, how early and deep should the education of information technology start at school.<br>School lessons in computer science give the wrong overview on planning, developing and understanding software principles and their ideas.<br>To educate younger (and maybe also older) people on software development, the Chinese company <a href=\"http://www.makeblock.cc/\">Makeblock</a> created a robot called <a href=\"http://mblock.cc/mbot/\">“mBot”</a>.<br>These projects support children to learn simple software algorithms.<br>They use the graphic user interface [“Scratch”][scratch] to let the robot move, see and react with the surrounding.</p>\n<p>There are several other educational concepts for learning informatics at school.<br>The company <a href=\"http://www.lego.com/en-gb/technic\">Lego</a> hosts the <a href=\"http://www.first-lego-league.org/en/\">First Lego League competition</a> every year, the network <a href=\"http://roberta-home.de/en\">Roberta</a> is closely connected with schools to implement this.</p>\n<h2 id=\"LECTURE-Gamification-in-projects\"><a href=\"#LECTURE-Gamification-in-projects\" class=\"headerlink\" title=\"LECTURE: Gamification in projects\"></a>LECTURE: Gamification in projects</h2><p>One of the lectures was related to team and project organisation, e.g. how to motivate teams over a long time in discouraging projects.</p>\n<p>A concept for the long-time motivation is the Gamification.<br>Currently, Gamification is present in customer software.<br>Software allures with ranking lists and virtual goods.<br>Is it possible to adapt this concept to the team structure?<br>An interesting concept like <a href=\"http://www.classcraft.com/\">ClassCraft</a> shows that this work.<br>The idea is to motivate younger people with role-playing games.<br>The student gets bonuses for example, one solved question in the next math test for helping other students and doing social things.</p>\n<p>If Gamification should work, two ideas should be considered: the person taking part in the Gamification should not see the real aim, i.e. carrying out a task.<br>And they should not be aware of all the “rules”.<br>They should not see what is needed to win the game.<br>Some companies try concepts like presenting a list of unpopular tasks.<br>If an employee finishes a defined number of theses tasks, they will receive a day of vacation.<br>Also, an interesting idea is to bet on a team related number after a special time period.<br>Some teams in companies bet on the number of tasks solved after a month.</p>\n"},{"layout":"post","title":"Help us improve our API documentation","date":"2015-09-04T08:20:00.000Z","image":"blog-header/tools.jpg","authors":["Birgit"],"_content":"\nOpinions, views and also tastes differ on how an API documentation should be structured, which information should be provided and in which level of detail is appropriate.\nOf course, the aim is to provide all important and required information for developers working with our API to keep things simple and easy to handle.\nIn order to achieve this, we'd like to involve the most important target group here: developers!\n\nWe prepared a short survey to find out more about the expectations and requirements you have in order to easily work with an API documentation.\nWe kindly ask you to participate and share your opinion with us.\nThe survey will take approx. 5 to 10 minutes.\n\n[Participate now!](http://eshop.polldaddy.com/s/api-documentation)\n\nThank you for your support!\n","source":"_posts/2015-09-04-survey-improve-api-docu.md","raw":"---\nlayout: post\ntitle: \"Help us improve our API documentation\"\ndate: \"2015-09-04 10:20:00\"\nimage: blog-header/tools.jpg\ncategories: api\nauthors: [\"Birgit\"]\n---\n\nOpinions, views and also tastes differ on how an API documentation should be structured, which information should be provided and in which level of detail is appropriate.\nOf course, the aim is to provide all important and required information for developers working with our API to keep things simple and easy to handle.\nIn order to achieve this, we'd like to involve the most important target group here: developers!\n\nWe prepared a short survey to find out more about the expectations and requirements you have in order to easily work with an API documentation.\nWe kindly ask you to participate and share your opinion with us.\nThe survey will take approx. 5 to 10 minutes.\n\n[Participate now!](http://eshop.polldaddy.com/s/api-documentation)\n\nThank you for your support!\n","slug":"2015-09-04-survey-improve-api-docu","published":1,"updated":"2016-09-20T14:19:22.000Z","comments":1,"photos":[],"link":"","_id":"ciu6nuh8s000vhqyxlrpcu3nb","content":"<p>Opinions, views and also tastes differ on how an API documentation should be structured, which information should be provided and in which level of detail is appropriate.<br>Of course, the aim is to provide all important and required information for developers working with our API to keep things simple and easy to handle.<br>In order to achieve this, we’d like to involve the most important target group here: developers!</p>\n<p>We prepared a short survey to find out more about the expectations and requirements you have in order to easily work with an API documentation.<br>We kindly ask you to participate and share your opinion with us.<br>The survey will take approx. 5 to 10 minutes.</p>\n<p><a href=\"http://eshop.polldaddy.com/s/api-documentation\" target=\"_blank\" rel=\"external\">Participate now!</a></p>\n<p>Thank you for your support!</p>\n","excerpt":"","more":"<p>Opinions, views and also tastes differ on how an API documentation should be structured, which information should be provided and in which level of detail is appropriate.<br>Of course, the aim is to provide all important and required information for developers working with our API to keep things simple and easy to handle.<br>In order to achieve this, we’d like to involve the most important target group here: developers!</p>\n<p>We prepared a short survey to find out more about the expectations and requirements you have in order to easily work with an API documentation.<br>We kindly ask you to participate and share your opinion with us.<br>The survey will take approx. 5 to 10 minutes.</p>\n<p><a href=\"http://eshop.polldaddy.com/s/api-documentation\">Participate now!</a></p>\n<p>Thank you for your support!</p>\n"},{"layout":"post","title":"ePages talks REST API","date":"2015-09-08T06:10:00.000Z","image":"blog-header/talk.jpg","authors":["Birgit"],"_content":"\nHave you signed up for the [`code.talks`](https://www.codetalks.de/) 2015 in Hamburg?\nThis conference thrives on a variety of interesting topics in the field of web development, exciting talks and of course lots of fun.\nAnd we're participating!\n\nSpeaker: Oliver Trosien\n\nTopic: Documented and Tested Microservices for Fun and Profit\n\nDate & Time: 30th of September 2015, 10:00 - 10:45 a.m.\n\nLocation: Room 7\n\nAbstract: Software documentation is not one of a developer's best-loved topics.\nIn the field of Microservices, it is therefore all the more important to provide a meaningful and well documented REST API that other teams and external developers can build upon.\nSo, let's build some nice REST API docs!\n\nThe `code.talks` will be also a great chance to meet with ePages developers and designers to network, exchange experience as well as discuss best practices.\n\nHope to see you all!\n","source":"_posts/2015-09-08-code-talks.md","raw":"---\nlayout: post\ntitle: \"ePages talks REST API\"\ndate: \"2015-09-08 08:10:00\"\nimage: blog-header/talk.jpg\ncategories: events\nauthors: [\"Birgit\"]\n---\n\nHave you signed up for the [`code.talks`](https://www.codetalks.de/) 2015 in Hamburg?\nThis conference thrives on a variety of interesting topics in the field of web development, exciting talks and of course lots of fun.\nAnd we're participating!\n\nSpeaker: Oliver Trosien\n\nTopic: Documented and Tested Microservices for Fun and Profit\n\nDate & Time: 30th of September 2015, 10:00 - 10:45 a.m.\n\nLocation: Room 7\n\nAbstract: Software documentation is not one of a developer's best-loved topics.\nIn the field of Microservices, it is therefore all the more important to provide a meaningful and well documented REST API that other teams and external developers can build upon.\nSo, let's build some nice REST API docs!\n\nThe `code.talks` will be also a great chance to meet with ePages developers and designers to network, exchange experience as well as discuss best practices.\n\nHope to see you all!\n","slug":"2015-09-08-code-talks","published":1,"updated":"2016-09-20T14:19:22.000Z","comments":1,"photos":[],"link":"","_id":"ciu6nuh8t000xhqyxovyj2jks","content":"<p>Have you signed up for the <a href=\"https://www.codetalks.de/\" target=\"_blank\" rel=\"external\"><code>code.talks</code></a> 2015 in Hamburg?<br>This conference thrives on a variety of interesting topics in the field of web development, exciting talks and of course lots of fun.<br>And we’re participating!</p>\n<p>Speaker: Oliver Trosien</p>\n<p>Topic: Documented and Tested Microservices for Fun and Profit</p>\n<p>Date &amp; Time: 30th of September 2015, 10:00 - 10:45 a.m.</p>\n<p>Location: Room 7</p>\n<p>Abstract: Software documentation is not one of a developer’s best-loved topics.<br>In the field of Microservices, it is therefore all the more important to provide a meaningful and well documented REST API that other teams and external developers can build upon.<br>So, let’s build some nice REST API docs!</p>\n<p>The <code>code.talks</code> will be also a great chance to meet with ePages developers and designers to network, exchange experience as well as discuss best practices.</p>\n<p>Hope to see you all!</p>\n","excerpt":"","more":"<p>Have you signed up for the <a href=\"https://www.codetalks.de/\"><code>code.talks</code></a> 2015 in Hamburg?<br>This conference thrives on a variety of interesting topics in the field of web development, exciting talks and of course lots of fun.<br>And we’re participating!</p>\n<p>Speaker: Oliver Trosien</p>\n<p>Topic: Documented and Tested Microservices for Fun and Profit</p>\n<p>Date &amp; Time: 30th of September 2015, 10:00 - 10:45 a.m.</p>\n<p>Location: Room 7</p>\n<p>Abstract: Software documentation is not one of a developer’s best-loved topics.<br>In the field of Microservices, it is therefore all the more important to provide a meaningful and well documented REST API that other teams and external developers can build upon.<br>So, let’s build some nice REST API docs!</p>\n<p>The <code>code.talks</code> will be also a great chance to meet with ePages developers and designers to network, exchange experience as well as discuss best practices.</p>\n<p>Hope to see you all!</p>\n"},{"layout":"post","title":"R&D Day 2015 in the spotlight","date":"2015-09-15T06:10:00.000Z","image":"blog-header/research.jpg","authors":["Birgit"],"_content":"\nePages developers from all company locations convened in Hamburg to spend an amazing time together on software development topics!\nIt was all about interesting lectures and workshops, healthy discussions and knowledge transfer among different teams of the Research & Development department.\n\nCurtains up for these fantastic topics:\n\n## Spotlight: ePages software architecture\n\nTeam Black started the R&D Day presenting their approach on a new software architecture that should be the technical foundation for ePages in the years to come.\n\n{% image blog/blog-rnd-architecture.jpg %}\n\nThe following principles drive the teams' work:\n\n* support development on the product in teams distributed across epages locations\n* create an architecture that is easy to change and to maintain\n* focus on the Java ecosystem.\n\nEach software development team should be able to independently deliver a piece of software that is ready for production deployment.\nIn addition, it should be possible to quickly change parts of the system without creating side effects.\nIn order to achieve that, they split up the product in business domains, where each domain is implemented in a vertical that:\n\n* represents a deployable unit\n* is exclusively responsible for its functionality\n* owns its data\n* provides REST API to leverage access to its functions\n* communicates with other verticals only by using REST-based interfaces or events\n* its micro-architecture needs to follow some high-level guidelines to ensure it is operational within the macro-architecture.\n\n## Spotlight: App & Theme Store\n\nTeam Red presented the architecture of the App & Theme Store.\nThe Store allows merchants to customise the design of their shop with certain themes.\nFurthermore, they can add additional functionalities to their shop by installing apps developed by external developers using the ePages APIs.\n\n{% image blog/blog-rnd-appstore.jpg %}\n\nThey explained the different app types, the store currently supports:\n\n* REST apps that use the ePages [REST API](https://developer.epages.com/)\n* SOAP apps that use the ePages [SOAP API](https://developer.epages.com/soap/index.html)\n* Themes and Affiliates\n\nThe challenge was to provide an architecture which not only allows external developers to develop and submit their app easily, but also to provide an administration tool for the product management which allows them to distribute the apps to the different providers.\n\nDespite the brief time frame of the session and the complexity of the architecture, Team Red succeeded and presented, in an understandable way, several diagrams and live demos of the different App & Theme Store use cases:\n\n- Developers point of view: How an app developer can submit an app\n- Product Management's point of view: How PM is able to review an app and manage apps for the different shop types\n- Merchants point of view: How to install and uninstall an app in the merchant's administration area.\n\n## Spotlight: New Storefront\n\n{% image blog/blog-rnd-unity.jpg %}\n\nTeam Unity shared insights on the new storefront and editor.\nThey explained how they plan to integrate this into the existing ePages product using the ePages [REST API](https://developer.epages.com/).\n\nUsing [node.js](https://nodejs.org/en/) and [akka](http://akka.io/), [React](http://facebook.github.io/react/) and [webpack](https://webpack.github.io/) they accomplished a cool and slick implementation.\n\n## Hands-on: Microservices\n\nIn this workshop, the participants gained first-hand experience of the new ePages architecture.\nThey completed hands-on exercises illuminating common microservice patterns, like synchronous and asynchronous communication and persistence - and had fun building a microservice-based [pizza bakery](https://github.com/ePages-de/rnd-microservices-handson).\n\n## Spotlight: Automating Jenkins\n\nCheck out our blog post [Infrastructure as code: automating Jenkins](https://developer.epages.com/blog/2015/06/25/infrastructure-as-code.html) to find out more.\nStay tuned for an upcoming update on this topic.\n\n## Spotlight: Test Automation\n\nIdeally, new features and bug fixes are available on the live systems as soon as they are implemented and verified.\nIn order to achieve that, there is a clear necessity for [automated tests](http://blog.daverooney.ca/2015/04/getting-started-with-test-driven.html).\nFor each application layer, specific test automation tools and techniques exist:\n\n* the Presentation layer is what the user gets to see\n* the Functionality layer represents the API of the system\n* the Unit layer consists of the source code components.\n\nEach of these approaches has advantages and disadvantages.\nThat's why it is important to know about those and then invest into a well-balanced test portfolio.\nThe testing community came up with a metaphor which suggests how much emphasis should be laid on each test level: the [Test Pyramid](http://mrselenium.blogspot.de/2014/12/the-automation-pyramid.html).\nDetailed reasons for this are described in the SWOT analysis for each respective test level.\nIn short: if we focus too much on the UI test automation, we will run into problems with the test maintenance and the runtime of the tests.\nOur result: 70% Unit tests, 20% Integration tests, 10% UI tests.\n\nRead further here in our blog post [The ePages Selenium Framework](https://developer.epages.com/blog/2015/07/23/the-epages-selenium-framework.html).\n\n## Hands-on: Writing tests\n\n{% image blog/blog-rnd-tests.jpg %}\n\nIn line with the Test Automation lecture, Team Ocean did a nice workshop session on writing tests.\nThey dealt with:\n\n* Differences between test types\n* Why mocking is needed and how to do it\n* How to structure code so that it can be tested\n* How to use mock frameworks\n* Best practices for testing.\n\n## Hands-on: How to use Docker\n\nIn this workshop we ran a client/server app using [Docker](https://www.docker.com/), as described in our blog post [Improving the development workflow with Docker](https://developer.epages.com/blog/2015/06/11/improve-development-with-docker.html).\nThe participants learned about [Docker CLI](https://docs.docker.com/reference/commandline/cli/), [Docker Compose](https://docs.docker.com/compose/), [Docker Hub](https://hub.docker.com/) as well as the general software lifecycle and best practices when using Docker.\n","source":"_posts/2015-09-15-rnd-day-2015.md","raw":"---\nlayout: post\ntitle: \"R&D Day 2015 in the spotlight\"\ndate: \"2015-09-15 08:10:00\"\nimage: blog-header/research.jpg\ncategories: tech-stories\nauthors: [\"Birgit\"]\n---\n\nePages developers from all company locations convened in Hamburg to spend an amazing time together on software development topics!\nIt was all about interesting lectures and workshops, healthy discussions and knowledge transfer among different teams of the Research & Development department.\n\nCurtains up for these fantastic topics:\n\n## Spotlight: ePages software architecture\n\nTeam Black started the R&D Day presenting their approach on a new software architecture that should be the technical foundation for ePages in the years to come.\n\n{% image blog/blog-rnd-architecture.jpg %}\n\nThe following principles drive the teams' work:\n\n* support development on the product in teams distributed across epages locations\n* create an architecture that is easy to change and to maintain\n* focus on the Java ecosystem.\n\nEach software development team should be able to independently deliver a piece of software that is ready for production deployment.\nIn addition, it should be possible to quickly change parts of the system without creating side effects.\nIn order to achieve that, they split up the product in business domains, where each domain is implemented in a vertical that:\n\n* represents a deployable unit\n* is exclusively responsible for its functionality\n* owns its data\n* provides REST API to leverage access to its functions\n* communicates with other verticals only by using REST-based interfaces or events\n* its micro-architecture needs to follow some high-level guidelines to ensure it is operational within the macro-architecture.\n\n## Spotlight: App & Theme Store\n\nTeam Red presented the architecture of the App & Theme Store.\nThe Store allows merchants to customise the design of their shop with certain themes.\nFurthermore, they can add additional functionalities to their shop by installing apps developed by external developers using the ePages APIs.\n\n{% image blog/blog-rnd-appstore.jpg %}\n\nThey explained the different app types, the store currently supports:\n\n* REST apps that use the ePages [REST API](https://developer.epages.com/)\n* SOAP apps that use the ePages [SOAP API](https://developer.epages.com/soap/index.html)\n* Themes and Affiliates\n\nThe challenge was to provide an architecture which not only allows external developers to develop and submit their app easily, but also to provide an administration tool for the product management which allows them to distribute the apps to the different providers.\n\nDespite the brief time frame of the session and the complexity of the architecture, Team Red succeeded and presented, in an understandable way, several diagrams and live demos of the different App & Theme Store use cases:\n\n- Developers point of view: How an app developer can submit an app\n- Product Management's point of view: How PM is able to review an app and manage apps for the different shop types\n- Merchants point of view: How to install and uninstall an app in the merchant's administration area.\n\n## Spotlight: New Storefront\n\n{% image blog/blog-rnd-unity.jpg %}\n\nTeam Unity shared insights on the new storefront and editor.\nThey explained how they plan to integrate this into the existing ePages product using the ePages [REST API](https://developer.epages.com/).\n\nUsing [node.js](https://nodejs.org/en/) and [akka](http://akka.io/), [React](http://facebook.github.io/react/) and [webpack](https://webpack.github.io/) they accomplished a cool and slick implementation.\n\n## Hands-on: Microservices\n\nIn this workshop, the participants gained first-hand experience of the new ePages architecture.\nThey completed hands-on exercises illuminating common microservice patterns, like synchronous and asynchronous communication and persistence - and had fun building a microservice-based [pizza bakery](https://github.com/ePages-de/rnd-microservices-handson).\n\n## Spotlight: Automating Jenkins\n\nCheck out our blog post [Infrastructure as code: automating Jenkins](https://developer.epages.com/blog/2015/06/25/infrastructure-as-code.html) to find out more.\nStay tuned for an upcoming update on this topic.\n\n## Spotlight: Test Automation\n\nIdeally, new features and bug fixes are available on the live systems as soon as they are implemented and verified.\nIn order to achieve that, there is a clear necessity for [automated tests](http://blog.daverooney.ca/2015/04/getting-started-with-test-driven.html).\nFor each application layer, specific test automation tools and techniques exist:\n\n* the Presentation layer is what the user gets to see\n* the Functionality layer represents the API of the system\n* the Unit layer consists of the source code components.\n\nEach of these approaches has advantages and disadvantages.\nThat's why it is important to know about those and then invest into a well-balanced test portfolio.\nThe testing community came up with a metaphor which suggests how much emphasis should be laid on each test level: the [Test Pyramid](http://mrselenium.blogspot.de/2014/12/the-automation-pyramid.html).\nDetailed reasons for this are described in the SWOT analysis for each respective test level.\nIn short: if we focus too much on the UI test automation, we will run into problems with the test maintenance and the runtime of the tests.\nOur result: 70% Unit tests, 20% Integration tests, 10% UI tests.\n\nRead further here in our blog post [The ePages Selenium Framework](https://developer.epages.com/blog/2015/07/23/the-epages-selenium-framework.html).\n\n## Hands-on: Writing tests\n\n{% image blog/blog-rnd-tests.jpg %}\n\nIn line with the Test Automation lecture, Team Ocean did a nice workshop session on writing tests.\nThey dealt with:\n\n* Differences between test types\n* Why mocking is needed and how to do it\n* How to structure code so that it can be tested\n* How to use mock frameworks\n* Best practices for testing.\n\n## Hands-on: How to use Docker\n\nIn this workshop we ran a client/server app using [Docker](https://www.docker.com/), as described in our blog post [Improving the development workflow with Docker](https://developer.epages.com/blog/2015/06/11/improve-development-with-docker.html).\nThe participants learned about [Docker CLI](https://docs.docker.com/reference/commandline/cli/), [Docker Compose](https://docs.docker.com/compose/), [Docker Hub](https://hub.docker.com/) as well as the general software lifecycle and best practices when using Docker.\n","slug":"2015-09-15-rnd-day-2015","published":1,"updated":"2016-09-20T14:19:22.000Z","comments":1,"photos":[],"link":"","_id":"ciu6nuh8u000zhqyx7o78wana","content":"<p>ePages developers from all company locations convened in Hamburg to spend an amazing time together on software development topics!<br>It was all about interesting lectures and workshops, healthy discussions and knowledge transfer among different teams of the Research &amp; Development department.</p>\n<p>Curtains up for these fantastic topics:</p>\n<h2 id=\"Spotlight-ePages-software-architecture\"><a href=\"#Spotlight-ePages-software-architecture\" class=\"headerlink\" title=\"Spotlight: ePages software architecture\"></a>Spotlight: ePages software architecture</h2><p>Team Black started the R&amp;D Day presenting their approach on a new software architecture that should be the technical foundation for ePages in the years to come.</p>\n<img class=\"blog/blog-rnd-architecture.jpg\">\n<p>The following principles drive the teams’ work:</p>\n<ul>\n<li>support development on the product in teams distributed across epages locations</li>\n<li>create an architecture that is easy to change and to maintain</li>\n<li>focus on the Java ecosystem.</li>\n</ul>\n<p>Each software development team should be able to independently deliver a piece of software that is ready for production deployment.<br>In addition, it should be possible to quickly change parts of the system without creating side effects.<br>In order to achieve that, they split up the product in business domains, where each domain is implemented in a vertical that:</p>\n<ul>\n<li>represents a deployable unit</li>\n<li>is exclusively responsible for its functionality</li>\n<li>owns its data</li>\n<li>provides REST API to leverage access to its functions</li>\n<li>communicates with other verticals only by using REST-based interfaces or events</li>\n<li>its micro-architecture needs to follow some high-level guidelines to ensure it is operational within the macro-architecture.</li>\n</ul>\n<h2 id=\"Spotlight-App-amp-Theme-Store\"><a href=\"#Spotlight-App-amp-Theme-Store\" class=\"headerlink\" title=\"Spotlight: App &amp; Theme Store\"></a>Spotlight: App &amp; Theme Store</h2><p>Team Red presented the architecture of the App &amp; Theme Store.<br>The Store allows merchants to customise the design of their shop with certain themes.<br>Furthermore, they can add additional functionalities to their shop by installing apps developed by external developers using the ePages APIs.</p>\n<img class=\"blog/blog-rnd-appstore.jpg\">\n<p>They explained the different app types, the store currently supports:</p>\n<ul>\n<li>REST apps that use the ePages <a href=\"https://developer.epages.com/\" target=\"_blank\" rel=\"external\">REST API</a></li>\n<li>SOAP apps that use the ePages <a href=\"https://developer.epages.com/soap/index.html\" target=\"_blank\" rel=\"external\">SOAP API</a></li>\n<li>Themes and Affiliates</li>\n</ul>\n<p>The challenge was to provide an architecture which not only allows external developers to develop and submit their app easily, but also to provide an administration tool for the product management which allows them to distribute the apps to the different providers.</p>\n<p>Despite the brief time frame of the session and the complexity of the architecture, Team Red succeeded and presented, in an understandable way, several diagrams and live demos of the different App &amp; Theme Store use cases:</p>\n<ul>\n<li>Developers point of view: How an app developer can submit an app</li>\n<li>Product Management’s point of view: How PM is able to review an app and manage apps for the different shop types</li>\n<li>Merchants point of view: How to install and uninstall an app in the merchant’s administration area.</li>\n</ul>\n<h2 id=\"Spotlight-New-Storefront\"><a href=\"#Spotlight-New-Storefront\" class=\"headerlink\" title=\"Spotlight: New Storefront\"></a>Spotlight: New Storefront</h2><img class=\"blog/blog-rnd-unity.jpg\">\n<p>Team Unity shared insights on the new storefront and editor.<br>They explained how they plan to integrate this into the existing ePages product using the ePages <a href=\"https://developer.epages.com/\" target=\"_blank\" rel=\"external\">REST API</a>.</p>\n<p>Using <a href=\"https://nodejs.org/en/\" target=\"_blank\" rel=\"external\">node.js</a> and <a href=\"http://akka.io/\" target=\"_blank\" rel=\"external\">akka</a>, <a href=\"http://facebook.github.io/react/\" target=\"_blank\" rel=\"external\">React</a> and <a href=\"https://webpack.github.io/\" target=\"_blank\" rel=\"external\">webpack</a> they accomplished a cool and slick implementation.</p>\n<h2 id=\"Hands-on-Microservices\"><a href=\"#Hands-on-Microservices\" class=\"headerlink\" title=\"Hands-on: Microservices\"></a>Hands-on: Microservices</h2><p>In this workshop, the participants gained first-hand experience of the new ePages architecture.<br>They completed hands-on exercises illuminating common microservice patterns, like synchronous and asynchronous communication and persistence - and had fun building a microservice-based <a href=\"https://github.com/ePages-de/rnd-microservices-handson\" target=\"_blank\" rel=\"external\">pizza bakery</a>.</p>\n<h2 id=\"Spotlight-Automating-Jenkins\"><a href=\"#Spotlight-Automating-Jenkins\" class=\"headerlink\" title=\"Spotlight: Automating Jenkins\"></a>Spotlight: Automating Jenkins</h2><p>Check out our blog post <a href=\"https://developer.epages.com/blog/2015/06/25/infrastructure-as-code.html\" target=\"_blank\" rel=\"external\">Infrastructure as code: automating Jenkins</a> to find out more.<br>Stay tuned for an upcoming update on this topic.</p>\n<h2 id=\"Spotlight-Test-Automation\"><a href=\"#Spotlight-Test-Automation\" class=\"headerlink\" title=\"Spotlight: Test Automation\"></a>Spotlight: Test Automation</h2><p>Ideally, new features and bug fixes are available on the live systems as soon as they are implemented and verified.<br>In order to achieve that, there is a clear necessity for <a href=\"http://blog.daverooney.ca/2015/04/getting-started-with-test-driven.html\" target=\"_blank\" rel=\"external\">automated tests</a>.<br>For each application layer, specific test automation tools and techniques exist:</p>\n<ul>\n<li>the Presentation layer is what the user gets to see</li>\n<li>the Functionality layer represents the API of the system</li>\n<li>the Unit layer consists of the source code components.</li>\n</ul>\n<p>Each of these approaches has advantages and disadvantages.<br>That’s why it is important to know about those and then invest into a well-balanced test portfolio.<br>The testing community came up with a metaphor which suggests how much emphasis should be laid on each test level: the <a href=\"http://mrselenium.blogspot.de/2014/12/the-automation-pyramid.html\" target=\"_blank\" rel=\"external\">Test Pyramid</a>.<br>Detailed reasons for this are described in the SWOT analysis for each respective test level.<br>In short: if we focus too much on the UI test automation, we will run into problems with the test maintenance and the runtime of the tests.<br>Our result: 70% Unit tests, 20% Integration tests, 10% UI tests.</p>\n<p>Read further here in our blog post <a href=\"https://developer.epages.com/blog/2015/07/23/the-epages-selenium-framework.html\" target=\"_blank\" rel=\"external\">The ePages Selenium Framework</a>.</p>\n<h2 id=\"Hands-on-Writing-tests\"><a href=\"#Hands-on-Writing-tests\" class=\"headerlink\" title=\"Hands-on: Writing tests\"></a>Hands-on: Writing tests</h2><img class=\"blog/blog-rnd-tests.jpg\">\n<p>In line with the Test Automation lecture, Team Ocean did a nice workshop session on writing tests.<br>They dealt with:</p>\n<ul>\n<li>Differences between test types</li>\n<li>Why mocking is needed and how to do it</li>\n<li>How to structure code so that it can be tested</li>\n<li>How to use mock frameworks</li>\n<li>Best practices for testing.</li>\n</ul>\n<h2 id=\"Hands-on-How-to-use-Docker\"><a href=\"#Hands-on-How-to-use-Docker\" class=\"headerlink\" title=\"Hands-on: How to use Docker\"></a>Hands-on: How to use Docker</h2><p>In this workshop we ran a client/server app using <a href=\"https://www.docker.com/\" target=\"_blank\" rel=\"external\">Docker</a>, as described in our blog post <a href=\"https://developer.epages.com/blog/2015/06/11/improve-development-with-docker.html\" target=\"_blank\" rel=\"external\">Improving the development workflow with Docker</a>.<br>The participants learned about <a href=\"https://docs.docker.com/reference/commandline/cli/\" target=\"_blank\" rel=\"external\">Docker CLI</a>, <a href=\"https://docs.docker.com/compose/\" target=\"_blank\" rel=\"external\">Docker Compose</a>, <a href=\"https://hub.docker.com/\" target=\"_blank\" rel=\"external\">Docker Hub</a> as well as the general software lifecycle and best practices when using Docker.</p>\n","excerpt":"","more":"<p>ePages developers from all company locations convened in Hamburg to spend an amazing time together on software development topics!<br>It was all about interesting lectures and workshops, healthy discussions and knowledge transfer among different teams of the Research &amp; Development department.</p>\n<p>Curtains up for these fantastic topics:</p>\n<h2 id=\"Spotlight-ePages-software-architecture\"><a href=\"#Spotlight-ePages-software-architecture\" class=\"headerlink\" title=\"Spotlight: ePages software architecture\"></a>Spotlight: ePages software architecture</h2><p>Team Black started the R&amp;D Day presenting their approach on a new software architecture that should be the technical foundation for ePages in the years to come.</p>\n<img class=\"blog/blog-rnd-architecture.jpg\">\n<p>The following principles drive the teams’ work:</p>\n<ul>\n<li>support development on the product in teams distributed across epages locations</li>\n<li>create an architecture that is easy to change and to maintain</li>\n<li>focus on the Java ecosystem.</li>\n</ul>\n<p>Each software development team should be able to independently deliver a piece of software that is ready for production deployment.<br>In addition, it should be possible to quickly change parts of the system without creating side effects.<br>In order to achieve that, they split up the product in business domains, where each domain is implemented in a vertical that:</p>\n<ul>\n<li>represents a deployable unit</li>\n<li>is exclusively responsible for its functionality</li>\n<li>owns its data</li>\n<li>provides REST API to leverage access to its functions</li>\n<li>communicates with other verticals only by using REST-based interfaces or events</li>\n<li>its micro-architecture needs to follow some high-level guidelines to ensure it is operational within the macro-architecture.</li>\n</ul>\n<h2 id=\"Spotlight-App-amp-Theme-Store\"><a href=\"#Spotlight-App-amp-Theme-Store\" class=\"headerlink\" title=\"Spotlight: App &amp; Theme Store\"></a>Spotlight: App &amp; Theme Store</h2><p>Team Red presented the architecture of the App &amp; Theme Store.<br>The Store allows merchants to customise the design of their shop with certain themes.<br>Furthermore, they can add additional functionalities to their shop by installing apps developed by external developers using the ePages APIs.</p>\n<img class=\"blog/blog-rnd-appstore.jpg\">\n<p>They explained the different app types, the store currently supports:</p>\n<ul>\n<li>REST apps that use the ePages <a href=\"https://developer.epages.com/\">REST API</a></li>\n<li>SOAP apps that use the ePages <a href=\"https://developer.epages.com/soap/index.html\">SOAP API</a></li>\n<li>Themes and Affiliates</li>\n</ul>\n<p>The challenge was to provide an architecture which not only allows external developers to develop and submit their app easily, but also to provide an administration tool for the product management which allows them to distribute the apps to the different providers.</p>\n<p>Despite the brief time frame of the session and the complexity of the architecture, Team Red succeeded and presented, in an understandable way, several diagrams and live demos of the different App &amp; Theme Store use cases:</p>\n<ul>\n<li>Developers point of view: How an app developer can submit an app</li>\n<li>Product Management’s point of view: How PM is able to review an app and manage apps for the different shop types</li>\n<li>Merchants point of view: How to install and uninstall an app in the merchant’s administration area.</li>\n</ul>\n<h2 id=\"Spotlight-New-Storefront\"><a href=\"#Spotlight-New-Storefront\" class=\"headerlink\" title=\"Spotlight: New Storefront\"></a>Spotlight: New Storefront</h2><img class=\"blog/blog-rnd-unity.jpg\">\n<p>Team Unity shared insights on the new storefront and editor.<br>They explained how they plan to integrate this into the existing ePages product using the ePages <a href=\"https://developer.epages.com/\">REST API</a>.</p>\n<p>Using <a href=\"https://nodejs.org/en/\">node.js</a> and <a href=\"http://akka.io/\">akka</a>, <a href=\"http://facebook.github.io/react/\">React</a> and <a href=\"https://webpack.github.io/\">webpack</a> they accomplished a cool and slick implementation.</p>\n<h2 id=\"Hands-on-Microservices\"><a href=\"#Hands-on-Microservices\" class=\"headerlink\" title=\"Hands-on: Microservices\"></a>Hands-on: Microservices</h2><p>In this workshop, the participants gained first-hand experience of the new ePages architecture.<br>They completed hands-on exercises illuminating common microservice patterns, like synchronous and asynchronous communication and persistence - and had fun building a microservice-based <a href=\"https://github.com/ePages-de/rnd-microservices-handson\">pizza bakery</a>.</p>\n<h2 id=\"Spotlight-Automating-Jenkins\"><a href=\"#Spotlight-Automating-Jenkins\" class=\"headerlink\" title=\"Spotlight: Automating Jenkins\"></a>Spotlight: Automating Jenkins</h2><p>Check out our blog post <a href=\"https://developer.epages.com/blog/2015/06/25/infrastructure-as-code.html\">Infrastructure as code: automating Jenkins</a> to find out more.<br>Stay tuned for an upcoming update on this topic.</p>\n<h2 id=\"Spotlight-Test-Automation\"><a href=\"#Spotlight-Test-Automation\" class=\"headerlink\" title=\"Spotlight: Test Automation\"></a>Spotlight: Test Automation</h2><p>Ideally, new features and bug fixes are available on the live systems as soon as they are implemented and verified.<br>In order to achieve that, there is a clear necessity for <a href=\"http://blog.daverooney.ca/2015/04/getting-started-with-test-driven.html\">automated tests</a>.<br>For each application layer, specific test automation tools and techniques exist:</p>\n<ul>\n<li>the Presentation layer is what the user gets to see</li>\n<li>the Functionality layer represents the API of the system</li>\n<li>the Unit layer consists of the source code components.</li>\n</ul>\n<p>Each of these approaches has advantages and disadvantages.<br>That’s why it is important to know about those and then invest into a well-balanced test portfolio.<br>The testing community came up with a metaphor which suggests how much emphasis should be laid on each test level: the <a href=\"http://mrselenium.blogspot.de/2014/12/the-automation-pyramid.html\">Test Pyramid</a>.<br>Detailed reasons for this are described in the SWOT analysis for each respective test level.<br>In short: if we focus too much on the UI test automation, we will run into problems with the test maintenance and the runtime of the tests.<br>Our result: 70% Unit tests, 20% Integration tests, 10% UI tests.</p>\n<p>Read further here in our blog post <a href=\"https://developer.epages.com/blog/2015/07/23/the-epages-selenium-framework.html\">The ePages Selenium Framework</a>.</p>\n<h2 id=\"Hands-on-Writing-tests\"><a href=\"#Hands-on-Writing-tests\" class=\"headerlink\" title=\"Hands-on: Writing tests\"></a>Hands-on: Writing tests</h2><img class=\"blog/blog-rnd-tests.jpg\">\n<p>In line with the Test Automation lecture, Team Ocean did a nice workshop session on writing tests.<br>They dealt with:</p>\n<ul>\n<li>Differences between test types</li>\n<li>Why mocking is needed and how to do it</li>\n<li>How to structure code so that it can be tested</li>\n<li>How to use mock frameworks</li>\n<li>Best practices for testing.</li>\n</ul>\n<h2 id=\"Hands-on-How-to-use-Docker\"><a href=\"#Hands-on-How-to-use-Docker\" class=\"headerlink\" title=\"Hands-on: How to use Docker\"></a>Hands-on: How to use Docker</h2><p>In this workshop we ran a client/server app using <a href=\"https://www.docker.com/\">Docker</a>, as described in our blog post <a href=\"https://developer.epages.com/blog/2015/06/11/improve-development-with-docker.html\">Improving the development workflow with Docker</a>.<br>The participants learned about <a href=\"https://docs.docker.com/reference/commandline/cli/\">Docker CLI</a>, <a href=\"https://docs.docker.com/compose/\">Docker Compose</a>, <a href=\"https://hub.docker.com/\">Docker Hub</a> as well as the general software lifecycle and best practices when using Docker.</p>\n"},{"layout":"post","title":"Annual company event: ePagees rock the YOU","date":"2015-09-21T11:09:00.000Z","authors":["Birgit"],"_content":"\nCreative team presentations, team building activities, workshops and lots of fun: last weeks' activities and corridor talks at ePages all revolved around the ePages annual company event: the YOU.\nThe YOU is a formal, annual company event which all ePages employees are required to attend.\nThis sounds really tough.\nBut it's not.\nOver the two day's the YOU requires hard work and long hours, but is an incredibly fun event.\n\nMain goal of the event:\n\n* get to know each other better\n* unite colleagues from all company locations\n* exchange ideas among colleagues, departments and countries.\n\n## Event task force\n\nLong before the actual date of the YOU, the event task force start preparing activities for the two awesome days.\nTo make it a big surprise for everyone, the agenda was kept a secret for a long time.\nHowever, leading up to the YOU we were given teasers for the event which kept us all excited.\n\n## Prepare for action\n\nEvery team was asked to prepare a 1-minute video that presents their departments.\nTo make it short: that was a hell of a lot of fun!\nTo keep it interesting, the team presentations had some restrictions: 12-minutes only for the presentation and then 12-minutes for a Q&A session.\nThat was definitely a challenge and required time for a careful preparation.\n\n{% image blog/blog-you-prepare.jpg 100% %}\n\n## Patience required\n\nThere were rumors that we would go for an outdoor activity.\nBefore long you could hear colleagues whisper and chatter in the corridors about what that might be.\nClimbing? Geocaching? City walk?\nNo chance to find that out.\nStaying patient was required.\n\n## Kick-off at the beach\n\n{% image blog/blog-you-beachclub.jpg 100% %}\n\nFinally the YOU started in a beach club above the city roofs of Hamburg.\nWe enjoyed a beautiful view across the city, along with food and drinks, a relaxed atmosphere and lots of fun.\nIncidentally, we also had the chance to observe a beautiful sunset!\n\n## Opening YOU\n\nThe next day we all convened at the Hamburg University to spend the first day watching funny and awesome team videos and listening to well-prepared team presentations.\n\n{% image blog/blog-you-presentation.jpg 100% %}\n\nExciting: the team that was going to present was drawn right before the presentation, so every team had to be prepared at all times!\n\n## Dragon boat race\n\nIn the afternoon, the secret was finally revealed as to what our outdoor activity would be. We were taken to a small dock at a branch of the Alster to spend the afternoon competing in dragon boat races.\n\n{% image blog/blog-you-dragonboat.jpg 100% %}\n\nThis outdoor activity was simply spectacular!\nThere was so much enthusiasm and ambition amongst the colleagues learning the skills, performing the strokes in sync, being one effective entity to win the race - with a good battle cry, of course.\n\n## Being rewarded\n\n{% image blog/blog-you-reward.jpg 100% %}\n\nWe finished the day chilling out at a restaurant with cocktails and burgers.\nThe composition of the tables was chosen at random.\nAgain, helping everyone get pushed out of their comfort zones to get to know new colleagues from other locations.\n\n## Prepare for the coming day\n\nJust one (short) night to recover from the current events and then it was time to jump right into the next.\nWe briefly wrapped up the first day and continued with creative team videos and presentations.\nNext to this, we had a speaker presenting future company events as well as a lecture sharing knowledge on our merchants.\n\n## Workshops & wrap-up\n\nThe afternoon was packed with workshops.\n\n{% image blog/blog-you-workshop.jpg 100% %}\n\nThe groups were again chosen at random and worked on the following topics:\n\n* How to become a focused person?\n* Different personalities in teams\n* Responsible acting\n* Ways to give feedback\n* How to make a project successful\n* Ways of communication\n\nAt the end of the day, the management wrapped up the event and we ended with a Q&A session.\n\n## Rapturous applause\n\nIt has been an awesome event and we all look forward for the next YOU to come!\n","source":"_posts/2015-09-21-epages-you-2015.md","raw":"---\nlayout: post\ntitle: \"Annual company event: ePagees rock the YOU\"\ndate: \"2015-09-21 13:09:00\"\ncategories: events\nauthors: [\"Birgit\"]\n---\n\nCreative team presentations, team building activities, workshops and lots of fun: last weeks' activities and corridor talks at ePages all revolved around the ePages annual company event: the YOU.\nThe YOU is a formal, annual company event which all ePages employees are required to attend.\nThis sounds really tough.\nBut it's not.\nOver the two day's the YOU requires hard work and long hours, but is an incredibly fun event.\n\nMain goal of the event:\n\n* get to know each other better\n* unite colleagues from all company locations\n* exchange ideas among colleagues, departments and countries.\n\n## Event task force\n\nLong before the actual date of the YOU, the event task force start preparing activities for the two awesome days.\nTo make it a big surprise for everyone, the agenda was kept a secret for a long time.\nHowever, leading up to the YOU we were given teasers for the event which kept us all excited.\n\n## Prepare for action\n\nEvery team was asked to prepare a 1-minute video that presents their departments.\nTo make it short: that was a hell of a lot of fun!\nTo keep it interesting, the team presentations had some restrictions: 12-minutes only for the presentation and then 12-minutes for a Q&A session.\nThat was definitely a challenge and required time for a careful preparation.\n\n{% image blog/blog-you-prepare.jpg 100% %}\n\n## Patience required\n\nThere were rumors that we would go for an outdoor activity.\nBefore long you could hear colleagues whisper and chatter in the corridors about what that might be.\nClimbing? Geocaching? City walk?\nNo chance to find that out.\nStaying patient was required.\n\n## Kick-off at the beach\n\n{% image blog/blog-you-beachclub.jpg 100% %}\n\nFinally the YOU started in a beach club above the city roofs of Hamburg.\nWe enjoyed a beautiful view across the city, along with food and drinks, a relaxed atmosphere and lots of fun.\nIncidentally, we also had the chance to observe a beautiful sunset!\n\n## Opening YOU\n\nThe next day we all convened at the Hamburg University to spend the first day watching funny and awesome team videos and listening to well-prepared team presentations.\n\n{% image blog/blog-you-presentation.jpg 100% %}\n\nExciting: the team that was going to present was drawn right before the presentation, so every team had to be prepared at all times!\n\n## Dragon boat race\n\nIn the afternoon, the secret was finally revealed as to what our outdoor activity would be. We were taken to a small dock at a branch of the Alster to spend the afternoon competing in dragon boat races.\n\n{% image blog/blog-you-dragonboat.jpg 100% %}\n\nThis outdoor activity was simply spectacular!\nThere was so much enthusiasm and ambition amongst the colleagues learning the skills, performing the strokes in sync, being one effective entity to win the race - with a good battle cry, of course.\n\n## Being rewarded\n\n{% image blog/blog-you-reward.jpg 100% %}\n\nWe finished the day chilling out at a restaurant with cocktails and burgers.\nThe composition of the tables was chosen at random.\nAgain, helping everyone get pushed out of their comfort zones to get to know new colleagues from other locations.\n\n## Prepare for the coming day\n\nJust one (short) night to recover from the current events and then it was time to jump right into the next.\nWe briefly wrapped up the first day and continued with creative team videos and presentations.\nNext to this, we had a speaker presenting future company events as well as a lecture sharing knowledge on our merchants.\n\n## Workshops & wrap-up\n\nThe afternoon was packed with workshops.\n\n{% image blog/blog-you-workshop.jpg 100% %}\n\nThe groups were again chosen at random and worked on the following topics:\n\n* How to become a focused person?\n* Different personalities in teams\n* Responsible acting\n* Ways to give feedback\n* How to make a project successful\n* Ways of communication\n\nAt the end of the day, the management wrapped up the event and we ended with a Q&A session.\n\n## Rapturous applause\n\nIt has been an awesome event and we all look forward for the next YOU to come!\n","slug":"2015-09-21-epages-you-2015","published":1,"updated":"2016-09-20T14:19:22.000Z","comments":1,"photos":[],"link":"","_id":"ciu6nuh8v0011hqyxe5jsnoga","content":"<p>Creative team presentations, team building activities, workshops and lots of fun: last weeks’ activities and corridor talks at ePages all revolved around the ePages annual company event: the YOU.<br>The YOU is a formal, annual company event which all ePages employees are required to attend.<br>This sounds really tough.<br>But it’s not.<br>Over the two day’s the YOU requires hard work and long hours, but is an incredibly fun event.</p>\n<p>Main goal of the event:</p>\n<ul>\n<li>get to know each other better</li>\n<li>unite colleagues from all company locations</li>\n<li>exchange ideas among colleagues, departments and countries.</li>\n</ul>\n<h2 id=\"Event-task-force\"><a href=\"#Event-task-force\" class=\"headerlink\" title=\"Event task force\"></a>Event task force</h2><p>Long before the actual date of the YOU, the event task force start preparing activities for the two awesome days.<br>To make it a big surprise for everyone, the agenda was kept a secret for a long time.<br>However, leading up to the YOU we were given teasers for the event which kept us all excited.</p>\n<h2 id=\"Prepare-for-action\"><a href=\"#Prepare-for-action\" class=\"headerlink\" title=\"Prepare for action\"></a>Prepare for action</h2><p>Every team was asked to prepare a 1-minute video that presents their departments.<br>To make it short: that was a hell of a lot of fun!<br>To keep it interesting, the team presentations had some restrictions: 12-minutes only for the presentation and then 12-minutes for a Q&amp;A session.<br>That was definitely a challenge and required time for a careful preparation.</p>\n<img class=\"blog/blog-you-prepare.jpg 100%\">\n<h2 id=\"Patience-required\"><a href=\"#Patience-required\" class=\"headerlink\" title=\"Patience required\"></a>Patience required</h2><p>There were rumors that we would go for an outdoor activity.<br>Before long you could hear colleagues whisper and chatter in the corridors about what that might be.<br>Climbing? Geocaching? City walk?<br>No chance to find that out.<br>Staying patient was required.</p>\n<h2 id=\"Kick-off-at-the-beach\"><a href=\"#Kick-off-at-the-beach\" class=\"headerlink\" title=\"Kick-off at the beach\"></a>Kick-off at the beach</h2><img class=\"blog/blog-you-beachclub.jpg 100%\">\n<p>Finally the YOU started in a beach club above the city roofs of Hamburg.<br>We enjoyed a beautiful view across the city, along with food and drinks, a relaxed atmosphere and lots of fun.<br>Incidentally, we also had the chance to observe a beautiful sunset!</p>\n<h2 id=\"Opening-YOU\"><a href=\"#Opening-YOU\" class=\"headerlink\" title=\"Opening YOU\"></a>Opening YOU</h2><p>The next day we all convened at the Hamburg University to spend the first day watching funny and awesome team videos and listening to well-prepared team presentations.</p>\n<img class=\"blog/blog-you-presentation.jpg 100%\">\n<p>Exciting: the team that was going to present was drawn right before the presentation, so every team had to be prepared at all times!</p>\n<h2 id=\"Dragon-boat-race\"><a href=\"#Dragon-boat-race\" class=\"headerlink\" title=\"Dragon boat race\"></a>Dragon boat race</h2><p>In the afternoon, the secret was finally revealed as to what our outdoor activity would be. We were taken to a small dock at a branch of the Alster to spend the afternoon competing in dragon boat races.</p>\n<img class=\"blog/blog-you-dragonboat.jpg 100%\">\n<p>This outdoor activity was simply spectacular!<br>There was so much enthusiasm and ambition amongst the colleagues learning the skills, performing the strokes in sync, being one effective entity to win the race - with a good battle cry, of course.</p>\n<h2 id=\"Being-rewarded\"><a href=\"#Being-rewarded\" class=\"headerlink\" title=\"Being rewarded\"></a>Being rewarded</h2><img class=\"blog/blog-you-reward.jpg 100%\">\n<p>We finished the day chilling out at a restaurant with cocktails and burgers.<br>The composition of the tables was chosen at random.<br>Again, helping everyone get pushed out of their comfort zones to get to know new colleagues from other locations.</p>\n<h2 id=\"Prepare-for-the-coming-day\"><a href=\"#Prepare-for-the-coming-day\" class=\"headerlink\" title=\"Prepare for the coming day\"></a>Prepare for the coming day</h2><p>Just one (short) night to recover from the current events and then it was time to jump right into the next.<br>We briefly wrapped up the first day and continued with creative team videos and presentations.<br>Next to this, we had a speaker presenting future company events as well as a lecture sharing knowledge on our merchants.</p>\n<h2 id=\"Workshops-amp-wrap-up\"><a href=\"#Workshops-amp-wrap-up\" class=\"headerlink\" title=\"Workshops &amp; wrap-up\"></a>Workshops &amp; wrap-up</h2><p>The afternoon was packed with workshops.</p>\n<img class=\"blog/blog-you-workshop.jpg 100%\">\n<p>The groups were again chosen at random and worked on the following topics:</p>\n<ul>\n<li>How to become a focused person?</li>\n<li>Different personalities in teams</li>\n<li>Responsible acting</li>\n<li>Ways to give feedback</li>\n<li>How to make a project successful</li>\n<li>Ways of communication</li>\n</ul>\n<p>At the end of the day, the management wrapped up the event and we ended with a Q&amp;A session.</p>\n<h2 id=\"Rapturous-applause\"><a href=\"#Rapturous-applause\" class=\"headerlink\" title=\"Rapturous applause\"></a>Rapturous applause</h2><p>It has been an awesome event and we all look forward for the next YOU to come!</p>\n","excerpt":"","more":"<p>Creative team presentations, team building activities, workshops and lots of fun: last weeks’ activities and corridor talks at ePages all revolved around the ePages annual company event: the YOU.<br>The YOU is a formal, annual company event which all ePages employees are required to attend.<br>This sounds really tough.<br>But it’s not.<br>Over the two day’s the YOU requires hard work and long hours, but is an incredibly fun event.</p>\n<p>Main goal of the event:</p>\n<ul>\n<li>get to know each other better</li>\n<li>unite colleagues from all company locations</li>\n<li>exchange ideas among colleagues, departments and countries.</li>\n</ul>\n<h2 id=\"Event-task-force\"><a href=\"#Event-task-force\" class=\"headerlink\" title=\"Event task force\"></a>Event task force</h2><p>Long before the actual date of the YOU, the event task force start preparing activities for the two awesome days.<br>To make it a big surprise for everyone, the agenda was kept a secret for a long time.<br>However, leading up to the YOU we were given teasers for the event which kept us all excited.</p>\n<h2 id=\"Prepare-for-action\"><a href=\"#Prepare-for-action\" class=\"headerlink\" title=\"Prepare for action\"></a>Prepare for action</h2><p>Every team was asked to prepare a 1-minute video that presents their departments.<br>To make it short: that was a hell of a lot of fun!<br>To keep it interesting, the team presentations had some restrictions: 12-minutes only for the presentation and then 12-minutes for a Q&amp;A session.<br>That was definitely a challenge and required time for a careful preparation.</p>\n<img class=\"blog/blog-you-prepare.jpg 100%\">\n<h2 id=\"Patience-required\"><a href=\"#Patience-required\" class=\"headerlink\" title=\"Patience required\"></a>Patience required</h2><p>There were rumors that we would go for an outdoor activity.<br>Before long you could hear colleagues whisper and chatter in the corridors about what that might be.<br>Climbing? Geocaching? City walk?<br>No chance to find that out.<br>Staying patient was required.</p>\n<h2 id=\"Kick-off-at-the-beach\"><a href=\"#Kick-off-at-the-beach\" class=\"headerlink\" title=\"Kick-off at the beach\"></a>Kick-off at the beach</h2><img class=\"blog/blog-you-beachclub.jpg 100%\">\n<p>Finally the YOU started in a beach club above the city roofs of Hamburg.<br>We enjoyed a beautiful view across the city, along with food and drinks, a relaxed atmosphere and lots of fun.<br>Incidentally, we also had the chance to observe a beautiful sunset!</p>\n<h2 id=\"Opening-YOU\"><a href=\"#Opening-YOU\" class=\"headerlink\" title=\"Opening YOU\"></a>Opening YOU</h2><p>The next day we all convened at the Hamburg University to spend the first day watching funny and awesome team videos and listening to well-prepared team presentations.</p>\n<img class=\"blog/blog-you-presentation.jpg 100%\">\n<p>Exciting: the team that was going to present was drawn right before the presentation, so every team had to be prepared at all times!</p>\n<h2 id=\"Dragon-boat-race\"><a href=\"#Dragon-boat-race\" class=\"headerlink\" title=\"Dragon boat race\"></a>Dragon boat race</h2><p>In the afternoon, the secret was finally revealed as to what our outdoor activity would be. We were taken to a small dock at a branch of the Alster to spend the afternoon competing in dragon boat races.</p>\n<img class=\"blog/blog-you-dragonboat.jpg 100%\">\n<p>This outdoor activity was simply spectacular!<br>There was so much enthusiasm and ambition amongst the colleagues learning the skills, performing the strokes in sync, being one effective entity to win the race - with a good battle cry, of course.</p>\n<h2 id=\"Being-rewarded\"><a href=\"#Being-rewarded\" class=\"headerlink\" title=\"Being rewarded\"></a>Being rewarded</h2><img class=\"blog/blog-you-reward.jpg 100%\">\n<p>We finished the day chilling out at a restaurant with cocktails and burgers.<br>The composition of the tables was chosen at random.<br>Again, helping everyone get pushed out of their comfort zones to get to know new colleagues from other locations.</p>\n<h2 id=\"Prepare-for-the-coming-day\"><a href=\"#Prepare-for-the-coming-day\" class=\"headerlink\" title=\"Prepare for the coming day\"></a>Prepare for the coming day</h2><p>Just one (short) night to recover from the current events and then it was time to jump right into the next.<br>We briefly wrapped up the first day and continued with creative team videos and presentations.<br>Next to this, we had a speaker presenting future company events as well as a lecture sharing knowledge on our merchants.</p>\n<h2 id=\"Workshops-amp-wrap-up\"><a href=\"#Workshops-amp-wrap-up\" class=\"headerlink\" title=\"Workshops &amp; wrap-up\"></a>Workshops &amp; wrap-up</h2><p>The afternoon was packed with workshops.</p>\n<img class=\"blog/blog-you-workshop.jpg 100%\">\n<p>The groups were again chosen at random and worked on the following topics:</p>\n<ul>\n<li>How to become a focused person?</li>\n<li>Different personalities in teams</li>\n<li>Responsible acting</li>\n<li>Ways to give feedback</li>\n<li>How to make a project successful</li>\n<li>Ways of communication</li>\n</ul>\n<p>At the end of the day, the management wrapped up the event and we ended with a Q&amp;A session.</p>\n<h2 id=\"Rapturous-applause\"><a href=\"#Rapturous-applause\" class=\"headerlink\" title=\"Rapturous applause\"></a>Rapturous applause</h2><p>It has been an awesome event and we all look forward for the next YOU to come!</p>\n"},{"layout":"post","title":"ePages turns agile","date":"2015-09-24T08:10:00.000Z","authors":["Anja B."],"_content":"\nHave you ever wonder how companies that are going the agile way are developing further over time?\nAnd how long it actually takes to get from level to level?\nOr how many companies achieve certain levels of agility?\n\nHere are all the answers:\n\n{% image blog/blog-agile-fluency.png %}\n\nThe picture shows the so called Agile Fluency Model (originally released by Diana Larsen and James Shore, read [here](http://martinfowler.com/articles/agileFluency.html) for further information).\nThe numbers are based on questions that had been asked to companies who changed to an agile methodology some years ago.\nThe most impressive numbers are probably, that it takes a really long time to achieve two or three stars.\nIt is astonishing that only 5% of all companies who decide to go the agile way, actually achieve a three star model.\n\nWhy is that interesting for ePages?\nePages changed from Waterfall to Scrum in 2013.\nThe Agile Fluency Model helps us now to find out, where we are standing in comparison to other companies who went the agile way.\n\nThe good news is that ePages is pretty far along the agile road, when looking at the time frames.\nWe have already achieved the first star, sorting all our epics according to business value and rearranging teams to fit our different products.\nNow we are working hard to establish the second star.\nWe have already managed to have a release package ready every two weeks, which is a huge step for the goal to deliver on the marked cadence.\nWe are in closer contact than ever with our end-customers, for example in the [ePages Academies](http://www.epages.com/academy/en/) or even by visiting them at their working places and doing questionnaires.\n\nIt is a long-term goal for us to continually improve our agile processes by getting faster rollout cycles and with that faster feedback and reach the exceptional third star.\n","source":"_posts/2015-09-24-agile-fluency.md","raw":"---\nlayout: post\ntitle: \"ePages turns agile\"\ndate: \"2015-09-24 10:10:00\"\ncategories: agile\nauthors: [\"Anja B.\"]\n---\n\nHave you ever wonder how companies that are going the agile way are developing further over time?\nAnd how long it actually takes to get from level to level?\nOr how many companies achieve certain levels of agility?\n\nHere are all the answers:\n\n{% image blog/blog-agile-fluency.png %}\n\nThe picture shows the so called Agile Fluency Model (originally released by Diana Larsen and James Shore, read [here](http://martinfowler.com/articles/agileFluency.html) for further information).\nThe numbers are based on questions that had been asked to companies who changed to an agile methodology some years ago.\nThe most impressive numbers are probably, that it takes a really long time to achieve two or three stars.\nIt is astonishing that only 5% of all companies who decide to go the agile way, actually achieve a three star model.\n\nWhy is that interesting for ePages?\nePages changed from Waterfall to Scrum in 2013.\nThe Agile Fluency Model helps us now to find out, where we are standing in comparison to other companies who went the agile way.\n\nThe good news is that ePages is pretty far along the agile road, when looking at the time frames.\nWe have already achieved the first star, sorting all our epics according to business value and rearranging teams to fit our different products.\nNow we are working hard to establish the second star.\nWe have already managed to have a release package ready every two weeks, which is a huge step for the goal to deliver on the marked cadence.\nWe are in closer contact than ever with our end-customers, for example in the [ePages Academies](http://www.epages.com/academy/en/) or even by visiting them at their working places and doing questionnaires.\n\nIt is a long-term goal for us to continually improve our agile processes by getting faster rollout cycles and with that faster feedback and reach the exceptional third star.\n","slug":"2015-09-24-agile-fluency","published":1,"updated":"2016-09-20T14:19:22.000Z","comments":1,"photos":[],"link":"","_id":"ciu6nuh8w0013hqyx5p5iyy6c","content":"<p>Have you ever wonder how companies that are going the agile way are developing further over time?<br>And how long it actually takes to get from level to level?<br>Or how many companies achieve certain levels of agility?</p>\n<p>Here are all the answers:</p>\n<img class=\"blog/blog-agile-fluency.png\">\n<p>The picture shows the so called Agile Fluency Model (originally released by Diana Larsen and James Shore, read <a href=\"http://martinfowler.com/articles/agileFluency.html\" target=\"_blank\" rel=\"external\">here</a> for further information).<br>The numbers are based on questions that had been asked to companies who changed to an agile methodology some years ago.<br>The most impressive numbers are probably, that it takes a really long time to achieve two or three stars.<br>It is astonishing that only 5% of all companies who decide to go the agile way, actually achieve a three star model.</p>\n<p>Why is that interesting for ePages?<br>ePages changed from Waterfall to Scrum in 2013.<br>The Agile Fluency Model helps us now to find out, where we are standing in comparison to other companies who went the agile way.</p>\n<p>The good news is that ePages is pretty far along the agile road, when looking at the time frames.<br>We have already achieved the first star, sorting all our epics according to business value and rearranging teams to fit our different products.<br>Now we are working hard to establish the second star.<br>We have already managed to have a release package ready every two weeks, which is a huge step for the goal to deliver on the marked cadence.<br>We are in closer contact than ever with our end-customers, for example in the <a href=\"http://www.epages.com/academy/en/\" target=\"_blank\" rel=\"external\">ePages Academies</a> or even by visiting them at their working places and doing questionnaires.</p>\n<p>It is a long-term goal for us to continually improve our agile processes by getting faster rollout cycles and with that faster feedback and reach the exceptional third star.</p>\n","excerpt":"","more":"<p>Have you ever wonder how companies that are going the agile way are developing further over time?<br>And how long it actually takes to get from level to level?<br>Or how many companies achieve certain levels of agility?</p>\n<p>Here are all the answers:</p>\n<img class=\"blog/blog-agile-fluency.png\">\n<p>The picture shows the so called Agile Fluency Model (originally released by Diana Larsen and James Shore, read <a href=\"http://martinfowler.com/articles/agileFluency.html\">here</a> for further information).<br>The numbers are based on questions that had been asked to companies who changed to an agile methodology some years ago.<br>The most impressive numbers are probably, that it takes a really long time to achieve two or three stars.<br>It is astonishing that only 5% of all companies who decide to go the agile way, actually achieve a three star model.</p>\n<p>Why is that interesting for ePages?<br>ePages changed from Waterfall to Scrum in 2013.<br>The Agile Fluency Model helps us now to find out, where we are standing in comparison to other companies who went the agile way.</p>\n<p>The good news is that ePages is pretty far along the agile road, when looking at the time frames.<br>We have already achieved the first star, sorting all our epics according to business value and rearranging teams to fit our different products.<br>Now we are working hard to establish the second star.<br>We have already managed to have a release package ready every two weeks, which is a huge step for the goal to deliver on the marked cadence.<br>We are in closer contact than ever with our end-customers, for example in the <a href=\"http://www.epages.com/academy/en/\">ePages Academies</a> or even by visiting them at their working places and doing questionnaires.</p>\n<p>It is a long-term goal for us to continually improve our agile processes by getting faster rollout cycles and with that faster feedback and reach the exceptional third star.</p>\n"},{"layout":"post","title":"Service discovery with Consul, Registrator & HAProxy","date":"2015-09-28T06:30:00.000Z","image":"blog-header/discovery.jpg","authors":["Dirk"],"_content":"\nAs ePages heads towards a new microservice-based architecture, new challenges arise. In this kind of architecture, there are a lot of services, which are usually deployed redundantly for high availability. But from a client perspective, all these service instances should be transparent. The client should not need to care about multiple instances of a service, their different locations on the network or if they are operational, down for maintenance or in a failure state. A client should only need to deal with a single address of the service.\n\nThe solution to this challenge is *Service Discovery*. It is the means by which any service is able to find other services without the need to know about the actual location or other details. In our solution, Service Discovery means that you only need to know a generic URI to communicate with other REST-based services (or even some infrastructure components like message brokers).\n\n## How does it work?\n\nA service discovery solution usually consists of three core building blocks:\n\n* A *service registry* which holds the data about currently available services and instances\n* A *health-check* mechanism to monitor service health\n* A *lookup* or *routing* mechanism to connect to services\n\n### Service Registry\nAt the heart of the service discovery infrastructure, there is a so-called service registry. This registry has the knowledge about all available services and their instances. It gains this knowledge by providing an API to register and deregister hosts or service instances, so the services have a central point to make themselves available to the public.\n\n##### Consul\n\nWe chose [Consul](https://consul.io/) as our service registry implementation. Consul provides the core functionality of a service registry by utilising an agent-based setup. This means, an agent, which is kind of a daemon process, runs on every machine that provides services. Here is a short abstract of Consul's introduction documentation to get to know the most important parts:\n\n>Consul is a distributed, highly available system. [...]\n>Every node that provides services to Consul runs a *Consul agent*.  Running an agent is not required for discovering other services or getting/setting key/value data. The agent is responsible for health checking the services on the node as well as the node itself.\n>The agents talk to one or more *Consul servers*. The Consul servers are where data is stored and replicated. The servers themselves elect a leader.\n>[...]\n>Components of your infrastructure that need to discover other services or nodes can query any of the Consul servers\n>or any of the Consul agents. The agents forward queries to the servers automatically.\n\nFor more details, see the full [introduction](https://www.consul.io/intro/index.html) and the [in-depth architecture overview](https://www.consul.io/docs/internals/architecture.html) on the Consul web site.\n\n### Health-Checks\n\nThe data inside the service registry only provides real value if it is up to date. Just knowing there once was a service available at a certain location is not enough. Therefore, checking the availability or health status of all service instances is crucial for service discovery.\n\nIn our setup, the health checking is also done by Consul. The servers check the general availability of the agents, and therefore the hosts. In addition, you can register different types of service checks with an agent, which then performs these checks against the services registered locally in fixed intervals. Whenever such a check fails, the according service or host will be marked as unavailable, and therefore the service registry will no longer promote the faulty instance any longer.\n\n### Lookup / Routing\n\nThe third major building block is a component, which is able to look up or route requests to an appropriate service instance, given an identifier for the target service. With this identifier, the clients should either receive an actual service instance address to connect to, or have its requests routed transparently to the service instance.\n\nWe decided for the routing solution, to keep the logic and also library dependencies out of the services. As the identifier, we use the first path element of any request URI, which means that a request to `http://insert.hostname.here/myservice/recource1` will be routed to an appropriate service instance of the `myservice` service.\n\nWith this naming schema defined, the actual routing is done by [HAProxy](http://www.haproxy.org/), a reliable, high performance TCP/HTTP load balancer. It is configured by a process called consul-template, which queries the information about available service instances from Consul and applies it to a provided template, in this case a template HAProxy configuration file, and (gracefully) restarts HAProxy afterwards.\n\n{% image blog/blog-consul-template-haproxy.png %}\n\nNow that we have this logic in place, HAProxy routes any incoming request to the most appropriate instance of the service given by the first path element of the request. The determination of the most appropriate instance of the service can be decided by the various load balancing features of HAProxy.\n\n### Dynamic Service Registration\n\nSo far, service discovery works fine, but how do the services register with the Consul agent on the hosts on which they are started? To solve this, we introduce another component, [Registrator](http://gliderlabs.com/registrator/latest/). This is a so-called service registry bridge for Docker. What it actually does is nicely summarised on their website:\n\n>Registrator automatically registers and deregisters services for any Docker container by inspecting containers as they come online. Registrator supports pluggable service registries, which currently includes Consul, etcd and SkyDNS 2.\n\nRunning Registrator as an additional Docker container on each host, it automatically registers new containers with the local Consul agent, and therefore makes them publicly available. Customisations, like providing the service name to be used, health check details or add-on data (tags) for a given instance can be provided in the usual Docker way by passing environment variables to the docker run command.\n\n### Conclusion\n\nThe Service Discovery solution described in this post provides all the features we need so far.\nThere are other, similar solutions out there, but with our choice, we are also able to cover other aspects of the microservice architecture with the same technology, which is a big plus for this solution.\n","source":"_posts/2015-09-28-service-discovery.md","raw":"---\nlayout: post\ntitle: \"Service discovery with Consul, Registrator & HAProxy\"\ndate: \"2015-09-28 08:30:00\"\nimage: blog-header/discovery.jpg\ncategories: tech-stories\nauthors: [\"Dirk\"]\n---\n\nAs ePages heads towards a new microservice-based architecture, new challenges arise. In this kind of architecture, there are a lot of services, which are usually deployed redundantly for high availability. But from a client perspective, all these service instances should be transparent. The client should not need to care about multiple instances of a service, their different locations on the network or if they are operational, down for maintenance or in a failure state. A client should only need to deal with a single address of the service.\n\nThe solution to this challenge is *Service Discovery*. It is the means by which any service is able to find other services without the need to know about the actual location or other details. In our solution, Service Discovery means that you only need to know a generic URI to communicate with other REST-based services (or even some infrastructure components like message brokers).\n\n## How does it work?\n\nA service discovery solution usually consists of three core building blocks:\n\n* A *service registry* which holds the data about currently available services and instances\n* A *health-check* mechanism to monitor service health\n* A *lookup* or *routing* mechanism to connect to services\n\n### Service Registry\nAt the heart of the service discovery infrastructure, there is a so-called service registry. This registry has the knowledge about all available services and their instances. It gains this knowledge by providing an API to register and deregister hosts or service instances, so the services have a central point to make themselves available to the public.\n\n##### Consul\n\nWe chose [Consul](https://consul.io/) as our service registry implementation. Consul provides the core functionality of a service registry by utilising an agent-based setup. This means, an agent, which is kind of a daemon process, runs on every machine that provides services. Here is a short abstract of Consul's introduction documentation to get to know the most important parts:\n\n>Consul is a distributed, highly available system. [...]\n>Every node that provides services to Consul runs a *Consul agent*.  Running an agent is not required for discovering other services or getting/setting key/value data. The agent is responsible for health checking the services on the node as well as the node itself.\n>The agents talk to one or more *Consul servers*. The Consul servers are where data is stored and replicated. The servers themselves elect a leader.\n>[...]\n>Components of your infrastructure that need to discover other services or nodes can query any of the Consul servers\n>or any of the Consul agents. The agents forward queries to the servers automatically.\n\nFor more details, see the full [introduction](https://www.consul.io/intro/index.html) and the [in-depth architecture overview](https://www.consul.io/docs/internals/architecture.html) on the Consul web site.\n\n### Health-Checks\n\nThe data inside the service registry only provides real value if it is up to date. Just knowing there once was a service available at a certain location is not enough. Therefore, checking the availability or health status of all service instances is crucial for service discovery.\n\nIn our setup, the health checking is also done by Consul. The servers check the general availability of the agents, and therefore the hosts. In addition, you can register different types of service checks with an agent, which then performs these checks against the services registered locally in fixed intervals. Whenever such a check fails, the according service or host will be marked as unavailable, and therefore the service registry will no longer promote the faulty instance any longer.\n\n### Lookup / Routing\n\nThe third major building block is a component, which is able to look up or route requests to an appropriate service instance, given an identifier for the target service. With this identifier, the clients should either receive an actual service instance address to connect to, or have its requests routed transparently to the service instance.\n\nWe decided for the routing solution, to keep the logic and also library dependencies out of the services. As the identifier, we use the first path element of any request URI, which means that a request to `http://insert.hostname.here/myservice/recource1` will be routed to an appropriate service instance of the `myservice` service.\n\nWith this naming schema defined, the actual routing is done by [HAProxy](http://www.haproxy.org/), a reliable, high performance TCP/HTTP load balancer. It is configured by a process called consul-template, which queries the information about available service instances from Consul and applies it to a provided template, in this case a template HAProxy configuration file, and (gracefully) restarts HAProxy afterwards.\n\n{% image blog/blog-consul-template-haproxy.png %}\n\nNow that we have this logic in place, HAProxy routes any incoming request to the most appropriate instance of the service given by the first path element of the request. The determination of the most appropriate instance of the service can be decided by the various load balancing features of HAProxy.\n\n### Dynamic Service Registration\n\nSo far, service discovery works fine, but how do the services register with the Consul agent on the hosts on which they are started? To solve this, we introduce another component, [Registrator](http://gliderlabs.com/registrator/latest/). This is a so-called service registry bridge for Docker. What it actually does is nicely summarised on their website:\n\n>Registrator automatically registers and deregisters services for any Docker container by inspecting containers as they come online. Registrator supports pluggable service registries, which currently includes Consul, etcd and SkyDNS 2.\n\nRunning Registrator as an additional Docker container on each host, it automatically registers new containers with the local Consul agent, and therefore makes them publicly available. Customisations, like providing the service name to be used, health check details or add-on data (tags) for a given instance can be provided in the usual Docker way by passing environment variables to the docker run command.\n\n### Conclusion\n\nThe Service Discovery solution described in this post provides all the features we need so far.\nThere are other, similar solutions out there, but with our choice, we are also able to cover other aspects of the microservice architecture with the same technology, which is a big plus for this solution.\n","slug":"2015-09-28-service-discovery","published":1,"updated":"2016-09-20T14:19:22.000Z","comments":1,"photos":[],"link":"","_id":"ciu6nuh8y0015hqyxs4nm44zv","content":"<p>As ePages heads towards a new microservice-based architecture, new challenges arise. In this kind of architecture, there are a lot of services, which are usually deployed redundantly for high availability. But from a client perspective, all these service instances should be transparent. The client should not need to care about multiple instances of a service, their different locations on the network or if they are operational, down for maintenance or in a failure state. A client should only need to deal with a single address of the service.</p>\n<p>The solution to this challenge is <em>Service Discovery</em>. It is the means by which any service is able to find other services without the need to know about the actual location or other details. In our solution, Service Discovery means that you only need to know a generic URI to communicate with other REST-based services (or even some infrastructure components like message brokers).</p>\n<h2 id=\"How-does-it-work\"><a href=\"#How-does-it-work\" class=\"headerlink\" title=\"How does it work?\"></a>How does it work?</h2><p>A service discovery solution usually consists of three core building blocks:</p>\n<ul>\n<li>A <em>service registry</em> which holds the data about currently available services and instances</li>\n<li>A <em>health-check</em> mechanism to monitor service health</li>\n<li>A <em>lookup</em> or <em>routing</em> mechanism to connect to services</li>\n</ul>\n<h3 id=\"Service-Registry\"><a href=\"#Service-Registry\" class=\"headerlink\" title=\"Service Registry\"></a>Service Registry</h3><p>At the heart of the service discovery infrastructure, there is a so-called service registry. This registry has the knowledge about all available services and their instances. It gains this knowledge by providing an API to register and deregister hosts or service instances, so the services have a central point to make themselves available to the public.</p>\n<h5 id=\"Consul\"><a href=\"#Consul\" class=\"headerlink\" title=\"Consul\"></a>Consul</h5><p>We chose <a href=\"https://consul.io/\" target=\"_blank\" rel=\"external\">Consul</a> as our service registry implementation. Consul provides the core functionality of a service registry by utilising an agent-based setup. This means, an agent, which is kind of a daemon process, runs on every machine that provides services. Here is a short abstract of Consul’s introduction documentation to get to know the most important parts:</p>\n<blockquote>\n<p>Consul is a distributed, highly available system. […]<br>Every node that provides services to Consul runs a <em>Consul agent</em>.  Running an agent is not required for discovering other services or getting/setting key/value data. The agent is responsible for health checking the services on the node as well as the node itself.<br>The agents talk to one or more <em>Consul servers</em>. The Consul servers are where data is stored and replicated. The servers themselves elect a leader.<br>[…]<br>Components of your infrastructure that need to discover other services or nodes can query any of the Consul servers<br>or any of the Consul agents. The agents forward queries to the servers automatically.</p>\n</blockquote>\n<p>For more details, see the full <a href=\"https://www.consul.io/intro/index.html\" target=\"_blank\" rel=\"external\">introduction</a> and the <a href=\"https://www.consul.io/docs/internals/architecture.html\" target=\"_blank\" rel=\"external\">in-depth architecture overview</a> on the Consul web site.</p>\n<h3 id=\"Health-Checks\"><a href=\"#Health-Checks\" class=\"headerlink\" title=\"Health-Checks\"></a>Health-Checks</h3><p>The data inside the service registry only provides real value if it is up to date. Just knowing there once was a service available at a certain location is not enough. Therefore, checking the availability or health status of all service instances is crucial for service discovery.</p>\n<p>In our setup, the health checking is also done by Consul. The servers check the general availability of the agents, and therefore the hosts. In addition, you can register different types of service checks with an agent, which then performs these checks against the services registered locally in fixed intervals. Whenever such a check fails, the according service or host will be marked as unavailable, and therefore the service registry will no longer promote the faulty instance any longer.</p>\n<h3 id=\"Lookup-Routing\"><a href=\"#Lookup-Routing\" class=\"headerlink\" title=\"Lookup / Routing\"></a>Lookup / Routing</h3><p>The third major building block is a component, which is able to look up or route requests to an appropriate service instance, given an identifier for the target service. With this identifier, the clients should either receive an actual service instance address to connect to, or have its requests routed transparently to the service instance.</p>\n<p>We decided for the routing solution, to keep the logic and also library dependencies out of the services. As the identifier, we use the first path element of any request URI, which means that a request to <code>http://insert.hostname.here/myservice/recource1</code> will be routed to an appropriate service instance of the <code>myservice</code> service.</p>\n<p>With this naming schema defined, the actual routing is done by <a href=\"http://www.haproxy.org/\" target=\"_blank\" rel=\"external\">HAProxy</a>, a reliable, high performance TCP/HTTP load balancer. It is configured by a process called consul-template, which queries the information about available service instances from Consul and applies it to a provided template, in this case a template HAProxy configuration file, and (gracefully) restarts HAProxy afterwards.</p>\n<img class=\"blog/blog-consul-template-haproxy.png\">\n<p>Now that we have this logic in place, HAProxy routes any incoming request to the most appropriate instance of the service given by the first path element of the request. The determination of the most appropriate instance of the service can be decided by the various load balancing features of HAProxy.</p>\n<h3 id=\"Dynamic-Service-Registration\"><a href=\"#Dynamic-Service-Registration\" class=\"headerlink\" title=\"Dynamic Service Registration\"></a>Dynamic Service Registration</h3><p>So far, service discovery works fine, but how do the services register with the Consul agent on the hosts on which they are started? To solve this, we introduce another component, <a href=\"http://gliderlabs.com/registrator/latest/\" target=\"_blank\" rel=\"external\">Registrator</a>. This is a so-called service registry bridge for Docker. What it actually does is nicely summarised on their website:</p>\n<blockquote>\n<p>Registrator automatically registers and deregisters services for any Docker container by inspecting containers as they come online. Registrator supports pluggable service registries, which currently includes Consul, etcd and SkyDNS 2.</p>\n</blockquote>\n<p>Running Registrator as an additional Docker container on each host, it automatically registers new containers with the local Consul agent, and therefore makes them publicly available. Customisations, like providing the service name to be used, health check details or add-on data (tags) for a given instance can be provided in the usual Docker way by passing environment variables to the docker run command.</p>\n<h3 id=\"Conclusion\"><a href=\"#Conclusion\" class=\"headerlink\" title=\"Conclusion\"></a>Conclusion</h3><p>The Service Discovery solution described in this post provides all the features we need so far.<br>There are other, similar solutions out there, but with our choice, we are also able to cover other aspects of the microservice architecture with the same technology, which is a big plus for this solution.</p>\n","excerpt":"","more":"<p>As ePages heads towards a new microservice-based architecture, new challenges arise. In this kind of architecture, there are a lot of services, which are usually deployed redundantly for high availability. But from a client perspective, all these service instances should be transparent. The client should not need to care about multiple instances of a service, their different locations on the network or if they are operational, down for maintenance or in a failure state. A client should only need to deal with a single address of the service.</p>\n<p>The solution to this challenge is <em>Service Discovery</em>. It is the means by which any service is able to find other services without the need to know about the actual location or other details. In our solution, Service Discovery means that you only need to know a generic URI to communicate with other REST-based services (or even some infrastructure components like message brokers).</p>\n<h2 id=\"How-does-it-work\"><a href=\"#How-does-it-work\" class=\"headerlink\" title=\"How does it work?\"></a>How does it work?</h2><p>A service discovery solution usually consists of three core building blocks:</p>\n<ul>\n<li>A <em>service registry</em> which holds the data about currently available services and instances</li>\n<li>A <em>health-check</em> mechanism to monitor service health</li>\n<li>A <em>lookup</em> or <em>routing</em> mechanism to connect to services</li>\n</ul>\n<h3 id=\"Service-Registry\"><a href=\"#Service-Registry\" class=\"headerlink\" title=\"Service Registry\"></a>Service Registry</h3><p>At the heart of the service discovery infrastructure, there is a so-called service registry. This registry has the knowledge about all available services and their instances. It gains this knowledge by providing an API to register and deregister hosts or service instances, so the services have a central point to make themselves available to the public.</p>\n<h5 id=\"Consul\"><a href=\"#Consul\" class=\"headerlink\" title=\"Consul\"></a>Consul</h5><p>We chose <a href=\"https://consul.io/\">Consul</a> as our service registry implementation. Consul provides the core functionality of a service registry by utilising an agent-based setup. This means, an agent, which is kind of a daemon process, runs on every machine that provides services. Here is a short abstract of Consul’s introduction documentation to get to know the most important parts:</p>\n<blockquote>\n<p>Consul is a distributed, highly available system. […]<br>Every node that provides services to Consul runs a <em>Consul agent</em>.  Running an agent is not required for discovering other services or getting/setting key/value data. The agent is responsible for health checking the services on the node as well as the node itself.<br>The agents talk to one or more <em>Consul servers</em>. The Consul servers are where data is stored and replicated. The servers themselves elect a leader.<br>[…]<br>Components of your infrastructure that need to discover other services or nodes can query any of the Consul servers<br>or any of the Consul agents. The agents forward queries to the servers automatically.</p>\n</blockquote>\n<p>For more details, see the full <a href=\"https://www.consul.io/intro/index.html\">introduction</a> and the <a href=\"https://www.consul.io/docs/internals/architecture.html\">in-depth architecture overview</a> on the Consul web site.</p>\n<h3 id=\"Health-Checks\"><a href=\"#Health-Checks\" class=\"headerlink\" title=\"Health-Checks\"></a>Health-Checks</h3><p>The data inside the service registry only provides real value if it is up to date. Just knowing there once was a service available at a certain location is not enough. Therefore, checking the availability or health status of all service instances is crucial for service discovery.</p>\n<p>In our setup, the health checking is also done by Consul. The servers check the general availability of the agents, and therefore the hosts. In addition, you can register different types of service checks with an agent, which then performs these checks against the services registered locally in fixed intervals. Whenever such a check fails, the according service or host will be marked as unavailable, and therefore the service registry will no longer promote the faulty instance any longer.</p>\n<h3 id=\"Lookup-Routing\"><a href=\"#Lookup-Routing\" class=\"headerlink\" title=\"Lookup / Routing\"></a>Lookup / Routing</h3><p>The third major building block is a component, which is able to look up or route requests to an appropriate service instance, given an identifier for the target service. With this identifier, the clients should either receive an actual service instance address to connect to, or have its requests routed transparently to the service instance.</p>\n<p>We decided for the routing solution, to keep the logic and also library dependencies out of the services. As the identifier, we use the first path element of any request URI, which means that a request to <code>http://insert.hostname.here/myservice/recource1</code> will be routed to an appropriate service instance of the <code>myservice</code> service.</p>\n<p>With this naming schema defined, the actual routing is done by <a href=\"http://www.haproxy.org/\">HAProxy</a>, a reliable, high performance TCP/HTTP load balancer. It is configured by a process called consul-template, which queries the information about available service instances from Consul and applies it to a provided template, in this case a template HAProxy configuration file, and (gracefully) restarts HAProxy afterwards.</p>\n<img class=\"blog/blog-consul-template-haproxy.png\">\n<p>Now that we have this logic in place, HAProxy routes any incoming request to the most appropriate instance of the service given by the first path element of the request. The determination of the most appropriate instance of the service can be decided by the various load balancing features of HAProxy.</p>\n<h3 id=\"Dynamic-Service-Registration\"><a href=\"#Dynamic-Service-Registration\" class=\"headerlink\" title=\"Dynamic Service Registration\"></a>Dynamic Service Registration</h3><p>So far, service discovery works fine, but how do the services register with the Consul agent on the hosts on which they are started? To solve this, we introduce another component, <a href=\"http://gliderlabs.com/registrator/latest/\">Registrator</a>. This is a so-called service registry bridge for Docker. What it actually does is nicely summarised on their website:</p>\n<blockquote>\n<p>Registrator automatically registers and deregisters services for any Docker container by inspecting containers as they come online. Registrator supports pluggable service registries, which currently includes Consul, etcd and SkyDNS 2.</p>\n</blockquote>\n<p>Running Registrator as an additional Docker container on each host, it automatically registers new containers with the local Consul agent, and therefore makes them publicly available. Customisations, like providing the service name to be used, health check details or add-on data (tags) for a given instance can be provided in the usual Docker way by passing environment variables to the docker run command.</p>\n<h3 id=\"Conclusion\"><a href=\"#Conclusion\" class=\"headerlink\" title=\"Conclusion\"></a>Conclusion</h3><p>The Service Discovery solution described in this post provides all the features we need so far.<br>There are other, similar solutions out there, but with our choice, we are also able to cover other aspects of the microservice architecture with the same technology, which is a big plus for this solution.</p>\n"},{"layout":"post","title":"code.talks 2015 retrospective","date":"2015-10-07T07:00:00.000Z","authors":["Jens"],"_content":"\nFor the fifth time about 1,500 developers gathered for the yearly `code.talks` conference in Hamburg:\non September 29 and 30, a dozen ePagees went to the Cinemaxx Hamburg Dammtor to enjoy two days fully packed with [lots of talks](https://www.codetalks.de/2015/programm) from 13 different tracks.\n\nEach track focussed on a specific theme like E-Commerce, IT Management, Startups, New Technology, Big Data, Mobile, DevOps, Scaling, Infrastructure, UX/Frontend, PHP, JavaScript and Java - the latter also being sponsored by ePages.\nTalks from these tracks where held in parallel at eight movie theater rooms.\nEach talk was 45 minutes long, with a small break afterwards plus a longer break for lunch.\nWatching these talks on huge cinema screens while sitting in cozy chairs and eating popcorn with nachos is a very special experience!\n\nDue to the huge amount of different talks, there was almost always at least one interesting session for everyone - more often than not it was a tough choice between two or more competing topics being presented at the same time.\nBetween the talks there was time for meeting and networking with other visitors to exchange impressions and ideas.\nAll the times there was more than enough excellent food and drinks provided; not only water, coffee and tea, but of course also [1337 mate](http://www.1337mate.com/) ;-)\n\nThose not already too exhausted by the intense first day had the opportunity to attend an exclusive party in the evening, also with vouchers for free drinks.\nAt breakfast the next day you could clearly tell who had a tough night, but judging from the full conference rooms only a few visitors slept in.\n\n## The talks\n\nI started the conference attending talks highly related to my current project at ePages:\n[Microservices](https://www.codetalks.de/2015/programm/radical-agility-with-autonomous-teams-and-microservices-in-the-cloud), [Docker containers](https://www.codetalks.de/2015/programm/patterns-in-a-containerized-world), [Consul](https://www.codetalks.de/2015/programm/die-cloud-im-griff-mit-consul), [Mesos & Marathon](https://www.codetalks.de/2015/programm/scalable-micro-services-with-apache-mesos-and-marathon) are technologies my team evaluates during our daily work.\nThe amount of relevant input from these talks was so intense that I had to switch to other topics in the afternoon.\nChoosing the very entertaining talk about creating PDFs using JavaScript for [printing out websites](https://www.codetalks.de/2015/programm/internet-ausdrucken-mit-javascript) was a welcome alternative and recharged my batteries to focus on [e-commerce topics](https://www.codetalks.de/2015/programm/demystify-the-commercetools-platform-how-to-build-a-global-e-commerce-api-platform) in the afternoon.\n\nOn Wednesday I started the conference with [Microservices](https://www.codetalks.de/2015/programm/microservices-und-die-jagd-nach-mehr-konversion) and [e-commerce](https://www.codetalks.de/2015/programm/spryker-e-commerce-framework-als-alternative-zu-traditioneller-shop-software) talks.\nAgain it proved to be a good choice to regain some energy by joining a more entertaining talk covering [elephants and squirrels](https://www.codetalks.de/2015/programm/liebling-ich-habe-das-framework-geschrumpft) before diving back into [e-commerce](https://www.codetalks.de/2015/programm/der-kunde-im-fokus-personalisierte-aussteuerung-von-inhalten-als-erfolgsfaktor-im-e-commerce) and [Docker](https://www.codetalks.de/2015/programm/docker-why-we-shouldn-t-use-it) again.\nThe biggest pleasant surprise for me that day was the talk about [monkey testing with genetic algorithms](https://www.codetalks.de/2015/programm/wenn-affen-testen-das-ende-der-bananensoftware), though:\nfinally the speaker managed to explain to me how mutation and crossover can be modeled in Software while still maintaining an entertaining talk and showing the applicability to tedious testing chores.\n\nOf course ePages also contributed a presentation to this year's `code.talks` - [Oliver](https://www.codetalks.de/2015/speaker/oliver-trosien) gave an interesting overview about documenting and testing REST APIs in a microservice world - [Documented and Tested Microservices For Fun And Profit](https://github.com/ePages-de/codetalks2015).\nThe talk provided a good overview of types of REST APIs, introduced HAL and [Spring Data REST](http://projects.spring.io/spring-data-rest/) as a framework to implement a HAL-based REST API.\nOliver also did some live coding showing how to use [Spring REST Docs](http://projects.spring.io/spring-restdocs/) to document REST APIs.\nThis showed an elegant way to include the API documentation into the integration tests of a project and thus keeping the API up-to-date.\n\nI really enjoyed the diversity of talks, which allowed me to switch focus based on my cognitive capacity.\nOf course different talks had different levels of complexity and quality, but my general impression was that most speakers knew their topic pretty well and were also able to deliver their talk in an interesting fashion.\nAnd meeting old and new contacts from _our_ development community in a friendly and relaxing environment is always something to look for.\n\n\n## Slides and presentations\n\n[About You](http://www.aboutyou.de/), the organizers of the `code.talks`, are going to [publish material](http://developer.aboutyou.de/blog/2015/09/code-talks-2015-talks-und-slides-der-speaker/) from the talks as the speakers submit their slides and presentations.\n","source":"_posts/2015-10-07-code-talks-2015-retrospective.md","raw":"---\nlayout: post\ntitle: \"code.talks 2015 retrospective\"\ndate: \"2015-10-07 09:00:00\"\ncategories: events\nauthors: [\"Jens\"]\n---\n\nFor the fifth time about 1,500 developers gathered for the yearly `code.talks` conference in Hamburg:\non September 29 and 30, a dozen ePagees went to the Cinemaxx Hamburg Dammtor to enjoy two days fully packed with [lots of talks](https://www.codetalks.de/2015/programm) from 13 different tracks.\n\nEach track focussed on a specific theme like E-Commerce, IT Management, Startups, New Technology, Big Data, Mobile, DevOps, Scaling, Infrastructure, UX/Frontend, PHP, JavaScript and Java - the latter also being sponsored by ePages.\nTalks from these tracks where held in parallel at eight movie theater rooms.\nEach talk was 45 minutes long, with a small break afterwards plus a longer break for lunch.\nWatching these talks on huge cinema screens while sitting in cozy chairs and eating popcorn with nachos is a very special experience!\n\nDue to the huge amount of different talks, there was almost always at least one interesting session for everyone - more often than not it was a tough choice between two or more competing topics being presented at the same time.\nBetween the talks there was time for meeting and networking with other visitors to exchange impressions and ideas.\nAll the times there was more than enough excellent food and drinks provided; not only water, coffee and tea, but of course also [1337 mate](http://www.1337mate.com/) ;-)\n\nThose not already too exhausted by the intense first day had the opportunity to attend an exclusive party in the evening, also with vouchers for free drinks.\nAt breakfast the next day you could clearly tell who had a tough night, but judging from the full conference rooms only a few visitors slept in.\n\n## The talks\n\nI started the conference attending talks highly related to my current project at ePages:\n[Microservices](https://www.codetalks.de/2015/programm/radical-agility-with-autonomous-teams-and-microservices-in-the-cloud), [Docker containers](https://www.codetalks.de/2015/programm/patterns-in-a-containerized-world), [Consul](https://www.codetalks.de/2015/programm/die-cloud-im-griff-mit-consul), [Mesos & Marathon](https://www.codetalks.de/2015/programm/scalable-micro-services-with-apache-mesos-and-marathon) are technologies my team evaluates during our daily work.\nThe amount of relevant input from these talks was so intense that I had to switch to other topics in the afternoon.\nChoosing the very entertaining talk about creating PDFs using JavaScript for [printing out websites](https://www.codetalks.de/2015/programm/internet-ausdrucken-mit-javascript) was a welcome alternative and recharged my batteries to focus on [e-commerce topics](https://www.codetalks.de/2015/programm/demystify-the-commercetools-platform-how-to-build-a-global-e-commerce-api-platform) in the afternoon.\n\nOn Wednesday I started the conference with [Microservices](https://www.codetalks.de/2015/programm/microservices-und-die-jagd-nach-mehr-konversion) and [e-commerce](https://www.codetalks.de/2015/programm/spryker-e-commerce-framework-als-alternative-zu-traditioneller-shop-software) talks.\nAgain it proved to be a good choice to regain some energy by joining a more entertaining talk covering [elephants and squirrels](https://www.codetalks.de/2015/programm/liebling-ich-habe-das-framework-geschrumpft) before diving back into [e-commerce](https://www.codetalks.de/2015/programm/der-kunde-im-fokus-personalisierte-aussteuerung-von-inhalten-als-erfolgsfaktor-im-e-commerce) and [Docker](https://www.codetalks.de/2015/programm/docker-why-we-shouldn-t-use-it) again.\nThe biggest pleasant surprise for me that day was the talk about [monkey testing with genetic algorithms](https://www.codetalks.de/2015/programm/wenn-affen-testen-das-ende-der-bananensoftware), though:\nfinally the speaker managed to explain to me how mutation and crossover can be modeled in Software while still maintaining an entertaining talk and showing the applicability to tedious testing chores.\n\nOf course ePages also contributed a presentation to this year's `code.talks` - [Oliver](https://www.codetalks.de/2015/speaker/oliver-trosien) gave an interesting overview about documenting and testing REST APIs in a microservice world - [Documented and Tested Microservices For Fun And Profit](https://github.com/ePages-de/codetalks2015).\nThe talk provided a good overview of types of REST APIs, introduced HAL and [Spring Data REST](http://projects.spring.io/spring-data-rest/) as a framework to implement a HAL-based REST API.\nOliver also did some live coding showing how to use [Spring REST Docs](http://projects.spring.io/spring-restdocs/) to document REST APIs.\nThis showed an elegant way to include the API documentation into the integration tests of a project and thus keeping the API up-to-date.\n\nI really enjoyed the diversity of talks, which allowed me to switch focus based on my cognitive capacity.\nOf course different talks had different levels of complexity and quality, but my general impression was that most speakers knew their topic pretty well and were also able to deliver their talk in an interesting fashion.\nAnd meeting old and new contacts from _our_ development community in a friendly and relaxing environment is always something to look for.\n\n\n## Slides and presentations\n\n[About You](http://www.aboutyou.de/), the organizers of the `code.talks`, are going to [publish material](http://developer.aboutyou.de/blog/2015/09/code-talks-2015-talks-und-slides-der-speaker/) from the talks as the speakers submit their slides and presentations.\n","slug":"2015-10-07-code-talks-2015-retrospective","published":1,"updated":"2016-09-20T14:19:22.000Z","comments":1,"photos":[],"link":"","_id":"ciu6nuh8z0018hqyxlh478ilq","content":"<p>For the fifth time about 1,500 developers gathered for the yearly <code>code.talks</code> conference in Hamburg:<br>on September 29 and 30, a dozen ePagees went to the Cinemaxx Hamburg Dammtor to enjoy two days fully packed with <a href=\"https://www.codetalks.de/2015/programm\" target=\"_blank\" rel=\"external\">lots of talks</a> from 13 different tracks.</p>\n<p>Each track focussed on a specific theme like E-Commerce, IT Management, Startups, New Technology, Big Data, Mobile, DevOps, Scaling, Infrastructure, UX/Frontend, PHP, JavaScript and Java - the latter also being sponsored by ePages.<br>Talks from these tracks where held in parallel at eight movie theater rooms.<br>Each talk was 45 minutes long, with a small break afterwards plus a longer break for lunch.<br>Watching these talks on huge cinema screens while sitting in cozy chairs and eating popcorn with nachos is a very special experience!</p>\n<p>Due to the huge amount of different talks, there was almost always at least one interesting session for everyone - more often than not it was a tough choice between two or more competing topics being presented at the same time.<br>Between the talks there was time for meeting and networking with other visitors to exchange impressions and ideas.<br>All the times there was more than enough excellent food and drinks provided; not only water, coffee and tea, but of course also <a href=\"http://www.1337mate.com/\" target=\"_blank\" rel=\"external\">1337 mate</a> ;-)</p>\n<p>Those not already too exhausted by the intense first day had the opportunity to attend an exclusive party in the evening, also with vouchers for free drinks.<br>At breakfast the next day you could clearly tell who had a tough night, but judging from the full conference rooms only a few visitors slept in.</p>\n<h2 id=\"The-talks\"><a href=\"#The-talks\" class=\"headerlink\" title=\"The talks\"></a>The talks</h2><p>I started the conference attending talks highly related to my current project at ePages:<br><a href=\"https://www.codetalks.de/2015/programm/radical-agility-with-autonomous-teams-and-microservices-in-the-cloud\" target=\"_blank\" rel=\"external\">Microservices</a>, <a href=\"https://www.codetalks.de/2015/programm/patterns-in-a-containerized-world\" target=\"_blank\" rel=\"external\">Docker containers</a>, <a href=\"https://www.codetalks.de/2015/programm/die-cloud-im-griff-mit-consul\" target=\"_blank\" rel=\"external\">Consul</a>, <a href=\"https://www.codetalks.de/2015/programm/scalable-micro-services-with-apache-mesos-and-marathon\" target=\"_blank\" rel=\"external\">Mesos &amp; Marathon</a> are technologies my team evaluates during our daily work.<br>The amount of relevant input from these talks was so intense that I had to switch to other topics in the afternoon.<br>Choosing the very entertaining talk about creating PDFs using JavaScript for <a href=\"https://www.codetalks.de/2015/programm/internet-ausdrucken-mit-javascript\" target=\"_blank\" rel=\"external\">printing out websites</a> was a welcome alternative and recharged my batteries to focus on <a href=\"https://www.codetalks.de/2015/programm/demystify-the-commercetools-platform-how-to-build-a-global-e-commerce-api-platform\" target=\"_blank\" rel=\"external\">e-commerce topics</a> in the afternoon.</p>\n<p>On Wednesday I started the conference with <a href=\"https://www.codetalks.de/2015/programm/microservices-und-die-jagd-nach-mehr-konversion\" target=\"_blank\" rel=\"external\">Microservices</a> and <a href=\"https://www.codetalks.de/2015/programm/spryker-e-commerce-framework-als-alternative-zu-traditioneller-shop-software\" target=\"_blank\" rel=\"external\">e-commerce</a> talks.<br>Again it proved to be a good choice to regain some energy by joining a more entertaining talk covering <a href=\"https://www.codetalks.de/2015/programm/liebling-ich-habe-das-framework-geschrumpft\" target=\"_blank\" rel=\"external\">elephants and squirrels</a> before diving back into <a href=\"https://www.codetalks.de/2015/programm/der-kunde-im-fokus-personalisierte-aussteuerung-von-inhalten-als-erfolgsfaktor-im-e-commerce\" target=\"_blank\" rel=\"external\">e-commerce</a> and <a href=\"https://www.codetalks.de/2015/programm/docker-why-we-shouldn-t-use-it\" target=\"_blank\" rel=\"external\">Docker</a> again.<br>The biggest pleasant surprise for me that day was the talk about <a href=\"https://www.codetalks.de/2015/programm/wenn-affen-testen-das-ende-der-bananensoftware\" target=\"_blank\" rel=\"external\">monkey testing with genetic algorithms</a>, though:<br>finally the speaker managed to explain to me how mutation and crossover can be modeled in Software while still maintaining an entertaining talk and showing the applicability to tedious testing chores.</p>\n<p>Of course ePages also contributed a presentation to this year’s <code>code.talks</code> - <a href=\"https://www.codetalks.de/2015/speaker/oliver-trosien\" target=\"_blank\" rel=\"external\">Oliver</a> gave an interesting overview about documenting and testing REST APIs in a microservice world - <a href=\"https://github.com/ePages-de/codetalks2015\" target=\"_blank\" rel=\"external\">Documented and Tested Microservices For Fun And Profit</a>.<br>The talk provided a good overview of types of REST APIs, introduced HAL and <a href=\"http://projects.spring.io/spring-data-rest/\" target=\"_blank\" rel=\"external\">Spring Data REST</a> as a framework to implement a HAL-based REST API.<br>Oliver also did some live coding showing how to use <a href=\"http://projects.spring.io/spring-restdocs/\" target=\"_blank\" rel=\"external\">Spring REST Docs</a> to document REST APIs.<br>This showed an elegant way to include the API documentation into the integration tests of a project and thus keeping the API up-to-date.</p>\n<p>I really enjoyed the diversity of talks, which allowed me to switch focus based on my cognitive capacity.<br>Of course different talks had different levels of complexity and quality, but my general impression was that most speakers knew their topic pretty well and were also able to deliver their talk in an interesting fashion.<br>And meeting old and new contacts from <em>our</em> development community in a friendly and relaxing environment is always something to look for.</p>\n<h2 id=\"Slides-and-presentations\"><a href=\"#Slides-and-presentations\" class=\"headerlink\" title=\"Slides and presentations\"></a>Slides and presentations</h2><p><a href=\"http://www.aboutyou.de/\" target=\"_blank\" rel=\"external\">About You</a>, the organizers of the <code>code.talks</code>, are going to <a href=\"http://developer.aboutyou.de/blog/2015/09/code-talks-2015-talks-und-slides-der-speaker/\" target=\"_blank\" rel=\"external\">publish material</a> from the talks as the speakers submit their slides and presentations.</p>\n","excerpt":"","more":"<p>For the fifth time about 1,500 developers gathered for the yearly <code>code.talks</code> conference in Hamburg:<br>on September 29 and 30, a dozen ePagees went to the Cinemaxx Hamburg Dammtor to enjoy two days fully packed with <a href=\"https://www.codetalks.de/2015/programm\">lots of talks</a> from 13 different tracks.</p>\n<p>Each track focussed on a specific theme like E-Commerce, IT Management, Startups, New Technology, Big Data, Mobile, DevOps, Scaling, Infrastructure, UX/Frontend, PHP, JavaScript and Java - the latter also being sponsored by ePages.<br>Talks from these tracks where held in parallel at eight movie theater rooms.<br>Each talk was 45 minutes long, with a small break afterwards plus a longer break for lunch.<br>Watching these talks on huge cinema screens while sitting in cozy chairs and eating popcorn with nachos is a very special experience!</p>\n<p>Due to the huge amount of different talks, there was almost always at least one interesting session for everyone - more often than not it was a tough choice between two or more competing topics being presented at the same time.<br>Between the talks there was time for meeting and networking with other visitors to exchange impressions and ideas.<br>All the times there was more than enough excellent food and drinks provided; not only water, coffee and tea, but of course also <a href=\"http://www.1337mate.com/\">1337 mate</a> ;-)</p>\n<p>Those not already too exhausted by the intense first day had the opportunity to attend an exclusive party in the evening, also with vouchers for free drinks.<br>At breakfast the next day you could clearly tell who had a tough night, but judging from the full conference rooms only a few visitors slept in.</p>\n<h2 id=\"The-talks\"><a href=\"#The-talks\" class=\"headerlink\" title=\"The talks\"></a>The talks</h2><p>I started the conference attending talks highly related to my current project at ePages:<br><a href=\"https://www.codetalks.de/2015/programm/radical-agility-with-autonomous-teams-and-microservices-in-the-cloud\">Microservices</a>, <a href=\"https://www.codetalks.de/2015/programm/patterns-in-a-containerized-world\">Docker containers</a>, <a href=\"https://www.codetalks.de/2015/programm/die-cloud-im-griff-mit-consul\">Consul</a>, <a href=\"https://www.codetalks.de/2015/programm/scalable-micro-services-with-apache-mesos-and-marathon\">Mesos &amp; Marathon</a> are technologies my team evaluates during our daily work.<br>The amount of relevant input from these talks was so intense that I had to switch to other topics in the afternoon.<br>Choosing the very entertaining talk about creating PDFs using JavaScript for <a href=\"https://www.codetalks.de/2015/programm/internet-ausdrucken-mit-javascript\">printing out websites</a> was a welcome alternative and recharged my batteries to focus on <a href=\"https://www.codetalks.de/2015/programm/demystify-the-commercetools-platform-how-to-build-a-global-e-commerce-api-platform\">e-commerce topics</a> in the afternoon.</p>\n<p>On Wednesday I started the conference with <a href=\"https://www.codetalks.de/2015/programm/microservices-und-die-jagd-nach-mehr-konversion\">Microservices</a> and <a href=\"https://www.codetalks.de/2015/programm/spryker-e-commerce-framework-als-alternative-zu-traditioneller-shop-software\">e-commerce</a> talks.<br>Again it proved to be a good choice to regain some energy by joining a more entertaining talk covering <a href=\"https://www.codetalks.de/2015/programm/liebling-ich-habe-das-framework-geschrumpft\">elephants and squirrels</a> before diving back into <a href=\"https://www.codetalks.de/2015/programm/der-kunde-im-fokus-personalisierte-aussteuerung-von-inhalten-als-erfolgsfaktor-im-e-commerce\">e-commerce</a> and <a href=\"https://www.codetalks.de/2015/programm/docker-why-we-shouldn-t-use-it\">Docker</a> again.<br>The biggest pleasant surprise for me that day was the talk about <a href=\"https://www.codetalks.de/2015/programm/wenn-affen-testen-das-ende-der-bananensoftware\">monkey testing with genetic algorithms</a>, though:<br>finally the speaker managed to explain to me how mutation and crossover can be modeled in Software while still maintaining an entertaining talk and showing the applicability to tedious testing chores.</p>\n<p>Of course ePages also contributed a presentation to this year’s <code>code.talks</code> - <a href=\"https://www.codetalks.de/2015/speaker/oliver-trosien\">Oliver</a> gave an interesting overview about documenting and testing REST APIs in a microservice world - <a href=\"https://github.com/ePages-de/codetalks2015\">Documented and Tested Microservices For Fun And Profit</a>.<br>The talk provided a good overview of types of REST APIs, introduced HAL and <a href=\"http://projects.spring.io/spring-data-rest/\">Spring Data REST</a> as a framework to implement a HAL-based REST API.<br>Oliver also did some live coding showing how to use <a href=\"http://projects.spring.io/spring-restdocs/\">Spring REST Docs</a> to document REST APIs.<br>This showed an elegant way to include the API documentation into the integration tests of a project and thus keeping the API up-to-date.</p>\n<p>I really enjoyed the diversity of talks, which allowed me to switch focus based on my cognitive capacity.<br>Of course different talks had different levels of complexity and quality, but my general impression was that most speakers knew their topic pretty well and were also able to deliver their talk in an interesting fashion.<br>And meeting old and new contacts from <em>our</em> development community in a friendly and relaxing environment is always something to look for.</p>\n<h2 id=\"Slides-and-presentations\"><a href=\"#Slides-and-presentations\" class=\"headerlink\" title=\"Slides and presentations\"></a>Slides and presentations</h2><p><a href=\"http://www.aboutyou.de/\">About You</a>, the organizers of the <code>code.talks</code>, are going to <a href=\"http://developer.aboutyou.de/blog/2015/09/code-talks-2015-talks-und-slides-der-speaker/\">publish material</a> from the talks as the speakers submit their slides and presentations.</p>\n"},{"layout":"post","title":"#refugeehackathon","date":"2015-10-27T11:00:00.000Z","authors":["Jan"],"_content":"\nLots of refugees arrived in Germany.\nTasks like organising accommodation, food and clothing and supporting them with their onwards journey raises many challenges.\nThough I am not able to work day and night for the solution like some people in the crisis management group, I wanted to fly the flag to show that a significant amount of people are willing to help.\nThis blog post is a report about participating in the #refugeehackathon in Berlin, Germany.\n\n## Overview of the event\n\nThe [#refugeehackathon](https://twitter.com/search?src=typd&q=%23refugeehackathon) started on Friday, 24th October 2015 with a requirements workshop.\nA small group of people visited the refugees and talked about project ideas which could be helpful for them.\nThe official start was on Saturday morning.\nAfter some welcoming words, a short video about the challenging situation of refugees travelling through Europe was shown.\nNext there was a motivational speech from a Somalian lady.\nShe invited us not to label people as refugees but to regard them as newcomers.\nAfterwards there was a presentation of project ideas from the workshop as well as outlining existing ideas.\n\n## The Volunteer Planner project\n\nThe project which I selected was the [Volunteer Planner](https://volunteer-planner.org/).\nIt is an online platform which enables volunteers to sign up for tasks identified\nby different aid organisations and is created by a handful of programmers, designers and project managers.\nThough the project is only three month old and thus not yet feature complete they already have 19,354 registered users and 51,286 completed volunteer work hours.\n\n{% image blog/blog-refugeehackathon-volunteer-planner.jpg %}\n\n## What we achieved\n\nAt the beginning we collected and discussed feature ideas for the Volunteer Planner.\nWe prioritised the ideas (which was shown in\n[the news](http://www.heute.de/refugee-hackathon-in-berlin-digitale-fluechtlingshilfe-in-48-stunden-von-it-leuten-40700228.html)) and then started to work in pairs on the things we were most interested in.\nWe implemented an overview page for individual aid organisations, a language switch and fixed a couple of interesting bugs.\n\nMy main focus was on the implementation of a feature which will enable staff of aid organisations to maintain their volunteer shifts by themselves instead of mailing them to the admin team.\nWe created a [wireframe model](https://gomockingbird.com/projects/fnzc6qu) for the shift creation workflow and a shift template mechanism similar to online banking transactions.\nLater on, it should be extended with some kind of batch templates for the support of power users.\nFor some reasons we did not manage to finish the implementation in time so there is still some pending work after the hackathon.\n\n## Conclusion\n\nThis #refugeehackathon was a very enriching experience for me.\nI got to know interesting people and we had a lot of fun together.\nOn top of that, I learned a number of lessons about web development in general and Python/Django in particular.\n\nHopefully my journey will also result in a little bit of practical help for the newcomers.\n\nSo many thanks at [@ePages](https://twitter.com/ePages) for sponsoring me with some work hours, the train tickets and hotel costs.\n","source":"_posts/2015-10-27-refugeehackathon.md","raw":"---\nlayout: post\ntitle: \"#refugeehackathon\"\ndate: \"2015-10-27 12:00:00\"\ncategories: events\nauthors: [\"Jan\"]\n---\n\nLots of refugees arrived in Germany.\nTasks like organising accommodation, food and clothing and supporting them with their onwards journey raises many challenges.\nThough I am not able to work day and night for the solution like some people in the crisis management group, I wanted to fly the flag to show that a significant amount of people are willing to help.\nThis blog post is a report about participating in the #refugeehackathon in Berlin, Germany.\n\n## Overview of the event\n\nThe [#refugeehackathon](https://twitter.com/search?src=typd&q=%23refugeehackathon) started on Friday, 24th October 2015 with a requirements workshop.\nA small group of people visited the refugees and talked about project ideas which could be helpful for them.\nThe official start was on Saturday morning.\nAfter some welcoming words, a short video about the challenging situation of refugees travelling through Europe was shown.\nNext there was a motivational speech from a Somalian lady.\nShe invited us not to label people as refugees but to regard them as newcomers.\nAfterwards there was a presentation of project ideas from the workshop as well as outlining existing ideas.\n\n## The Volunteer Planner project\n\nThe project which I selected was the [Volunteer Planner](https://volunteer-planner.org/).\nIt is an online platform which enables volunteers to sign up for tasks identified\nby different aid organisations and is created by a handful of programmers, designers and project managers.\nThough the project is only three month old and thus not yet feature complete they already have 19,354 registered users and 51,286 completed volunteer work hours.\n\n{% image blog/blog-refugeehackathon-volunteer-planner.jpg %}\n\n## What we achieved\n\nAt the beginning we collected and discussed feature ideas for the Volunteer Planner.\nWe prioritised the ideas (which was shown in\n[the news](http://www.heute.de/refugee-hackathon-in-berlin-digitale-fluechtlingshilfe-in-48-stunden-von-it-leuten-40700228.html)) and then started to work in pairs on the things we were most interested in.\nWe implemented an overview page for individual aid organisations, a language switch and fixed a couple of interesting bugs.\n\nMy main focus was on the implementation of a feature which will enable staff of aid organisations to maintain their volunteer shifts by themselves instead of mailing them to the admin team.\nWe created a [wireframe model](https://gomockingbird.com/projects/fnzc6qu) for the shift creation workflow and a shift template mechanism similar to online banking transactions.\nLater on, it should be extended with some kind of batch templates for the support of power users.\nFor some reasons we did not manage to finish the implementation in time so there is still some pending work after the hackathon.\n\n## Conclusion\n\nThis #refugeehackathon was a very enriching experience for me.\nI got to know interesting people and we had a lot of fun together.\nOn top of that, I learned a number of lessons about web development in general and Python/Django in particular.\n\nHopefully my journey will also result in a little bit of practical help for the newcomers.\n\nSo many thanks at [@ePages](https://twitter.com/ePages) for sponsoring me with some work hours, the train tickets and hotel costs.\n","slug":"2015-10-27-refugeehackathon","published":1,"updated":"2016-09-20T14:19:22.000Z","comments":1,"photos":[],"link":"","_id":"ciu6nuh90001ahqyxviyljtf2","content":"<p>Lots of refugees arrived in Germany.<br>Tasks like organising accommodation, food and clothing and supporting them with their onwards journey raises many challenges.<br>Though I am not able to work day and night for the solution like some people in the crisis management group, I wanted to fly the flag to show that a significant amount of people are willing to help.<br>This blog post is a report about participating in the #refugeehackathon in Berlin, Germany.</p>\n<h2 id=\"Overview-of-the-event\"><a href=\"#Overview-of-the-event\" class=\"headerlink\" title=\"Overview of the event\"></a>Overview of the event</h2><p>The <a href=\"https://twitter.com/search?src=typd&amp;q=%23refugeehackathon\" target=\"_blank\" rel=\"external\">#refugeehackathon</a> started on Friday, 24th October 2015 with a requirements workshop.<br>A small group of people visited the refugees and talked about project ideas which could be helpful for them.<br>The official start was on Saturday morning.<br>After some welcoming words, a short video about the challenging situation of refugees travelling through Europe was shown.<br>Next there was a motivational speech from a Somalian lady.<br>She invited us not to label people as refugees but to regard them as newcomers.<br>Afterwards there was a presentation of project ideas from the workshop as well as outlining existing ideas.</p>\n<h2 id=\"The-Volunteer-Planner-project\"><a href=\"#The-Volunteer-Planner-project\" class=\"headerlink\" title=\"The Volunteer Planner project\"></a>The Volunteer Planner project</h2><p>The project which I selected was the <a href=\"https://volunteer-planner.org/\" target=\"_blank\" rel=\"external\">Volunteer Planner</a>.<br>It is an online platform which enables volunteers to sign up for tasks identified<br>by different aid organisations and is created by a handful of programmers, designers and project managers.<br>Though the project is only three month old and thus not yet feature complete they already have 19,354 registered users and 51,286 completed volunteer work hours.</p>\n<img class=\"blog/blog-refugeehackathon-volunteer-planner.jpg\">\n<h2 id=\"What-we-achieved\"><a href=\"#What-we-achieved\" class=\"headerlink\" title=\"What we achieved\"></a>What we achieved</h2><p>At the beginning we collected and discussed feature ideas for the Volunteer Planner.<br>We prioritised the ideas (which was shown in<br><a href=\"http://www.heute.de/refugee-hackathon-in-berlin-digitale-fluechtlingshilfe-in-48-stunden-von-it-leuten-40700228.html\" target=\"_blank\" rel=\"external\">the news</a>) and then started to work in pairs on the things we were most interested in.<br>We implemented an overview page for individual aid organisations, a language switch and fixed a couple of interesting bugs.</p>\n<p>My main focus was on the implementation of a feature which will enable staff of aid organisations to maintain their volunteer shifts by themselves instead of mailing them to the admin team.<br>We created a <a href=\"https://gomockingbird.com/projects/fnzc6qu\" target=\"_blank\" rel=\"external\">wireframe model</a> for the shift creation workflow and a shift template mechanism similar to online banking transactions.<br>Later on, it should be extended with some kind of batch templates for the support of power users.<br>For some reasons we did not manage to finish the implementation in time so there is still some pending work after the hackathon.</p>\n<h2 id=\"Conclusion\"><a href=\"#Conclusion\" class=\"headerlink\" title=\"Conclusion\"></a>Conclusion</h2><p>This #refugeehackathon was a very enriching experience for me.<br>I got to know interesting people and we had a lot of fun together.<br>On top of that, I learned a number of lessons about web development in general and Python/Django in particular.</p>\n<p>Hopefully my journey will also result in a little bit of practical help for the newcomers.</p>\n<p>So many thanks at <a href=\"https://twitter.com/ePages\" target=\"_blank\" rel=\"external\">@ePages</a> for sponsoring me with some work hours, the train tickets and hotel costs.</p>\n","excerpt":"","more":"<p>Lots of refugees arrived in Germany.<br>Tasks like organising accommodation, food and clothing and supporting them with their onwards journey raises many challenges.<br>Though I am not able to work day and night for the solution like some people in the crisis management group, I wanted to fly the flag to show that a significant amount of people are willing to help.<br>This blog post is a report about participating in the #refugeehackathon in Berlin, Germany.</p>\n<h2 id=\"Overview-of-the-event\"><a href=\"#Overview-of-the-event\" class=\"headerlink\" title=\"Overview of the event\"></a>Overview of the event</h2><p>The <a href=\"https://twitter.com/search?src=typd&amp;q=%23refugeehackathon\">#refugeehackathon</a> started on Friday, 24th October 2015 with a requirements workshop.<br>A small group of people visited the refugees and talked about project ideas which could be helpful for them.<br>The official start was on Saturday morning.<br>After some welcoming words, a short video about the challenging situation of refugees travelling through Europe was shown.<br>Next there was a motivational speech from a Somalian lady.<br>She invited us not to label people as refugees but to regard them as newcomers.<br>Afterwards there was a presentation of project ideas from the workshop as well as outlining existing ideas.</p>\n<h2 id=\"The-Volunteer-Planner-project\"><a href=\"#The-Volunteer-Planner-project\" class=\"headerlink\" title=\"The Volunteer Planner project\"></a>The Volunteer Planner project</h2><p>The project which I selected was the <a href=\"https://volunteer-planner.org/\">Volunteer Planner</a>.<br>It is an online platform which enables volunteers to sign up for tasks identified<br>by different aid organisations and is created by a handful of programmers, designers and project managers.<br>Though the project is only three month old and thus not yet feature complete they already have 19,354 registered users and 51,286 completed volunteer work hours.</p>\n<img class=\"blog/blog-refugeehackathon-volunteer-planner.jpg\">\n<h2 id=\"What-we-achieved\"><a href=\"#What-we-achieved\" class=\"headerlink\" title=\"What we achieved\"></a>What we achieved</h2><p>At the beginning we collected and discussed feature ideas for the Volunteer Planner.<br>We prioritised the ideas (which was shown in<br><a href=\"http://www.heute.de/refugee-hackathon-in-berlin-digitale-fluechtlingshilfe-in-48-stunden-von-it-leuten-40700228.html\">the news</a>) and then started to work in pairs on the things we were most interested in.<br>We implemented an overview page for individual aid organisations, a language switch and fixed a couple of interesting bugs.</p>\n<p>My main focus was on the implementation of a feature which will enable staff of aid organisations to maintain their volunteer shifts by themselves instead of mailing them to the admin team.<br>We created a <a href=\"https://gomockingbird.com/projects/fnzc6qu\">wireframe model</a> for the shift creation workflow and a shift template mechanism similar to online banking transactions.<br>Later on, it should be extended with some kind of batch templates for the support of power users.<br>For some reasons we did not manage to finish the implementation in time so there is still some pending work after the hackathon.</p>\n<h2 id=\"Conclusion\"><a href=\"#Conclusion\" class=\"headerlink\" title=\"Conclusion\"></a>Conclusion</h2><p>This #refugeehackathon was a very enriching experience for me.<br>I got to know interesting people and we had a lot of fun together.<br>On top of that, I learned a number of lessons about web development in general and Python/Django in particular.</p>\n<p>Hopefully my journey will also result in a little bit of practical help for the newcomers.</p>\n<p>So many thanks at <a href=\"https://twitter.com/ePages\">@ePages</a> for sponsoring me with some work hours, the train tickets and hotel costs.</p>\n"},{"layout":"post","title":"code.talks: code & nachos","date":"2015-10-28T06:17:00.000Z","image":"blog-header/nachos.jpg","authors":["Erik"],"_content":"\nSome weeks ago we attended the `code.talks` developer conference in Hamburg.\nBesides the amazing location (which was the Cinemaxx Dammtor) and the awesome catering (as much nachos, popcorn and Mate as you can endure) the conference was also (who would have guessed that) packed with lots of interesting presentations and people.\n\nListening to the many great presentations we found things that we're already doing right (according to the speakers) but also other aspects we can improve on.\nThere were also talks that we were able to contribute to since we had already come across their problems and solved them already.\nI'd like to cover **three** main points that I got during this conference in the following paragraphs.\nOne last word of advice: Not everything should be taken too seriously ;)\n\n## 1. Node is acknowledged by the Java world\n\nThe first talk (I attended) was about *JavaScript on Java Servers* and was said to cover how the new kid on the block coming around as JavaScript 5 and JavaScript 6 is going to run on a Java Server.\nOur Java gurus instantly asked the ultimate question: What is a \"Java Server\"?\nOk, we all knew it's probably the JVM.\nAnd I myself was wondering if the JavaScript versions 5 and 6 might have something to do with the corresponding ECMA-Script standards.\nBut hey, let's not get hung up on naming issues, shall we?\n\nBesides advertising *jWebSockets* there was a benchmark showing that *Nashorn* (the new JavaScript engine coming with Java8) is way faster than the old *Rhino* (Java6/7) implementation.\nWhile leveraging Java8's `invokedynamic` it takes some additional time to warm up but afterwards outruns rhino for good.\nWith *warming up* the \"compiler people\" refer to having the programme optimised by the machine until it runs several 10 times faster than in a cold state.\nAnd honestly the difference was impressive.\nThat being said I noticed that `V8`, Google's JavaScript engine powering *nodejs* as well as Chrome, still being **twice** as fast as the warmed up Nashorn.\nNow that's something.\n\nAnyway, one has to keep in mind that Google threw a lot of resources into developing this awesome piece of software.\nOf course you don't get all of the JVM's nifty little things like concurrency, sandboxing and... well basically the complete Java stack but there have to be some drawbacks, right?\nTo overcome this single-process-problem, node recently introduced a completely overhauled `cluster` module.\nThis native module as well as process managers like *pm2* and *strongloop* do a great job in distributing load between several single-threaded node processes (and with that still crushing any JVM based JS engine).\n\nNonetheless, the talk was pretty interesting with regards to what is possible with the JVM and how easy it is to run JavaScript code on a \"Java Server\" (I was again reminded why Java is called a typed language: Because you have to type so freaking much!).\nThings to keep in mind though: All used `npm` packages must be \"nashorn compatible\".\nWhatever this means.\n\nFor reading this far you deserve a well kept secret about `npm`: It's **not** an abbreviation for the **n**ode **p**ackage **m**anager but a recursive bacronymic abbreviation for \"npm is not an acronym\".\n\nHowever rumor has it, the package manager sends \"**n**aughty **p**ush **m**essages\" once installed (see [npm-expansions](https://github.com/npm/npm-expansions)).\n\n## 2. We're pretty much up-to-date\n\nIn the Frontend/JavaScript track there were several talks covering various aspects.\nFrom the language itself ('There is no JavaScript' - awesome presentation by Noam Kfir) to pretty interesting testing approaches and the life of suffering with React and ES6.\nWe realised that our current testing and build pipeline which consists of `mocha`, `babel`, `karma` and `webpack` is not only considered state of the art but is just discovered by some companies.\nThey shared knowledge of pitfalls they encountered and how they overcame them (or at least how they tried to do so).\nTheir solution was basically our current build configuration.\nBut since the topic is pretty tricky, there were of course some nifty tricks we've yet to adopt so we're very glad they went through all that pain and shared these valuable findings.\nAnyway, it still gave us a pretty confident feeling about how we're doing things.\nThese days it seems to be the mix of ES6, ES5 and React modules together with universal JavaScript that is the most challenging thing to overcome.\n\n## 3. Operations is your new best friend\n\nFirst I have to say that this talk, done by two guys from 1&1, was really inspiring and made you think of changing a thing or two in your own development workflow.\n\nPlainly put, the whole talk was about **DevOps** and how this construct can help to smoothen relations between all kinds of different departments throughout the whole company.\nTranslated to ourselves they mainly spoke of improving workflows between the RND department (the developers) and the team which takes care of managing and deploying the application (AM).\nThe scenario described was one that I myself experienced one time or another: The over-the-fence phenomenon.\nA developer finishes a feature and sends it to Operations.\nNow they can deal with it!\n**But**: It might be hard to deploy because of several reasons (be it a changed database structure or some changes in the build pipeline), it might have bugs, break other features or cause who knows what.\nSo a developer should not only take care of finishing the feature assigned to him but also have in mind that there's work *after* he did his final commit.\nHe (or she of course) should feel responsible for the software as a whole (and everything that is related to it).\n\nThe 1&1 guys gave several tips on how to improve communications and workflows. They also talked about how *they* tried to establish DevOps.\nBringing together developers and operations not only smoothens (and probably speeds up) the workflows but also widens the knowledge of both department's members.\nAnd learning new things can never be bad ;)\n","source":"_posts/2015-10-28-code-talks-java.md","raw":"---\nlayout: post\ntitle: \"code.talks: code & nachos\"\ndate: \"2015-10-28 07:17:00\"\nimage: blog-header/nachos.jpg\ncategories: events\nauthors: [\"Erik\"]\n---\n\nSome weeks ago we attended the `code.talks` developer conference in Hamburg.\nBesides the amazing location (which was the Cinemaxx Dammtor) and the awesome catering (as much nachos, popcorn and Mate as you can endure) the conference was also (who would have guessed that) packed with lots of interesting presentations and people.\n\nListening to the many great presentations we found things that we're already doing right (according to the speakers) but also other aspects we can improve on.\nThere were also talks that we were able to contribute to since we had already come across their problems and solved them already.\nI'd like to cover **three** main points that I got during this conference in the following paragraphs.\nOne last word of advice: Not everything should be taken too seriously ;)\n\n## 1. Node is acknowledged by the Java world\n\nThe first talk (I attended) was about *JavaScript on Java Servers* and was said to cover how the new kid on the block coming around as JavaScript 5 and JavaScript 6 is going to run on a Java Server.\nOur Java gurus instantly asked the ultimate question: What is a \"Java Server\"?\nOk, we all knew it's probably the JVM.\nAnd I myself was wondering if the JavaScript versions 5 and 6 might have something to do with the corresponding ECMA-Script standards.\nBut hey, let's not get hung up on naming issues, shall we?\n\nBesides advertising *jWebSockets* there was a benchmark showing that *Nashorn* (the new JavaScript engine coming with Java8) is way faster than the old *Rhino* (Java6/7) implementation.\nWhile leveraging Java8's `invokedynamic` it takes some additional time to warm up but afterwards outruns rhino for good.\nWith *warming up* the \"compiler people\" refer to having the programme optimised by the machine until it runs several 10 times faster than in a cold state.\nAnd honestly the difference was impressive.\nThat being said I noticed that `V8`, Google's JavaScript engine powering *nodejs* as well as Chrome, still being **twice** as fast as the warmed up Nashorn.\nNow that's something.\n\nAnyway, one has to keep in mind that Google threw a lot of resources into developing this awesome piece of software.\nOf course you don't get all of the JVM's nifty little things like concurrency, sandboxing and... well basically the complete Java stack but there have to be some drawbacks, right?\nTo overcome this single-process-problem, node recently introduced a completely overhauled `cluster` module.\nThis native module as well as process managers like *pm2* and *strongloop* do a great job in distributing load between several single-threaded node processes (and with that still crushing any JVM based JS engine).\n\nNonetheless, the talk was pretty interesting with regards to what is possible with the JVM and how easy it is to run JavaScript code on a \"Java Server\" (I was again reminded why Java is called a typed language: Because you have to type so freaking much!).\nThings to keep in mind though: All used `npm` packages must be \"nashorn compatible\".\nWhatever this means.\n\nFor reading this far you deserve a well kept secret about `npm`: It's **not** an abbreviation for the **n**ode **p**ackage **m**anager but a recursive bacronymic abbreviation for \"npm is not an acronym\".\n\nHowever rumor has it, the package manager sends \"**n**aughty **p**ush **m**essages\" once installed (see [npm-expansions](https://github.com/npm/npm-expansions)).\n\n## 2. We're pretty much up-to-date\n\nIn the Frontend/JavaScript track there were several talks covering various aspects.\nFrom the language itself ('There is no JavaScript' - awesome presentation by Noam Kfir) to pretty interesting testing approaches and the life of suffering with React and ES6.\nWe realised that our current testing and build pipeline which consists of `mocha`, `babel`, `karma` and `webpack` is not only considered state of the art but is just discovered by some companies.\nThey shared knowledge of pitfalls they encountered and how they overcame them (or at least how they tried to do so).\nTheir solution was basically our current build configuration.\nBut since the topic is pretty tricky, there were of course some nifty tricks we've yet to adopt so we're very glad they went through all that pain and shared these valuable findings.\nAnyway, it still gave us a pretty confident feeling about how we're doing things.\nThese days it seems to be the mix of ES6, ES5 and React modules together with universal JavaScript that is the most challenging thing to overcome.\n\n## 3. Operations is your new best friend\n\nFirst I have to say that this talk, done by two guys from 1&1, was really inspiring and made you think of changing a thing or two in your own development workflow.\n\nPlainly put, the whole talk was about **DevOps** and how this construct can help to smoothen relations between all kinds of different departments throughout the whole company.\nTranslated to ourselves they mainly spoke of improving workflows between the RND department (the developers) and the team which takes care of managing and deploying the application (AM).\nThe scenario described was one that I myself experienced one time or another: The over-the-fence phenomenon.\nA developer finishes a feature and sends it to Operations.\nNow they can deal with it!\n**But**: It might be hard to deploy because of several reasons (be it a changed database structure or some changes in the build pipeline), it might have bugs, break other features or cause who knows what.\nSo a developer should not only take care of finishing the feature assigned to him but also have in mind that there's work *after* he did his final commit.\nHe (or she of course) should feel responsible for the software as a whole (and everything that is related to it).\n\nThe 1&1 guys gave several tips on how to improve communications and workflows. They also talked about how *they* tried to establish DevOps.\nBringing together developers and operations not only smoothens (and probably speeds up) the workflows but also widens the knowledge of both department's members.\nAnd learning new things can never be bad ;)\n","slug":"2015-10-28-code-talks-java","published":1,"updated":"2016-09-20T14:19:22.000Z","comments":1,"photos":[],"link":"","_id":"ciu6nuh91001chqyxzkvx9zyy","content":"<p>Some weeks ago we attended the <code>code.talks</code> developer conference in Hamburg.<br>Besides the amazing location (which was the Cinemaxx Dammtor) and the awesome catering (as much nachos, popcorn and Mate as you can endure) the conference was also (who would have guessed that) packed with lots of interesting presentations and people.</p>\n<p>Listening to the many great presentations we found things that we’re already doing right (according to the speakers) but also other aspects we can improve on.<br>There were also talks that we were able to contribute to since we had already come across their problems and solved them already.<br>I’d like to cover <strong>three</strong> main points that I got during this conference in the following paragraphs.<br>One last word of advice: Not everything should be taken too seriously ;)</p>\n<h2 id=\"1-Node-is-acknowledged-by-the-Java-world\"><a href=\"#1-Node-is-acknowledged-by-the-Java-world\" class=\"headerlink\" title=\"1. Node is acknowledged by the Java world\"></a>1. Node is acknowledged by the Java world</h2><p>The first talk (I attended) was about <em>JavaScript on Java Servers</em> and was said to cover how the new kid on the block coming around as JavaScript 5 and JavaScript 6 is going to run on a Java Server.<br>Our Java gurus instantly asked the ultimate question: What is a “Java Server”?<br>Ok, we all knew it’s probably the JVM.<br>And I myself was wondering if the JavaScript versions 5 and 6 might have something to do with the corresponding ECMA-Script standards.<br>But hey, let’s not get hung up on naming issues, shall we?</p>\n<p>Besides advertising <em>jWebSockets</em> there was a benchmark showing that <em>Nashorn</em> (the new JavaScript engine coming with Java8) is way faster than the old <em>Rhino</em> (Java6/7) implementation.<br>While leveraging Java8’s <code>invokedynamic</code> it takes some additional time to warm up but afterwards outruns rhino for good.<br>With <em>warming up</em> the “compiler people” refer to having the programme optimised by the machine until it runs several 10 times faster than in a cold state.<br>And honestly the difference was impressive.<br>That being said I noticed that <code>V8</code>, Google’s JavaScript engine powering <em>nodejs</em> as well as Chrome, still being <strong>twice</strong> as fast as the warmed up Nashorn.<br>Now that’s something.</p>\n<p>Anyway, one has to keep in mind that Google threw a lot of resources into developing this awesome piece of software.<br>Of course you don’t get all of the JVM’s nifty little things like concurrency, sandboxing and… well basically the complete Java stack but there have to be some drawbacks, right?<br>To overcome this single-process-problem, node recently introduced a completely overhauled <code>cluster</code> module.<br>This native module as well as process managers like <em>pm2</em> and <em>strongloop</em> do a great job in distributing load between several single-threaded node processes (and with that still crushing any JVM based JS engine).</p>\n<p>Nonetheless, the talk was pretty interesting with regards to what is possible with the JVM and how easy it is to run JavaScript code on a “Java Server” (I was again reminded why Java is called a typed language: Because you have to type so freaking much!).<br>Things to keep in mind though: All used <code>npm</code> packages must be “nashorn compatible”.<br>Whatever this means.</p>\n<p>For reading this far you deserve a well kept secret about <code>npm</code>: It’s <strong>not</strong> an abbreviation for the <strong>n</strong>ode <strong>p</strong>ackage <strong>m</strong>anager but a recursive bacronymic abbreviation for “npm is not an acronym”.</p>\n<p>However rumor has it, the package manager sends “<strong>n</strong>aughty <strong>p</strong>ush <strong>m</strong>essages” once installed (see <a href=\"https://github.com/npm/npm-expansions\" target=\"_blank\" rel=\"external\">npm-expansions</a>).</p>\n<h2 id=\"2-We’re-pretty-much-up-to-date\"><a href=\"#2-We’re-pretty-much-up-to-date\" class=\"headerlink\" title=\"2. We’re pretty much up-to-date\"></a>2. We’re pretty much up-to-date</h2><p>In the Frontend/JavaScript track there were several talks covering various aspects.<br>From the language itself (‘There is no JavaScript’ - awesome presentation by Noam Kfir) to pretty interesting testing approaches and the life of suffering with React and ES6.<br>We realised that our current testing and build pipeline which consists of <code>mocha</code>, <code>babel</code>, <code>karma</code> and <code>webpack</code> is not only considered state of the art but is just discovered by some companies.<br>They shared knowledge of pitfalls they encountered and how they overcame them (or at least how they tried to do so).<br>Their solution was basically our current build configuration.<br>But since the topic is pretty tricky, there were of course some nifty tricks we’ve yet to adopt so we’re very glad they went through all that pain and shared these valuable findings.<br>Anyway, it still gave us a pretty confident feeling about how we’re doing things.<br>These days it seems to be the mix of ES6, ES5 and React modules together with universal JavaScript that is the most challenging thing to overcome.</p>\n<h2 id=\"3-Operations-is-your-new-best-friend\"><a href=\"#3-Operations-is-your-new-best-friend\" class=\"headerlink\" title=\"3. Operations is your new best friend\"></a>3. Operations is your new best friend</h2><p>First I have to say that this talk, done by two guys from 1&amp;1, was really inspiring and made you think of changing a thing or two in your own development workflow.</p>\n<p>Plainly put, the whole talk was about <strong>DevOps</strong> and how this construct can help to smoothen relations between all kinds of different departments throughout the whole company.<br>Translated to ourselves they mainly spoke of improving workflows between the RND department (the developers) and the team which takes care of managing and deploying the application (AM).<br>The scenario described was one that I myself experienced one time or another: The over-the-fence phenomenon.<br>A developer finishes a feature and sends it to Operations.<br>Now they can deal with it!<br><strong>But</strong>: It might be hard to deploy because of several reasons (be it a changed database structure or some changes in the build pipeline), it might have bugs, break other features or cause who knows what.<br>So a developer should not only take care of finishing the feature assigned to him but also have in mind that there’s work <em>after</em> he did his final commit.<br>He (or she of course) should feel responsible for the software as a whole (and everything that is related to it).</p>\n<p>The 1&amp;1 guys gave several tips on how to improve communications and workflows. They also talked about how <em>they</em> tried to establish DevOps.<br>Bringing together developers and operations not only smoothens (and probably speeds up) the workflows but also widens the knowledge of both department’s members.<br>And learning new things can never be bad ;)</p>\n","excerpt":"","more":"<p>Some weeks ago we attended the <code>code.talks</code> developer conference in Hamburg.<br>Besides the amazing location (which was the Cinemaxx Dammtor) and the awesome catering (as much nachos, popcorn and Mate as you can endure) the conference was also (who would have guessed that) packed with lots of interesting presentations and people.</p>\n<p>Listening to the many great presentations we found things that we’re already doing right (according to the speakers) but also other aspects we can improve on.<br>There were also talks that we were able to contribute to since we had already come across their problems and solved them already.<br>I’d like to cover <strong>three</strong> main points that I got during this conference in the following paragraphs.<br>One last word of advice: Not everything should be taken too seriously ;)</p>\n<h2 id=\"1-Node-is-acknowledged-by-the-Java-world\"><a href=\"#1-Node-is-acknowledged-by-the-Java-world\" class=\"headerlink\" title=\"1. Node is acknowledged by the Java world\"></a>1. Node is acknowledged by the Java world</h2><p>The first talk (I attended) was about <em>JavaScript on Java Servers</em> and was said to cover how the new kid on the block coming around as JavaScript 5 and JavaScript 6 is going to run on a Java Server.<br>Our Java gurus instantly asked the ultimate question: What is a “Java Server”?<br>Ok, we all knew it’s probably the JVM.<br>And I myself was wondering if the JavaScript versions 5 and 6 might have something to do with the corresponding ECMA-Script standards.<br>But hey, let’s not get hung up on naming issues, shall we?</p>\n<p>Besides advertising <em>jWebSockets</em> there was a benchmark showing that <em>Nashorn</em> (the new JavaScript engine coming with Java8) is way faster than the old <em>Rhino</em> (Java6/7) implementation.<br>While leveraging Java8’s <code>invokedynamic</code> it takes some additional time to warm up but afterwards outruns rhino for good.<br>With <em>warming up</em> the “compiler people” refer to having the programme optimised by the machine until it runs several 10 times faster than in a cold state.<br>And honestly the difference was impressive.<br>That being said I noticed that <code>V8</code>, Google’s JavaScript engine powering <em>nodejs</em> as well as Chrome, still being <strong>twice</strong> as fast as the warmed up Nashorn.<br>Now that’s something.</p>\n<p>Anyway, one has to keep in mind that Google threw a lot of resources into developing this awesome piece of software.<br>Of course you don’t get all of the JVM’s nifty little things like concurrency, sandboxing and… well basically the complete Java stack but there have to be some drawbacks, right?<br>To overcome this single-process-problem, node recently introduced a completely overhauled <code>cluster</code> module.<br>This native module as well as process managers like <em>pm2</em> and <em>strongloop</em> do a great job in distributing load between several single-threaded node processes (and with that still crushing any JVM based JS engine).</p>\n<p>Nonetheless, the talk was pretty interesting with regards to what is possible with the JVM and how easy it is to run JavaScript code on a “Java Server” (I was again reminded why Java is called a typed language: Because you have to type so freaking much!).<br>Things to keep in mind though: All used <code>npm</code> packages must be “nashorn compatible”.<br>Whatever this means.</p>\n<p>For reading this far you deserve a well kept secret about <code>npm</code>: It’s <strong>not</strong> an abbreviation for the <strong>n</strong>ode <strong>p</strong>ackage <strong>m</strong>anager but a recursive bacronymic abbreviation for “npm is not an acronym”.</p>\n<p>However rumor has it, the package manager sends “<strong>n</strong>aughty <strong>p</strong>ush <strong>m</strong>essages” once installed (see <a href=\"https://github.com/npm/npm-expansions\">npm-expansions</a>).</p>\n<h2 id=\"2-We’re-pretty-much-up-to-date\"><a href=\"#2-We’re-pretty-much-up-to-date\" class=\"headerlink\" title=\"2. We’re pretty much up-to-date\"></a>2. We’re pretty much up-to-date</h2><p>In the Frontend/JavaScript track there were several talks covering various aspects.<br>From the language itself (‘There is no JavaScript’ - awesome presentation by Noam Kfir) to pretty interesting testing approaches and the life of suffering with React and ES6.<br>We realised that our current testing and build pipeline which consists of <code>mocha</code>, <code>babel</code>, <code>karma</code> and <code>webpack</code> is not only considered state of the art but is just discovered by some companies.<br>They shared knowledge of pitfalls they encountered and how they overcame them (or at least how they tried to do so).<br>Their solution was basically our current build configuration.<br>But since the topic is pretty tricky, there were of course some nifty tricks we’ve yet to adopt so we’re very glad they went through all that pain and shared these valuable findings.<br>Anyway, it still gave us a pretty confident feeling about how we’re doing things.<br>These days it seems to be the mix of ES6, ES5 and React modules together with universal JavaScript that is the most challenging thing to overcome.</p>\n<h2 id=\"3-Operations-is-your-new-best-friend\"><a href=\"#3-Operations-is-your-new-best-friend\" class=\"headerlink\" title=\"3. Operations is your new best friend\"></a>3. Operations is your new best friend</h2><p>First I have to say that this talk, done by two guys from 1&amp;1, was really inspiring and made you think of changing a thing or two in your own development workflow.</p>\n<p>Plainly put, the whole talk was about <strong>DevOps</strong> and how this construct can help to smoothen relations between all kinds of different departments throughout the whole company.<br>Translated to ourselves they mainly spoke of improving workflows between the RND department (the developers) and the team which takes care of managing and deploying the application (AM).<br>The scenario described was one that I myself experienced one time or another: The over-the-fence phenomenon.<br>A developer finishes a feature and sends it to Operations.<br>Now they can deal with it!<br><strong>But</strong>: It might be hard to deploy because of several reasons (be it a changed database structure or some changes in the build pipeline), it might have bugs, break other features or cause who knows what.<br>So a developer should not only take care of finishing the feature assigned to him but also have in mind that there’s work <em>after</em> he did his final commit.<br>He (or she of course) should feel responsible for the software as a whole (and everything that is related to it).</p>\n<p>The 1&amp;1 guys gave several tips on how to improve communications and workflows. They also talked about how <em>they</em> tried to establish DevOps.<br>Bringing together developers and operations not only smoothens (and probably speeds up) the workflows but also widens the knowledge of both department’s members.<br>And learning new things can never be bad ;)</p>\n"},{"layout":"post","title":"Scrum Basics: Scrum Roles","date":"2015-11-19T06:23:00.000Z","image":"blog-header/roles.jpg","authors":["Anja B."],"_content":"\nWelcome to part two of our Scrum Basics Series.\nThis part deals with the three different roles involved in the Scrum process.\nOne thing to clarify right from the beginning: All three roles together form one Scrum Team.\nAll are equal and neither the Product Owner (PO) nor the Scrum Master (SM) are superiors to the Development Team.\n\nTo function well they need to work closely together and, in an ideal world, also sit together in one room.\nThey need to understand that they are ONE team, fighting for the same goal: to release the best possible product for the end-customer.\n\n## Development Team\n\n{% image blog/blog-scrum2-devteam.jpg 50% left %}\n\nA typical Development Team consists of 7 members +/-2 with cross-functional abilities.\nThey should organise themselves and decide on their own, how tickets will be implemented within a sprint.\nIt’s also the Development Team's decision on how many tickets they decide to solve within a sprint.\nThis freedom comes with the duty to commit completely to the goal to deliver all the planned tickets within a sprint.\n\nTo being able to know how many tickets they are usually able to solve within a sprint, the team estimates all tickets by themselves.\nNobody else is allowed to give estimates for tickets but the Development Team as they will solve those tickets in the end.\nDuring the sprint, the Development Team also has the duty to track their progress.\nThat means, they keep the Sprint/Scrum Board clean and move the cards across the board according to their progress.\nEveryone in the team, including PO and SM, should always know the status of each ticket within a sprint.\n\nThe most important task for the Development Team, also in Scrum, is to deliver.\nJust as in Scrum they can tell themselves how much time they need to deliver something, this gives them the freedom to achieve the big goal of the Scrum Framework: to deliver quality products.\n\n## Product Owner\n\n{% image blog/blog-scrum2-productowner.jpg 25% right %}\n\nThe Product Owner is a very important role in Scrum.\nI’ve heard trainers say that a Scrum Team can rise or fall with their PO.\nThe speciality in Scrum is, that the PO is not the boss of the Development Team, but part of the team.\nThis is not easy, especially for POs who have worked as Project Managers in the past.\nIn Scrum they are a lateral leader.\n\nHowever, the PO determines what the team is going to develop next.\nThey set up the Product Backlog and decide the ticket's business value (containing a lot of information like how many customers would find a specific new feature useful, how long would the development take or how severe the impact of a bug is) and with that the ticket order.\nThey determine an appropriate balance of fixing bugs and developing new features within a sprint.\nThey spend a lot of time maintaining the Product Backlog, which means creating new tickets and prioritising them as well as keeping the Backlog up to date.\nSeveral techniques exist of how to prioritise a Backlog.\nThe technique to be used mainly depends on the product the team is working on.\n\nTo create the tickets the PO is also responsible for gathering all the requirements as well as to talk to the stakeholders.\nManaging all the stakeholders for a product can be quite time consuming.\nBut there are some techniques that can help the PO to keep an overview.\n\nThe PO's superior task is to create a common product vision and to steer the product release.\nThey are also responsible for accepting (or not) the developed tickets from the Development Team.\nAs you can see, the Product Owner is a very important and complex role in Scrum and so it’s no wonder that several training sessions exist and that one should participate in before agreeing on this job.\n\n## Scrum Master\n\n{% image blog/blog-scrum2-scrummaster.jpg 25% left %}\n\nThe Scrum Master is normally the most unclear role for people who are new to Scrum.\nThe concept is just not existing in other frameworks and therefore the value of this role is often underestimated.\nAfter all, the Scrum Master is not directly adding development power to the team, so why should a company still invest in an extra employee?\n\nThe superior task of a Scrum Master is to protect the Scrum Team!\nAnd yes, this includes developers and PO.\nOne example that most software developers probably understand is the problem of scope creep.\nThe developers are working on their feature, when some manager steps into the room and forces someone to take care of an ultra-urgent topic.\nThe developer is distracted from their actual task and since it was a manager who told them to go work on something else, they usually do it.\nNot in Scrum!\nIn Scrum it would be the task of the Scrum Master to step inbetween the manager and the developer.\nThe Scrum Master would tell the manager politely to go and talk to the PO, who will create a ticket for his request and sort it into the Backlog according to its business value.\nIf it really is ultra-urgent, it will be solved within the next sprint.\nOnly in real blocker situations (like a live-platform being down) a running sprint would be interrupted.\nAnd ONLY the PO has the right to decide this.\n\nThat little story already leads to the third biggest part of the Scrum Masters time: Coaching.\nHis responsibility is to coach not only the team and the PO on Scrum and agile development topics, but also all other departments in the company that have to interact with the Scrum Teams.\nThey need to know the rules to being able to follow them.\nNormally they also need a constant reminder of those rules.\nCoaching the Product Owner is another big topic.\nAs you have already learned, the PO role is quite complex and there are several techniques that can help him in his daily business.\nBut someone needs to teach him those techniques and also make him aware of problems.\nOnly if someone tells the PO that something is not working, they can improve themselves and their work.\nThe same goes for the Development Team.\nIt’s the SM's job to constantly push them to improve themselves, to become more self-organised and to be open for changes.\n\nYou may have noticed that I switched from the first to the third biggest part of the Scrum Master's job, so here is the second: They have to ensure that impediments are removed.\nImpediments are all things that block the team from performing.\nIf it is the manager in the room, a computer that’s too slow or a suddenly unusual high amount of support tickets: The Scrum Master needs to investigate and find a solution.\nThat doesn’t mean that they have to solve everything by themselves.\nThey only need to find the responsible people and ensure that they are solving the problem.\nLike pushing the decision maker for a fast “go” on a new computer to replace the slow one.\nTo order and install it is then up to IT.\nOr the SM would have to investigate why there are suddenly so many support tickets.\nHas the quality dropped?\nOr is there a high sick-leave rate in the Service Center so they aren’t able to work in detail on every ticket and just pass them on?\nThe SM would need to talk to them to understand if the Development Team should plan to do less tickets in the next sprint in order to have more support time.\n\nTwo more tasks are left for the Scrum Master to do: facilitating meetings as well as mediation talks.\nThe SM is responsible to moderate all the Scrum meetings and to make sure the meetings start and end on time.\nBut if they do their job correctly and improved the team's self-organisation, they will soon take over moderation, e.g. for the review.\nEqually important are mediations skills.\nIf there are problems within a team or also between teams the Scrum Master has to solve them.\nThe SM needs to be the person of trust for every team member.\n\nIn total you could say the Scrum Master has to keep the process running.\nNo matter what happens, he has to make sure the Scrum Team is still able to work on their tickets.\nFor that, it’s also important to promote Scrum in the organisation.\nIf for example the Marketing department knows that the Scrum Team shows their development results every two weeks, they might just join these meetings to be up to date all the time.\nIf managers know the two-week time frames, they can go early to the POs and ask if there's space for an additional task in the next sprint.\nCombine “protect the team”, “remove impediments”, “push for constant improvement” and “moderate meeting so they have a valuable outcome and end on time” and you can see where the value of this extra employee pushes in.\nI’ve seen Scrum Teams that were able to double or even quadruple their development speed, after they have been assigned a full-time SM.\n\n## Related posts\n\n* [Scrum Basics: What is Scrum?](https://developer.epages.com/blog/2015/10/13/scrum-basics-1.html)\n* [Scrum Basics: Scrum Meetings](https://developer.epages.com/blog/2015/12/15/scrum-basics-3.html)\n* [Scrum Basics: Estimating](https://developer.epages.com/blog/2016/01/26/scrum-basics-4.html)\n* [Scrum Basics: Principles and Values](https://developer.epages.com/blog/2016/02/25/scrum-basics-5.html)\n* [Scrum Basics: Practicing it](https://developer.epages.com/blog/2016/03/22/scrum-basics-6.html)\n","source":"_posts/2015-11-19-scrum-basics-2.md","raw":"---\nlayout: post\ntitle: \"Scrum Basics: Scrum Roles\"\ndate: \"2015-11-19 07:23:00\"\nimage: blog-header/roles.jpg\ncategories: agile\nauthors: [\"Anja B.\"]\n---\n\nWelcome to part two of our Scrum Basics Series.\nThis part deals with the three different roles involved in the Scrum process.\nOne thing to clarify right from the beginning: All three roles together form one Scrum Team.\nAll are equal and neither the Product Owner (PO) nor the Scrum Master (SM) are superiors to the Development Team.\n\nTo function well they need to work closely together and, in an ideal world, also sit together in one room.\nThey need to understand that they are ONE team, fighting for the same goal: to release the best possible product for the end-customer.\n\n## Development Team\n\n{% image blog/blog-scrum2-devteam.jpg 50% left %}\n\nA typical Development Team consists of 7 members +/-2 with cross-functional abilities.\nThey should organise themselves and decide on their own, how tickets will be implemented within a sprint.\nIt’s also the Development Team's decision on how many tickets they decide to solve within a sprint.\nThis freedom comes with the duty to commit completely to the goal to deliver all the planned tickets within a sprint.\n\nTo being able to know how many tickets they are usually able to solve within a sprint, the team estimates all tickets by themselves.\nNobody else is allowed to give estimates for tickets but the Development Team as they will solve those tickets in the end.\nDuring the sprint, the Development Team also has the duty to track their progress.\nThat means, they keep the Sprint/Scrum Board clean and move the cards across the board according to their progress.\nEveryone in the team, including PO and SM, should always know the status of each ticket within a sprint.\n\nThe most important task for the Development Team, also in Scrum, is to deliver.\nJust as in Scrum they can tell themselves how much time they need to deliver something, this gives them the freedom to achieve the big goal of the Scrum Framework: to deliver quality products.\n\n## Product Owner\n\n{% image blog/blog-scrum2-productowner.jpg 25% right %}\n\nThe Product Owner is a very important role in Scrum.\nI’ve heard trainers say that a Scrum Team can rise or fall with their PO.\nThe speciality in Scrum is, that the PO is not the boss of the Development Team, but part of the team.\nThis is not easy, especially for POs who have worked as Project Managers in the past.\nIn Scrum they are a lateral leader.\n\nHowever, the PO determines what the team is going to develop next.\nThey set up the Product Backlog and decide the ticket's business value (containing a lot of information like how many customers would find a specific new feature useful, how long would the development take or how severe the impact of a bug is) and with that the ticket order.\nThey determine an appropriate balance of fixing bugs and developing new features within a sprint.\nThey spend a lot of time maintaining the Product Backlog, which means creating new tickets and prioritising them as well as keeping the Backlog up to date.\nSeveral techniques exist of how to prioritise a Backlog.\nThe technique to be used mainly depends on the product the team is working on.\n\nTo create the tickets the PO is also responsible for gathering all the requirements as well as to talk to the stakeholders.\nManaging all the stakeholders for a product can be quite time consuming.\nBut there are some techniques that can help the PO to keep an overview.\n\nThe PO's superior task is to create a common product vision and to steer the product release.\nThey are also responsible for accepting (or not) the developed tickets from the Development Team.\nAs you can see, the Product Owner is a very important and complex role in Scrum and so it’s no wonder that several training sessions exist and that one should participate in before agreeing on this job.\n\n## Scrum Master\n\n{% image blog/blog-scrum2-scrummaster.jpg 25% left %}\n\nThe Scrum Master is normally the most unclear role for people who are new to Scrum.\nThe concept is just not existing in other frameworks and therefore the value of this role is often underestimated.\nAfter all, the Scrum Master is not directly adding development power to the team, so why should a company still invest in an extra employee?\n\nThe superior task of a Scrum Master is to protect the Scrum Team!\nAnd yes, this includes developers and PO.\nOne example that most software developers probably understand is the problem of scope creep.\nThe developers are working on their feature, when some manager steps into the room and forces someone to take care of an ultra-urgent topic.\nThe developer is distracted from their actual task and since it was a manager who told them to go work on something else, they usually do it.\nNot in Scrum!\nIn Scrum it would be the task of the Scrum Master to step inbetween the manager and the developer.\nThe Scrum Master would tell the manager politely to go and talk to the PO, who will create a ticket for his request and sort it into the Backlog according to its business value.\nIf it really is ultra-urgent, it will be solved within the next sprint.\nOnly in real blocker situations (like a live-platform being down) a running sprint would be interrupted.\nAnd ONLY the PO has the right to decide this.\n\nThat little story already leads to the third biggest part of the Scrum Masters time: Coaching.\nHis responsibility is to coach not only the team and the PO on Scrum and agile development topics, but also all other departments in the company that have to interact with the Scrum Teams.\nThey need to know the rules to being able to follow them.\nNormally they also need a constant reminder of those rules.\nCoaching the Product Owner is another big topic.\nAs you have already learned, the PO role is quite complex and there are several techniques that can help him in his daily business.\nBut someone needs to teach him those techniques and also make him aware of problems.\nOnly if someone tells the PO that something is not working, they can improve themselves and their work.\nThe same goes for the Development Team.\nIt’s the SM's job to constantly push them to improve themselves, to become more self-organised and to be open for changes.\n\nYou may have noticed that I switched from the first to the third biggest part of the Scrum Master's job, so here is the second: They have to ensure that impediments are removed.\nImpediments are all things that block the team from performing.\nIf it is the manager in the room, a computer that’s too slow or a suddenly unusual high amount of support tickets: The Scrum Master needs to investigate and find a solution.\nThat doesn’t mean that they have to solve everything by themselves.\nThey only need to find the responsible people and ensure that they are solving the problem.\nLike pushing the decision maker for a fast “go” on a new computer to replace the slow one.\nTo order and install it is then up to IT.\nOr the SM would have to investigate why there are suddenly so many support tickets.\nHas the quality dropped?\nOr is there a high sick-leave rate in the Service Center so they aren’t able to work in detail on every ticket and just pass them on?\nThe SM would need to talk to them to understand if the Development Team should plan to do less tickets in the next sprint in order to have more support time.\n\nTwo more tasks are left for the Scrum Master to do: facilitating meetings as well as mediation talks.\nThe SM is responsible to moderate all the Scrum meetings and to make sure the meetings start and end on time.\nBut if they do their job correctly and improved the team's self-organisation, they will soon take over moderation, e.g. for the review.\nEqually important are mediations skills.\nIf there are problems within a team or also between teams the Scrum Master has to solve them.\nThe SM needs to be the person of trust for every team member.\n\nIn total you could say the Scrum Master has to keep the process running.\nNo matter what happens, he has to make sure the Scrum Team is still able to work on their tickets.\nFor that, it’s also important to promote Scrum in the organisation.\nIf for example the Marketing department knows that the Scrum Team shows their development results every two weeks, they might just join these meetings to be up to date all the time.\nIf managers know the two-week time frames, they can go early to the POs and ask if there's space for an additional task in the next sprint.\nCombine “protect the team”, “remove impediments”, “push for constant improvement” and “moderate meeting so they have a valuable outcome and end on time” and you can see where the value of this extra employee pushes in.\nI’ve seen Scrum Teams that were able to double or even quadruple their development speed, after they have been assigned a full-time SM.\n\n## Related posts\n\n* [Scrum Basics: What is Scrum?](https://developer.epages.com/blog/2015/10/13/scrum-basics-1.html)\n* [Scrum Basics: Scrum Meetings](https://developer.epages.com/blog/2015/12/15/scrum-basics-3.html)\n* [Scrum Basics: Estimating](https://developer.epages.com/blog/2016/01/26/scrum-basics-4.html)\n* [Scrum Basics: Principles and Values](https://developer.epages.com/blog/2016/02/25/scrum-basics-5.html)\n* [Scrum Basics: Practicing it](https://developer.epages.com/blog/2016/03/22/scrum-basics-6.html)\n","slug":"2015-11-19-scrum-basics-2","published":1,"updated":"2016-09-20T14:19:22.000Z","comments":1,"photos":[],"link":"","_id":"ciu6nuh91001ehqyxai2f80dx","content":"<p>Welcome to part two of our Scrum Basics Series.<br>This part deals with the three different roles involved in the Scrum process.<br>One thing to clarify right from the beginning: All three roles together form one Scrum Team.<br>All are equal and neither the Product Owner (PO) nor the Scrum Master (SM) are superiors to the Development Team.</p>\n<p>To function well they need to work closely together and, in an ideal world, also sit together in one room.<br>They need to understand that they are ONE team, fighting for the same goal: to release the best possible product for the end-customer.</p>\n<h2 id=\"Development-Team\"><a href=\"#Development-Team\" class=\"headerlink\" title=\"Development Team\"></a>Development Team</h2><img class=\"blog/blog-scrum2-devteam.jpg 50% left\">\n<p>A typical Development Team consists of 7 members +/-2 with cross-functional abilities.<br>They should organise themselves and decide on their own, how tickets will be implemented within a sprint.<br>It’s also the Development Team’s decision on how many tickets they decide to solve within a sprint.<br>This freedom comes with the duty to commit completely to the goal to deliver all the planned tickets within a sprint.</p>\n<p>To being able to know how many tickets they are usually able to solve within a sprint, the team estimates all tickets by themselves.<br>Nobody else is allowed to give estimates for tickets but the Development Team as they will solve those tickets in the end.<br>During the sprint, the Development Team also has the duty to track their progress.<br>That means, they keep the Sprint/Scrum Board clean and move the cards across the board according to their progress.<br>Everyone in the team, including PO and SM, should always know the status of each ticket within a sprint.</p>\n<p>The most important task for the Development Team, also in Scrum, is to deliver.<br>Just as in Scrum they can tell themselves how much time they need to deliver something, this gives them the freedom to achieve the big goal of the Scrum Framework: to deliver quality products.</p>\n<h2 id=\"Product-Owner\"><a href=\"#Product-Owner\" class=\"headerlink\" title=\"Product Owner\"></a>Product Owner</h2><img class=\"blog/blog-scrum2-productowner.jpg 25% right\">\n<p>The Product Owner is a very important role in Scrum.<br>I’ve heard trainers say that a Scrum Team can rise or fall with their PO.<br>The speciality in Scrum is, that the PO is not the boss of the Development Team, but part of the team.<br>This is not easy, especially for POs who have worked as Project Managers in the past.<br>In Scrum they are a lateral leader.</p>\n<p>However, the PO determines what the team is going to develop next.<br>They set up the Product Backlog and decide the ticket’s business value (containing a lot of information like how many customers would find a specific new feature useful, how long would the development take or how severe the impact of a bug is) and with that the ticket order.<br>They determine an appropriate balance of fixing bugs and developing new features within a sprint.<br>They spend a lot of time maintaining the Product Backlog, which means creating new tickets and prioritising them as well as keeping the Backlog up to date.<br>Several techniques exist of how to prioritise a Backlog.<br>The technique to be used mainly depends on the product the team is working on.</p>\n<p>To create the tickets the PO is also responsible for gathering all the requirements as well as to talk to the stakeholders.<br>Managing all the stakeholders for a product can be quite time consuming.<br>But there are some techniques that can help the PO to keep an overview.</p>\n<p>The PO’s superior task is to create a common product vision and to steer the product release.<br>They are also responsible for accepting (or not) the developed tickets from the Development Team.<br>As you can see, the Product Owner is a very important and complex role in Scrum and so it’s no wonder that several training sessions exist and that one should participate in before agreeing on this job.</p>\n<h2 id=\"Scrum-Master\"><a href=\"#Scrum-Master\" class=\"headerlink\" title=\"Scrum Master\"></a>Scrum Master</h2><img class=\"blog/blog-scrum2-scrummaster.jpg 25% left\">\n<p>The Scrum Master is normally the most unclear role for people who are new to Scrum.<br>The concept is just not existing in other frameworks and therefore the value of this role is often underestimated.<br>After all, the Scrum Master is not directly adding development power to the team, so why should a company still invest in an extra employee?</p>\n<p>The superior task of a Scrum Master is to protect the Scrum Team!<br>And yes, this includes developers and PO.<br>One example that most software developers probably understand is the problem of scope creep.<br>The developers are working on their feature, when some manager steps into the room and forces someone to take care of an ultra-urgent topic.<br>The developer is distracted from their actual task and since it was a manager who told them to go work on something else, they usually do it.<br>Not in Scrum!<br>In Scrum it would be the task of the Scrum Master to step inbetween the manager and the developer.<br>The Scrum Master would tell the manager politely to go and talk to the PO, who will create a ticket for his request and sort it into the Backlog according to its business value.<br>If it really is ultra-urgent, it will be solved within the next sprint.<br>Only in real blocker situations (like a live-platform being down) a running sprint would be interrupted.<br>And ONLY the PO has the right to decide this.</p>\n<p>That little story already leads to the third biggest part of the Scrum Masters time: Coaching.<br>His responsibility is to coach not only the team and the PO on Scrum and agile development topics, but also all other departments in the company that have to interact with the Scrum Teams.<br>They need to know the rules to being able to follow them.<br>Normally they also need a constant reminder of those rules.<br>Coaching the Product Owner is another big topic.<br>As you have already learned, the PO role is quite complex and there are several techniques that can help him in his daily business.<br>But someone needs to teach him those techniques and also make him aware of problems.<br>Only if someone tells the PO that something is not working, they can improve themselves and their work.<br>The same goes for the Development Team.<br>It’s the SM’s job to constantly push them to improve themselves, to become more self-organised and to be open for changes.</p>\n<p>You may have noticed that I switched from the first to the third biggest part of the Scrum Master’s job, so here is the second: They have to ensure that impediments are removed.<br>Impediments are all things that block the team from performing.<br>If it is the manager in the room, a computer that’s too slow or a suddenly unusual high amount of support tickets: The Scrum Master needs to investigate and find a solution.<br>That doesn’t mean that they have to solve everything by themselves.<br>They only need to find the responsible people and ensure that they are solving the problem.<br>Like pushing the decision maker for a fast “go” on a new computer to replace the slow one.<br>To order and install it is then up to IT.<br>Or the SM would have to investigate why there are suddenly so many support tickets.<br>Has the quality dropped?<br>Or is there a high sick-leave rate in the Service Center so they aren’t able to work in detail on every ticket and just pass them on?<br>The SM would need to talk to them to understand if the Development Team should plan to do less tickets in the next sprint in order to have more support time.</p>\n<p>Two more tasks are left for the Scrum Master to do: facilitating meetings as well as mediation talks.<br>The SM is responsible to moderate all the Scrum meetings and to make sure the meetings start and end on time.<br>But if they do their job correctly and improved the team’s self-organisation, they will soon take over moderation, e.g. for the review.<br>Equally important are mediations skills.<br>If there are problems within a team or also between teams the Scrum Master has to solve them.<br>The SM needs to be the person of trust for every team member.</p>\n<p>In total you could say the Scrum Master has to keep the process running.<br>No matter what happens, he has to make sure the Scrum Team is still able to work on their tickets.<br>For that, it’s also important to promote Scrum in the organisation.<br>If for example the Marketing department knows that the Scrum Team shows their development results every two weeks, they might just join these meetings to be up to date all the time.<br>If managers know the two-week time frames, they can go early to the POs and ask if there’s space for an additional task in the next sprint.<br>Combine “protect the team”, “remove impediments”, “push for constant improvement” and “moderate meeting so they have a valuable outcome and end on time” and you can see where the value of this extra employee pushes in.<br>I’ve seen Scrum Teams that were able to double or even quadruple their development speed, after they have been assigned a full-time SM.</p>\n<h2 id=\"Related-posts\"><a href=\"#Related-posts\" class=\"headerlink\" title=\"Related posts\"></a>Related posts</h2><ul>\n<li><a href=\"https://developer.epages.com/blog/2015/10/13/scrum-basics-1.html\" target=\"_blank\" rel=\"external\">Scrum Basics: What is Scrum?</a></li>\n<li><a href=\"https://developer.epages.com/blog/2015/12/15/scrum-basics-3.html\" target=\"_blank\" rel=\"external\">Scrum Basics: Scrum Meetings</a></li>\n<li><a href=\"https://developer.epages.com/blog/2016/01/26/scrum-basics-4.html\" target=\"_blank\" rel=\"external\">Scrum Basics: Estimating</a></li>\n<li><a href=\"https://developer.epages.com/blog/2016/02/25/scrum-basics-5.html\" target=\"_blank\" rel=\"external\">Scrum Basics: Principles and Values</a></li>\n<li><a href=\"https://developer.epages.com/blog/2016/03/22/scrum-basics-6.html\" target=\"_blank\" rel=\"external\">Scrum Basics: Practicing it</a></li>\n</ul>\n","excerpt":"","more":"<p>Welcome to part two of our Scrum Basics Series.<br>This part deals with the three different roles involved in the Scrum process.<br>One thing to clarify right from the beginning: All three roles together form one Scrum Team.<br>All are equal and neither the Product Owner (PO) nor the Scrum Master (SM) are superiors to the Development Team.</p>\n<p>To function well they need to work closely together and, in an ideal world, also sit together in one room.<br>They need to understand that they are ONE team, fighting for the same goal: to release the best possible product for the end-customer.</p>\n<h2 id=\"Development-Team\"><a href=\"#Development-Team\" class=\"headerlink\" title=\"Development Team\"></a>Development Team</h2><img class=\"blog/blog-scrum2-devteam.jpg 50% left\">\n<p>A typical Development Team consists of 7 members +/-2 with cross-functional abilities.<br>They should organise themselves and decide on their own, how tickets will be implemented within a sprint.<br>It’s also the Development Team’s decision on how many tickets they decide to solve within a sprint.<br>This freedom comes with the duty to commit completely to the goal to deliver all the planned tickets within a sprint.</p>\n<p>To being able to know how many tickets they are usually able to solve within a sprint, the team estimates all tickets by themselves.<br>Nobody else is allowed to give estimates for tickets but the Development Team as they will solve those tickets in the end.<br>During the sprint, the Development Team also has the duty to track their progress.<br>That means, they keep the Sprint/Scrum Board clean and move the cards across the board according to their progress.<br>Everyone in the team, including PO and SM, should always know the status of each ticket within a sprint.</p>\n<p>The most important task for the Development Team, also in Scrum, is to deliver.<br>Just as in Scrum they can tell themselves how much time they need to deliver something, this gives them the freedom to achieve the big goal of the Scrum Framework: to deliver quality products.</p>\n<h2 id=\"Product-Owner\"><a href=\"#Product-Owner\" class=\"headerlink\" title=\"Product Owner\"></a>Product Owner</h2><img class=\"blog/blog-scrum2-productowner.jpg 25% right\">\n<p>The Product Owner is a very important role in Scrum.<br>I’ve heard trainers say that a Scrum Team can rise or fall with their PO.<br>The speciality in Scrum is, that the PO is not the boss of the Development Team, but part of the team.<br>This is not easy, especially for POs who have worked as Project Managers in the past.<br>In Scrum they are a lateral leader.</p>\n<p>However, the PO determines what the team is going to develop next.<br>They set up the Product Backlog and decide the ticket’s business value (containing a lot of information like how many customers would find a specific new feature useful, how long would the development take or how severe the impact of a bug is) and with that the ticket order.<br>They determine an appropriate balance of fixing bugs and developing new features within a sprint.<br>They spend a lot of time maintaining the Product Backlog, which means creating new tickets and prioritising them as well as keeping the Backlog up to date.<br>Several techniques exist of how to prioritise a Backlog.<br>The technique to be used mainly depends on the product the team is working on.</p>\n<p>To create the tickets the PO is also responsible for gathering all the requirements as well as to talk to the stakeholders.<br>Managing all the stakeholders for a product can be quite time consuming.<br>But there are some techniques that can help the PO to keep an overview.</p>\n<p>The PO’s superior task is to create a common product vision and to steer the product release.<br>They are also responsible for accepting (or not) the developed tickets from the Development Team.<br>As you can see, the Product Owner is a very important and complex role in Scrum and so it’s no wonder that several training sessions exist and that one should participate in before agreeing on this job.</p>\n<h2 id=\"Scrum-Master\"><a href=\"#Scrum-Master\" class=\"headerlink\" title=\"Scrum Master\"></a>Scrum Master</h2><img class=\"blog/blog-scrum2-scrummaster.jpg 25% left\">\n<p>The Scrum Master is normally the most unclear role for people who are new to Scrum.<br>The concept is just not existing in other frameworks and therefore the value of this role is often underestimated.<br>After all, the Scrum Master is not directly adding development power to the team, so why should a company still invest in an extra employee?</p>\n<p>The superior task of a Scrum Master is to protect the Scrum Team!<br>And yes, this includes developers and PO.<br>One example that most software developers probably understand is the problem of scope creep.<br>The developers are working on their feature, when some manager steps into the room and forces someone to take care of an ultra-urgent topic.<br>The developer is distracted from their actual task and since it was a manager who told them to go work on something else, they usually do it.<br>Not in Scrum!<br>In Scrum it would be the task of the Scrum Master to step inbetween the manager and the developer.<br>The Scrum Master would tell the manager politely to go and talk to the PO, who will create a ticket for his request and sort it into the Backlog according to its business value.<br>If it really is ultra-urgent, it will be solved within the next sprint.<br>Only in real blocker situations (like a live-platform being down) a running sprint would be interrupted.<br>And ONLY the PO has the right to decide this.</p>\n<p>That little story already leads to the third biggest part of the Scrum Masters time: Coaching.<br>His responsibility is to coach not only the team and the PO on Scrum and agile development topics, but also all other departments in the company that have to interact with the Scrum Teams.<br>They need to know the rules to being able to follow them.<br>Normally they also need a constant reminder of those rules.<br>Coaching the Product Owner is another big topic.<br>As you have already learned, the PO role is quite complex and there are several techniques that can help him in his daily business.<br>But someone needs to teach him those techniques and also make him aware of problems.<br>Only if someone tells the PO that something is not working, they can improve themselves and their work.<br>The same goes for the Development Team.<br>It’s the SM’s job to constantly push them to improve themselves, to become more self-organised and to be open for changes.</p>\n<p>You may have noticed that I switched from the first to the third biggest part of the Scrum Master’s job, so here is the second: They have to ensure that impediments are removed.<br>Impediments are all things that block the team from performing.<br>If it is the manager in the room, a computer that’s too slow or a suddenly unusual high amount of support tickets: The Scrum Master needs to investigate and find a solution.<br>That doesn’t mean that they have to solve everything by themselves.<br>They only need to find the responsible people and ensure that they are solving the problem.<br>Like pushing the decision maker for a fast “go” on a new computer to replace the slow one.<br>To order and install it is then up to IT.<br>Or the SM would have to investigate why there are suddenly so many support tickets.<br>Has the quality dropped?<br>Or is there a high sick-leave rate in the Service Center so they aren’t able to work in detail on every ticket and just pass them on?<br>The SM would need to talk to them to understand if the Development Team should plan to do less tickets in the next sprint in order to have more support time.</p>\n<p>Two more tasks are left for the Scrum Master to do: facilitating meetings as well as mediation talks.<br>The SM is responsible to moderate all the Scrum meetings and to make sure the meetings start and end on time.<br>But if they do their job correctly and improved the team’s self-organisation, they will soon take over moderation, e.g. for the review.<br>Equally important are mediations skills.<br>If there are problems within a team or also between teams the Scrum Master has to solve them.<br>The SM needs to be the person of trust for every team member.</p>\n<p>In total you could say the Scrum Master has to keep the process running.<br>No matter what happens, he has to make sure the Scrum Team is still able to work on their tickets.<br>For that, it’s also important to promote Scrum in the organisation.<br>If for example the Marketing department knows that the Scrum Team shows their development results every two weeks, they might just join these meetings to be up to date all the time.<br>If managers know the two-week time frames, they can go early to the POs and ask if there’s space for an additional task in the next sprint.<br>Combine “protect the team”, “remove impediments”, “push for constant improvement” and “moderate meeting so they have a valuable outcome and end on time” and you can see where the value of this extra employee pushes in.<br>I’ve seen Scrum Teams that were able to double or even quadruple their development speed, after they have been assigned a full-time SM.</p>\n<h2 id=\"Related-posts\"><a href=\"#Related-posts\" class=\"headerlink\" title=\"Related posts\"></a>Related posts</h2><ul>\n<li><a href=\"https://developer.epages.com/blog/2015/10/13/scrum-basics-1.html\">Scrum Basics: What is Scrum?</a></li>\n<li><a href=\"https://developer.epages.com/blog/2015/12/15/scrum-basics-3.html\">Scrum Basics: Scrum Meetings</a></li>\n<li><a href=\"https://developer.epages.com/blog/2016/01/26/scrum-basics-4.html\">Scrum Basics: Estimating</a></li>\n<li><a href=\"https://developer.epages.com/blog/2016/02/25/scrum-basics-5.html\">Scrum Basics: Principles and Values</a></li>\n<li><a href=\"https://developer.epages.com/blog/2016/03/22/scrum-basics-6.html\">Scrum Basics: Practicing it</a></li>\n</ul>\n"},{"layout":"post","title":"Scrum Basics: What is Scrum?","date":"2015-10-13T06:23:00.000Z","authors":["Anja B."],"_content":"\nAs a Scrum Master I’m often asked what Scrum is and what I’m doing the whole day long.\nWell, part of my job is to teach new colleagues exactly that.\nNow we'd like to share this knowledge with you in our **Scrum Basics Series**.\nThis series will consist of 6 parts and starts with the basic question:\nWhat is Scrum?\n\nSo let’s start with a short definition:\n\n>“Scrum is a team based framework\nto develop complex products\nor systems in an iterative way.“\n\n## What does that mean in detail?\n\nIn Scrum you are always working in a team.\nThis team should be cross-functional.\nIt should have all the abilities needed to fulfil the tasks, e.g. in software development a team consists of backend developers and frontend developers as well as designers and testers.\nIn an ideal world it would go from creating concepts, over developing and testing the product, to rollout, marketing and sales.\nBut most companies “only” have the development part in their Scrum teams.\nThe members of those teams should strive to get “T-shaped”.\nThat means they not only have one field of expertise, but also a broad basis so they can help out in other areas in the team.\nThat doesn’t mean everyone should know everything, it only means everyone is willing to do more than just their own thing.\n\n## Advantages\n\nThe big advantage of those teams in comparison to assigning a single person to specific parts of the product development is that you always have all the abilities needed in one room.\nIn [waterfall](https://en.wikipedia.org/wiki/Waterfall_model) you often have the problem that the person who did the backend development is already working on the next project when the designers realise that they need some more data from the backend.\nIn Scrum that won’t happen.\nAnother advantage is that you always have several eyes on one problem.\nSolutions can be found faster if you have more experience in the room and people who get stuck at some point always have someone to ask right next to them.\nAnd let's not forget the much faster feedback cycle with the testers when they are right inside the team!\nNo ticket is really done until it has been tested.\n\n{% img blog/blog-scrum1-waterfall-project-trap.jpg 45% right %}Waterfall-projects-trap\n\n## How is Scrum made for developing complex products or systems?\n\nComplex problems are usually better solved if more minds are involved.\nAn idea can be good but it will only become really great if you open it up to your team partners and get as much information and experience involved as possible.\nIf you have to do the same thing every day again (like on an assembly line), Scrum would be too much overhead, you could use Kanban instead.\nBut if you have to solve new challenges every day and are working on complex products, Scrum is your best choice.\n\n## Iterations\n\nThe iterations differ between the teams from 1 to 6 weeks.\nUsually they are 2 weeks long.\nThat means you only plan in detail what will be developed for the next two weeks.\nYou will then get feedback on the development and include this feedback into your next iteration.\nThis way you get quick feedback and alway know if you are developing the right thing.\nYou don’t need to be afraid of the “waterfall-projects-trap”.\n\nAll that may sound more difficult than it actually is.\nIn contrary, the Scrum framework is so simple that it easily fits on one sheet of paper.\n\n{% img blog/blog-scrum1-scrum-framework.jpg 45% left %}Scrum artefacts\n\nTwo important artefacts in Scrum are the Product Backlog and the Sprint Backlog.\nThe Product Backlog is an estimated, prioritised list of tickets (stories, bugs, tasks) that is sorted by the Product Owner according to the business value of these tickets.\nThat means this list contains all the tickets that need to be done for a product to be developed.\nThe Sprint Backlog is also a list of estimated, prioritised tickets, but it only contains those tickets that will be solved within the next iteration.\n\nIn the middle you can see the iteration, in Scrum called Sprint, which is a period of time (at ePages it's 2 weeks) during which the tickets in the Sprint Backlog have to be done and the scope of the Sprint Backlog should not change.\nThe development status of those tickets is represented on a so called Scrum Board or Sprint Board.\nIt provides an overview of all tickets of one team for one Sprint including the status of those tickets (e.g. Open, In Progress, Review, QA, Done) and which team member is currently working on which ticket.\nWith this Scrum Board everyone knows at all times about the development status and if the team is struggling or ahead of time.\nIt also shows if one person is working on too many tickets at the same time or if the team has a long queue in QA or Review.\n\nAt ePages we only have one team that is using a paper board.\nHaving a visual board present in the room at all times has more advantages for them.\nThe quick and easy way of adding tasks to stories (more about that in [ Estimating](https://developer.epages.com/blog/2016/01/26/scrum-basics-4.html)) outbalance the higher administrative effort that occurs because one has to maintain the tickets on the physical board as well as in Jira.\nThe other teams are using Jira Boards.\n\n## What will be next?\n\nScrum defines three roles, which are Product Owner, Scrum Master and the Development Team.\nThose roles will be discussed in detail in the [next part](https://developer.epages.com/blog/2015/11/19/scrum-basics-2.html) of this Scrum Basics Series.\n\nNext to the roles Scrum brings four standard meetings: Sprint Planning, Daily Standup, Sprint Review and the Retrospective.\nWe will talk about these meetings in detail in [Scrum Meetings](https://developer.epages.com/blog/2015/12/15/scrum-basics-3.html).\n\n## Related posts\n\n* [Scrum Basics: Scrum Roles](https://developer.epages.com/blog/2015/11/19/scrum-basics-2.html)\n* [Scrum Basics: Scrum Meetings](https://developer.epages.com/blog/2015/12/15/scrum-basics-3.html)\n* [Scrum Basics: Estimating](https://developer.epages.com/blog/2016/01/26/scrum-basics-4.html)\n* [Scrum Basics: Principles and Values](https://developer.epages.com/blog/2016/02/25/scrum-basics-5.html)\n* [Scrum Basics: Practicing it](https://developer.epages.com/blog/2016/03/22/scrum-basics-6.html)\n","source":"_posts/2015-10-13-scrum-basics-1.md","raw":"---\nlayout: post\ntitle: \"Scrum Basics: What is Scrum?\"\ndate: \"2015-10-13 08:23:00\"\ncategories: agile\nauthors: [\"Anja B.\"]\n---\n\nAs a Scrum Master I’m often asked what Scrum is and what I’m doing the whole day long.\nWell, part of my job is to teach new colleagues exactly that.\nNow we'd like to share this knowledge with you in our **Scrum Basics Series**.\nThis series will consist of 6 parts and starts with the basic question:\nWhat is Scrum?\n\nSo let’s start with a short definition:\n\n>“Scrum is a team based framework\nto develop complex products\nor systems in an iterative way.“\n\n## What does that mean in detail?\n\nIn Scrum you are always working in a team.\nThis team should be cross-functional.\nIt should have all the abilities needed to fulfil the tasks, e.g. in software development a team consists of backend developers and frontend developers as well as designers and testers.\nIn an ideal world it would go from creating concepts, over developing and testing the product, to rollout, marketing and sales.\nBut most companies “only” have the development part in their Scrum teams.\nThe members of those teams should strive to get “T-shaped”.\nThat means they not only have one field of expertise, but also a broad basis so they can help out in other areas in the team.\nThat doesn’t mean everyone should know everything, it only means everyone is willing to do more than just their own thing.\n\n## Advantages\n\nThe big advantage of those teams in comparison to assigning a single person to specific parts of the product development is that you always have all the abilities needed in one room.\nIn [waterfall](https://en.wikipedia.org/wiki/Waterfall_model) you often have the problem that the person who did the backend development is already working on the next project when the designers realise that they need some more data from the backend.\nIn Scrum that won’t happen.\nAnother advantage is that you always have several eyes on one problem.\nSolutions can be found faster if you have more experience in the room and people who get stuck at some point always have someone to ask right next to them.\nAnd let's not forget the much faster feedback cycle with the testers when they are right inside the team!\nNo ticket is really done until it has been tested.\n\n{% img blog/blog-scrum1-waterfall-project-trap.jpg 45% right %}Waterfall-projects-trap\n\n## How is Scrum made for developing complex products or systems?\n\nComplex problems are usually better solved if more minds are involved.\nAn idea can be good but it will only become really great if you open it up to your team partners and get as much information and experience involved as possible.\nIf you have to do the same thing every day again (like on an assembly line), Scrum would be too much overhead, you could use Kanban instead.\nBut if you have to solve new challenges every day and are working on complex products, Scrum is your best choice.\n\n## Iterations\n\nThe iterations differ between the teams from 1 to 6 weeks.\nUsually they are 2 weeks long.\nThat means you only plan in detail what will be developed for the next two weeks.\nYou will then get feedback on the development and include this feedback into your next iteration.\nThis way you get quick feedback and alway know if you are developing the right thing.\nYou don’t need to be afraid of the “waterfall-projects-trap”.\n\nAll that may sound more difficult than it actually is.\nIn contrary, the Scrum framework is so simple that it easily fits on one sheet of paper.\n\n{% img blog/blog-scrum1-scrum-framework.jpg 45% left %}Scrum artefacts\n\nTwo important artefacts in Scrum are the Product Backlog and the Sprint Backlog.\nThe Product Backlog is an estimated, prioritised list of tickets (stories, bugs, tasks) that is sorted by the Product Owner according to the business value of these tickets.\nThat means this list contains all the tickets that need to be done for a product to be developed.\nThe Sprint Backlog is also a list of estimated, prioritised tickets, but it only contains those tickets that will be solved within the next iteration.\n\nIn the middle you can see the iteration, in Scrum called Sprint, which is a period of time (at ePages it's 2 weeks) during which the tickets in the Sprint Backlog have to be done and the scope of the Sprint Backlog should not change.\nThe development status of those tickets is represented on a so called Scrum Board or Sprint Board.\nIt provides an overview of all tickets of one team for one Sprint including the status of those tickets (e.g. Open, In Progress, Review, QA, Done) and which team member is currently working on which ticket.\nWith this Scrum Board everyone knows at all times about the development status and if the team is struggling or ahead of time.\nIt also shows if one person is working on too many tickets at the same time or if the team has a long queue in QA or Review.\n\nAt ePages we only have one team that is using a paper board.\nHaving a visual board present in the room at all times has more advantages for them.\nThe quick and easy way of adding tasks to stories (more about that in [ Estimating](https://developer.epages.com/blog/2016/01/26/scrum-basics-4.html)) outbalance the higher administrative effort that occurs because one has to maintain the tickets on the physical board as well as in Jira.\nThe other teams are using Jira Boards.\n\n## What will be next?\n\nScrum defines three roles, which are Product Owner, Scrum Master and the Development Team.\nThose roles will be discussed in detail in the [next part](https://developer.epages.com/blog/2015/11/19/scrum-basics-2.html) of this Scrum Basics Series.\n\nNext to the roles Scrum brings four standard meetings: Sprint Planning, Daily Standup, Sprint Review and the Retrospective.\nWe will talk about these meetings in detail in [Scrum Meetings](https://developer.epages.com/blog/2015/12/15/scrum-basics-3.html).\n\n## Related posts\n\n* [Scrum Basics: Scrum Roles](https://developer.epages.com/blog/2015/11/19/scrum-basics-2.html)\n* [Scrum Basics: Scrum Meetings](https://developer.epages.com/blog/2015/12/15/scrum-basics-3.html)\n* [Scrum Basics: Estimating](https://developer.epages.com/blog/2016/01/26/scrum-basics-4.html)\n* [Scrum Basics: Principles and Values](https://developer.epages.com/blog/2016/02/25/scrum-basics-5.html)\n* [Scrum Basics: Practicing it](https://developer.epages.com/blog/2016/03/22/scrum-basics-6.html)\n","slug":"2015-10-13-scrum-basics-1","published":1,"updated":"2016-09-20T14:28:04.000Z","comments":1,"photos":[],"link":"","_id":"ciu6nuh93001ghqyx3pv42aih","content":"<p>As a Scrum Master I’m often asked what Scrum is and what I’m doing the whole day long.<br>Well, part of my job is to teach new colleagues exactly that.<br>Now we’d like to share this knowledge with you in our <strong>Scrum Basics Series</strong>.<br>This series will consist of 6 parts and starts with the basic question:<br>What is Scrum?</p>\n<p>So let’s start with a short definition:</p>\n<blockquote>\n<p>“Scrum is a team based framework<br>to develop complex products<br>or systems in an iterative way.“</p>\n</blockquote>\n<h2 id=\"What-does-that-mean-in-detail\"><a href=\"#What-does-that-mean-in-detail\" class=\"headerlink\" title=\"What does that mean in detail?\"></a>What does that mean in detail?</h2><p>In Scrum you are always working in a team.<br>This team should be cross-functional.<br>It should have all the abilities needed to fulfil the tasks, e.g. in software development a team consists of backend developers and frontend developers as well as designers and testers.<br>In an ideal world it would go from creating concepts, over developing and testing the product, to rollout, marketing and sales.<br>But most companies “only” have the development part in their Scrum teams.<br>The members of those teams should strive to get “T-shaped”.<br>That means they not only have one field of expertise, but also a broad basis so they can help out in other areas in the team.<br>That doesn’t mean everyone should know everything, it only means everyone is willing to do more than just their own thing.</p>\n<h2 id=\"Advantages\"><a href=\"#Advantages\" class=\"headerlink\" title=\"Advantages\"></a>Advantages</h2><p>The big advantage of those teams in comparison to assigning a single person to specific parts of the product development is that you always have all the abilities needed in one room.<br>In <a href=\"https://en.wikipedia.org/wiki/Waterfall_model\" target=\"_blank\" rel=\"external\">waterfall</a> you often have the problem that the person who did the backend development is already working on the next project when the designers realise that they need some more data from the backend.<br>In Scrum that won’t happen.<br>Another advantage is that you always have several eyes on one problem.<br>Solutions can be found faster if you have more experience in the room and people who get stuck at some point always have someone to ask right next to them.<br>And let’s not forget the much faster feedback cycle with the testers when they are right inside the team!<br>No ticket is really done until it has been tested.</p>\n<p><img class=\"blog/blog-scrum1-waterfall-project-trap.jpg 45% right\">Waterfall-projects-trap</p>\n<h2 id=\"How-is-Scrum-made-for-developing-complex-products-or-systems\"><a href=\"#How-is-Scrum-made-for-developing-complex-products-or-systems\" class=\"headerlink\" title=\"How is Scrum made for developing complex products or systems?\"></a>How is Scrum made for developing complex products or systems?</h2><p>Complex problems are usually better solved if more minds are involved.<br>An idea can be good but it will only become really great if you open it up to your team partners and get as much information and experience involved as possible.<br>If you have to do the same thing every day again (like on an assembly line), Scrum would be too much overhead, you could use Kanban instead.<br>But if you have to solve new challenges every day and are working on complex products, Scrum is your best choice.</p>\n<h2 id=\"Iterations\"><a href=\"#Iterations\" class=\"headerlink\" title=\"Iterations\"></a>Iterations</h2><p>The iterations differ between the teams from 1 to 6 weeks.<br>Usually they are 2 weeks long.<br>That means you only plan in detail what will be developed for the next two weeks.<br>You will then get feedback on the development and include this feedback into your next iteration.<br>This way you get quick feedback and alway know if you are developing the right thing.<br>You don’t need to be afraid of the “waterfall-projects-trap”.</p>\n<p>All that may sound more difficult than it actually is.<br>In contrary, the Scrum framework is so simple that it easily fits on one sheet of paper.</p>\n<p><img class=\"blog/blog-scrum1-scrum-framework.jpg 45% left\">Scrum artefacts</p>\n<p>Two important artefacts in Scrum are the Product Backlog and the Sprint Backlog.<br>The Product Backlog is an estimated, prioritised list of tickets (stories, bugs, tasks) that is sorted by the Product Owner according to the business value of these tickets.<br>That means this list contains all the tickets that need to be done for a product to be developed.<br>The Sprint Backlog is also a list of estimated, prioritised tickets, but it only contains those tickets that will be solved within the next iteration.</p>\n<p>In the middle you can see the iteration, in Scrum called Sprint, which is a period of time (at ePages it’s 2 weeks) during which the tickets in the Sprint Backlog have to be done and the scope of the Sprint Backlog should not change.<br>The development status of those tickets is represented on a so called Scrum Board or Sprint Board.<br>It provides an overview of all tickets of one team for one Sprint including the status of those tickets (e.g. Open, In Progress, Review, QA, Done) and which team member is currently working on which ticket.<br>With this Scrum Board everyone knows at all times about the development status and if the team is struggling or ahead of time.<br>It also shows if one person is working on too many tickets at the same time or if the team has a long queue in QA or Review.</p>\n<p>At ePages we only have one team that is using a paper board.<br>Having a visual board present in the room at all times has more advantages for them.<br>The quick and easy way of adding tasks to stories (more about that in <a href=\"https://developer.epages.com/blog/2016/01/26/scrum-basics-4.html\" target=\"_blank\" rel=\"external\"> Estimating</a>) outbalance the higher administrative effort that occurs because one has to maintain the tickets on the physical board as well as in Jira.<br>The other teams are using Jira Boards.</p>\n<h2 id=\"What-will-be-next\"><a href=\"#What-will-be-next\" class=\"headerlink\" title=\"What will be next?\"></a>What will be next?</h2><p>Scrum defines three roles, which are Product Owner, Scrum Master and the Development Team.<br>Those roles will be discussed in detail in the <a href=\"https://developer.epages.com/blog/2015/11/19/scrum-basics-2.html\" target=\"_blank\" rel=\"external\">next part</a> of this Scrum Basics Series.</p>\n<p>Next to the roles Scrum brings four standard meetings: Sprint Planning, Daily Standup, Sprint Review and the Retrospective.<br>We will talk about these meetings in detail in <a href=\"https://developer.epages.com/blog/2015/12/15/scrum-basics-3.html\" target=\"_blank\" rel=\"external\">Scrum Meetings</a>.</p>\n<h2 id=\"Related-posts\"><a href=\"#Related-posts\" class=\"headerlink\" title=\"Related posts\"></a>Related posts</h2><ul>\n<li><a href=\"https://developer.epages.com/blog/2015/11/19/scrum-basics-2.html\" target=\"_blank\" rel=\"external\">Scrum Basics: Scrum Roles</a></li>\n<li><a href=\"https://developer.epages.com/blog/2015/12/15/scrum-basics-3.html\" target=\"_blank\" rel=\"external\">Scrum Basics: Scrum Meetings</a></li>\n<li><a href=\"https://developer.epages.com/blog/2016/01/26/scrum-basics-4.html\" target=\"_blank\" rel=\"external\">Scrum Basics: Estimating</a></li>\n<li><a href=\"https://developer.epages.com/blog/2016/02/25/scrum-basics-5.html\" target=\"_blank\" rel=\"external\">Scrum Basics: Principles and Values</a></li>\n<li><a href=\"https://developer.epages.com/blog/2016/03/22/scrum-basics-6.html\" target=\"_blank\" rel=\"external\">Scrum Basics: Practicing it</a></li>\n</ul>\n","excerpt":"","more":"<p>As a Scrum Master I’m often asked what Scrum is and what I’m doing the whole day long.<br>Well, part of my job is to teach new colleagues exactly that.<br>Now we’d like to share this knowledge with you in our <strong>Scrum Basics Series</strong>.<br>This series will consist of 6 parts and starts with the basic question:<br>What is Scrum?</p>\n<p>So let’s start with a short definition:</p>\n<blockquote>\n<p>“Scrum is a team based framework<br>to develop complex products<br>or systems in an iterative way.“</p>\n</blockquote>\n<h2 id=\"What-does-that-mean-in-detail\"><a href=\"#What-does-that-mean-in-detail\" class=\"headerlink\" title=\"What does that mean in detail?\"></a>What does that mean in detail?</h2><p>In Scrum you are always working in a team.<br>This team should be cross-functional.<br>It should have all the abilities needed to fulfil the tasks, e.g. in software development a team consists of backend developers and frontend developers as well as designers and testers.<br>In an ideal world it would go from creating concepts, over developing and testing the product, to rollout, marketing and sales.<br>But most companies “only” have the development part in their Scrum teams.<br>The members of those teams should strive to get “T-shaped”.<br>That means they not only have one field of expertise, but also a broad basis so they can help out in other areas in the team.<br>That doesn’t mean everyone should know everything, it only means everyone is willing to do more than just their own thing.</p>\n<h2 id=\"Advantages\"><a href=\"#Advantages\" class=\"headerlink\" title=\"Advantages\"></a>Advantages</h2><p>The big advantage of those teams in comparison to assigning a single person to specific parts of the product development is that you always have all the abilities needed in one room.<br>In <a href=\"https://en.wikipedia.org/wiki/Waterfall_model\">waterfall</a> you often have the problem that the person who did the backend development is already working on the next project when the designers realise that they need some more data from the backend.<br>In Scrum that won’t happen.<br>Another advantage is that you always have several eyes on one problem.<br>Solutions can be found faster if you have more experience in the room and people who get stuck at some point always have someone to ask right next to them.<br>And let’s not forget the much faster feedback cycle with the testers when they are right inside the team!<br>No ticket is really done until it has been tested.</p>\n<p><img class=\"blog/blog-scrum1-waterfall-project-trap.jpg 45% right\">Waterfall-projects-trap</p>\n<h2 id=\"How-is-Scrum-made-for-developing-complex-products-or-systems\"><a href=\"#How-is-Scrum-made-for-developing-complex-products-or-systems\" class=\"headerlink\" title=\"How is Scrum made for developing complex products or systems?\"></a>How is Scrum made for developing complex products or systems?</h2><p>Complex problems are usually better solved if more minds are involved.<br>An idea can be good but it will only become really great if you open it up to your team partners and get as much information and experience involved as possible.<br>If you have to do the same thing every day again (like on an assembly line), Scrum would be too much overhead, you could use Kanban instead.<br>But if you have to solve new challenges every day and are working on complex products, Scrum is your best choice.</p>\n<h2 id=\"Iterations\"><a href=\"#Iterations\" class=\"headerlink\" title=\"Iterations\"></a>Iterations</h2><p>The iterations differ between the teams from 1 to 6 weeks.<br>Usually they are 2 weeks long.<br>That means you only plan in detail what will be developed for the next two weeks.<br>You will then get feedback on the development and include this feedback into your next iteration.<br>This way you get quick feedback and alway know if you are developing the right thing.<br>You don’t need to be afraid of the “waterfall-projects-trap”.</p>\n<p>All that may sound more difficult than it actually is.<br>In contrary, the Scrum framework is so simple that it easily fits on one sheet of paper.</p>\n<p><img class=\"blog/blog-scrum1-scrum-framework.jpg 45% left\">Scrum artefacts</p>\n<p>Two important artefacts in Scrum are the Product Backlog and the Sprint Backlog.<br>The Product Backlog is an estimated, prioritised list of tickets (stories, bugs, tasks) that is sorted by the Product Owner according to the business value of these tickets.<br>That means this list contains all the tickets that need to be done for a product to be developed.<br>The Sprint Backlog is also a list of estimated, prioritised tickets, but it only contains those tickets that will be solved within the next iteration.</p>\n<p>In the middle you can see the iteration, in Scrum called Sprint, which is a period of time (at ePages it’s 2 weeks) during which the tickets in the Sprint Backlog have to be done and the scope of the Sprint Backlog should not change.<br>The development status of those tickets is represented on a so called Scrum Board or Sprint Board.<br>It provides an overview of all tickets of one team for one Sprint including the status of those tickets (e.g. Open, In Progress, Review, QA, Done) and which team member is currently working on which ticket.<br>With this Scrum Board everyone knows at all times about the development status and if the team is struggling or ahead of time.<br>It also shows if one person is working on too many tickets at the same time or if the team has a long queue in QA or Review.</p>\n<p>At ePages we only have one team that is using a paper board.<br>Having a visual board present in the room at all times has more advantages for them.<br>The quick and easy way of adding tasks to stories (more about that in <a href=\"https://developer.epages.com/blog/2016/01/26/scrum-basics-4.html\"> Estimating</a>) outbalance the higher administrative effort that occurs because one has to maintain the tickets on the physical board as well as in Jira.<br>The other teams are using Jira Boards.</p>\n<h2 id=\"What-will-be-next\"><a href=\"#What-will-be-next\" class=\"headerlink\" title=\"What will be next?\"></a>What will be next?</h2><p>Scrum defines three roles, which are Product Owner, Scrum Master and the Development Team.<br>Those roles will be discussed in detail in the <a href=\"https://developer.epages.com/blog/2015/11/19/scrum-basics-2.html\">next part</a> of this Scrum Basics Series.</p>\n<p>Next to the roles Scrum brings four standard meetings: Sprint Planning, Daily Standup, Sprint Review and the Retrospective.<br>We will talk about these meetings in detail in <a href=\"https://developer.epages.com/blog/2015/12/15/scrum-basics-3.html\">Scrum Meetings</a>.</p>\n<h2 id=\"Related-posts\"><a href=\"#Related-posts\" class=\"headerlink\" title=\"Related posts\"></a>Related posts</h2><ul>\n<li><a href=\"https://developer.epages.com/blog/2015/11/19/scrum-basics-2.html\">Scrum Basics: Scrum Roles</a></li>\n<li><a href=\"https://developer.epages.com/blog/2015/12/15/scrum-basics-3.html\">Scrum Basics: Scrum Meetings</a></li>\n<li><a href=\"https://developer.epages.com/blog/2016/01/26/scrum-basics-4.html\">Scrum Basics: Estimating</a></li>\n<li><a href=\"https://developer.epages.com/blog/2016/02/25/scrum-basics-5.html\">Scrum Basics: Principles and Values</a></li>\n<li><a href=\"https://developer.epages.com/blog/2016/03/22/scrum-basics-6.html\">Scrum Basics: Practicing it</a></li>\n</ul>\n"},{"layout":"post","title":"SEOkomm 2015 Retrospective","date":"2015-11-27T06:23:00.000Z","image":"blog-header/seokomm.jpg","authors":["Björn"],"_content":"\nThe sixth [SEOkomm](http://www.seokomm.at/) recently took place in Salzburg, Austria.\nA day full of topics about search engine optimisation, a nice atmosphere, plenty of good food and many interesting discussions allured over 800 people to the city of Mozart.\n\n{% image blog/blog-seokomm-1.jpg 50% left %}\n\nThe OnPage optimisation turned out to be a recurring topic in nearly all the talks.\nAlthough, as Johannes Müller (Google) pointed out in his Q&A-Session, links and off-page optimisation are still very important as a ranking factor.\nBut the main statement of the SEOkomm was “make good content”, use high quality pictures and videos, don’t write SEO-texts anymore, but focus on your customer.\nFind out their requirements, learn their language and terms, create and serve their needs.\nDon’t show only the product, but also serve trends, offer guidance, give practical tips (Buzzword alert!) and create holistic content.\n\nAnother way to improve your content is to concentrate on what is really needed.\nSacrifice 10% of your lousiest pages in order to help the other 90% rank better.\n\n{% image blog/blog-seokomm-2.jpg 50% left %}\n\nAn inspiring keynote was held by [Marcus Tandler](http://www.mediadonis.net/).\nHe spoke about what Google once was and what it has become today - a learning machine - an Artificial Intelligence.\nAn AI-System, called RankBrain, already analyses the queries in Google and should help to handle questions which are not asked yet.\nSo probably one day could a smartwatch answer a users question before it is asked.\nTandler used the example of a smartwatch explaining unknown foreign words which it hears in a conversation.\nThis eavesdropping is something that Google is already doing from time to time.\nSo told speaker [Karl Kratz](http://www.google.com) that after a chat about steaks during a car driving Google later suggested steak houses.\nScary, isn't it?\nBut Tandler demanded “a little bit confidence in Google”.\nThe main goal of Google is to make the user happy and so websites have to be made for the users and not for search engines.\nMake good content, reduce loading time and deal with broken links.\nThis all has influence on user interaction and good user feedback leads to a better ranking.\nA big thing for 2016 could be Google’s new framework AMP (Accelerated mobile pages) which should speed up the loading time on mobile devices.\nIt uses current web technologies but supports only a subset of HTML and CSS and does not allow third-party JavaScript.\n\n{% image blog/blog-seokomm-3.jpg 50% right %}\n\nAnother excellent [talk about PageSpeed](http://bit.ly/1Pc37R8) was held by [Bastian Grimm](http://www.peakace.de).\n47% of people expect a website to load within 2 seconds, and 40% of the users leave the website if they had to wait longer than three seconds for the page to load fully.\nAmazon found out that saving 100ms loading time increases the revenue by 1%.\nOne second more waiting time decreases the page views by 11% and the conversions by 7%.\nSo it is still crucial to reduce page loading time.\nOptimise the critical rendering path, minify CSS and JS, optimise images, actual caching and compressing on the server etc. is very important.\nUse asynchronous requests whenever it’s possible.\nReduce the use of custom web fonts.\n\nAnother traffic issue is images.\nPictures constitute 62% of web traffic.\n51% of all URLs load more than 40 images per request.\nA possible solution is to use alternative image types like Google's WebP, which have a 30% smaller file size than JPEG and are as much as 80% smaller than PNG.\nUnfortunately WebP is not supported by all browsers yet, but why not serving it to those users who can use it already.\nOne could replace PNGs and JPGs per rewrite via .htaccess or use the HTML5-tag &lt;picture&gt; with &lt;img&gt; as fallback.\nThere are also other image formats (FLIF, BPG, JPEG XR) in contention.\nA final thing which Grimm pointed out was HTTP/2 (published in May 2015) with its data compression and loading of page elements in parallel in a single connection.\nCurrently it's supported by more than 80% of servers.\n\n{% image blog/blog-seokomm-4.jpg 50% left %}\n\nThe talk of Karl Kratz was very thought-provoking.\nHe asked, why Google is the most famous search engine?\nAnswer: Because we allow it.\nBut what can we do against this “Googlegedon”?\nWe don’t need a new SEO-Partner, we need a new mindset.\nGoogle is good for mainstream searches, but bad for specialties.\nLooking for a restaurant in a new city?\nYou’re searching in Yelp.\nLooking for a vacation apartment?\nYou’re searching in booking.com.\nLooking for food delivery?\nYou’re using Lieferheld.\nThere are many special search possibilities without using Google.\nEven Amazon is a big search engine for many products.\nAnd what if you have a device without keyboard and display?\nIt’s irrelevant if your hotel is ranked very well in Google but isn’t found asking Apple’s Siri.\nBecause Siri doesn't use Google search but Bing, Yelp and Yahoo.\nA dependency of more than 20% on one search engine is a problem.\nSo spread your energy, use portals, use different search engines and optimise on “events and contextual incidents”.\n\nAll in all it was a good, well organised conference, which I left with a lot of valuable information and thought provoking ideas.\nI really look forward to visiting the SEOkomm again in 2016.\n\nSource of pictures: Uwe Brandl / www.salzburg-cityguide.at\n","source":"_posts/2015-11-27-seokomm-2015.md","raw":"---\nlayout: post\ntitle: \"SEOkomm 2015 Retrospective\"\ndate: \"2015-11-27 07:23:00\"\nimage: blog-header/seokomm.jpg\ncategories: events\nauthors: [\"Björn\"]\n---\n\nThe sixth [SEOkomm](http://www.seokomm.at/) recently took place in Salzburg, Austria.\nA day full of topics about search engine optimisation, a nice atmosphere, plenty of good food and many interesting discussions allured over 800 people to the city of Mozart.\n\n{% image blog/blog-seokomm-1.jpg 50% left %}\n\nThe OnPage optimisation turned out to be a recurring topic in nearly all the talks.\nAlthough, as Johannes Müller (Google) pointed out in his Q&A-Session, links and off-page optimisation are still very important as a ranking factor.\nBut the main statement of the SEOkomm was “make good content”, use high quality pictures and videos, don’t write SEO-texts anymore, but focus on your customer.\nFind out their requirements, learn their language and terms, create and serve their needs.\nDon’t show only the product, but also serve trends, offer guidance, give practical tips (Buzzword alert!) and create holistic content.\n\nAnother way to improve your content is to concentrate on what is really needed.\nSacrifice 10% of your lousiest pages in order to help the other 90% rank better.\n\n{% image blog/blog-seokomm-2.jpg 50% left %}\n\nAn inspiring keynote was held by [Marcus Tandler](http://www.mediadonis.net/).\nHe spoke about what Google once was and what it has become today - a learning machine - an Artificial Intelligence.\nAn AI-System, called RankBrain, already analyses the queries in Google and should help to handle questions which are not asked yet.\nSo probably one day could a smartwatch answer a users question before it is asked.\nTandler used the example of a smartwatch explaining unknown foreign words which it hears in a conversation.\nThis eavesdropping is something that Google is already doing from time to time.\nSo told speaker [Karl Kratz](http://www.google.com) that after a chat about steaks during a car driving Google later suggested steak houses.\nScary, isn't it?\nBut Tandler demanded “a little bit confidence in Google”.\nThe main goal of Google is to make the user happy and so websites have to be made for the users and not for search engines.\nMake good content, reduce loading time and deal with broken links.\nThis all has influence on user interaction and good user feedback leads to a better ranking.\nA big thing for 2016 could be Google’s new framework AMP (Accelerated mobile pages) which should speed up the loading time on mobile devices.\nIt uses current web technologies but supports only a subset of HTML and CSS and does not allow third-party JavaScript.\n\n{% image blog/blog-seokomm-3.jpg 50% right %}\n\nAnother excellent [talk about PageSpeed](http://bit.ly/1Pc37R8) was held by [Bastian Grimm](http://www.peakace.de).\n47% of people expect a website to load within 2 seconds, and 40% of the users leave the website if they had to wait longer than three seconds for the page to load fully.\nAmazon found out that saving 100ms loading time increases the revenue by 1%.\nOne second more waiting time decreases the page views by 11% and the conversions by 7%.\nSo it is still crucial to reduce page loading time.\nOptimise the critical rendering path, minify CSS and JS, optimise images, actual caching and compressing on the server etc. is very important.\nUse asynchronous requests whenever it’s possible.\nReduce the use of custom web fonts.\n\nAnother traffic issue is images.\nPictures constitute 62% of web traffic.\n51% of all URLs load more than 40 images per request.\nA possible solution is to use alternative image types like Google's WebP, which have a 30% smaller file size than JPEG and are as much as 80% smaller than PNG.\nUnfortunately WebP is not supported by all browsers yet, but why not serving it to those users who can use it already.\nOne could replace PNGs and JPGs per rewrite via .htaccess or use the HTML5-tag &lt;picture&gt; with &lt;img&gt; as fallback.\nThere are also other image formats (FLIF, BPG, JPEG XR) in contention.\nA final thing which Grimm pointed out was HTTP/2 (published in May 2015) with its data compression and loading of page elements in parallel in a single connection.\nCurrently it's supported by more than 80% of servers.\n\n{% image blog/blog-seokomm-4.jpg 50% left %}\n\nThe talk of Karl Kratz was very thought-provoking.\nHe asked, why Google is the most famous search engine?\nAnswer: Because we allow it.\nBut what can we do against this “Googlegedon”?\nWe don’t need a new SEO-Partner, we need a new mindset.\nGoogle is good for mainstream searches, but bad for specialties.\nLooking for a restaurant in a new city?\nYou’re searching in Yelp.\nLooking for a vacation apartment?\nYou’re searching in booking.com.\nLooking for food delivery?\nYou’re using Lieferheld.\nThere are many special search possibilities without using Google.\nEven Amazon is a big search engine for many products.\nAnd what if you have a device without keyboard and display?\nIt’s irrelevant if your hotel is ranked very well in Google but isn’t found asking Apple’s Siri.\nBecause Siri doesn't use Google search but Bing, Yelp and Yahoo.\nA dependency of more than 20% on one search engine is a problem.\nSo spread your energy, use portals, use different search engines and optimise on “events and contextual incidents”.\n\nAll in all it was a good, well organised conference, which I left with a lot of valuable information and thought provoking ideas.\nI really look forward to visiting the SEOkomm again in 2016.\n\nSource of pictures: Uwe Brandl / www.salzburg-cityguide.at\n","slug":"2015-11-27-seokomm-2015","published":1,"updated":"2016-09-20T14:19:22.000Z","comments":1,"photos":[],"link":"","_id":"ciu6nuh94001ihqyx6px89mgc","content":"<p>The sixth <a href=\"http://www.seokomm.at/\" target=\"_blank\" rel=\"external\">SEOkomm</a> recently took place in Salzburg, Austria.<br>A day full of topics about search engine optimisation, a nice atmosphere, plenty of good food and many interesting discussions allured over 800 people to the city of Mozart.</p>\n<img class=\"blog/blog-seokomm-1.jpg 50% left\">\n<p>The OnPage optimisation turned out to be a recurring topic in nearly all the talks.<br>Although, as Johannes Müller (Google) pointed out in his Q&amp;A-Session, links and off-page optimisation are still very important as a ranking factor.<br>But the main statement of the SEOkomm was “make good content”, use high quality pictures and videos, don’t write SEO-texts anymore, but focus on your customer.<br>Find out their requirements, learn their language and terms, create and serve their needs.<br>Don’t show only the product, but also serve trends, offer guidance, give practical tips (Buzzword alert!) and create holistic content.</p>\n<p>Another way to improve your content is to concentrate on what is really needed.<br>Sacrifice 10% of your lousiest pages in order to help the other 90% rank better.</p>\n<img class=\"blog/blog-seokomm-2.jpg 50% left\">\n<p>An inspiring keynote was held by <a href=\"http://www.mediadonis.net/\" target=\"_blank\" rel=\"external\">Marcus Tandler</a>.<br>He spoke about what Google once was and what it has become today - a learning machine - an Artificial Intelligence.<br>An AI-System, called RankBrain, already analyses the queries in Google and should help to handle questions which are not asked yet.<br>So probably one day could a smartwatch answer a users question before it is asked.<br>Tandler used the example of a smartwatch explaining unknown foreign words which it hears in a conversation.<br>This eavesdropping is something that Google is already doing from time to time.<br>So told speaker <a href=\"http://www.google.com\" target=\"_blank\" rel=\"external\">Karl Kratz</a> that after a chat about steaks during a car driving Google later suggested steak houses.<br>Scary, isn’t it?<br>But Tandler demanded “a little bit confidence in Google”.<br>The main goal of Google is to make the user happy and so websites have to be made for the users and not for search engines.<br>Make good content, reduce loading time and deal with broken links.<br>This all has influence on user interaction and good user feedback leads to a better ranking.<br>A big thing for 2016 could be Google’s new framework AMP (Accelerated mobile pages) which should speed up the loading time on mobile devices.<br>It uses current web technologies but supports only a subset of HTML and CSS and does not allow third-party JavaScript.</p>\n<img class=\"blog/blog-seokomm-3.jpg 50% right\">\n<p>Another excellent <a href=\"http://bit.ly/1Pc37R8\" target=\"_blank\" rel=\"external\">talk about PageSpeed</a> was held by <a href=\"http://www.peakace.de\" target=\"_blank\" rel=\"external\">Bastian Grimm</a>.<br>47% of people expect a website to load within 2 seconds, and 40% of the users leave the website if they had to wait longer than three seconds for the page to load fully.<br>Amazon found out that saving 100ms loading time increases the revenue by 1%.<br>One second more waiting time decreases the page views by 11% and the conversions by 7%.<br>So it is still crucial to reduce page loading time.<br>Optimise the critical rendering path, minify CSS and JS, optimise images, actual caching and compressing on the server etc. is very important.<br>Use asynchronous requests whenever it’s possible.<br>Reduce the use of custom web fonts.</p>\n<p>Another traffic issue is images.<br>Pictures constitute 62% of web traffic.<br>51% of all URLs load more than 40 images per request.<br>A possible solution is to use alternative image types like Google’s WebP, which have a 30% smaller file size than JPEG and are as much as 80% smaller than PNG.<br>Unfortunately WebP is not supported by all browsers yet, but why not serving it to those users who can use it already.<br>One could replace PNGs and JPGs per rewrite via .htaccess or use the HTML5-tag &lt;picture&gt; with &lt;img&gt; as fallback.<br>There are also other image formats (FLIF, BPG, JPEG XR) in contention.<br>A final thing which Grimm pointed out was HTTP/2 (published in May 2015) with its data compression and loading of page elements in parallel in a single connection.<br>Currently it’s supported by more than 80% of servers.</p>\n<img class=\"blog/blog-seokomm-4.jpg 50% left\">\n<p>The talk of Karl Kratz was very thought-provoking.<br>He asked, why Google is the most famous search engine?<br>Answer: Because we allow it.<br>But what can we do against this “Googlegedon”?<br>We don’t need a new SEO-Partner, we need a new mindset.<br>Google is good for mainstream searches, but bad for specialties.<br>Looking for a restaurant in a new city?<br>You’re searching in Yelp.<br>Looking for a vacation apartment?<br>You’re searching in booking.com.<br>Looking for food delivery?<br>You’re using Lieferheld.<br>There are many special search possibilities without using Google.<br>Even Amazon is a big search engine for many products.<br>And what if you have a device without keyboard and display?<br>It’s irrelevant if your hotel is ranked very well in Google but isn’t found asking Apple’s Siri.<br>Because Siri doesn’t use Google search but Bing, Yelp and Yahoo.<br>A dependency of more than 20% on one search engine is a problem.<br>So spread your energy, use portals, use different search engines and optimise on “events and contextual incidents”.</p>\n<p>All in all it was a good, well organised conference, which I left with a lot of valuable information and thought provoking ideas.<br>I really look forward to visiting the SEOkomm again in 2016.</p>\n<p>Source of pictures: Uwe Brandl / www.salzburg-cityguide.at</p>\n","excerpt":"","more":"<p>The sixth <a href=\"http://www.seokomm.at/\">SEOkomm</a> recently took place in Salzburg, Austria.<br>A day full of topics about search engine optimisation, a nice atmosphere, plenty of good food and many interesting discussions allured over 800 people to the city of Mozart.</p>\n<img class=\"blog/blog-seokomm-1.jpg 50% left\">\n<p>The OnPage optimisation turned out to be a recurring topic in nearly all the talks.<br>Although, as Johannes Müller (Google) pointed out in his Q&amp;A-Session, links and off-page optimisation are still very important as a ranking factor.<br>But the main statement of the SEOkomm was “make good content”, use high quality pictures and videos, don’t write SEO-texts anymore, but focus on your customer.<br>Find out their requirements, learn their language and terms, create and serve their needs.<br>Don’t show only the product, but also serve trends, offer guidance, give practical tips (Buzzword alert!) and create holistic content.</p>\n<p>Another way to improve your content is to concentrate on what is really needed.<br>Sacrifice 10% of your lousiest pages in order to help the other 90% rank better.</p>\n<img class=\"blog/blog-seokomm-2.jpg 50% left\">\n<p>An inspiring keynote was held by <a href=\"http://www.mediadonis.net/\">Marcus Tandler</a>.<br>He spoke about what Google once was and what it has become today - a learning machine - an Artificial Intelligence.<br>An AI-System, called RankBrain, already analyses the queries in Google and should help to handle questions which are not asked yet.<br>So probably one day could a smartwatch answer a users question before it is asked.<br>Tandler used the example of a smartwatch explaining unknown foreign words which it hears in a conversation.<br>This eavesdropping is something that Google is already doing from time to time.<br>So told speaker <a href=\"http://www.google.com\">Karl Kratz</a> that after a chat about steaks during a car driving Google later suggested steak houses.<br>Scary, isn’t it?<br>But Tandler demanded “a little bit confidence in Google”.<br>The main goal of Google is to make the user happy and so websites have to be made for the users and not for search engines.<br>Make good content, reduce loading time and deal with broken links.<br>This all has influence on user interaction and good user feedback leads to a better ranking.<br>A big thing for 2016 could be Google’s new framework AMP (Accelerated mobile pages) which should speed up the loading time on mobile devices.<br>It uses current web technologies but supports only a subset of HTML and CSS and does not allow third-party JavaScript.</p>\n<img class=\"blog/blog-seokomm-3.jpg 50% right\">\n<p>Another excellent <a href=\"http://bit.ly/1Pc37R8\">talk about PageSpeed</a> was held by <a href=\"http://www.peakace.de\">Bastian Grimm</a>.<br>47% of people expect a website to load within 2 seconds, and 40% of the users leave the website if they had to wait longer than three seconds for the page to load fully.<br>Amazon found out that saving 100ms loading time increases the revenue by 1%.<br>One second more waiting time decreases the page views by 11% and the conversions by 7%.<br>So it is still crucial to reduce page loading time.<br>Optimise the critical rendering path, minify CSS and JS, optimise images, actual caching and compressing on the server etc. is very important.<br>Use asynchronous requests whenever it’s possible.<br>Reduce the use of custom web fonts.</p>\n<p>Another traffic issue is images.<br>Pictures constitute 62% of web traffic.<br>51% of all URLs load more than 40 images per request.<br>A possible solution is to use alternative image types like Google’s WebP, which have a 30% smaller file size than JPEG and are as much as 80% smaller than PNG.<br>Unfortunately WebP is not supported by all browsers yet, but why not serving it to those users who can use it already.<br>One could replace PNGs and JPGs per rewrite via .htaccess or use the HTML5-tag &lt;picture&gt; with &lt;img&gt; as fallback.<br>There are also other image formats (FLIF, BPG, JPEG XR) in contention.<br>A final thing which Grimm pointed out was HTTP/2 (published in May 2015) with its data compression and loading of page elements in parallel in a single connection.<br>Currently it’s supported by more than 80% of servers.</p>\n<img class=\"blog/blog-seokomm-4.jpg 50% left\">\n<p>The talk of Karl Kratz was very thought-provoking.<br>He asked, why Google is the most famous search engine?<br>Answer: Because we allow it.<br>But what can we do against this “Googlegedon”?<br>We don’t need a new SEO-Partner, we need a new mindset.<br>Google is good for mainstream searches, but bad for specialties.<br>Looking for a restaurant in a new city?<br>You’re searching in Yelp.<br>Looking for a vacation apartment?<br>You’re searching in booking.com.<br>Looking for food delivery?<br>You’re using Lieferheld.<br>There are many special search possibilities without using Google.<br>Even Amazon is a big search engine for many products.<br>And what if you have a device without keyboard and display?<br>It’s irrelevant if your hotel is ranked very well in Google but isn’t found asking Apple’s Siri.<br>Because Siri doesn’t use Google search but Bing, Yelp and Yahoo.<br>A dependency of more than 20% on one search engine is a problem.<br>So spread your energy, use portals, use different search engines and optimise on “events and contextual incidents”.</p>\n<p>All in all it was a good, well organised conference, which I left with a lot of valuable information and thought provoking ideas.<br>I really look forward to visiting the SEOkomm again in 2016.</p>\n<p>Source of pictures: Uwe Brandl / www.salzburg-cityguide.at</p>\n"},{"layout":"post","title":"Global Scrum Gathering 2015 Prague","date":"2015-12-07T06:23:00.000Z","authors":["Anja B."],"_content":"\nThis November I visted the Global Scrum Gathering in Prague.\nIt's been three days filled with interesting workshops, presentations and getting to know people.\n\n## Keynote: Niels Pflaeging - Organize for Complexity\n\nThe keynote of Niels Pflaeging followed the ideas of his book \"Organize for Complexity\".\nThe basic idea is that top down management structures were working in the industrial age with slow moving dull markets but that they die with the fast moving markets today.\n\n{% image blog/blog-gsg-1.jpg 50% left %}\n\nHe described organisations as peaches rather than pyramids, with a centre and a periphery.\nThe customer always contacts the periphery and the periphery the centre.\nThe problem with pyramids is that if the centre would steer, they would be too slow and also lack of the information the periphery has.\nHe suggests to build teams/squads in the periphery and let them steer.\nIt's the idea of empowered self-organised teams.\nHe also had a whole slide with example companies (big ones!) that are already working this way to prove it works.\n\nOne really interesting point was when he started to talk about the theory of X- and Y-people.\n\n{% image blog/blog-gsg-2.jpg %}\n\nEveryone in the room wrote on a sticky note if they thinks whether they are an X or a Y person and on a second sticky note they put a guess of percentage of people who think they are an X person.\nThen we exchanged notes and those holding an X were supposed to raise their hands.\nIt appeared that out of 500 guests only a handful was holding an X and the presenter said out of statistics you can round that to zero.\nThe conclusion is that there are no X-people but in organisations there are a lot of systems for them.\nStatistics show that only 5% of the problems at work occur due to people while 95% come from the organisational systems.\n\nSystems that got designed for non-existing X-people are destructive and we should get rid of them.\nHe had a whole slide with examples, but I personally most liked his statement: **\"Bonus systems are a crime against humanity.\"**\nIf you want to see his whole presentation, you can find it [here](http://de.slideshare.net/npflaeging/organize-for-complexity-keynote-by-niels-pflaeging-at-scrum-gatering-prague-praguecz).\n\n## Ralph Miarka - From Non-Violent Communication to Potential-Focused Communication\n\nRalph Miarka enhanced the idea of [Non-Violent Communication](https://en.wikipedia.org/wiki/Nonviolent_Communication) with solution focused thinking.\nThat means while the non-violent communication is centred on problems, you should rather focus on the future.\nTalking about problems creates problems, but talking about the future opens up new possibilities.\nRalph Miarka enhanced the non-violent communication model to\nPotential Focused Communication:\n\n1. Preferred observation\n2. Preferred feelings\n3. Needs\n4. Solution focused questions\n\n## Gary Bamberger - Introduction to Coaching Skills for SMs and Leaders\n\nIn this workshop Gary Bamberger gave an introduction to what coaching actually is and how you do it.\nHe explained that coaches help to expand the thinking of the clients so they find own solutions for their problems.\nCoaches don't dictate the solutions.\nHe introduced seven Coaching Skills you can use in a session:\n\n1. Curiosity\n2. Powerful questions - not judging\n3. Silence\n4. Listening\n5. Reflecting\n6. Interruption\n7. Acknowledgment\n\nA coaching session itself should follow three steps:\n\n1. Clarify what is the topic?\n2. Coaching - use the skills\n3. Commitment - Set a fixed goal including a timeframe to achieve it.\n\nAfter the theory part we went to practicing it in groups of three.\nOne person presenting a problem, the second one coaching them and the third person was observing and giving feedback after the coaching session. The funniest problem in our group was definitely \"My daughter wants a kitten for Christmas!\"\nIt was really interesting to try it and afterwards we all agreed that the hardest part is to not give solutions when you are confronted with a problem but try and get the person to find the solution themselves.\n\n## Taghi Paksima - Slowing down to speed up: agile and technical debt\n\nTaghi Paksima was talking about technical debt, its consequences and how to tackle it.\nI liked his definition of the term:\n\n>\"Technical debt is all the mess you are leaving behind when you think you are done.\"\n\nAs consequences of TD he listed the creation of a financial burden, the killing of productivity and that it makes maintenance difficult.\nMost interesting was the point that too much technical debt can even lead to reverse the culture in the team or company from \"we are good\" to \"life sucks\" (Following the Tribal culture: 1 = Life sucks, 2 = I'm good, 3 = We are good, 4 = Life is good).\nHe also made clear that TD is inevitable, but there is a big difference between conscious decisions to do something quick and dirty right now but having a payback plan later, or doing unconscious TD or even conscious TD without a payback plan.\n\nHis advice to tackle TD was to make it visible.\nUse a special kind of ticket either on the backlog or a separate board.\nPlan it in the sprint or take a certain percentage of the sprint (e.g. one day per sprint) to only work on TD.\n\n{% image blog/blog-gsg-4.jpg %}\n\n## Pavel Dabrytski - Scrum Economics 101: Contracts, Budgets, Capitalization\n\nPavel Dabrytski was teaching the audience all the basics about contract, budgets and capitalisation in Scrum.\nIt was interesting to hear it from someone that has worked with this in practice.\nThere were many information I couldn't fully grab because I've never worked in Sales, so my advice would be to have a look at this [video](https://www.youtube.com/watch?v=cteAb9Ap7_4).\nIt's roughly the same presentation Pavel was holding on the Agile Africa conference this year.\n\n{% image blog/blog-gsg-5.jpg 50% left %}\n\nThe different contract models you can use in Scrum are all based on the idea to fix time and cost, but not scope.\n\n* Upper limit contract: Fixed cost, fixed time, see what's done until then.\n* Contract for only 3-4 sprints: see how the team is processing, then make long term contract.\n* Contract per sprint.\n* Fixed Profit -> share risk.\nBoth are interested to finish early.\nFor example 20k per sprint for a fixed time, if not finished by then go down to 15k per sprint (if team costs 15k) = finish late scenario\n* Target price -> Money for nothing, change for free.\nFinish early scenario.\nSprints that were paid but not needed anymore -> pay back 25% per sprint.\n* You can combine the last two contract models.\n\nYou can find the slides of this presentation [here](http://de.slideshare.net/PavelDabrytski/agile-economics-budgets-contacts-capitalization).\n","source":"_posts/2015-12-07-global-scrum-gathering-2015-prague.md","raw":"---\nlayout: post\ntitle: \"Global Scrum Gathering 2015 Prague\"\ndate: \"2015-12-07 07:23:00\"\ncategories: events\nauthors: [\"Anja B.\"]\n---\n\nThis November I visted the Global Scrum Gathering in Prague.\nIt's been three days filled with interesting workshops, presentations and getting to know people.\n\n## Keynote: Niels Pflaeging - Organize for Complexity\n\nThe keynote of Niels Pflaeging followed the ideas of his book \"Organize for Complexity\".\nThe basic idea is that top down management structures were working in the industrial age with slow moving dull markets but that they die with the fast moving markets today.\n\n{% image blog/blog-gsg-1.jpg 50% left %}\n\nHe described organisations as peaches rather than pyramids, with a centre and a periphery.\nThe customer always contacts the periphery and the periphery the centre.\nThe problem with pyramids is that if the centre would steer, they would be too slow and also lack of the information the periphery has.\nHe suggests to build teams/squads in the periphery and let them steer.\nIt's the idea of empowered self-organised teams.\nHe also had a whole slide with example companies (big ones!) that are already working this way to prove it works.\n\nOne really interesting point was when he started to talk about the theory of X- and Y-people.\n\n{% image blog/blog-gsg-2.jpg %}\n\nEveryone in the room wrote on a sticky note if they thinks whether they are an X or a Y person and on a second sticky note they put a guess of percentage of people who think they are an X person.\nThen we exchanged notes and those holding an X were supposed to raise their hands.\nIt appeared that out of 500 guests only a handful was holding an X and the presenter said out of statistics you can round that to zero.\nThe conclusion is that there are no X-people but in organisations there are a lot of systems for them.\nStatistics show that only 5% of the problems at work occur due to people while 95% come from the organisational systems.\n\nSystems that got designed for non-existing X-people are destructive and we should get rid of them.\nHe had a whole slide with examples, but I personally most liked his statement: **\"Bonus systems are a crime against humanity.\"**\nIf you want to see his whole presentation, you can find it [here](http://de.slideshare.net/npflaeging/organize-for-complexity-keynote-by-niels-pflaeging-at-scrum-gatering-prague-praguecz).\n\n## Ralph Miarka - From Non-Violent Communication to Potential-Focused Communication\n\nRalph Miarka enhanced the idea of [Non-Violent Communication](https://en.wikipedia.org/wiki/Nonviolent_Communication) with solution focused thinking.\nThat means while the non-violent communication is centred on problems, you should rather focus on the future.\nTalking about problems creates problems, but talking about the future opens up new possibilities.\nRalph Miarka enhanced the non-violent communication model to\nPotential Focused Communication:\n\n1. Preferred observation\n2. Preferred feelings\n3. Needs\n4. Solution focused questions\n\n## Gary Bamberger - Introduction to Coaching Skills for SMs and Leaders\n\nIn this workshop Gary Bamberger gave an introduction to what coaching actually is and how you do it.\nHe explained that coaches help to expand the thinking of the clients so they find own solutions for their problems.\nCoaches don't dictate the solutions.\nHe introduced seven Coaching Skills you can use in a session:\n\n1. Curiosity\n2. Powerful questions - not judging\n3. Silence\n4. Listening\n5. Reflecting\n6. Interruption\n7. Acknowledgment\n\nA coaching session itself should follow three steps:\n\n1. Clarify what is the topic?\n2. Coaching - use the skills\n3. Commitment - Set a fixed goal including a timeframe to achieve it.\n\nAfter the theory part we went to practicing it in groups of three.\nOne person presenting a problem, the second one coaching them and the third person was observing and giving feedback after the coaching session. The funniest problem in our group was definitely \"My daughter wants a kitten for Christmas!\"\nIt was really interesting to try it and afterwards we all agreed that the hardest part is to not give solutions when you are confronted with a problem but try and get the person to find the solution themselves.\n\n## Taghi Paksima - Slowing down to speed up: agile and technical debt\n\nTaghi Paksima was talking about technical debt, its consequences and how to tackle it.\nI liked his definition of the term:\n\n>\"Technical debt is all the mess you are leaving behind when you think you are done.\"\n\nAs consequences of TD he listed the creation of a financial burden, the killing of productivity and that it makes maintenance difficult.\nMost interesting was the point that too much technical debt can even lead to reverse the culture in the team or company from \"we are good\" to \"life sucks\" (Following the Tribal culture: 1 = Life sucks, 2 = I'm good, 3 = We are good, 4 = Life is good).\nHe also made clear that TD is inevitable, but there is a big difference between conscious decisions to do something quick and dirty right now but having a payback plan later, or doing unconscious TD or even conscious TD without a payback plan.\n\nHis advice to tackle TD was to make it visible.\nUse a special kind of ticket either on the backlog or a separate board.\nPlan it in the sprint or take a certain percentage of the sprint (e.g. one day per sprint) to only work on TD.\n\n{% image blog/blog-gsg-4.jpg %}\n\n## Pavel Dabrytski - Scrum Economics 101: Contracts, Budgets, Capitalization\n\nPavel Dabrytski was teaching the audience all the basics about contract, budgets and capitalisation in Scrum.\nIt was interesting to hear it from someone that has worked with this in practice.\nThere were many information I couldn't fully grab because I've never worked in Sales, so my advice would be to have a look at this [video](https://www.youtube.com/watch?v=cteAb9Ap7_4).\nIt's roughly the same presentation Pavel was holding on the Agile Africa conference this year.\n\n{% image blog/blog-gsg-5.jpg 50% left %}\n\nThe different contract models you can use in Scrum are all based on the idea to fix time and cost, but not scope.\n\n* Upper limit contract: Fixed cost, fixed time, see what's done until then.\n* Contract for only 3-4 sprints: see how the team is processing, then make long term contract.\n* Contract per sprint.\n* Fixed Profit -> share risk.\nBoth are interested to finish early.\nFor example 20k per sprint for a fixed time, if not finished by then go down to 15k per sprint (if team costs 15k) = finish late scenario\n* Target price -> Money for nothing, change for free.\nFinish early scenario.\nSprints that were paid but not needed anymore -> pay back 25% per sprint.\n* You can combine the last two contract models.\n\nYou can find the slides of this presentation [here](http://de.slideshare.net/PavelDabrytski/agile-economics-budgets-contacts-capitalization).\n","slug":"2015-12-07-global-scrum-gathering-2015-prague","published":1,"updated":"2016-09-20T14:19:22.000Z","comments":1,"photos":[],"link":"","_id":"ciu6nuh95001khqyxf18ou0zf","content":"<p>This November I visted the Global Scrum Gathering in Prague.<br>It’s been three days filled with interesting workshops, presentations and getting to know people.</p>\n<h2 id=\"Keynote-Niels-Pflaeging-Organize-for-Complexity\"><a href=\"#Keynote-Niels-Pflaeging-Organize-for-Complexity\" class=\"headerlink\" title=\"Keynote: Niels Pflaeging - Organize for Complexity\"></a>Keynote: Niels Pflaeging - Organize for Complexity</h2><p>The keynote of Niels Pflaeging followed the ideas of his book “Organize for Complexity”.<br>The basic idea is that top down management structures were working in the industrial age with slow moving dull markets but that they die with the fast moving markets today.</p>\n<img class=\"blog/blog-gsg-1.jpg 50% left\">\n<p>He described organisations as peaches rather than pyramids, with a centre and a periphery.<br>The customer always contacts the periphery and the periphery the centre.<br>The problem with pyramids is that if the centre would steer, they would be too slow and also lack of the information the periphery has.<br>He suggests to build teams/squads in the periphery and let them steer.<br>It’s the idea of empowered self-organised teams.<br>He also had a whole slide with example companies (big ones!) that are already working this way to prove it works.</p>\n<p>One really interesting point was when he started to talk about the theory of X- and Y-people.</p>\n<img class=\"blog/blog-gsg-2.jpg\">\n<p>Everyone in the room wrote on a sticky note if they thinks whether they are an X or a Y person and on a second sticky note they put a guess of percentage of people who think they are an X person.<br>Then we exchanged notes and those holding an X were supposed to raise their hands.<br>It appeared that out of 500 guests only a handful was holding an X and the presenter said out of statistics you can round that to zero.<br>The conclusion is that there are no X-people but in organisations there are a lot of systems for them.<br>Statistics show that only 5% of the problems at work occur due to people while 95% come from the organisational systems.</p>\n<p>Systems that got designed for non-existing X-people are destructive and we should get rid of them.<br>He had a whole slide with examples, but I personally most liked his statement: <strong>“Bonus systems are a crime against humanity.”</strong><br>If you want to see his whole presentation, you can find it <a href=\"http://de.slideshare.net/npflaeging/organize-for-complexity-keynote-by-niels-pflaeging-at-scrum-gatering-prague-praguecz\" target=\"_blank\" rel=\"external\">here</a>.</p>\n<h2 id=\"Ralph-Miarka-From-Non-Violent-Communication-to-Potential-Focused-Communication\"><a href=\"#Ralph-Miarka-From-Non-Violent-Communication-to-Potential-Focused-Communication\" class=\"headerlink\" title=\"Ralph Miarka - From Non-Violent Communication to Potential-Focused Communication\"></a>Ralph Miarka - From Non-Violent Communication to Potential-Focused Communication</h2><p>Ralph Miarka enhanced the idea of <a href=\"https://en.wikipedia.org/wiki/Nonviolent_Communication\" target=\"_blank\" rel=\"external\">Non-Violent Communication</a> with solution focused thinking.<br>That means while the non-violent communication is centred on problems, you should rather focus on the future.<br>Talking about problems creates problems, but talking about the future opens up new possibilities.<br>Ralph Miarka enhanced the non-violent communication model to<br>Potential Focused Communication:</p>\n<ol>\n<li>Preferred observation</li>\n<li>Preferred feelings</li>\n<li>Needs</li>\n<li>Solution focused questions</li>\n</ol>\n<h2 id=\"Gary-Bamberger-Introduction-to-Coaching-Skills-for-SMs-and-Leaders\"><a href=\"#Gary-Bamberger-Introduction-to-Coaching-Skills-for-SMs-and-Leaders\" class=\"headerlink\" title=\"Gary Bamberger - Introduction to Coaching Skills for SMs and Leaders\"></a>Gary Bamberger - Introduction to Coaching Skills for SMs and Leaders</h2><p>In this workshop Gary Bamberger gave an introduction to what coaching actually is and how you do it.<br>He explained that coaches help to expand the thinking of the clients so they find own solutions for their problems.<br>Coaches don’t dictate the solutions.<br>He introduced seven Coaching Skills you can use in a session:</p>\n<ol>\n<li>Curiosity</li>\n<li>Powerful questions - not judging</li>\n<li>Silence</li>\n<li>Listening</li>\n<li>Reflecting</li>\n<li>Interruption</li>\n<li>Acknowledgment</li>\n</ol>\n<p>A coaching session itself should follow three steps:</p>\n<ol>\n<li>Clarify what is the topic?</li>\n<li>Coaching - use the skills</li>\n<li>Commitment - Set a fixed goal including a timeframe to achieve it.</li>\n</ol>\n<p>After the theory part we went to practicing it in groups of three.<br>One person presenting a problem, the second one coaching them and the third person was observing and giving feedback after the coaching session. The funniest problem in our group was definitely “My daughter wants a kitten for Christmas!”<br>It was really interesting to try it and afterwards we all agreed that the hardest part is to not give solutions when you are confronted with a problem but try and get the person to find the solution themselves.</p>\n<h2 id=\"Taghi-Paksima-Slowing-down-to-speed-up-agile-and-technical-debt\"><a href=\"#Taghi-Paksima-Slowing-down-to-speed-up-agile-and-technical-debt\" class=\"headerlink\" title=\"Taghi Paksima - Slowing down to speed up: agile and technical debt\"></a>Taghi Paksima - Slowing down to speed up: agile and technical debt</h2><p>Taghi Paksima was talking about technical debt, its consequences and how to tackle it.<br>I liked his definition of the term:</p>\n<blockquote>\n<p>“Technical debt is all the mess you are leaving behind when you think you are done.”</p>\n</blockquote>\n<p>As consequences of TD he listed the creation of a financial burden, the killing of productivity and that it makes maintenance difficult.<br>Most interesting was the point that too much technical debt can even lead to reverse the culture in the team or company from “we are good” to “life sucks” (Following the Tribal culture: 1 = Life sucks, 2 = I’m good, 3 = We are good, 4 = Life is good).<br>He also made clear that TD is inevitable, but there is a big difference between conscious decisions to do something quick and dirty right now but having a payback plan later, or doing unconscious TD or even conscious TD without a payback plan.</p>\n<p>His advice to tackle TD was to make it visible.<br>Use a special kind of ticket either on the backlog or a separate board.<br>Plan it in the sprint or take a certain percentage of the sprint (e.g. one day per sprint) to only work on TD.</p>\n<img class=\"blog/blog-gsg-4.jpg\">\n<h2 id=\"Pavel-Dabrytski-Scrum-Economics-101-Contracts-Budgets-Capitalization\"><a href=\"#Pavel-Dabrytski-Scrum-Economics-101-Contracts-Budgets-Capitalization\" class=\"headerlink\" title=\"Pavel Dabrytski - Scrum Economics 101: Contracts, Budgets, Capitalization\"></a>Pavel Dabrytski - Scrum Economics 101: Contracts, Budgets, Capitalization</h2><p>Pavel Dabrytski was teaching the audience all the basics about contract, budgets and capitalisation in Scrum.<br>It was interesting to hear it from someone that has worked with this in practice.<br>There were many information I couldn’t fully grab because I’ve never worked in Sales, so my advice would be to have a look at this <a href=\"https://www.youtube.com/watch?v=cteAb9Ap7_4\" target=\"_blank\" rel=\"external\">video</a>.<br>It’s roughly the same presentation Pavel was holding on the Agile Africa conference this year.</p>\n<img class=\"blog/blog-gsg-5.jpg 50% left\">\n<p>The different contract models you can use in Scrum are all based on the idea to fix time and cost, but not scope.</p>\n<ul>\n<li>Upper limit contract: Fixed cost, fixed time, see what’s done until then.</li>\n<li>Contract for only 3-4 sprints: see how the team is processing, then make long term contract.</li>\n<li>Contract per sprint.</li>\n<li>Fixed Profit -&gt; share risk.<br>Both are interested to finish early.<br>For example 20k per sprint for a fixed time, if not finished by then go down to 15k per sprint (if team costs 15k) = finish late scenario</li>\n<li>Target price -&gt; Money for nothing, change for free.<br>Finish early scenario.<br>Sprints that were paid but not needed anymore -&gt; pay back 25% per sprint.</li>\n<li>You can combine the last two contract models.</li>\n</ul>\n<p>You can find the slides of this presentation <a href=\"http://de.slideshare.net/PavelDabrytski/agile-economics-budgets-contacts-capitalization\" target=\"_blank\" rel=\"external\">here</a>.</p>\n","excerpt":"","more":"<p>This November I visted the Global Scrum Gathering in Prague.<br>It’s been three days filled with interesting workshops, presentations and getting to know people.</p>\n<h2 id=\"Keynote-Niels-Pflaeging-Organize-for-Complexity\"><a href=\"#Keynote-Niels-Pflaeging-Organize-for-Complexity\" class=\"headerlink\" title=\"Keynote: Niels Pflaeging - Organize for Complexity\"></a>Keynote: Niels Pflaeging - Organize for Complexity</h2><p>The keynote of Niels Pflaeging followed the ideas of his book “Organize for Complexity”.<br>The basic idea is that top down management structures were working in the industrial age with slow moving dull markets but that they die with the fast moving markets today.</p>\n<img class=\"blog/blog-gsg-1.jpg 50% left\">\n<p>He described organisations as peaches rather than pyramids, with a centre and a periphery.<br>The customer always contacts the periphery and the periphery the centre.<br>The problem with pyramids is that if the centre would steer, they would be too slow and also lack of the information the periphery has.<br>He suggests to build teams/squads in the periphery and let them steer.<br>It’s the idea of empowered self-organised teams.<br>He also had a whole slide with example companies (big ones!) that are already working this way to prove it works.</p>\n<p>One really interesting point was when he started to talk about the theory of X- and Y-people.</p>\n<img class=\"blog/blog-gsg-2.jpg\">\n<p>Everyone in the room wrote on a sticky note if they thinks whether they are an X or a Y person and on a second sticky note they put a guess of percentage of people who think they are an X person.<br>Then we exchanged notes and those holding an X were supposed to raise their hands.<br>It appeared that out of 500 guests only a handful was holding an X and the presenter said out of statistics you can round that to zero.<br>The conclusion is that there are no X-people but in organisations there are a lot of systems for them.<br>Statistics show that only 5% of the problems at work occur due to people while 95% come from the organisational systems.</p>\n<p>Systems that got designed for non-existing X-people are destructive and we should get rid of them.<br>He had a whole slide with examples, but I personally most liked his statement: <strong>“Bonus systems are a crime against humanity.”</strong><br>If you want to see his whole presentation, you can find it <a href=\"http://de.slideshare.net/npflaeging/organize-for-complexity-keynote-by-niels-pflaeging-at-scrum-gatering-prague-praguecz\">here</a>.</p>\n<h2 id=\"Ralph-Miarka-From-Non-Violent-Communication-to-Potential-Focused-Communication\"><a href=\"#Ralph-Miarka-From-Non-Violent-Communication-to-Potential-Focused-Communication\" class=\"headerlink\" title=\"Ralph Miarka - From Non-Violent Communication to Potential-Focused Communication\"></a>Ralph Miarka - From Non-Violent Communication to Potential-Focused Communication</h2><p>Ralph Miarka enhanced the idea of <a href=\"https://en.wikipedia.org/wiki/Nonviolent_Communication\">Non-Violent Communication</a> with solution focused thinking.<br>That means while the non-violent communication is centred on problems, you should rather focus on the future.<br>Talking about problems creates problems, but talking about the future opens up new possibilities.<br>Ralph Miarka enhanced the non-violent communication model to<br>Potential Focused Communication:</p>\n<ol>\n<li>Preferred observation</li>\n<li>Preferred feelings</li>\n<li>Needs</li>\n<li>Solution focused questions</li>\n</ol>\n<h2 id=\"Gary-Bamberger-Introduction-to-Coaching-Skills-for-SMs-and-Leaders\"><a href=\"#Gary-Bamberger-Introduction-to-Coaching-Skills-for-SMs-and-Leaders\" class=\"headerlink\" title=\"Gary Bamberger - Introduction to Coaching Skills for SMs and Leaders\"></a>Gary Bamberger - Introduction to Coaching Skills for SMs and Leaders</h2><p>In this workshop Gary Bamberger gave an introduction to what coaching actually is and how you do it.<br>He explained that coaches help to expand the thinking of the clients so they find own solutions for their problems.<br>Coaches don’t dictate the solutions.<br>He introduced seven Coaching Skills you can use in a session:</p>\n<ol>\n<li>Curiosity</li>\n<li>Powerful questions - not judging</li>\n<li>Silence</li>\n<li>Listening</li>\n<li>Reflecting</li>\n<li>Interruption</li>\n<li>Acknowledgment</li>\n</ol>\n<p>A coaching session itself should follow three steps:</p>\n<ol>\n<li>Clarify what is the topic?</li>\n<li>Coaching - use the skills</li>\n<li>Commitment - Set a fixed goal including a timeframe to achieve it.</li>\n</ol>\n<p>After the theory part we went to practicing it in groups of three.<br>One person presenting a problem, the second one coaching them and the third person was observing and giving feedback after the coaching session. The funniest problem in our group was definitely “My daughter wants a kitten for Christmas!”<br>It was really interesting to try it and afterwards we all agreed that the hardest part is to not give solutions when you are confronted with a problem but try and get the person to find the solution themselves.</p>\n<h2 id=\"Taghi-Paksima-Slowing-down-to-speed-up-agile-and-technical-debt\"><a href=\"#Taghi-Paksima-Slowing-down-to-speed-up-agile-and-technical-debt\" class=\"headerlink\" title=\"Taghi Paksima - Slowing down to speed up: agile and technical debt\"></a>Taghi Paksima - Slowing down to speed up: agile and technical debt</h2><p>Taghi Paksima was talking about technical debt, its consequences and how to tackle it.<br>I liked his definition of the term:</p>\n<blockquote>\n<p>“Technical debt is all the mess you are leaving behind when you think you are done.”</p>\n</blockquote>\n<p>As consequences of TD he listed the creation of a financial burden, the killing of productivity and that it makes maintenance difficult.<br>Most interesting was the point that too much technical debt can even lead to reverse the culture in the team or company from “we are good” to “life sucks” (Following the Tribal culture: 1 = Life sucks, 2 = I’m good, 3 = We are good, 4 = Life is good).<br>He also made clear that TD is inevitable, but there is a big difference between conscious decisions to do something quick and dirty right now but having a payback plan later, or doing unconscious TD or even conscious TD without a payback plan.</p>\n<p>His advice to tackle TD was to make it visible.<br>Use a special kind of ticket either on the backlog or a separate board.<br>Plan it in the sprint or take a certain percentage of the sprint (e.g. one day per sprint) to only work on TD.</p>\n<img class=\"blog/blog-gsg-4.jpg\">\n<h2 id=\"Pavel-Dabrytski-Scrum-Economics-101-Contracts-Budgets-Capitalization\"><a href=\"#Pavel-Dabrytski-Scrum-Economics-101-Contracts-Budgets-Capitalization\" class=\"headerlink\" title=\"Pavel Dabrytski - Scrum Economics 101: Contracts, Budgets, Capitalization\"></a>Pavel Dabrytski - Scrum Economics 101: Contracts, Budgets, Capitalization</h2><p>Pavel Dabrytski was teaching the audience all the basics about contract, budgets and capitalisation in Scrum.<br>It was interesting to hear it from someone that has worked with this in practice.<br>There were many information I couldn’t fully grab because I’ve never worked in Sales, so my advice would be to have a look at this <a href=\"https://www.youtube.com/watch?v=cteAb9Ap7_4\">video</a>.<br>It’s roughly the same presentation Pavel was holding on the Agile Africa conference this year.</p>\n<img class=\"blog/blog-gsg-5.jpg 50% left\">\n<p>The different contract models you can use in Scrum are all based on the idea to fix time and cost, but not scope.</p>\n<ul>\n<li>Upper limit contract: Fixed cost, fixed time, see what’s done until then.</li>\n<li>Contract for only 3-4 sprints: see how the team is processing, then make long term contract.</li>\n<li>Contract per sprint.</li>\n<li>Fixed Profit -&gt; share risk.<br>Both are interested to finish early.<br>For example 20k per sprint for a fixed time, if not finished by then go down to 15k per sprint (if team costs 15k) = finish late scenario</li>\n<li>Target price -&gt; Money for nothing, change for free.<br>Finish early scenario.<br>Sprints that were paid but not needed anymore -&gt; pay back 25% per sprint.</li>\n<li>You can combine the last two contract models.</li>\n</ul>\n<p>You can find the slides of this presentation <a href=\"http://de.slideshare.net/PavelDabrytski/agile-economics-budgets-contacts-capitalization\">here</a>.</p>\n"},{"layout":"post","title":"W-JAX 2015 Retrospect Part 2: Microservices","date":"2015-12-08T11:00:00.000Z","authors":["David"],"_content":"\nWith this follow-up article of the W-JAX retrospect, I'd like to concentrate on the microservices part of the conference.\n\n## Living with microservices\n\nThe concepts to develop a software change regularly.\nSome of these changes do not make sense.\nThey do not helps us in the development process and are only a refreshed concept of a dusted software idea: Give them a buzzword, talk about it, and everyone will use it.\n\nHowever, a few of these new software design concepts are meaningful and solve current software development problems.\nOne of them is the idea of microservices.\nThe speakers of the W-JAX 2015 conference talked about this idea in many sessions.\n\n### When do we need microservices\n\nDeveloping software until now often had the idea of developing a [monolith](https://en.wikipedia.org/wiki/Monolithic_system).\nWith a monolith we build a software in one application with one database and (mostly) one programming language.\nTo test the complete software will entail huge tests.\n\nWith a few millions of lines of code developing and testing this big monolith will be a huge problem.\nIf the developer wants to invest more time in service instead of in extending his code they should think about switching to a microservice system.\nThis will also help to avoid using always the same patterns and requires a code generator to automatically create static structure.\n\n### The idea of microservices\n\nBasically, the idea of using microservices is to encapsulate every part of the software into a separate service.\nEvery service can run on its own and use its own de-central database.\nIf one service crashes the whole system can work without failing.\nIt is possible to run more instances of this service to scale it in case of being required more often.\n\nTo structure a monolith into small microservices, it is important to find a way to slice the software code into small parts.\nThe following checklist shows some important remarks:\n\n- To be used in a way to avoid big communication.\nIf two components have to communicate very often both should be in the same microservice.\n- Should not influence another microservice.\n- Every microservice can stand alone without knowing other components of the software.\n- Complete microservice should be handled by only one team.\nIf the sliced software component cannot be serviced by one team alone, slice it again.\n\n### Challenges and hints\n\nMicroservices will put the weight of complexity from algorithm complexity to communication complexity.\nThe dependencies of each software part are now moved to the way of communication.\n\nA second big challenge can be the [Two-Phase Commit](http://www.enterpriseintegrationpatterns.com/ramblings/18_starbucks.html) and data consistency.\nLet's imagine we want to transfer money from one to another bank account.\nThe monolith would have a controller layer which sends a request to the model layout.\nThis layer will transfer the money from one bank account to another instantly.\nIn a microservice world every bank account can be in another microservice.\nMicroservice 1 will send the money to microservice 2 and decrease the money in its own database.\nIn this moment the money is not existent: neither in microservice 1 nor in microservice 2.\n\nA very important concept is the **Design for Failure**.\nWith different services the input values of every service should be mistrusted.\nFurthermore, every microservice has a fallback output value if something is wrong.\n\nAnother important hint is to monitor the communication over all microservices.\nThat is important to know in which component will be an error, why and when.\nFor this an overall identification number of each data element would be helpful.\nSome tools like [Netflix/eureka](https://github.com/Netflix/eureka) help to monitor all microservices.\n\n### Linked sources\n\n- [The Art of Scalability](http://www.amazon.de/The-Art-Scalability-Martin-Abbott/dp/0137030428)\n- [Building Microservices](http://www.amazon.de/Building-Microservices-Sam-Newman/dp/1491950358)\n- [Domain-Driven Design: Tackling Complexity in the Heart of Software](http://www.amazon.de/Domain-Driven-Design-Tackling-Complexity-Software/dp/0321125215)\n- [Implementing Domain-Driven Design](http://www.amazon.de/Implementing-Domain-Driven-Design-Vaughn-Vernon/dp/0321834577)\n\n## Related post\n\n[W-JAX 2015 Retrospect Part 1: Agile Day](https://developer.epages.com/blog/2015/11/30/wjax2015-agile-day.html)\n","source":"_posts/2015-12-08-wjax2015-microservices.md","raw":"---\nlayout: post\ntitle: \"W-JAX 2015 Retrospect Part 2: Microservices\"\ndate: \"2015-12-08 12:00:00\"\ncategories: events\nauthors: [\"David\"]\n---\n\nWith this follow-up article of the W-JAX retrospect, I'd like to concentrate on the microservices part of the conference.\n\n## Living with microservices\n\nThe concepts to develop a software change regularly.\nSome of these changes do not make sense.\nThey do not helps us in the development process and are only a refreshed concept of a dusted software idea: Give them a buzzword, talk about it, and everyone will use it.\n\nHowever, a few of these new software design concepts are meaningful and solve current software development problems.\nOne of them is the idea of microservices.\nThe speakers of the W-JAX 2015 conference talked about this idea in many sessions.\n\n### When do we need microservices\n\nDeveloping software until now often had the idea of developing a [monolith](https://en.wikipedia.org/wiki/Monolithic_system).\nWith a monolith we build a software in one application with one database and (mostly) one programming language.\nTo test the complete software will entail huge tests.\n\nWith a few millions of lines of code developing and testing this big monolith will be a huge problem.\nIf the developer wants to invest more time in service instead of in extending his code they should think about switching to a microservice system.\nThis will also help to avoid using always the same patterns and requires a code generator to automatically create static structure.\n\n### The idea of microservices\n\nBasically, the idea of using microservices is to encapsulate every part of the software into a separate service.\nEvery service can run on its own and use its own de-central database.\nIf one service crashes the whole system can work without failing.\nIt is possible to run more instances of this service to scale it in case of being required more often.\n\nTo structure a monolith into small microservices, it is important to find a way to slice the software code into small parts.\nThe following checklist shows some important remarks:\n\n- To be used in a way to avoid big communication.\nIf two components have to communicate very often both should be in the same microservice.\n- Should not influence another microservice.\n- Every microservice can stand alone without knowing other components of the software.\n- Complete microservice should be handled by only one team.\nIf the sliced software component cannot be serviced by one team alone, slice it again.\n\n### Challenges and hints\n\nMicroservices will put the weight of complexity from algorithm complexity to communication complexity.\nThe dependencies of each software part are now moved to the way of communication.\n\nA second big challenge can be the [Two-Phase Commit](http://www.enterpriseintegrationpatterns.com/ramblings/18_starbucks.html) and data consistency.\nLet's imagine we want to transfer money from one to another bank account.\nThe monolith would have a controller layer which sends a request to the model layout.\nThis layer will transfer the money from one bank account to another instantly.\nIn a microservice world every bank account can be in another microservice.\nMicroservice 1 will send the money to microservice 2 and decrease the money in its own database.\nIn this moment the money is not existent: neither in microservice 1 nor in microservice 2.\n\nA very important concept is the **Design for Failure**.\nWith different services the input values of every service should be mistrusted.\nFurthermore, every microservice has a fallback output value if something is wrong.\n\nAnother important hint is to monitor the communication over all microservices.\nThat is important to know in which component will be an error, why and when.\nFor this an overall identification number of each data element would be helpful.\nSome tools like [Netflix/eureka](https://github.com/Netflix/eureka) help to monitor all microservices.\n\n### Linked sources\n\n- [The Art of Scalability](http://www.amazon.de/The-Art-Scalability-Martin-Abbott/dp/0137030428)\n- [Building Microservices](http://www.amazon.de/Building-Microservices-Sam-Newman/dp/1491950358)\n- [Domain-Driven Design: Tackling Complexity in the Heart of Software](http://www.amazon.de/Domain-Driven-Design-Tackling-Complexity-Software/dp/0321125215)\n- [Implementing Domain-Driven Design](http://www.amazon.de/Implementing-Domain-Driven-Design-Vaughn-Vernon/dp/0321834577)\n\n## Related post\n\n[W-JAX 2015 Retrospect Part 1: Agile Day](https://developer.epages.com/blog/2015/11/30/wjax2015-agile-day.html)\n","slug":"2015-12-08-wjax2015-microservices","published":1,"updated":"2016-09-20T14:19:22.000Z","comments":1,"photos":[],"link":"","_id":"ciu6nuh96001mhqyxuynhe2z8","content":"<p>With this follow-up article of the W-JAX retrospect, I’d like to concentrate on the microservices part of the conference.</p>\n<h2 id=\"Living-with-microservices\"><a href=\"#Living-with-microservices\" class=\"headerlink\" title=\"Living with microservices\"></a>Living with microservices</h2><p>The concepts to develop a software change regularly.<br>Some of these changes do not make sense.<br>They do not helps us in the development process and are only a refreshed concept of a dusted software idea: Give them a buzzword, talk about it, and everyone will use it.</p>\n<p>However, a few of these new software design concepts are meaningful and solve current software development problems.<br>One of them is the idea of microservices.<br>The speakers of the W-JAX 2015 conference talked about this idea in many sessions.</p>\n<h3 id=\"When-do-we-need-microservices\"><a href=\"#When-do-we-need-microservices\" class=\"headerlink\" title=\"When do we need microservices\"></a>When do we need microservices</h3><p>Developing software until now often had the idea of developing a <a href=\"https://en.wikipedia.org/wiki/Monolithic_system\" target=\"_blank\" rel=\"external\">monolith</a>.<br>With a monolith we build a software in one application with one database and (mostly) one programming language.<br>To test the complete software will entail huge tests.</p>\n<p>With a few millions of lines of code developing and testing this big monolith will be a huge problem.<br>If the developer wants to invest more time in service instead of in extending his code they should think about switching to a microservice system.<br>This will also help to avoid using always the same patterns and requires a code generator to automatically create static structure.</p>\n<h3 id=\"The-idea-of-microservices\"><a href=\"#The-idea-of-microservices\" class=\"headerlink\" title=\"The idea of microservices\"></a>The idea of microservices</h3><p>Basically, the idea of using microservices is to encapsulate every part of the software into a separate service.<br>Every service can run on its own and use its own de-central database.<br>If one service crashes the whole system can work without failing.<br>It is possible to run more instances of this service to scale it in case of being required more often.</p>\n<p>To structure a monolith into small microservices, it is important to find a way to slice the software code into small parts.<br>The following checklist shows some important remarks:</p>\n<ul>\n<li>To be used in a way to avoid big communication.<br>If two components have to communicate very often both should be in the same microservice.</li>\n<li>Should not influence another microservice.</li>\n<li>Every microservice can stand alone without knowing other components of the software.</li>\n<li>Complete microservice should be handled by only one team.<br>If the sliced software component cannot be serviced by one team alone, slice it again.</li>\n</ul>\n<h3 id=\"Challenges-and-hints\"><a href=\"#Challenges-and-hints\" class=\"headerlink\" title=\"Challenges and hints\"></a>Challenges and hints</h3><p>Microservices will put the weight of complexity from algorithm complexity to communication complexity.<br>The dependencies of each software part are now moved to the way of communication.</p>\n<p>A second big challenge can be the <a href=\"http://www.enterpriseintegrationpatterns.com/ramblings/18_starbucks.html\" target=\"_blank\" rel=\"external\">Two-Phase Commit</a> and data consistency.<br>Let’s imagine we want to transfer money from one to another bank account.<br>The monolith would have a controller layer which sends a request to the model layout.<br>This layer will transfer the money from one bank account to another instantly.<br>In a microservice world every bank account can be in another microservice.<br>Microservice 1 will send the money to microservice 2 and decrease the money in its own database.<br>In this moment the money is not existent: neither in microservice 1 nor in microservice 2.</p>\n<p>A very important concept is the <strong>Design for Failure</strong>.<br>With different services the input values of every service should be mistrusted.<br>Furthermore, every microservice has a fallback output value if something is wrong.</p>\n<p>Another important hint is to monitor the communication over all microservices.<br>That is important to know in which component will be an error, why and when.<br>For this an overall identification number of each data element would be helpful.<br>Some tools like <a href=\"https://github.com/Netflix/eureka\" target=\"_blank\" rel=\"external\">Netflix/eureka</a> help to monitor all microservices.</p>\n<h3 id=\"Linked-sources\"><a href=\"#Linked-sources\" class=\"headerlink\" title=\"Linked sources\"></a>Linked sources</h3><ul>\n<li><a href=\"http://www.amazon.de/The-Art-Scalability-Martin-Abbott/dp/0137030428\" target=\"_blank\" rel=\"external\">The Art of Scalability</a></li>\n<li><a href=\"http://www.amazon.de/Building-Microservices-Sam-Newman/dp/1491950358\" target=\"_blank\" rel=\"external\">Building Microservices</a></li>\n<li><a href=\"http://www.amazon.de/Domain-Driven-Design-Tackling-Complexity-Software/dp/0321125215\" target=\"_blank\" rel=\"external\">Domain-Driven Design: Tackling Complexity in the Heart of Software</a></li>\n<li><a href=\"http://www.amazon.de/Implementing-Domain-Driven-Design-Vaughn-Vernon/dp/0321834577\" target=\"_blank\" rel=\"external\">Implementing Domain-Driven Design</a></li>\n</ul>\n<h2 id=\"Related-post\"><a href=\"#Related-post\" class=\"headerlink\" title=\"Related post\"></a>Related post</h2><p><a href=\"https://developer.epages.com/blog/2015/11/30/wjax2015-agile-day.html\" target=\"_blank\" rel=\"external\">W-JAX 2015 Retrospect Part 1: Agile Day</a></p>\n","excerpt":"","more":"<p>With this follow-up article of the W-JAX retrospect, I’d like to concentrate on the microservices part of the conference.</p>\n<h2 id=\"Living-with-microservices\"><a href=\"#Living-with-microservices\" class=\"headerlink\" title=\"Living with microservices\"></a>Living with microservices</h2><p>The concepts to develop a software change regularly.<br>Some of these changes do not make sense.<br>They do not helps us in the development process and are only a refreshed concept of a dusted software idea: Give them a buzzword, talk about it, and everyone will use it.</p>\n<p>However, a few of these new software design concepts are meaningful and solve current software development problems.<br>One of them is the idea of microservices.<br>The speakers of the W-JAX 2015 conference talked about this idea in many sessions.</p>\n<h3 id=\"When-do-we-need-microservices\"><a href=\"#When-do-we-need-microservices\" class=\"headerlink\" title=\"When do we need microservices\"></a>When do we need microservices</h3><p>Developing software until now often had the idea of developing a <a href=\"https://en.wikipedia.org/wiki/Monolithic_system\">monolith</a>.<br>With a monolith we build a software in one application with one database and (mostly) one programming language.<br>To test the complete software will entail huge tests.</p>\n<p>With a few millions of lines of code developing and testing this big monolith will be a huge problem.<br>If the developer wants to invest more time in service instead of in extending his code they should think about switching to a microservice system.<br>This will also help to avoid using always the same patterns and requires a code generator to automatically create static structure.</p>\n<h3 id=\"The-idea-of-microservices\"><a href=\"#The-idea-of-microservices\" class=\"headerlink\" title=\"The idea of microservices\"></a>The idea of microservices</h3><p>Basically, the idea of using microservices is to encapsulate every part of the software into a separate service.<br>Every service can run on its own and use its own de-central database.<br>If one service crashes the whole system can work without failing.<br>It is possible to run more instances of this service to scale it in case of being required more often.</p>\n<p>To structure a monolith into small microservices, it is important to find a way to slice the software code into small parts.<br>The following checklist shows some important remarks:</p>\n<ul>\n<li>To be used in a way to avoid big communication.<br>If two components have to communicate very often both should be in the same microservice.</li>\n<li>Should not influence another microservice.</li>\n<li>Every microservice can stand alone without knowing other components of the software.</li>\n<li>Complete microservice should be handled by only one team.<br>If the sliced software component cannot be serviced by one team alone, slice it again.</li>\n</ul>\n<h3 id=\"Challenges-and-hints\"><a href=\"#Challenges-and-hints\" class=\"headerlink\" title=\"Challenges and hints\"></a>Challenges and hints</h3><p>Microservices will put the weight of complexity from algorithm complexity to communication complexity.<br>The dependencies of each software part are now moved to the way of communication.</p>\n<p>A second big challenge can be the <a href=\"http://www.enterpriseintegrationpatterns.com/ramblings/18_starbucks.html\">Two-Phase Commit</a> and data consistency.<br>Let’s imagine we want to transfer money from one to another bank account.<br>The monolith would have a controller layer which sends a request to the model layout.<br>This layer will transfer the money from one bank account to another instantly.<br>In a microservice world every bank account can be in another microservice.<br>Microservice 1 will send the money to microservice 2 and decrease the money in its own database.<br>In this moment the money is not existent: neither in microservice 1 nor in microservice 2.</p>\n<p>A very important concept is the <strong>Design for Failure</strong>.<br>With different services the input values of every service should be mistrusted.<br>Furthermore, every microservice has a fallback output value if something is wrong.</p>\n<p>Another important hint is to monitor the communication over all microservices.<br>That is important to know in which component will be an error, why and when.<br>For this an overall identification number of each data element would be helpful.<br>Some tools like <a href=\"https://github.com/Netflix/eureka\">Netflix/eureka</a> help to monitor all microservices.</p>\n<h3 id=\"Linked-sources\"><a href=\"#Linked-sources\" class=\"headerlink\" title=\"Linked sources\"></a>Linked sources</h3><ul>\n<li><a href=\"http://www.amazon.de/The-Art-Scalability-Martin-Abbott/dp/0137030428\">The Art of Scalability</a></li>\n<li><a href=\"http://www.amazon.de/Building-Microservices-Sam-Newman/dp/1491950358\">Building Microservices</a></li>\n<li><a href=\"http://www.amazon.de/Domain-Driven-Design-Tackling-Complexity-Software/dp/0321125215\">Domain-Driven Design: Tackling Complexity in the Heart of Software</a></li>\n<li><a href=\"http://www.amazon.de/Implementing-Domain-Driven-Design-Vaughn-Vernon/dp/0321834577\">Implementing Domain-Driven Design</a></li>\n</ul>\n<h2 id=\"Related-post\"><a href=\"#Related-post\" class=\"headerlink\" title=\"Related post\"></a>Related post</h2><p><a href=\"https://developer.epages.com/blog/2015/11/30/wjax2015-agile-day.html\">W-JAX 2015 Retrospect Part 1: Agile Day</a></p>\n"},{"layout":"post","title":"Microservices Meetup: Service Discovery","date":"2016-02-09T06:16:34.000Z","image":"blog-header/microservice-meetup.jpg","authors":["Mathias"],"_content":"\nFull house at ePages in Hamburg!\nLast Wednesday, we hosted the [Microservices Meetup Hamburg](http://www.meetup.com/de-DE/Microservices-Meetup-Hamburg/events/224965581/?a=socialmedia).\nAbout 30 developers accepted the invitation and came to listen to the story about our journey through the world of Service Discovery.\n\nWe had two presentation slots that filled the evening.\nAnd next to soft drinks, beer and pizza, there was also enough time to talk shop.\n\nWith microservices, we are pushing complexity from the application into the infrastructure.\nService discovery is one of the complexities that you find yourself confronted with in the world of microservices.\n\n{% image blog/blog-microservice-meetup-2.jpg 45% right %}\n\nWhen many services need to find their peers you want a service discovery solution that:\n\n* can add and remove services as they come and go\n* check the health of known services\n* remove unhealthy services\n* provide load balancing capabilities to be able to spread the load among the service instances.\nOf course all that should be feasible as transparent to the client service as possible.\n\nWe evaluated different service discovery solutions with different strategies.\nIn his presentation Dirk went through these solutions, explained their characteristics, and reasoned about the pros and cons.\n\nHe started with [Eureka](https://github.com/Netflix/eureka/wiki/Eureka-at-a-glance) from the Netflix OSS stack. We used it in one of our early prototypes. Eureka works with a central registry that is replicated on each service and uses client-side load balancing for service calls.\nEureka itself made a good impression but we discarded it along the way - also because back then it required code changes on the client side and we wanted something less intrusive.\n\nWe tried to keep service discovery out of our code as much as possible and we added Docker to our infrastructure tool set.\nSo the service discovery solution should seamlessly integrate into this environment as well.\nThis lead us to a [Consul](https://www.consul.io/)-based service discovery approach that we already talked about in detail [earlier on this blog](https://developer.epages.com/blog/2015/09/28/service-discovery.html).\n\nLater we chose [Kubernetes](http://kubernetes.io/) as our container management solution.\nIn Kubernetes we already found a DNS-based service discovery solution that could also fulfill our needs.\nSo it felt strange to have our own service discovery stack running while Kubernetes offers something similar. That led us to the adoption of Kubernetes also for service discovery.\nIt helped us to reduce our infrastructure complexity and relieved us from managing additional components.\n\n{% image blog/blog-microservice-meetup-3.jpg 45% left %}\n\nOn the service client side we introduced [Ribbon](https://github.com/Netflix/ribbon/wiki) for outbound service calls.\nThus we can work with logical service names in a managed environment like Kubernetes but can also wire services together that run locally in a dev environment.\nUsing the Spring framework, the usage of Ribbon can be reduced to a few annotations enabling us to keep our service code (almost) free of service discovery concerns.\n\nAfter Dirk finished to guide us through this journey towards our current service discovery solution we took a break to recover with beer and pizza.\nThere were excited discussions about the topic showing that service discovery is a topic that is of great interest in the community at the moment.\n\nAfter the pizza break Oli continued with a demo including live coding of two services demonstrating our service discovery solution in action.\nOli not only showed how easy calling a service is on the development side, but also how scaling and health-checking can work in Kubernetes.\nYou can find the [demo code on GitHub](https://github.com/otrosien/meetup-2016-02-code).\nThe slides of our talk can be found [here](http://epages-de.github.io/meetup-2016-02-slides/).\n\nWe really like the idea of Meetups and are happy that we could participate.\nSo it is not unlikely that more Meetups at ePages will follow.\nLast but not least we would like to thank [Thomas Hackbarth](http://www.meetup.com/de-DE/Microservices-Meetup-Hamburg/members/182490822/) for organising the Microservices Meetup Hamburg and for giving us the opportunity to host this event.\n","source":"_posts/2016-02-09-microservice-meetup.md","raw":"---\nlayout: post\ntitle: \"Microservices Meetup: Service Discovery\"\ndate: \"2016-02-09 07:16:34\"\nimage: blog-header/microservice-meetup.jpg\ncategories: events\nauthors: [\"Mathias\"]\n---\n\nFull house at ePages in Hamburg!\nLast Wednesday, we hosted the [Microservices Meetup Hamburg](http://www.meetup.com/de-DE/Microservices-Meetup-Hamburg/events/224965581/?a=socialmedia).\nAbout 30 developers accepted the invitation and came to listen to the story about our journey through the world of Service Discovery.\n\nWe had two presentation slots that filled the evening.\nAnd next to soft drinks, beer and pizza, there was also enough time to talk shop.\n\nWith microservices, we are pushing complexity from the application into the infrastructure.\nService discovery is one of the complexities that you find yourself confronted with in the world of microservices.\n\n{% image blog/blog-microservice-meetup-2.jpg 45% right %}\n\nWhen many services need to find their peers you want a service discovery solution that:\n\n* can add and remove services as they come and go\n* check the health of known services\n* remove unhealthy services\n* provide load balancing capabilities to be able to spread the load among the service instances.\nOf course all that should be feasible as transparent to the client service as possible.\n\nWe evaluated different service discovery solutions with different strategies.\nIn his presentation Dirk went through these solutions, explained their characteristics, and reasoned about the pros and cons.\n\nHe started with [Eureka](https://github.com/Netflix/eureka/wiki/Eureka-at-a-glance) from the Netflix OSS stack. We used it in one of our early prototypes. Eureka works with a central registry that is replicated on each service and uses client-side load balancing for service calls.\nEureka itself made a good impression but we discarded it along the way - also because back then it required code changes on the client side and we wanted something less intrusive.\n\nWe tried to keep service discovery out of our code as much as possible and we added Docker to our infrastructure tool set.\nSo the service discovery solution should seamlessly integrate into this environment as well.\nThis lead us to a [Consul](https://www.consul.io/)-based service discovery approach that we already talked about in detail [earlier on this blog](https://developer.epages.com/blog/2015/09/28/service-discovery.html).\n\nLater we chose [Kubernetes](http://kubernetes.io/) as our container management solution.\nIn Kubernetes we already found a DNS-based service discovery solution that could also fulfill our needs.\nSo it felt strange to have our own service discovery stack running while Kubernetes offers something similar. That led us to the adoption of Kubernetes also for service discovery.\nIt helped us to reduce our infrastructure complexity and relieved us from managing additional components.\n\n{% image blog/blog-microservice-meetup-3.jpg 45% left %}\n\nOn the service client side we introduced [Ribbon](https://github.com/Netflix/ribbon/wiki) for outbound service calls.\nThus we can work with logical service names in a managed environment like Kubernetes but can also wire services together that run locally in a dev environment.\nUsing the Spring framework, the usage of Ribbon can be reduced to a few annotations enabling us to keep our service code (almost) free of service discovery concerns.\n\nAfter Dirk finished to guide us through this journey towards our current service discovery solution we took a break to recover with beer and pizza.\nThere were excited discussions about the topic showing that service discovery is a topic that is of great interest in the community at the moment.\n\nAfter the pizza break Oli continued with a demo including live coding of two services demonstrating our service discovery solution in action.\nOli not only showed how easy calling a service is on the development side, but also how scaling and health-checking can work in Kubernetes.\nYou can find the [demo code on GitHub](https://github.com/otrosien/meetup-2016-02-code).\nThe slides of our talk can be found [here](http://epages-de.github.io/meetup-2016-02-slides/).\n\nWe really like the idea of Meetups and are happy that we could participate.\nSo it is not unlikely that more Meetups at ePages will follow.\nLast but not least we would like to thank [Thomas Hackbarth](http://www.meetup.com/de-DE/Microservices-Meetup-Hamburg/members/182490822/) for organising the Microservices Meetup Hamburg and for giving us the opportunity to host this event.\n","slug":"2016-02-09-microservice-meetup","published":1,"updated":"2016-09-20T14:31:48.000Z","comments":1,"photos":[],"link":"","_id":"ciu6nuh98001ohqyx705fzivk","content":"<p>Full house at ePages in Hamburg!<br>Last Wednesday, we hosted the <a href=\"http://www.meetup.com/de-DE/Microservices-Meetup-Hamburg/events/224965581/?a=socialmedia\" target=\"_blank\" rel=\"external\">Microservices Meetup Hamburg</a>.<br>About 30 developers accepted the invitation and came to listen to the story about our journey through the world of Service Discovery.</p>\n<p>We had two presentation slots that filled the evening.<br>And next to soft drinks, beer and pizza, there was also enough time to talk shop.</p>\n<p>With microservices, we are pushing complexity from the application into the infrastructure.<br>Service discovery is one of the complexities that you find yourself confronted with in the world of microservices.</p>\n<img class=\"blog/blog-microservice-meetup-2.jpg 45% right\">\n<p>When many services need to find their peers you want a service discovery solution that:</p>\n<ul>\n<li>can add and remove services as they come and go</li>\n<li>check the health of known services</li>\n<li>remove unhealthy services</li>\n<li>provide load balancing capabilities to be able to spread the load among the service instances.<br>Of course all that should be feasible as transparent to the client service as possible.</li>\n</ul>\n<p>We evaluated different service discovery solutions with different strategies.<br>In his presentation Dirk went through these solutions, explained their characteristics, and reasoned about the pros and cons.</p>\n<p>He started with <a href=\"https://github.com/Netflix/eureka/wiki/Eureka-at-a-glance\" target=\"_blank\" rel=\"external\">Eureka</a> from the Netflix OSS stack. We used it in one of our early prototypes. Eureka works with a central registry that is replicated on each service and uses client-side load balancing for service calls.<br>Eureka itself made a good impression but we discarded it along the way - also because back then it required code changes on the client side and we wanted something less intrusive.</p>\n<p>We tried to keep service discovery out of our code as much as possible and we added Docker to our infrastructure tool set.<br>So the service discovery solution should seamlessly integrate into this environment as well.<br>This lead us to a <a href=\"https://www.consul.io/\" target=\"_blank\" rel=\"external\">Consul</a>-based service discovery approach that we already talked about in detail <a href=\"https://developer.epages.com/blog/2015/09/28/service-discovery.html\" target=\"_blank\" rel=\"external\">earlier on this blog</a>.</p>\n<p>Later we chose <a href=\"http://kubernetes.io/\" target=\"_blank\" rel=\"external\">Kubernetes</a> as our container management solution.<br>In Kubernetes we already found a DNS-based service discovery solution that could also fulfill our needs.<br>So it felt strange to have our own service discovery stack running while Kubernetes offers something similar. That led us to the adoption of Kubernetes also for service discovery.<br>It helped us to reduce our infrastructure complexity and relieved us from managing additional components.</p>\n<img class=\"blog/blog-microservice-meetup-3.jpg 45% left\">\n<p>On the service client side we introduced <a href=\"https://github.com/Netflix/ribbon/wiki\" target=\"_blank\" rel=\"external\">Ribbon</a> for outbound service calls.<br>Thus we can work with logical service names in a managed environment like Kubernetes but can also wire services together that run locally in a dev environment.<br>Using the Spring framework, the usage of Ribbon can be reduced to a few annotations enabling us to keep our service code (almost) free of service discovery concerns.</p>\n<p>After Dirk finished to guide us through this journey towards our current service discovery solution we took a break to recover with beer and pizza.<br>There were excited discussions about the topic showing that service discovery is a topic that is of great interest in the community at the moment.</p>\n<p>After the pizza break Oli continued with a demo including live coding of two services demonstrating our service discovery solution in action.<br>Oli not only showed how easy calling a service is on the development side, but also how scaling and health-checking can work in Kubernetes.<br>You can find the <a href=\"https://github.com/otrosien/meetup-2016-02-code\" target=\"_blank\" rel=\"external\">demo code on GitHub</a>.<br>The slides of our talk can be found <a href=\"http://epages-de.github.io/meetup-2016-02-slides/\" target=\"_blank\" rel=\"external\">here</a>.</p>\n<p>We really like the idea of Meetups and are happy that we could participate.<br>So it is not unlikely that more Meetups at ePages will follow.<br>Last but not least we would like to thank <a href=\"http://www.meetup.com/de-DE/Microservices-Meetup-Hamburg/members/182490822/\" target=\"_blank\" rel=\"external\">Thomas Hackbarth</a> for organising the Microservices Meetup Hamburg and for giving us the opportunity to host this event.</p>\n","excerpt":"","more":"<p>Full house at ePages in Hamburg!<br>Last Wednesday, we hosted the <a href=\"http://www.meetup.com/de-DE/Microservices-Meetup-Hamburg/events/224965581/?a=socialmedia\">Microservices Meetup Hamburg</a>.<br>About 30 developers accepted the invitation and came to listen to the story about our journey through the world of Service Discovery.</p>\n<p>We had two presentation slots that filled the evening.<br>And next to soft drinks, beer and pizza, there was also enough time to talk shop.</p>\n<p>With microservices, we are pushing complexity from the application into the infrastructure.<br>Service discovery is one of the complexities that you find yourself confronted with in the world of microservices.</p>\n<img class=\"blog/blog-microservice-meetup-2.jpg 45% right\">\n<p>When many services need to find their peers you want a service discovery solution that:</p>\n<ul>\n<li>can add and remove services as they come and go</li>\n<li>check the health of known services</li>\n<li>remove unhealthy services</li>\n<li>provide load balancing capabilities to be able to spread the load among the service instances.<br>Of course all that should be feasible as transparent to the client service as possible.</li>\n</ul>\n<p>We evaluated different service discovery solutions with different strategies.<br>In his presentation Dirk went through these solutions, explained their characteristics, and reasoned about the pros and cons.</p>\n<p>He started with <a href=\"https://github.com/Netflix/eureka/wiki/Eureka-at-a-glance\">Eureka</a> from the Netflix OSS stack. We used it in one of our early prototypes. Eureka works with a central registry that is replicated on each service and uses client-side load balancing for service calls.<br>Eureka itself made a good impression but we discarded it along the way - also because back then it required code changes on the client side and we wanted something less intrusive.</p>\n<p>We tried to keep service discovery out of our code as much as possible and we added Docker to our infrastructure tool set.<br>So the service discovery solution should seamlessly integrate into this environment as well.<br>This lead us to a <a href=\"https://www.consul.io/\">Consul</a>-based service discovery approach that we already talked about in detail <a href=\"https://developer.epages.com/blog/2015/09/28/service-discovery.html\">earlier on this blog</a>.</p>\n<p>Later we chose <a href=\"http://kubernetes.io/\">Kubernetes</a> as our container management solution.<br>In Kubernetes we already found a DNS-based service discovery solution that could also fulfill our needs.<br>So it felt strange to have our own service discovery stack running while Kubernetes offers something similar. That led us to the adoption of Kubernetes also for service discovery.<br>It helped us to reduce our infrastructure complexity and relieved us from managing additional components.</p>\n<img class=\"blog/blog-microservice-meetup-3.jpg 45% left\">\n<p>On the service client side we introduced <a href=\"https://github.com/Netflix/ribbon/wiki\">Ribbon</a> for outbound service calls.<br>Thus we can work with logical service names in a managed environment like Kubernetes but can also wire services together that run locally in a dev environment.<br>Using the Spring framework, the usage of Ribbon can be reduced to a few annotations enabling us to keep our service code (almost) free of service discovery concerns.</p>\n<p>After Dirk finished to guide us through this journey towards our current service discovery solution we took a break to recover with beer and pizza.<br>There were excited discussions about the topic showing that service discovery is a topic that is of great interest in the community at the moment.</p>\n<p>After the pizza break Oli continued with a demo including live coding of two services demonstrating our service discovery solution in action.<br>Oli not only showed how easy calling a service is on the development side, but also how scaling and health-checking can work in Kubernetes.<br>You can find the <a href=\"https://github.com/otrosien/meetup-2016-02-code\">demo code on GitHub</a>.<br>The slides of our talk can be found <a href=\"http://epages-de.github.io/meetup-2016-02-slides/\">here</a>.</p>\n<p>We really like the idea of Meetups and are happy that we could participate.<br>So it is not unlikely that more Meetups at ePages will follow.<br>Last but not least we would like to thank <a href=\"http://www.meetup.com/de-DE/Microservices-Meetup-Hamburg/members/182490822/\">Thomas Hackbarth</a> for organising the Microservices Meetup Hamburg and for giving us the opportunity to host this event.</p>\n"},{"layout":"post","title":"Optimised monitoring and evaluation of Selenium test results","date":"2016-02-11T09:11:12.000Z","image":"blog-header/test-automation-1.jpg","authors":["Benjamin N.","Bastian K."],"_content":"\nToday we want to share with you the first of two blog posts on a recent project concerning an optimised workflow for the monitoring and evaluation of the Selenium integration test results from multiple environments in our pipeline. This initial article should serve as brief introduction to the business context, encompass the major pain points of the established test evaluation process and constitute the essential requirements for a technical solution. Furthermore, we will envision two solution approaches and discuss which option fits best our needs and therefore will be implemented.\n\nThe second post will seamlessly follow up and elaborate in-depth on the technical aspects of the implementation, but now let us start digging towards the core of the business challenge.\n\n{% img blog/blog-pipeline-elk-test-evaluation-report.png 30% right %} The report index of a set \n\n## Background story\n\nCurrently our [ePages Selenium Framework](https://developer.epages.com/blog/2015/07/23/the-epages-selenium-framework.html) (**ESF**) has evolved to a reputable instrument for quality assurance of the next iteration of the ePages platform. The development teams are highly deliberated in implementing corresponding automated UI tests for each feature to safeguard the functionality of every Cartridge (platform module).\n\nIn our Continuous Delivery Pipeline (**CDP**) we run all of these tests in various test sets (see image) on every possible type of ePages environment, which is either freshly installed or patched to the latest release candidate. The monitoring and evaluation of all test results from each pipeline run is a fundamentally important duty before releasing the next version of ePages.\n\n### Motivation\n\nIn the past, an engineer of the release and test automation team needed to check a dozen of Jenkins Jobs – which represent the various use cases of ePages in production – to analyse the test results and create a list of failing tests in our wiki on a daily basis.\n\nThis tedious and time consuming collection task was soon identified as a major pain point. Hence, we decided to fully automate the process and figure out an effective, reliable and centralised storage solution for all test reports.\n\n### Requirements\n\nAfter careful consideration we determined that two non-functional requirements should be in the focus of the intended solution:\n\n* **Simplicity:** The solution needs to be easy to implement, test, configure and maintain.\n* **Expandability:** Later on, the solution needs to be able to additionally handle other kinds of logs from our pipeline machines as well as scale with the amount and frequency of data input.\n\n### Two options\n\nAt first glance we had two different ideas for our architectural solution approach:\n\n* **Option A:** Custom Python scripts at the end of a Selenium Jenkins job transfer the test results from a test machine into a dedicated MySQL database. Another script or a custom frontend should then retrieve all test results from the database at the end of a pipeline run and display them in an usable fashion.\n* **Option B:** Use the popular ELK-stack (Elasticsearch, Logstash, Kibana) as a basis and adapt it to fit our needs. Each part should run in it's own Docker container and Docker images are build and tested in a CI environment. Our pipeline pulls the containers on-time and runs them with a dedicated configuration for each Jenkins job. For scaleability we create a distributed storage cluster including mirroring for node data.\n\nAfter a team-internal discussion we concluded that we want to implement **Option B** as it relied on an established ecosystem which is popular for large-scale and high-performance system log monitoring. Like other key-value stores Elasticsearch supports a very flexible document structure, which does not need any database schema, and on top all documents can also be retrieved via simple REST calls, which leaves room for developing a custom-tailored client especially for our use case scenario.\nAnother important reason was that this approach would give us the opportunity to rather store other business-critical information (e.g. event logs) from a pipeline run in the near future as well. Last but not least, the ePages operations team is already using the ELK-stack at customer projects and hence there is a reliable knowledge source inside the company in case we would need it.\n\nIn summary, the mentioned ease of extension of Elasticsearch in combination with a generally low effort for maintenance convinced us to strongly opt against building every solution part on our own as suggested in **Option A**.\n\n### Read on\n\nIf you are interested in learning more about this project you may accompany us on the second post which will be published the next week. This comprehensive follow-up will outline the solution architecture, split it up into individual solution parts and then focus on the technical details including the setup of Elasticsearch, Logstash, Jenkins Jobs, Docker and CircleCI.\n\nLook forward to find out if we have choosen our options wisely!\n\n## Related post\n\n[Continuous Delivery: Implementation of automated Selenium test analysis with Elasticsearch and Docker](https://developer.epages.com/blog/2016/02/16/pipeline-elk-test-evaluation-2.html)\n","source":"_posts/2016-02-11-pipeline-elk-test-evaluation-1.md","raw":"---\nlayout: post\ntitle: \"Optimised monitoring and evaluation of Selenium test results\"\ndate: \"2016-02-11 10:11:12\"\nimage: blog-header/test-automation-1.jpg\ncategories: tech-stories\nauthors: [\"Benjamin N.\", \"Bastian K.\"]\n---\n\nToday we want to share with you the first of two blog posts on a recent project concerning an optimised workflow for the monitoring and evaluation of the Selenium integration test results from multiple environments in our pipeline. This initial article should serve as brief introduction to the business context, encompass the major pain points of the established test evaluation process and constitute the essential requirements for a technical solution. Furthermore, we will envision two solution approaches and discuss which option fits best our needs and therefore will be implemented.\n\nThe second post will seamlessly follow up and elaborate in-depth on the technical aspects of the implementation, but now let us start digging towards the core of the business challenge.\n\n{% img blog/blog-pipeline-elk-test-evaluation-report.png 30% right %} The report index of a set \n\n## Background story\n\nCurrently our [ePages Selenium Framework](https://developer.epages.com/blog/2015/07/23/the-epages-selenium-framework.html) (**ESF**) has evolved to a reputable instrument for quality assurance of the next iteration of the ePages platform. The development teams are highly deliberated in implementing corresponding automated UI tests for each feature to safeguard the functionality of every Cartridge (platform module).\n\nIn our Continuous Delivery Pipeline (**CDP**) we run all of these tests in various test sets (see image) on every possible type of ePages environment, which is either freshly installed or patched to the latest release candidate. The monitoring and evaluation of all test results from each pipeline run is a fundamentally important duty before releasing the next version of ePages.\n\n### Motivation\n\nIn the past, an engineer of the release and test automation team needed to check a dozen of Jenkins Jobs – which represent the various use cases of ePages in production – to analyse the test results and create a list of failing tests in our wiki on a daily basis.\n\nThis tedious and time consuming collection task was soon identified as a major pain point. Hence, we decided to fully automate the process and figure out an effective, reliable and centralised storage solution for all test reports.\n\n### Requirements\n\nAfter careful consideration we determined that two non-functional requirements should be in the focus of the intended solution:\n\n* **Simplicity:** The solution needs to be easy to implement, test, configure and maintain.\n* **Expandability:** Later on, the solution needs to be able to additionally handle other kinds of logs from our pipeline machines as well as scale with the amount and frequency of data input.\n\n### Two options\n\nAt first glance we had two different ideas for our architectural solution approach:\n\n* **Option A:** Custom Python scripts at the end of a Selenium Jenkins job transfer the test results from a test machine into a dedicated MySQL database. Another script or a custom frontend should then retrieve all test results from the database at the end of a pipeline run and display them in an usable fashion.\n* **Option B:** Use the popular ELK-stack (Elasticsearch, Logstash, Kibana) as a basis and adapt it to fit our needs. Each part should run in it's own Docker container and Docker images are build and tested in a CI environment. Our pipeline pulls the containers on-time and runs them with a dedicated configuration for each Jenkins job. For scaleability we create a distributed storage cluster including mirroring for node data.\n\nAfter a team-internal discussion we concluded that we want to implement **Option B** as it relied on an established ecosystem which is popular for large-scale and high-performance system log monitoring. Like other key-value stores Elasticsearch supports a very flexible document structure, which does not need any database schema, and on top all documents can also be retrieved via simple REST calls, which leaves room for developing a custom-tailored client especially for our use case scenario.\nAnother important reason was that this approach would give us the opportunity to rather store other business-critical information (e.g. event logs) from a pipeline run in the near future as well. Last but not least, the ePages operations team is already using the ELK-stack at customer projects and hence there is a reliable knowledge source inside the company in case we would need it.\n\nIn summary, the mentioned ease of extension of Elasticsearch in combination with a generally low effort for maintenance convinced us to strongly opt against building every solution part on our own as suggested in **Option A**.\n\n### Read on\n\nIf you are interested in learning more about this project you may accompany us on the second post which will be published the next week. This comprehensive follow-up will outline the solution architecture, split it up into individual solution parts and then focus on the technical details including the setup of Elasticsearch, Logstash, Jenkins Jobs, Docker and CircleCI.\n\nLook forward to find out if we have choosen our options wisely!\n\n## Related post\n\n[Continuous Delivery: Implementation of automated Selenium test analysis with Elasticsearch and Docker](https://developer.epages.com/blog/2016/02/16/pipeline-elk-test-evaluation-2.html)\n","slug":"2016-02-11-pipeline-elk-test-evaluation-1","published":1,"updated":"2016-09-20T14:42:20.000Z","comments":1,"photos":[],"link":"","_id":"ciu6nuh99001qhqyxt5j0ws1j","content":"<p>Today we want to share with you the first of two blog posts on a recent project concerning an optimised workflow for the monitoring and evaluation of the Selenium integration test results from multiple environments in our pipeline. This initial article should serve as brief introduction to the business context, encompass the major pain points of the established test evaluation process and constitute the essential requirements for a technical solution. Furthermore, we will envision two solution approaches and discuss which option fits best our needs and therefore will be implemented.</p>\n<p>The second post will seamlessly follow up and elaborate in-depth on the technical aspects of the implementation, but now let us start digging towards the core of the business challenge.</p>\n<p><img class=\"blog/blog-pipeline-elk-test-evaluation-report.png 30% right\"> The report index of a set </p>\n<h2 id=\"Background-story\"><a href=\"#Background-story\" class=\"headerlink\" title=\"Background story\"></a>Background story</h2><p>Currently our <a href=\"https://developer.epages.com/blog/2015/07/23/the-epages-selenium-framework.html\" target=\"_blank\" rel=\"external\">ePages Selenium Framework</a> (<strong>ESF</strong>) has evolved to a reputable instrument for quality assurance of the next iteration of the ePages platform. The development teams are highly deliberated in implementing corresponding automated UI tests for each feature to safeguard the functionality of every Cartridge (platform module).</p>\n<p>In our Continuous Delivery Pipeline (<strong>CDP</strong>) we run all of these tests in various test sets (see image) on every possible type of ePages environment, which is either freshly installed or patched to the latest release candidate. The monitoring and evaluation of all test results from each pipeline run is a fundamentally important duty before releasing the next version of ePages.</p>\n<h3 id=\"Motivation\"><a href=\"#Motivation\" class=\"headerlink\" title=\"Motivation\"></a>Motivation</h3><p>In the past, an engineer of the release and test automation team needed to check a dozen of Jenkins Jobs – which represent the various use cases of ePages in production – to analyse the test results and create a list of failing tests in our wiki on a daily basis.</p>\n<p>This tedious and time consuming collection task was soon identified as a major pain point. Hence, we decided to fully automate the process and figure out an effective, reliable and centralised storage solution for all test reports.</p>\n<h3 id=\"Requirements\"><a href=\"#Requirements\" class=\"headerlink\" title=\"Requirements\"></a>Requirements</h3><p>After careful consideration we determined that two non-functional requirements should be in the focus of the intended solution:</p>\n<ul>\n<li><strong>Simplicity:</strong> The solution needs to be easy to implement, test, configure and maintain.</li>\n<li><strong>Expandability:</strong> Later on, the solution needs to be able to additionally handle other kinds of logs from our pipeline machines as well as scale with the amount and frequency of data input.</li>\n</ul>\n<h3 id=\"Two-options\"><a href=\"#Two-options\" class=\"headerlink\" title=\"Two options\"></a>Two options</h3><p>At first glance we had two different ideas for our architectural solution approach:</p>\n<ul>\n<li><strong>Option A:</strong> Custom Python scripts at the end of a Selenium Jenkins job transfer the test results from a test machine into a dedicated MySQL database. Another script or a custom frontend should then retrieve all test results from the database at the end of a pipeline run and display them in an usable fashion.</li>\n<li><strong>Option B:</strong> Use the popular ELK-stack (Elasticsearch, Logstash, Kibana) as a basis and adapt it to fit our needs. Each part should run in it’s own Docker container and Docker images are build and tested in a CI environment. Our pipeline pulls the containers on-time and runs them with a dedicated configuration for each Jenkins job. For scaleability we create a distributed storage cluster including mirroring for node data.</li>\n</ul>\n<p>After a team-internal discussion we concluded that we want to implement <strong>Option B</strong> as it relied on an established ecosystem which is popular for large-scale and high-performance system log monitoring. Like other key-value stores Elasticsearch supports a very flexible document structure, which does not need any database schema, and on top all documents can also be retrieved via simple REST calls, which leaves room for developing a custom-tailored client especially for our use case scenario.<br>Another important reason was that this approach would give us the opportunity to rather store other business-critical information (e.g. event logs) from a pipeline run in the near future as well. Last but not least, the ePages operations team is already using the ELK-stack at customer projects and hence there is a reliable knowledge source inside the company in case we would need it.</p>\n<p>In summary, the mentioned ease of extension of Elasticsearch in combination with a generally low effort for maintenance convinced us to strongly opt against building every solution part on our own as suggested in <strong>Option A</strong>.</p>\n<h3 id=\"Read-on\"><a href=\"#Read-on\" class=\"headerlink\" title=\"Read on\"></a>Read on</h3><p>If you are interested in learning more about this project you may accompany us on the second post which will be published the next week. This comprehensive follow-up will outline the solution architecture, split it up into individual solution parts and then focus on the technical details including the setup of Elasticsearch, Logstash, Jenkins Jobs, Docker and CircleCI.</p>\n<p>Look forward to find out if we have choosen our options wisely!</p>\n<h2 id=\"Related-post\"><a href=\"#Related-post\" class=\"headerlink\" title=\"Related post\"></a>Related post</h2><p><a href=\"https://developer.epages.com/blog/2016/02/16/pipeline-elk-test-evaluation-2.html\" target=\"_blank\" rel=\"external\">Continuous Delivery: Implementation of automated Selenium test analysis with Elasticsearch and Docker</a></p>\n","excerpt":"","more":"<p>Today we want to share with you the first of two blog posts on a recent project concerning an optimised workflow for the monitoring and evaluation of the Selenium integration test results from multiple environments in our pipeline. This initial article should serve as brief introduction to the business context, encompass the major pain points of the established test evaluation process and constitute the essential requirements for a technical solution. Furthermore, we will envision two solution approaches and discuss which option fits best our needs and therefore will be implemented.</p>\n<p>The second post will seamlessly follow up and elaborate in-depth on the technical aspects of the implementation, but now let us start digging towards the core of the business challenge.</p>\n<p><img class=\"blog/blog-pipeline-elk-test-evaluation-report.png 30% right\"> The report index of a set </p>\n<h2 id=\"Background-story\"><a href=\"#Background-story\" class=\"headerlink\" title=\"Background story\"></a>Background story</h2><p>Currently our <a href=\"https://developer.epages.com/blog/2015/07/23/the-epages-selenium-framework.html\">ePages Selenium Framework</a> (<strong>ESF</strong>) has evolved to a reputable instrument for quality assurance of the next iteration of the ePages platform. The development teams are highly deliberated in implementing corresponding automated UI tests for each feature to safeguard the functionality of every Cartridge (platform module).</p>\n<p>In our Continuous Delivery Pipeline (<strong>CDP</strong>) we run all of these tests in various test sets (see image) on every possible type of ePages environment, which is either freshly installed or patched to the latest release candidate. The monitoring and evaluation of all test results from each pipeline run is a fundamentally important duty before releasing the next version of ePages.</p>\n<h3 id=\"Motivation\"><a href=\"#Motivation\" class=\"headerlink\" title=\"Motivation\"></a>Motivation</h3><p>In the past, an engineer of the release and test automation team needed to check a dozen of Jenkins Jobs – which represent the various use cases of ePages in production – to analyse the test results and create a list of failing tests in our wiki on a daily basis.</p>\n<p>This tedious and time consuming collection task was soon identified as a major pain point. Hence, we decided to fully automate the process and figure out an effective, reliable and centralised storage solution for all test reports.</p>\n<h3 id=\"Requirements\"><a href=\"#Requirements\" class=\"headerlink\" title=\"Requirements\"></a>Requirements</h3><p>After careful consideration we determined that two non-functional requirements should be in the focus of the intended solution:</p>\n<ul>\n<li><strong>Simplicity:</strong> The solution needs to be easy to implement, test, configure and maintain.</li>\n<li><strong>Expandability:</strong> Later on, the solution needs to be able to additionally handle other kinds of logs from our pipeline machines as well as scale with the amount and frequency of data input.</li>\n</ul>\n<h3 id=\"Two-options\"><a href=\"#Two-options\" class=\"headerlink\" title=\"Two options\"></a>Two options</h3><p>At first glance we had two different ideas for our architectural solution approach:</p>\n<ul>\n<li><strong>Option A:</strong> Custom Python scripts at the end of a Selenium Jenkins job transfer the test results from a test machine into a dedicated MySQL database. Another script or a custom frontend should then retrieve all test results from the database at the end of a pipeline run and display them in an usable fashion.</li>\n<li><strong>Option B:</strong> Use the popular ELK-stack (Elasticsearch, Logstash, Kibana) as a basis and adapt it to fit our needs. Each part should run in it’s own Docker container and Docker images are build and tested in a CI environment. Our pipeline pulls the containers on-time and runs them with a dedicated configuration for each Jenkins job. For scaleability we create a distributed storage cluster including mirroring for node data.</li>\n</ul>\n<p>After a team-internal discussion we concluded that we want to implement <strong>Option B</strong> as it relied on an established ecosystem which is popular for large-scale and high-performance system log monitoring. Like other key-value stores Elasticsearch supports a very flexible document structure, which does not need any database schema, and on top all documents can also be retrieved via simple REST calls, which leaves room for developing a custom-tailored client especially for our use case scenario.<br>Another important reason was that this approach would give us the opportunity to rather store other business-critical information (e.g. event logs) from a pipeline run in the near future as well. Last but not least, the ePages operations team is already using the ELK-stack at customer projects and hence there is a reliable knowledge source inside the company in case we would need it.</p>\n<p>In summary, the mentioned ease of extension of Elasticsearch in combination with a generally low effort for maintenance convinced us to strongly opt against building every solution part on our own as suggested in <strong>Option A</strong>.</p>\n<h3 id=\"Read-on\"><a href=\"#Read-on\" class=\"headerlink\" title=\"Read on\"></a>Read on</h3><p>If you are interested in learning more about this project you may accompany us on the second post which will be published the next week. This comprehensive follow-up will outline the solution architecture, split it up into individual solution parts and then focus on the technical details including the setup of Elasticsearch, Logstash, Jenkins Jobs, Docker and CircleCI.</p>\n<p>Look forward to find out if we have choosen our options wisely!</p>\n<h2 id=\"Related-post\"><a href=\"#Related-post\" class=\"headerlink\" title=\"Related post\"></a>Related post</h2><p><a href=\"https://developer.epages.com/blog/2016/02/16/pipeline-elk-test-evaluation-2.html\">Continuous Delivery: Implementation of automated Selenium test analysis with Elasticsearch and Docker</a></p>\n"},{"layout":"post","title":"Scrum Basics: Scrum Meetings","date":"2015-12-15T06:23:00.000Z","image":"blog-header/meeting.jpg","authors":["Anja B."],"_content":"\nWelcome back to part three of our Scrum Basics Series which deals with Scrum Meetings.\nMost of these meetings you might have already noticed on the Scrum Framework Picture of my post [What is Scrum](https://developer.epages.com/blog/2015/10/13/scrum-basics-1.html).\n\nSo let's jump right into Scrum Meetings:\n\n## Sprint Planning I\n\n{% image blog/blog-scrum3-planning.jpg 35% left %}\n\nThis meeting takes place right at the beginning of a Sprint.\nParticipants are the Development Team, the Product Owner (PO), the Scrum Master (SM) as well as sometimes relevant stakeholders of the product that is currently developed.\n\nThe goal of this meeting is to create the Sprint Backlog from the Product Backlog.\n\nThe workflow is as follows:\n\n1. The PO presents the Product Backlog to the team.\n2. The team can ask questions to understand the tickets in the Backlog.\n3. If required, the team adds estimations to tickets that are not yet estimated.\n4. The team decides how many tickets they are able to develop within in the next Sprint.\n5. The team commits to solve all tickets on the Sprint Backlog within the next Sprint.\n\nDesired outcome:\n\n* Common understanding of the stories.\n* Commitment to the stories on the Sprint Backlog as well as the Sprint Goal.\n\n## Sprint Planning II\n\nThis meeting takes place right after Sprint Planning I (the coffee break between both is a MUST :-)).\nParticipants are the Development Team and the SM.\nThe PO is not required, but should be available if questions come up.\n\nThe workflow is as follows:\n\n1. Talk about the tickets (one after another).\n2. Write down all tasks to be done.\n3. Talk about technical constraints.\n\nDesired outcome:\n\n* Each ticket broken down into manageable tasks with less than a day effort.\n* Each team member has understood what is required from them to achieve the Sprint Goal.\n\n## Daily Standup\n\n{% image blog/blog-scrum3-dailytoken.jpg 35% left %}\n\nThe Daily Standup (also called Daily Scrum) takes place every day at the same time, usually in the morning or before lunch.\nIt has a maximum timeframe of 15 minutes.\nParticipants are the Development Team, the PO and the SM.\nThe 15 minutes should be used by the team to synchronise themselves, plan their to do's until the next day and find out blockers.\nIt’s NOT a reporting session for the PO or the SM.\n\nThe workflow is pretty easy: each team member answers the following questions:\n\n1. What did I do since the last Daily?\n2. What will I do until the next Daily?\n3. What is blocking me?\n\nTo keep the focus on these three questions and make sure the Daily takes only 15 minutes, some teams pass around tokens (see picture above).\n\nDesired outcome:\n\n* Everyone is up to date.\n* Each team member knows what the others are doing and whom they might need to support.\n* Scrum Board is up to date.\n\n## Sprint Review\n\nAt the end of each Sprint the Review will take place.\nParticipants are not only the Development Team, SM and PO, but also stakeholders as well as other interested guests.\nIn the Review the Development Team shows what they have developed during the last Sprint.\nThe goal is to inform everyone of what has been achieved and receive feedback for the developed parts of the product.\n\nThe workflow is as follows:\n\n1. The Team presents the finished Tickets – and really only finished things are shown, no only half developed or not yet tested tickets!\n2. The Team gets feedback that is important for the further development.\n\nDesired outcome:\n\n* Common understanding of what has been achieved.\n* Everyone was able to give feedback to the team.\n\n## Retrospective\n\n{% image blog/blog-scrum3-retrospective.jpg 40% left %}\n\nThe Retrospective is the last meeting of the Sprint.\nIt takes place after the Review and before the Planning of the next Sprint.\nParticipants are the Development Team, the SM and normally, but not always, the PO.\nThe goal of this meeting is to improve the team performance.\n\nIt can have different workflows, but the one taught by the Scrum gurus Diana Larsen and Esther Derby is the one mostly used and I found it quite effective myself:\n\n1. Set the stage: get the developers head away from the problem they were just trying to solve and into the Retrospective.\nMostly also used to find out about the mood in the team.\n2. Gather data: what went well/wrong in the Sprint?\n3. Generate insight: find out what blocks the team most and then dig deeper until you find the real source of the problem.\n4. Decide what to do: setup the action plan.\nHow will the team solve the problem within the next Sprint?\n5. Close the Retrospective: reflect on the Retrospective itself.\nThis is feedback for the SM to improve this meeting.\n\nDesired outcome:\n\n* List of actions for improvement.\n\nThe PO is normally involved in this meeting, since they are part of the Scrum Team.\nHowever, sometimes they are still seen as a leading position and therefore could be “the elephant in the room”.\nThen it is good to do a Retrospective without them from time to time to make it easier for team members to talk openly.\nIn general there should be no other guests in this meeting as some topics are only meant for the team to hear.\n\n## Backlog Refinement\n\nThe Backlog Refinement takes place during the Sprint, some days before the next Sprint Planning.\nParticipants are the Development Team, SM, PO and sometimes Stakeholders.\nThe goal of this meeting is to present new tickets to the team and estimate them.\n\nThe workflow is as follows:\n\n1. The PO presents new tickets to the team.\n2. The team can ask the PO or, if present, also to the stakeholders about the tickets.\n3. The tickets are estimated by the team.\n(More information about estimation techniques will follow in part four of this series.)\n\nDesired outcome:\n\n* Common understanding of the tickets to be estimated.\n\n## Community of Practice\n\nThe Community of Practice differs from all the above mentioned meetings.\nIt’s not bound to a Sprint and includes several Scrum Teams.\nParticipants here are members of different Scrum Teams, which are working in the same field of expertise.\nIn this meeting they can discuss topics from their field of expertise and e.g. set cross-team rules.\nThis is especially important if several Scrum Teams are working on one product.\nGroups with the same expertise could be e.g. backend developers, designers or testers.\n\n## Scrum of Scrums\n\nLike the Community of Practice, the Scrum of Scrums is a meeting outside the Sprint and outside the Development Team.\nIt includes representatives from each Scrum Team and is set up to talk about topics that concern several Scrum Teams.\nIt should clarify cross-team problems and remove dependencies between the teams.\n\n## Related posts\n\n* [Scrum Basics: What is Scrum?](https://developer.epages.com/blog/2015/10/13/scrum-basics-1.html)\n* [Scrum Basics: Scrum Roles](https://developer.epages.com/blog/2015/11/19/scrum-basics-2.html)\n* [Scrum Basics: Estimating](https://developer.epages.com/blog/2016/01/26/scrum-basics-4.html)\n* [Scrum Basics: Principles and Values](https://developer.epages.com/blog/2016/02/25/scrum-basics-5.html)\n* [Scrum Basics: Practicing it](https://developer.epages.com/blog/2016/03/22/scrum-basics-6.html)\n","source":"_posts/2015-12-15-scrum-basics-3.md","raw":"---\nlayout: post\ntitle: \"Scrum Basics: Scrum Meetings\"\ndate: \"2015-12-15 07:23:00\"\nimage: blog-header/meeting.jpg\ncategories: agile\nauthors: [\"Anja B.\"]\n---\n\nWelcome back to part three of our Scrum Basics Series which deals with Scrum Meetings.\nMost of these meetings you might have already noticed on the Scrum Framework Picture of my post [What is Scrum](https://developer.epages.com/blog/2015/10/13/scrum-basics-1.html).\n\nSo let's jump right into Scrum Meetings:\n\n## Sprint Planning I\n\n{% image blog/blog-scrum3-planning.jpg 35% left %}\n\nThis meeting takes place right at the beginning of a Sprint.\nParticipants are the Development Team, the Product Owner (PO), the Scrum Master (SM) as well as sometimes relevant stakeholders of the product that is currently developed.\n\nThe goal of this meeting is to create the Sprint Backlog from the Product Backlog.\n\nThe workflow is as follows:\n\n1. The PO presents the Product Backlog to the team.\n2. The team can ask questions to understand the tickets in the Backlog.\n3. If required, the team adds estimations to tickets that are not yet estimated.\n4. The team decides how many tickets they are able to develop within in the next Sprint.\n5. The team commits to solve all tickets on the Sprint Backlog within the next Sprint.\n\nDesired outcome:\n\n* Common understanding of the stories.\n* Commitment to the stories on the Sprint Backlog as well as the Sprint Goal.\n\n## Sprint Planning II\n\nThis meeting takes place right after Sprint Planning I (the coffee break between both is a MUST :-)).\nParticipants are the Development Team and the SM.\nThe PO is not required, but should be available if questions come up.\n\nThe workflow is as follows:\n\n1. Talk about the tickets (one after another).\n2. Write down all tasks to be done.\n3. Talk about technical constraints.\n\nDesired outcome:\n\n* Each ticket broken down into manageable tasks with less than a day effort.\n* Each team member has understood what is required from them to achieve the Sprint Goal.\n\n## Daily Standup\n\n{% image blog/blog-scrum3-dailytoken.jpg 35% left %}\n\nThe Daily Standup (also called Daily Scrum) takes place every day at the same time, usually in the morning or before lunch.\nIt has a maximum timeframe of 15 minutes.\nParticipants are the Development Team, the PO and the SM.\nThe 15 minutes should be used by the team to synchronise themselves, plan their to do's until the next day and find out blockers.\nIt’s NOT a reporting session for the PO or the SM.\n\nThe workflow is pretty easy: each team member answers the following questions:\n\n1. What did I do since the last Daily?\n2. What will I do until the next Daily?\n3. What is blocking me?\n\nTo keep the focus on these three questions and make sure the Daily takes only 15 minutes, some teams pass around tokens (see picture above).\n\nDesired outcome:\n\n* Everyone is up to date.\n* Each team member knows what the others are doing and whom they might need to support.\n* Scrum Board is up to date.\n\n## Sprint Review\n\nAt the end of each Sprint the Review will take place.\nParticipants are not only the Development Team, SM and PO, but also stakeholders as well as other interested guests.\nIn the Review the Development Team shows what they have developed during the last Sprint.\nThe goal is to inform everyone of what has been achieved and receive feedback for the developed parts of the product.\n\nThe workflow is as follows:\n\n1. The Team presents the finished Tickets – and really only finished things are shown, no only half developed or not yet tested tickets!\n2. The Team gets feedback that is important for the further development.\n\nDesired outcome:\n\n* Common understanding of what has been achieved.\n* Everyone was able to give feedback to the team.\n\n## Retrospective\n\n{% image blog/blog-scrum3-retrospective.jpg 40% left %}\n\nThe Retrospective is the last meeting of the Sprint.\nIt takes place after the Review and before the Planning of the next Sprint.\nParticipants are the Development Team, the SM and normally, but not always, the PO.\nThe goal of this meeting is to improve the team performance.\n\nIt can have different workflows, but the one taught by the Scrum gurus Diana Larsen and Esther Derby is the one mostly used and I found it quite effective myself:\n\n1. Set the stage: get the developers head away from the problem they were just trying to solve and into the Retrospective.\nMostly also used to find out about the mood in the team.\n2. Gather data: what went well/wrong in the Sprint?\n3. Generate insight: find out what blocks the team most and then dig deeper until you find the real source of the problem.\n4. Decide what to do: setup the action plan.\nHow will the team solve the problem within the next Sprint?\n5. Close the Retrospective: reflect on the Retrospective itself.\nThis is feedback for the SM to improve this meeting.\n\nDesired outcome:\n\n* List of actions for improvement.\n\nThe PO is normally involved in this meeting, since they are part of the Scrum Team.\nHowever, sometimes they are still seen as a leading position and therefore could be “the elephant in the room”.\nThen it is good to do a Retrospective without them from time to time to make it easier for team members to talk openly.\nIn general there should be no other guests in this meeting as some topics are only meant for the team to hear.\n\n## Backlog Refinement\n\nThe Backlog Refinement takes place during the Sprint, some days before the next Sprint Planning.\nParticipants are the Development Team, SM, PO and sometimes Stakeholders.\nThe goal of this meeting is to present new tickets to the team and estimate them.\n\nThe workflow is as follows:\n\n1. The PO presents new tickets to the team.\n2. The team can ask the PO or, if present, also to the stakeholders about the tickets.\n3. The tickets are estimated by the team.\n(More information about estimation techniques will follow in part four of this series.)\n\nDesired outcome:\n\n* Common understanding of the tickets to be estimated.\n\n## Community of Practice\n\nThe Community of Practice differs from all the above mentioned meetings.\nIt’s not bound to a Sprint and includes several Scrum Teams.\nParticipants here are members of different Scrum Teams, which are working in the same field of expertise.\nIn this meeting they can discuss topics from their field of expertise and e.g. set cross-team rules.\nThis is especially important if several Scrum Teams are working on one product.\nGroups with the same expertise could be e.g. backend developers, designers or testers.\n\n## Scrum of Scrums\n\nLike the Community of Practice, the Scrum of Scrums is a meeting outside the Sprint and outside the Development Team.\nIt includes representatives from each Scrum Team and is set up to talk about topics that concern several Scrum Teams.\nIt should clarify cross-team problems and remove dependencies between the teams.\n\n## Related posts\n\n* [Scrum Basics: What is Scrum?](https://developer.epages.com/blog/2015/10/13/scrum-basics-1.html)\n* [Scrum Basics: Scrum Roles](https://developer.epages.com/blog/2015/11/19/scrum-basics-2.html)\n* [Scrum Basics: Estimating](https://developer.epages.com/blog/2016/01/26/scrum-basics-4.html)\n* [Scrum Basics: Principles and Values](https://developer.epages.com/blog/2016/02/25/scrum-basics-5.html)\n* [Scrum Basics: Practicing it](https://developer.epages.com/blog/2016/03/22/scrum-basics-6.html)\n","slug":"2015-12-15-scrum-basics-3","published":1,"updated":"2016-09-20T14:19:22.000Z","comments":1,"photos":[],"link":"","_id":"ciu6nuh9a001shqyxmkkg9f6g","content":"<p>Welcome back to part three of our Scrum Basics Series which deals with Scrum Meetings.<br>Most of these meetings you might have already noticed on the Scrum Framework Picture of my post <a href=\"https://developer.epages.com/blog/2015/10/13/scrum-basics-1.html\" target=\"_blank\" rel=\"external\">What is Scrum</a>.</p>\n<p>So let’s jump right into Scrum Meetings:</p>\n<h2 id=\"Sprint-Planning-I\"><a href=\"#Sprint-Planning-I\" class=\"headerlink\" title=\"Sprint Planning I\"></a>Sprint Planning I</h2><img class=\"blog/blog-scrum3-planning.jpg 35% left\">\n<p>This meeting takes place right at the beginning of a Sprint.<br>Participants are the Development Team, the Product Owner (PO), the Scrum Master (SM) as well as sometimes relevant stakeholders of the product that is currently developed.</p>\n<p>The goal of this meeting is to create the Sprint Backlog from the Product Backlog.</p>\n<p>The workflow is as follows:</p>\n<ol>\n<li>The PO presents the Product Backlog to the team.</li>\n<li>The team can ask questions to understand the tickets in the Backlog.</li>\n<li>If required, the team adds estimations to tickets that are not yet estimated.</li>\n<li>The team decides how many tickets they are able to develop within in the next Sprint.</li>\n<li>The team commits to solve all tickets on the Sprint Backlog within the next Sprint.</li>\n</ol>\n<p>Desired outcome:</p>\n<ul>\n<li>Common understanding of the stories.</li>\n<li>Commitment to the stories on the Sprint Backlog as well as the Sprint Goal.</li>\n</ul>\n<h2 id=\"Sprint-Planning-II\"><a href=\"#Sprint-Planning-II\" class=\"headerlink\" title=\"Sprint Planning II\"></a>Sprint Planning II</h2><p>This meeting takes place right after Sprint Planning I (the coffee break between both is a MUST :-)).<br>Participants are the Development Team and the SM.<br>The PO is not required, but should be available if questions come up.</p>\n<p>The workflow is as follows:</p>\n<ol>\n<li>Talk about the tickets (one after another).</li>\n<li>Write down all tasks to be done.</li>\n<li>Talk about technical constraints.</li>\n</ol>\n<p>Desired outcome:</p>\n<ul>\n<li>Each ticket broken down into manageable tasks with less than a day effort.</li>\n<li>Each team member has understood what is required from them to achieve the Sprint Goal.</li>\n</ul>\n<h2 id=\"Daily-Standup\"><a href=\"#Daily-Standup\" class=\"headerlink\" title=\"Daily Standup\"></a>Daily Standup</h2><img class=\"blog/blog-scrum3-dailytoken.jpg 35% left\">\n<p>The Daily Standup (also called Daily Scrum) takes place every day at the same time, usually in the morning or before lunch.<br>It has a maximum timeframe of 15 minutes.<br>Participants are the Development Team, the PO and the SM.<br>The 15 minutes should be used by the team to synchronise themselves, plan their to do’s until the next day and find out blockers.<br>It’s NOT a reporting session for the PO or the SM.</p>\n<p>The workflow is pretty easy: each team member answers the following questions:</p>\n<ol>\n<li>What did I do since the last Daily?</li>\n<li>What will I do until the next Daily?</li>\n<li>What is blocking me?</li>\n</ol>\n<p>To keep the focus on these three questions and make sure the Daily takes only 15 minutes, some teams pass around tokens (see picture above).</p>\n<p>Desired outcome:</p>\n<ul>\n<li>Everyone is up to date.</li>\n<li>Each team member knows what the others are doing and whom they might need to support.</li>\n<li>Scrum Board is up to date.</li>\n</ul>\n<h2 id=\"Sprint-Review\"><a href=\"#Sprint-Review\" class=\"headerlink\" title=\"Sprint Review\"></a>Sprint Review</h2><p>At the end of each Sprint the Review will take place.<br>Participants are not only the Development Team, SM and PO, but also stakeholders as well as other interested guests.<br>In the Review the Development Team shows what they have developed during the last Sprint.<br>The goal is to inform everyone of what has been achieved and receive feedback for the developed parts of the product.</p>\n<p>The workflow is as follows:</p>\n<ol>\n<li>The Team presents the finished Tickets – and really only finished things are shown, no only half developed or not yet tested tickets!</li>\n<li>The Team gets feedback that is important for the further development.</li>\n</ol>\n<p>Desired outcome:</p>\n<ul>\n<li>Common understanding of what has been achieved.</li>\n<li>Everyone was able to give feedback to the team.</li>\n</ul>\n<h2 id=\"Retrospective\"><a href=\"#Retrospective\" class=\"headerlink\" title=\"Retrospective\"></a>Retrospective</h2><img class=\"blog/blog-scrum3-retrospective.jpg 40% left\">\n<p>The Retrospective is the last meeting of the Sprint.<br>It takes place after the Review and before the Planning of the next Sprint.<br>Participants are the Development Team, the SM and normally, but not always, the PO.<br>The goal of this meeting is to improve the team performance.</p>\n<p>It can have different workflows, but the one taught by the Scrum gurus Diana Larsen and Esther Derby is the one mostly used and I found it quite effective myself:</p>\n<ol>\n<li>Set the stage: get the developers head away from the problem they were just trying to solve and into the Retrospective.<br>Mostly also used to find out about the mood in the team.</li>\n<li>Gather data: what went well/wrong in the Sprint?</li>\n<li>Generate insight: find out what blocks the team most and then dig deeper until you find the real source of the problem.</li>\n<li>Decide what to do: setup the action plan.<br>How will the team solve the problem within the next Sprint?</li>\n<li>Close the Retrospective: reflect on the Retrospective itself.<br>This is feedback for the SM to improve this meeting.</li>\n</ol>\n<p>Desired outcome:</p>\n<ul>\n<li>List of actions for improvement.</li>\n</ul>\n<p>The PO is normally involved in this meeting, since they are part of the Scrum Team.<br>However, sometimes they are still seen as a leading position and therefore could be “the elephant in the room”.<br>Then it is good to do a Retrospective without them from time to time to make it easier for team members to talk openly.<br>In general there should be no other guests in this meeting as some topics are only meant for the team to hear.</p>\n<h2 id=\"Backlog-Refinement\"><a href=\"#Backlog-Refinement\" class=\"headerlink\" title=\"Backlog Refinement\"></a>Backlog Refinement</h2><p>The Backlog Refinement takes place during the Sprint, some days before the next Sprint Planning.<br>Participants are the Development Team, SM, PO and sometimes Stakeholders.<br>The goal of this meeting is to present new tickets to the team and estimate them.</p>\n<p>The workflow is as follows:</p>\n<ol>\n<li>The PO presents new tickets to the team.</li>\n<li>The team can ask the PO or, if present, also to the stakeholders about the tickets.</li>\n<li>The tickets are estimated by the team.<br>(More information about estimation techniques will follow in part four of this series.)</li>\n</ol>\n<p>Desired outcome:</p>\n<ul>\n<li>Common understanding of the tickets to be estimated.</li>\n</ul>\n<h2 id=\"Community-of-Practice\"><a href=\"#Community-of-Practice\" class=\"headerlink\" title=\"Community of Practice\"></a>Community of Practice</h2><p>The Community of Practice differs from all the above mentioned meetings.<br>It’s not bound to a Sprint and includes several Scrum Teams.<br>Participants here are members of different Scrum Teams, which are working in the same field of expertise.<br>In this meeting they can discuss topics from their field of expertise and e.g. set cross-team rules.<br>This is especially important if several Scrum Teams are working on one product.<br>Groups with the same expertise could be e.g. backend developers, designers or testers.</p>\n<h2 id=\"Scrum-of-Scrums\"><a href=\"#Scrum-of-Scrums\" class=\"headerlink\" title=\"Scrum of Scrums\"></a>Scrum of Scrums</h2><p>Like the Community of Practice, the Scrum of Scrums is a meeting outside the Sprint and outside the Development Team.<br>It includes representatives from each Scrum Team and is set up to talk about topics that concern several Scrum Teams.<br>It should clarify cross-team problems and remove dependencies between the teams.</p>\n<h2 id=\"Related-posts\"><a href=\"#Related-posts\" class=\"headerlink\" title=\"Related posts\"></a>Related posts</h2><ul>\n<li><a href=\"https://developer.epages.com/blog/2015/10/13/scrum-basics-1.html\" target=\"_blank\" rel=\"external\">Scrum Basics: What is Scrum?</a></li>\n<li><a href=\"https://developer.epages.com/blog/2015/11/19/scrum-basics-2.html\" target=\"_blank\" rel=\"external\">Scrum Basics: Scrum Roles</a></li>\n<li><a href=\"https://developer.epages.com/blog/2016/01/26/scrum-basics-4.html\" target=\"_blank\" rel=\"external\">Scrum Basics: Estimating</a></li>\n<li><a href=\"https://developer.epages.com/blog/2016/02/25/scrum-basics-5.html\" target=\"_blank\" rel=\"external\">Scrum Basics: Principles and Values</a></li>\n<li><a href=\"https://developer.epages.com/blog/2016/03/22/scrum-basics-6.html\" target=\"_blank\" rel=\"external\">Scrum Basics: Practicing it</a></li>\n</ul>\n","excerpt":"","more":"<p>Welcome back to part three of our Scrum Basics Series which deals with Scrum Meetings.<br>Most of these meetings you might have already noticed on the Scrum Framework Picture of my post <a href=\"https://developer.epages.com/blog/2015/10/13/scrum-basics-1.html\">What is Scrum</a>.</p>\n<p>So let’s jump right into Scrum Meetings:</p>\n<h2 id=\"Sprint-Planning-I\"><a href=\"#Sprint-Planning-I\" class=\"headerlink\" title=\"Sprint Planning I\"></a>Sprint Planning I</h2><img class=\"blog/blog-scrum3-planning.jpg 35% left\">\n<p>This meeting takes place right at the beginning of a Sprint.<br>Participants are the Development Team, the Product Owner (PO), the Scrum Master (SM) as well as sometimes relevant stakeholders of the product that is currently developed.</p>\n<p>The goal of this meeting is to create the Sprint Backlog from the Product Backlog.</p>\n<p>The workflow is as follows:</p>\n<ol>\n<li>The PO presents the Product Backlog to the team.</li>\n<li>The team can ask questions to understand the tickets in the Backlog.</li>\n<li>If required, the team adds estimations to tickets that are not yet estimated.</li>\n<li>The team decides how many tickets they are able to develop within in the next Sprint.</li>\n<li>The team commits to solve all tickets on the Sprint Backlog within the next Sprint.</li>\n</ol>\n<p>Desired outcome:</p>\n<ul>\n<li>Common understanding of the stories.</li>\n<li>Commitment to the stories on the Sprint Backlog as well as the Sprint Goal.</li>\n</ul>\n<h2 id=\"Sprint-Planning-II\"><a href=\"#Sprint-Planning-II\" class=\"headerlink\" title=\"Sprint Planning II\"></a>Sprint Planning II</h2><p>This meeting takes place right after Sprint Planning I (the coffee break between both is a MUST :-)).<br>Participants are the Development Team and the SM.<br>The PO is not required, but should be available if questions come up.</p>\n<p>The workflow is as follows:</p>\n<ol>\n<li>Talk about the tickets (one after another).</li>\n<li>Write down all tasks to be done.</li>\n<li>Talk about technical constraints.</li>\n</ol>\n<p>Desired outcome:</p>\n<ul>\n<li>Each ticket broken down into manageable tasks with less than a day effort.</li>\n<li>Each team member has understood what is required from them to achieve the Sprint Goal.</li>\n</ul>\n<h2 id=\"Daily-Standup\"><a href=\"#Daily-Standup\" class=\"headerlink\" title=\"Daily Standup\"></a>Daily Standup</h2><img class=\"blog/blog-scrum3-dailytoken.jpg 35% left\">\n<p>The Daily Standup (also called Daily Scrum) takes place every day at the same time, usually in the morning or before lunch.<br>It has a maximum timeframe of 15 minutes.<br>Participants are the Development Team, the PO and the SM.<br>The 15 minutes should be used by the team to synchronise themselves, plan their to do’s until the next day and find out blockers.<br>It’s NOT a reporting session for the PO or the SM.</p>\n<p>The workflow is pretty easy: each team member answers the following questions:</p>\n<ol>\n<li>What did I do since the last Daily?</li>\n<li>What will I do until the next Daily?</li>\n<li>What is blocking me?</li>\n</ol>\n<p>To keep the focus on these three questions and make sure the Daily takes only 15 minutes, some teams pass around tokens (see picture above).</p>\n<p>Desired outcome:</p>\n<ul>\n<li>Everyone is up to date.</li>\n<li>Each team member knows what the others are doing and whom they might need to support.</li>\n<li>Scrum Board is up to date.</li>\n</ul>\n<h2 id=\"Sprint-Review\"><a href=\"#Sprint-Review\" class=\"headerlink\" title=\"Sprint Review\"></a>Sprint Review</h2><p>At the end of each Sprint the Review will take place.<br>Participants are not only the Development Team, SM and PO, but also stakeholders as well as other interested guests.<br>In the Review the Development Team shows what they have developed during the last Sprint.<br>The goal is to inform everyone of what has been achieved and receive feedback for the developed parts of the product.</p>\n<p>The workflow is as follows:</p>\n<ol>\n<li>The Team presents the finished Tickets – and really only finished things are shown, no only half developed or not yet tested tickets!</li>\n<li>The Team gets feedback that is important for the further development.</li>\n</ol>\n<p>Desired outcome:</p>\n<ul>\n<li>Common understanding of what has been achieved.</li>\n<li>Everyone was able to give feedback to the team.</li>\n</ul>\n<h2 id=\"Retrospective\"><a href=\"#Retrospective\" class=\"headerlink\" title=\"Retrospective\"></a>Retrospective</h2><img class=\"blog/blog-scrum3-retrospective.jpg 40% left\">\n<p>The Retrospective is the last meeting of the Sprint.<br>It takes place after the Review and before the Planning of the next Sprint.<br>Participants are the Development Team, the SM and normally, but not always, the PO.<br>The goal of this meeting is to improve the team performance.</p>\n<p>It can have different workflows, but the one taught by the Scrum gurus Diana Larsen and Esther Derby is the one mostly used and I found it quite effective myself:</p>\n<ol>\n<li>Set the stage: get the developers head away from the problem they were just trying to solve and into the Retrospective.<br>Mostly also used to find out about the mood in the team.</li>\n<li>Gather data: what went well/wrong in the Sprint?</li>\n<li>Generate insight: find out what blocks the team most and then dig deeper until you find the real source of the problem.</li>\n<li>Decide what to do: setup the action plan.<br>How will the team solve the problem within the next Sprint?</li>\n<li>Close the Retrospective: reflect on the Retrospective itself.<br>This is feedback for the SM to improve this meeting.</li>\n</ol>\n<p>Desired outcome:</p>\n<ul>\n<li>List of actions for improvement.</li>\n</ul>\n<p>The PO is normally involved in this meeting, since they are part of the Scrum Team.<br>However, sometimes they are still seen as a leading position and therefore could be “the elephant in the room”.<br>Then it is good to do a Retrospective without them from time to time to make it easier for team members to talk openly.<br>In general there should be no other guests in this meeting as some topics are only meant for the team to hear.</p>\n<h2 id=\"Backlog-Refinement\"><a href=\"#Backlog-Refinement\" class=\"headerlink\" title=\"Backlog Refinement\"></a>Backlog Refinement</h2><p>The Backlog Refinement takes place during the Sprint, some days before the next Sprint Planning.<br>Participants are the Development Team, SM, PO and sometimes Stakeholders.<br>The goal of this meeting is to present new tickets to the team and estimate them.</p>\n<p>The workflow is as follows:</p>\n<ol>\n<li>The PO presents new tickets to the team.</li>\n<li>The team can ask the PO or, if present, also to the stakeholders about the tickets.</li>\n<li>The tickets are estimated by the team.<br>(More information about estimation techniques will follow in part four of this series.)</li>\n</ol>\n<p>Desired outcome:</p>\n<ul>\n<li>Common understanding of the tickets to be estimated.</li>\n</ul>\n<h2 id=\"Community-of-Practice\"><a href=\"#Community-of-Practice\" class=\"headerlink\" title=\"Community of Practice\"></a>Community of Practice</h2><p>The Community of Practice differs from all the above mentioned meetings.<br>It’s not bound to a Sprint and includes several Scrum Teams.<br>Participants here are members of different Scrum Teams, which are working in the same field of expertise.<br>In this meeting they can discuss topics from their field of expertise and e.g. set cross-team rules.<br>This is especially important if several Scrum Teams are working on one product.<br>Groups with the same expertise could be e.g. backend developers, designers or testers.</p>\n<h2 id=\"Scrum-of-Scrums\"><a href=\"#Scrum-of-Scrums\" class=\"headerlink\" title=\"Scrum of Scrums\"></a>Scrum of Scrums</h2><p>Like the Community of Practice, the Scrum of Scrums is a meeting outside the Sprint and outside the Development Team.<br>It includes representatives from each Scrum Team and is set up to talk about topics that concern several Scrum Teams.<br>It should clarify cross-team problems and remove dependencies between the teams.</p>\n<h2 id=\"Related-posts\"><a href=\"#Related-posts\" class=\"headerlink\" title=\"Related posts\"></a>Related posts</h2><ul>\n<li><a href=\"https://developer.epages.com/blog/2015/10/13/scrum-basics-1.html\">Scrum Basics: What is Scrum?</a></li>\n<li><a href=\"https://developer.epages.com/blog/2015/11/19/scrum-basics-2.html\">Scrum Basics: Scrum Roles</a></li>\n<li><a href=\"https://developer.epages.com/blog/2016/01/26/scrum-basics-4.html\">Scrum Basics: Estimating</a></li>\n<li><a href=\"https://developer.epages.com/blog/2016/02/25/scrum-basics-5.html\">Scrum Basics: Principles and Values</a></li>\n<li><a href=\"https://developer.epages.com/blog/2016/03/22/scrum-basics-6.html\">Scrum Basics: Practicing it</a></li>\n</ul>\n"},{"layout":"post","title":"First Agile Meetup in Jena","date":"2016-02-17T06:23:00.000Z","image":"blog-header/agile-meetup.jpg","authors":["Anja B.","Fouad-Steffen"],"_content":"\nLast Monday we had our first agile meetup at ePages.\nSince there were no such meetups available in Jena or the surrounding cities, we decided at the end of last year to take the initiative and [organise one by ourselves](http://www.meetup.com/Agile-Jena/).\nThe feedback from other Jena agilists was great and in the end we were 16 participants from six different organisations.\n\nAt the beginning we had an introduction round with a Daily Standup asking three rather unusual questions:\n\n1. Who am I?\n2. What am I doing here today?\n3. What am I doing in my free time?\n\n{% image blog/blog-agile-meetup-2.jpg 45% left %}\n\nIt was a nice ice breaker after which we collected and discussed topics like \"agile fixed price projects\" and \"planning in an agile context\".\nThe discussion about agile fixed price projects was real fun:\nWe had participants who are doing it already to people who have never worked in an agile environment but have customers requesting it.\nThe topic “planning in an agile context” soon switched back to possible contract models.\nThe theoretical Scrum model is basically clear to everyone, but not how to actually work in an agile environment with real customers and contracts.\n\nNext to soft drinks, snacks and pizza, we talked about some contract models.\nIt soon became clear that it is most important to work closely together with the customer.\nMost customers have only heard of this cool new thing called agile development, but they don’t know what that actually means for them.\nWe concluded that it’s necessary to make the customer aware of his role in agile development.\nThey need to be present throughout the whole development in reviews as well as in between to give feedback and help with backlog decisions.\n\n{% image blog/blog-agile-meetup-3.jpg 40% right %}\n\nDuring the evening, we could not cover all of the topics due to time limits.\nBut we built a backlog for our next meetups.\nThe next topic would be to align our understanding of agile development as such, to have a common base for future discussions.\n\nIn the end we all agreed that the evening was a success in terms of exchanging experiences.\nWe'd like to do the meetups regularly every three months with changing locations between the participating companies.\n","source":"_posts/2016-02-17-agile-meetup.md","raw":"---\nlayout: post\ntitle: \"First Agile Meetup in Jena\"\ndate: \"2016-02-17 07:23:00\"\nimage: blog-header/agile-meetup.jpg\ncategories: events\nauthors: [\"Anja B.\", \"Fouad-Steffen\"]\n---\n\nLast Monday we had our first agile meetup at ePages.\nSince there were no such meetups available in Jena or the surrounding cities, we decided at the end of last year to take the initiative and [organise one by ourselves](http://www.meetup.com/Agile-Jena/).\nThe feedback from other Jena agilists was great and in the end we were 16 participants from six different organisations.\n\nAt the beginning we had an introduction round with a Daily Standup asking three rather unusual questions:\n\n1. Who am I?\n2. What am I doing here today?\n3. What am I doing in my free time?\n\n{% image blog/blog-agile-meetup-2.jpg 45% left %}\n\nIt was a nice ice breaker after which we collected and discussed topics like \"agile fixed price projects\" and \"planning in an agile context\".\nThe discussion about agile fixed price projects was real fun:\nWe had participants who are doing it already to people who have never worked in an agile environment but have customers requesting it.\nThe topic “planning in an agile context” soon switched back to possible contract models.\nThe theoretical Scrum model is basically clear to everyone, but not how to actually work in an agile environment with real customers and contracts.\n\nNext to soft drinks, snacks and pizza, we talked about some contract models.\nIt soon became clear that it is most important to work closely together with the customer.\nMost customers have only heard of this cool new thing called agile development, but they don’t know what that actually means for them.\nWe concluded that it’s necessary to make the customer aware of his role in agile development.\nThey need to be present throughout the whole development in reviews as well as in between to give feedback and help with backlog decisions.\n\n{% image blog/blog-agile-meetup-3.jpg 40% right %}\n\nDuring the evening, we could not cover all of the topics due to time limits.\nBut we built a backlog for our next meetups.\nThe next topic would be to align our understanding of agile development as such, to have a common base for future discussions.\n\nIn the end we all agreed that the evening was a success in terms of exchanging experiences.\nWe'd like to do the meetups regularly every three months with changing locations between the participating companies.\n","slug":"2016-02-17-agile-meetup","published":1,"updated":"2016-09-20T14:31:48.000Z","comments":1,"photos":[],"link":"","_id":"ciu6nuh9e001uhqyxk2o9mjjl","content":"<p>Last Monday we had our first agile meetup at ePages.<br>Since there were no such meetups available in Jena or the surrounding cities, we decided at the end of last year to take the initiative and <a href=\"http://www.meetup.com/Agile-Jena/\" target=\"_blank\" rel=\"external\">organise one by ourselves</a>.<br>The feedback from other Jena agilists was great and in the end we were 16 participants from six different organisations.</p>\n<p>At the beginning we had an introduction round with a Daily Standup asking three rather unusual questions:</p>\n<ol>\n<li>Who am I?</li>\n<li>What am I doing here today?</li>\n<li>What am I doing in my free time?</li>\n</ol>\n<img class=\"blog/blog-agile-meetup-2.jpg 45% left\">\n<p>It was a nice ice breaker after which we collected and discussed topics like “agile fixed price projects” and “planning in an agile context”.<br>The discussion about agile fixed price projects was real fun:<br>We had participants who are doing it already to people who have never worked in an agile environment but have customers requesting it.<br>The topic “planning in an agile context” soon switched back to possible contract models.<br>The theoretical Scrum model is basically clear to everyone, but not how to actually work in an agile environment with real customers and contracts.</p>\n<p>Next to soft drinks, snacks and pizza, we talked about some contract models.<br>It soon became clear that it is most important to work closely together with the customer.<br>Most customers have only heard of this cool new thing called agile development, but they don’t know what that actually means for them.<br>We concluded that it’s necessary to make the customer aware of his role in agile development.<br>They need to be present throughout the whole development in reviews as well as in between to give feedback and help with backlog decisions.</p>\n<img class=\"blog/blog-agile-meetup-3.jpg 40% right\">\n<p>During the evening, we could not cover all of the topics due to time limits.<br>But we built a backlog for our next meetups.<br>The next topic would be to align our understanding of agile development as such, to have a common base for future discussions.</p>\n<p>In the end we all agreed that the evening was a success in terms of exchanging experiences.<br>We’d like to do the meetups regularly every three months with changing locations between the participating companies.</p>\n","excerpt":"","more":"<p>Last Monday we had our first agile meetup at ePages.<br>Since there were no such meetups available in Jena or the surrounding cities, we decided at the end of last year to take the initiative and <a href=\"http://www.meetup.com/Agile-Jena/\">organise one by ourselves</a>.<br>The feedback from other Jena agilists was great and in the end we were 16 participants from six different organisations.</p>\n<p>At the beginning we had an introduction round with a Daily Standup asking three rather unusual questions:</p>\n<ol>\n<li>Who am I?</li>\n<li>What am I doing here today?</li>\n<li>What am I doing in my free time?</li>\n</ol>\n<img class=\"blog/blog-agile-meetup-2.jpg 45% left\">\n<p>It was a nice ice breaker after which we collected and discussed topics like “agile fixed price projects” and “planning in an agile context”.<br>The discussion about agile fixed price projects was real fun:<br>We had participants who are doing it already to people who have never worked in an agile environment but have customers requesting it.<br>The topic “planning in an agile context” soon switched back to possible contract models.<br>The theoretical Scrum model is basically clear to everyone, but not how to actually work in an agile environment with real customers and contracts.</p>\n<p>Next to soft drinks, snacks and pizza, we talked about some contract models.<br>It soon became clear that it is most important to work closely together with the customer.<br>Most customers have only heard of this cool new thing called agile development, but they don’t know what that actually means for them.<br>We concluded that it’s necessary to make the customer aware of his role in agile development.<br>They need to be present throughout the whole development in reviews as well as in between to give feedback and help with backlog decisions.</p>\n<img class=\"blog/blog-agile-meetup-3.jpg 40% right\">\n<p>During the evening, we could not cover all of the topics due to time limits.<br>But we built a backlog for our next meetups.<br>The next topic would be to align our understanding of agile development as such, to have a common base for future discussions.</p>\n<p>In the end we all agreed that the evening was a success in terms of exchanging experiences.<br>We’d like to do the meetups regularly every three months with changing locations between the participating companies.</p>\n"},{"layout":"post","title":"Scrum Basics: Principles and Values","date":"2016-02-25T06:23:00.000Z","authors":["Anja B."],"_content":"\nThis part of our Scrum Basics Series will take a look at the Principles and Values Scrum is trying to implement in your company.\nFor a start, I'd like to show you what the [Agile Manifesto](http://www.agilemanifesto.org) says about what agile development values:\n\n>„Individuals and interactions over processes and tools.\nWorking software over comprehensive documentation.\nCustomer collaboration over contract negotiation.\nResponding to change over following a plan.“\n\n>„That is, while there is value in the items on\nthe right, we value the items on the left more.“\n\nThese lines express basically everything Scrum and agile development stand for.\nIt’s a short but powerful summary and shows that implementing Scrum in your company goes much deeper than just changing development style in your software department.\n\n## Principles\n\nIn addition to this short summary the Agile Manifesto also lists [twelve principles](http://agilemanifesto.org/iso/en/principles.html) an agile company should follow.\nHere only a small selection:\n\n*“Our highest priority is to satisfy the customer\nthrough early and continuous delivery\nof valuable software.*\n\n*Welcome changing requirements, even late in\ndevelopment. Agile processes harness change for\nthe customer's competitive advantage.*\n\n*Deliver working software frequently, from a\ncouple of weeks to a couple of months, with a\npreference to the shorter timescale.*\n\n*Business people and developers must work\ntogether daily throughout the project.*\n\n*The most efficient and effective method of\nconveying information to and within a development\nteam is face-to-face conversation.*\n\nLike the fist quotes, also these principles show the deep impact of agile development within a company.\nA lot of points like “welcome changing requirements” or “business people and developers must work together daily” are not normal or even contrarian to companies developing projects with waterfall.\nThe principles also show that Scrum teams have to be self-organised and self-improving, but are also empowered to make their own decisions.\nThis requires a lot of trust from all other departments and the management in particular.\n\n## Values\n\nIn addition to the agile principles Scrum also brings five values.\nWhat are these values?\nWhat do they mean in detail and why are they important?\n\n### Focus\n\n{% image blog/blog-focus.jpg 40% left %}\n\nFocus means that the whole team is working on only one topic and that all expertise is available to solve the topic.\nFocussing on one thing at a time leads to early delivery and high quality.\nBut also small things like focussing on the core problem or core topic in meetings to make them short and effective can change your daily work life.\n\n### Openness\n\nIt requires a lot of trust to speak up completely openly about anything that bothers you in front of your team or even your boss, but it also works the other way around.\nIf everyone says openly what they are working on and where they have problems,  this avoids misunderstandings, minimises risks and in the end it builds trust.\nThis way everyone has a shared understanding of the product, how development is going and all work in the same direction.\n\n### Courage\n\nTo talk openly not only needs trust, but also (and especially if trust is missing) courage.\nBut only if everyone has the courage to speak openly about challenges, the team can work on fixing them.\nIt also means that you should openly speak about mistakes and not try to hide them.\nEveryone can make mistakes, we are just humans in the end, but the earlier you admit you made a mistake and involve the team in solving it, the smaller the impact of that mistake will be.\n\n### Commitment\n\n{% image blog/blog-commitment.jpg 40% right %}\n\nCommitment is very important when it comes to self-organised Scrum teams.\nThey decide on their own, how much they are going to solve within the next sprint.\nBut it’s also their commitment to fight to reach the goal they set for themselves.\nIt’s also in the direction of committing to a certain level of quality in the software.\nNo matter how much pressure comes from the outside, the team needs to stay true to their commitment for quality.\n\n### Respect\n\nEspecially within a Scrum team the members need to respect each other.\nEvery member should have an equal standing during discussions.\nIt is not only the senior’s voice that matters.\nThis value also means small things like showing up to meetings on time and let everyone speak their mind.\nOnly if colleagues are respecting each other they can work together efficiently and build great products.\n\nThose five basic values everyone in the Scrum team and their surroundings should live every day.\nSince April 2014 we have a chocolate trophy at ePages for people or teams who stood out in one of these values and got suggested for that by colleagues.\nUp until this day we have handed over 63 chocolates to colleagues and teams and some are collecting to get all five values.\nLet’s see who will achieve that first!\n\n## Related posts\n\n* [Scrum Basics: What is Scrum?](https://developer.epages.com/blog/2015/10/13/scrum-basics-1.html)\n* [Scrum Basics: Scrum Roles](https://developer.epages.com/blog/2015/11/19/scrum-basics-2.html)\n* [Scrum Basics: Scrum Meetings](https://developer.epages.com/blog/2015/12/15/scrum-basics-3.html)\n* [Scrum Basics: Estimating](https://developer.epages.com/blog/2016/01/26/scrum-basics-4.html)\n* [Scrum Basics: Practicing it](https://developer.epages.com/blog/2016/03/22/scrum-basics-6.html)\n","source":"_posts/2016-02-25-scrum-basics-5.md","raw":"---\nlayout: post\ntitle: \"Scrum Basics: Principles and Values\"\ndate: \"2016-02-25 07:23:00\"\ncategories: agile\nauthors: [\"Anja B.\"]\n---\n\nThis part of our Scrum Basics Series will take a look at the Principles and Values Scrum is trying to implement in your company.\nFor a start, I'd like to show you what the [Agile Manifesto](http://www.agilemanifesto.org) says about what agile development values:\n\n>„Individuals and interactions over processes and tools.\nWorking software over comprehensive documentation.\nCustomer collaboration over contract negotiation.\nResponding to change over following a plan.“\n\n>„That is, while there is value in the items on\nthe right, we value the items on the left more.“\n\nThese lines express basically everything Scrum and agile development stand for.\nIt’s a short but powerful summary and shows that implementing Scrum in your company goes much deeper than just changing development style in your software department.\n\n## Principles\n\nIn addition to this short summary the Agile Manifesto also lists [twelve principles](http://agilemanifesto.org/iso/en/principles.html) an agile company should follow.\nHere only a small selection:\n\n*“Our highest priority is to satisfy the customer\nthrough early and continuous delivery\nof valuable software.*\n\n*Welcome changing requirements, even late in\ndevelopment. Agile processes harness change for\nthe customer's competitive advantage.*\n\n*Deliver working software frequently, from a\ncouple of weeks to a couple of months, with a\npreference to the shorter timescale.*\n\n*Business people and developers must work\ntogether daily throughout the project.*\n\n*The most efficient and effective method of\nconveying information to and within a development\nteam is face-to-face conversation.*\n\nLike the fist quotes, also these principles show the deep impact of agile development within a company.\nA lot of points like “welcome changing requirements” or “business people and developers must work together daily” are not normal or even contrarian to companies developing projects with waterfall.\nThe principles also show that Scrum teams have to be self-organised and self-improving, but are also empowered to make their own decisions.\nThis requires a lot of trust from all other departments and the management in particular.\n\n## Values\n\nIn addition to the agile principles Scrum also brings five values.\nWhat are these values?\nWhat do they mean in detail and why are they important?\n\n### Focus\n\n{% image blog/blog-focus.jpg 40% left %}\n\nFocus means that the whole team is working on only one topic and that all expertise is available to solve the topic.\nFocussing on one thing at a time leads to early delivery and high quality.\nBut also small things like focussing on the core problem or core topic in meetings to make them short and effective can change your daily work life.\n\n### Openness\n\nIt requires a lot of trust to speak up completely openly about anything that bothers you in front of your team or even your boss, but it also works the other way around.\nIf everyone says openly what they are working on and where they have problems,  this avoids misunderstandings, minimises risks and in the end it builds trust.\nThis way everyone has a shared understanding of the product, how development is going and all work in the same direction.\n\n### Courage\n\nTo talk openly not only needs trust, but also (and especially if trust is missing) courage.\nBut only if everyone has the courage to speak openly about challenges, the team can work on fixing them.\nIt also means that you should openly speak about mistakes and not try to hide them.\nEveryone can make mistakes, we are just humans in the end, but the earlier you admit you made a mistake and involve the team in solving it, the smaller the impact of that mistake will be.\n\n### Commitment\n\n{% image blog/blog-commitment.jpg 40% right %}\n\nCommitment is very important when it comes to self-organised Scrum teams.\nThey decide on their own, how much they are going to solve within the next sprint.\nBut it’s also their commitment to fight to reach the goal they set for themselves.\nIt’s also in the direction of committing to a certain level of quality in the software.\nNo matter how much pressure comes from the outside, the team needs to stay true to their commitment for quality.\n\n### Respect\n\nEspecially within a Scrum team the members need to respect each other.\nEvery member should have an equal standing during discussions.\nIt is not only the senior’s voice that matters.\nThis value also means small things like showing up to meetings on time and let everyone speak their mind.\nOnly if colleagues are respecting each other they can work together efficiently and build great products.\n\nThose five basic values everyone in the Scrum team and their surroundings should live every day.\nSince April 2014 we have a chocolate trophy at ePages for people or teams who stood out in one of these values and got suggested for that by colleagues.\nUp until this day we have handed over 63 chocolates to colleagues and teams and some are collecting to get all five values.\nLet’s see who will achieve that first!\n\n## Related posts\n\n* [Scrum Basics: What is Scrum?](https://developer.epages.com/blog/2015/10/13/scrum-basics-1.html)\n* [Scrum Basics: Scrum Roles](https://developer.epages.com/blog/2015/11/19/scrum-basics-2.html)\n* [Scrum Basics: Scrum Meetings](https://developer.epages.com/blog/2015/12/15/scrum-basics-3.html)\n* [Scrum Basics: Estimating](https://developer.epages.com/blog/2016/01/26/scrum-basics-4.html)\n* [Scrum Basics: Practicing it](https://developer.epages.com/blog/2016/03/22/scrum-basics-6.html)\n","slug":"2016-02-25-scrum-basics-5","published":1,"updated":"2016-09-20T14:31:48.000Z","comments":1,"photos":[],"link":"","_id":"ciu6nuh9f001whqyxjo7xslxu","content":"<p>This part of our Scrum Basics Series will take a look at the Principles and Values Scrum is trying to implement in your company.<br>For a start, I’d like to show you what the <a href=\"http://www.agilemanifesto.org\" target=\"_blank\" rel=\"external\">Agile Manifesto</a> says about what agile development values:</p>\n<blockquote>\n<p>„Individuals and interactions over processes and tools.<br>Working software over comprehensive documentation.<br>Customer collaboration over contract negotiation.<br>Responding to change over following a plan.“</p>\n<p>„That is, while there is value in the items on<br>the right, we value the items on the left more.“</p>\n</blockquote>\n<p>These lines express basically everything Scrum and agile development stand for.<br>It’s a short but powerful summary and shows that implementing Scrum in your company goes much deeper than just changing development style in your software department.</p>\n<h2 id=\"Principles\"><a href=\"#Principles\" class=\"headerlink\" title=\"Principles\"></a>Principles</h2><p>In addition to this short summary the Agile Manifesto also lists <a href=\"http://agilemanifesto.org/iso/en/principles.html\" target=\"_blank\" rel=\"external\">twelve principles</a> an agile company should follow.<br>Here only a small selection:</p>\n<p><em>“Our highest priority is to satisfy the customer<br>through early and continuous delivery<br>of valuable software.</em></p>\n<p><em>Welcome changing requirements, even late in<br>development. Agile processes harness change for<br>the customer’s competitive advantage.</em></p>\n<p><em>Deliver working software frequently, from a<br>couple of weeks to a couple of months, with a<br>preference to the shorter timescale.</em></p>\n<p><em>Business people and developers must work<br>together daily throughout the project.</em></p>\n<p><em>The most efficient and effective method of<br>conveying information to and within a development<br>team is face-to-face conversation.</em></p>\n<p>Like the fist quotes, also these principles show the deep impact of agile development within a company.<br>A lot of points like “welcome changing requirements” or “business people and developers must work together daily” are not normal or even contrarian to companies developing projects with waterfall.<br>The principles also show that Scrum teams have to be self-organised and self-improving, but are also empowered to make their own decisions.<br>This requires a lot of trust from all other departments and the management in particular.</p>\n<h2 id=\"Values\"><a href=\"#Values\" class=\"headerlink\" title=\"Values\"></a>Values</h2><p>In addition to the agile principles Scrum also brings five values.<br>What are these values?<br>What do they mean in detail and why are they important?</p>\n<h3 id=\"Focus\"><a href=\"#Focus\" class=\"headerlink\" title=\"Focus\"></a>Focus</h3><img class=\"blog/blog-focus.jpg 40% left\">\n<p>Focus means that the whole team is working on only one topic and that all expertise is available to solve the topic.<br>Focussing on one thing at a time leads to early delivery and high quality.<br>But also small things like focussing on the core problem or core topic in meetings to make them short and effective can change your daily work life.</p>\n<h3 id=\"Openness\"><a href=\"#Openness\" class=\"headerlink\" title=\"Openness\"></a>Openness</h3><p>It requires a lot of trust to speak up completely openly about anything that bothers you in front of your team or even your boss, but it also works the other way around.<br>If everyone says openly what they are working on and where they have problems,  this avoids misunderstandings, minimises risks and in the end it builds trust.<br>This way everyone has a shared understanding of the product, how development is going and all work in the same direction.</p>\n<h3 id=\"Courage\"><a href=\"#Courage\" class=\"headerlink\" title=\"Courage\"></a>Courage</h3><p>To talk openly not only needs trust, but also (and especially if trust is missing) courage.<br>But only if everyone has the courage to speak openly about challenges, the team can work on fixing them.<br>It also means that you should openly speak about mistakes and not try to hide them.<br>Everyone can make mistakes, we are just humans in the end, but the earlier you admit you made a mistake and involve the team in solving it, the smaller the impact of that mistake will be.</p>\n<h3 id=\"Commitment\"><a href=\"#Commitment\" class=\"headerlink\" title=\"Commitment\"></a>Commitment</h3><img class=\"blog/blog-commitment.jpg 40% right\">\n<p>Commitment is very important when it comes to self-organised Scrum teams.<br>They decide on their own, how much they are going to solve within the next sprint.<br>But it’s also their commitment to fight to reach the goal they set for themselves.<br>It’s also in the direction of committing to a certain level of quality in the software.<br>No matter how much pressure comes from the outside, the team needs to stay true to their commitment for quality.</p>\n<h3 id=\"Respect\"><a href=\"#Respect\" class=\"headerlink\" title=\"Respect\"></a>Respect</h3><p>Especially within a Scrum team the members need to respect each other.<br>Every member should have an equal standing during discussions.<br>It is not only the senior’s voice that matters.<br>This value also means small things like showing up to meetings on time and let everyone speak their mind.<br>Only if colleagues are respecting each other they can work together efficiently and build great products.</p>\n<p>Those five basic values everyone in the Scrum team and their surroundings should live every day.<br>Since April 2014 we have a chocolate trophy at ePages for people or teams who stood out in one of these values and got suggested for that by colleagues.<br>Up until this day we have handed over 63 chocolates to colleagues and teams and some are collecting to get all five values.<br>Let’s see who will achieve that first!</p>\n<h2 id=\"Related-posts\"><a href=\"#Related-posts\" class=\"headerlink\" title=\"Related posts\"></a>Related posts</h2><ul>\n<li><a href=\"https://developer.epages.com/blog/2015/10/13/scrum-basics-1.html\" target=\"_blank\" rel=\"external\">Scrum Basics: What is Scrum?</a></li>\n<li><a href=\"https://developer.epages.com/blog/2015/11/19/scrum-basics-2.html\" target=\"_blank\" rel=\"external\">Scrum Basics: Scrum Roles</a></li>\n<li><a href=\"https://developer.epages.com/blog/2015/12/15/scrum-basics-3.html\" target=\"_blank\" rel=\"external\">Scrum Basics: Scrum Meetings</a></li>\n<li><a href=\"https://developer.epages.com/blog/2016/01/26/scrum-basics-4.html\" target=\"_blank\" rel=\"external\">Scrum Basics: Estimating</a></li>\n<li><a href=\"https://developer.epages.com/blog/2016/03/22/scrum-basics-6.html\" target=\"_blank\" rel=\"external\">Scrum Basics: Practicing it</a></li>\n</ul>\n","excerpt":"","more":"<p>This part of our Scrum Basics Series will take a look at the Principles and Values Scrum is trying to implement in your company.<br>For a start, I’d like to show you what the <a href=\"http://www.agilemanifesto.org\">Agile Manifesto</a> says about what agile development values:</p>\n<blockquote>\n<p>„Individuals and interactions over processes and tools.<br>Working software over comprehensive documentation.<br>Customer collaboration over contract negotiation.<br>Responding to change over following a plan.“</p>\n<p>„That is, while there is value in the items on<br>the right, we value the items on the left more.“</p>\n</blockquote>\n<p>These lines express basically everything Scrum and agile development stand for.<br>It’s a short but powerful summary and shows that implementing Scrum in your company goes much deeper than just changing development style in your software department.</p>\n<h2 id=\"Principles\"><a href=\"#Principles\" class=\"headerlink\" title=\"Principles\"></a>Principles</h2><p>In addition to this short summary the Agile Manifesto also lists <a href=\"http://agilemanifesto.org/iso/en/principles.html\">twelve principles</a> an agile company should follow.<br>Here only a small selection:</p>\n<p><em>“Our highest priority is to satisfy the customer<br>through early and continuous delivery<br>of valuable software.</em></p>\n<p><em>Welcome changing requirements, even late in<br>development. Agile processes harness change for<br>the customer’s competitive advantage.</em></p>\n<p><em>Deliver working software frequently, from a<br>couple of weeks to a couple of months, with a<br>preference to the shorter timescale.</em></p>\n<p><em>Business people and developers must work<br>together daily throughout the project.</em></p>\n<p><em>The most efficient and effective method of<br>conveying information to and within a development<br>team is face-to-face conversation.</em></p>\n<p>Like the fist quotes, also these principles show the deep impact of agile development within a company.<br>A lot of points like “welcome changing requirements” or “business people and developers must work together daily” are not normal or even contrarian to companies developing projects with waterfall.<br>The principles also show that Scrum teams have to be self-organised and self-improving, but are also empowered to make their own decisions.<br>This requires a lot of trust from all other departments and the management in particular.</p>\n<h2 id=\"Values\"><a href=\"#Values\" class=\"headerlink\" title=\"Values\"></a>Values</h2><p>In addition to the agile principles Scrum also brings five values.<br>What are these values?<br>What do they mean in detail and why are they important?</p>\n<h3 id=\"Focus\"><a href=\"#Focus\" class=\"headerlink\" title=\"Focus\"></a>Focus</h3><img class=\"blog/blog-focus.jpg 40% left\">\n<p>Focus means that the whole team is working on only one topic and that all expertise is available to solve the topic.<br>Focussing on one thing at a time leads to early delivery and high quality.<br>But also small things like focussing on the core problem or core topic in meetings to make them short and effective can change your daily work life.</p>\n<h3 id=\"Openness\"><a href=\"#Openness\" class=\"headerlink\" title=\"Openness\"></a>Openness</h3><p>It requires a lot of trust to speak up completely openly about anything that bothers you in front of your team or even your boss, but it also works the other way around.<br>If everyone says openly what they are working on and where they have problems,  this avoids misunderstandings, minimises risks and in the end it builds trust.<br>This way everyone has a shared understanding of the product, how development is going and all work in the same direction.</p>\n<h3 id=\"Courage\"><a href=\"#Courage\" class=\"headerlink\" title=\"Courage\"></a>Courage</h3><p>To talk openly not only needs trust, but also (and especially if trust is missing) courage.<br>But only if everyone has the courage to speak openly about challenges, the team can work on fixing them.<br>It also means that you should openly speak about mistakes and not try to hide them.<br>Everyone can make mistakes, we are just humans in the end, but the earlier you admit you made a mistake and involve the team in solving it, the smaller the impact of that mistake will be.</p>\n<h3 id=\"Commitment\"><a href=\"#Commitment\" class=\"headerlink\" title=\"Commitment\"></a>Commitment</h3><img class=\"blog/blog-commitment.jpg 40% right\">\n<p>Commitment is very important when it comes to self-organised Scrum teams.<br>They decide on their own, how much they are going to solve within the next sprint.<br>But it’s also their commitment to fight to reach the goal they set for themselves.<br>It’s also in the direction of committing to a certain level of quality in the software.<br>No matter how much pressure comes from the outside, the team needs to stay true to their commitment for quality.</p>\n<h3 id=\"Respect\"><a href=\"#Respect\" class=\"headerlink\" title=\"Respect\"></a>Respect</h3><p>Especially within a Scrum team the members need to respect each other.<br>Every member should have an equal standing during discussions.<br>It is not only the senior’s voice that matters.<br>This value also means small things like showing up to meetings on time and let everyone speak their mind.<br>Only if colleagues are respecting each other they can work together efficiently and build great products.</p>\n<p>Those five basic values everyone in the Scrum team and their surroundings should live every day.<br>Since April 2014 we have a chocolate trophy at ePages for people or teams who stood out in one of these values and got suggested for that by colleagues.<br>Up until this day we have handed over 63 chocolates to colleagues and teams and some are collecting to get all five values.<br>Let’s see who will achieve that first!</p>\n<h2 id=\"Related-posts\"><a href=\"#Related-posts\" class=\"headerlink\" title=\"Related posts\"></a>Related posts</h2><ul>\n<li><a href=\"https://developer.epages.com/blog/2015/10/13/scrum-basics-1.html\">Scrum Basics: What is Scrum?</a></li>\n<li><a href=\"https://developer.epages.com/blog/2015/11/19/scrum-basics-2.html\">Scrum Basics: Scrum Roles</a></li>\n<li><a href=\"https://developer.epages.com/blog/2015/12/15/scrum-basics-3.html\">Scrum Basics: Scrum Meetings</a></li>\n<li><a href=\"https://developer.epages.com/blog/2016/01/26/scrum-basics-4.html\">Scrum Basics: Estimating</a></li>\n<li><a href=\"https://developer.epages.com/blog/2016/03/22/scrum-basics-6.html\">Scrum Basics: Practicing it</a></li>\n</ul>\n"},{"layout":"post","title":"Online Schema Updates with MySQL","date":"2016-03-08T06:16:17.000Z","image":"blog-header/database.jpg","authors":["Mario"],"_content":"\nAvoiding the planned downtime during software maintenance is a requirement of one of our major customers.\nThat means, all changes to the database, including schema changes, have to be done during running mode.\nRead and write commands should be guaranteed without restricting the performance.\nCopying tables should be avoided.\n\n## Theory and choice of solutions\n\nEvery software release requires schema changes that have to be executed with DDL commands like `ADD INDEX` or `ADD COLUMN`.\nAt the same time, the entire functional range of the system has to be available, i.e. reading and writing to the database at a high performance.\nDue to the scale of the data files, this should be realised without copying tables.\nAs potential approaches we evaluated Online-DDL, high-availability solutions as well as replication solutions.\nMySQL 5.6 Online DDL turned out to be the most suitable solution.\nThis provides the advantage that we could challenge this project with our standard tools without using additional third-party software that has its own release cycles.\n\n## Quality - range of functions and limitations\n\n[MySQL](https://www.mysql.com/) does not cover the complete DDL command set according to the requirements mentioned above.\nFor example, the command `ADD FULLTEXT INDEX` does not allow simultaneous writing.\nChanging the data type of a column is also restricted.\nThese restrictions can be partially managed via a special patch flow:\n\n{% image blog/blog-online-schema-1.jpg %}\n\nWe use an interim version for preparatory and follow-up work on the database.\n\nDuring testing, we figured out that we can leave out the options ALGORITHM (COPY or INPLACE) and LOCK (SHARED or NONE) without having any disadvantages.\nThe system is able to find the optimal variant without a measurable time delay.\nInterim conclusion: most of the DDL commands in MySQL 5.6 meet the requirements.\n\n## Quantity\n\n{% img blog/blog-online-schema-2.jpg %} Test results with small database - UPDATE or SELECT operations \n\nAs we're working with Scrum processes at ePages, we have a new software release every two weeks.\nThe database changes accordingly.\nAll performance issues first have been tested with a small database and only then have been tested again with a real database.\nThese were mainly three tables with 0.6 million, 1.4 million and 9 million  entries.\n\nTo summarise the results:\n\n* Parallel execution extends the write commands.\n* It seems as if the commands `ADD FULLTEXT INDEX` or `DROP FULLTEXT INDEX`, `ADD FOREIGN KEY` or `DROP FOREIGN KEY` and `CHANGE DATATYPE` queue the writing commands, which indicates sequential processing.\n* Parallel execution does not have a significant impact on read commands.\n* The sole exception with complex SELECT statements are the commands `ADD FOREIGN KEY` or `DROP FOREIGN KEY`.\n\nWithin a wider context we had three different test scenarios:\n\n{% img blog/blog-online-schema-3.jpg %} Test scenario - wider context \n\nThe first results show this:\n\n{% img blog/blog-online-schema-4.jpg %} Test results - execution times of DDL commands \n\nYou can see clear improvement from version 5.1 to version 5.5.\nBut only from the results there's no significant difference between MySQL 5.5 and 5.6.\nSo why definitely 5.6?\nTaking a look at the occurred errors, log entries as well as the runtimes of the user test and the patch makes things clearer:\n\n{% img blog/blog-online-schema-5.jpg %} Test results - number of errors, log entries and run times - user tests and patch \n\nIn particular, this means:\n\n* Only minimal differences in runtimes of 5.5 to 5.6, both completely and database changes individually.\n* Analysis of Selenium tests and log files: clear improvement of error behaviour from 5.5 to 5.6.\n* With regards to error behaviour, variants B and C are the best methods in 5.6.\n* With regards to run time of Selenium tests, variant C is the best alternative in 5.6.\n\n## Conclusion\n\nWith MySQL 5.6 Oracle succeeded in taking a big step forward.\nThe supported command volume as well as the performance improved significantly.\nFor some operations still some patches are required, whereas preparatory database changes are executed with an interim patch and real features are activated afterwards.\nIn order to improve the execution times the DDL commands should be combined.\nThe initially stated customer requirement to perform maintenance tasks without downtime can be met.\nAll online shops will be online at all times.\n","source":"_posts/2016-03-08-online-schema-updates.md","raw":"---\nlayout: post\ntitle: \"Online Schema Updates with MySQL\"\ndate: \"2016-03-08 07:16:17\"\nimage: blog-header/database.jpg\ncategories: tech-stories\nauthors: [\"Mario\"]\n---\n\nAvoiding the planned downtime during software maintenance is a requirement of one of our major customers.\nThat means, all changes to the database, including schema changes, have to be done during running mode.\nRead and write commands should be guaranteed without restricting the performance.\nCopying tables should be avoided.\n\n## Theory and choice of solutions\n\nEvery software release requires schema changes that have to be executed with DDL commands like `ADD INDEX` or `ADD COLUMN`.\nAt the same time, the entire functional range of the system has to be available, i.e. reading and writing to the database at a high performance.\nDue to the scale of the data files, this should be realised without copying tables.\nAs potential approaches we evaluated Online-DDL, high-availability solutions as well as replication solutions.\nMySQL 5.6 Online DDL turned out to be the most suitable solution.\nThis provides the advantage that we could challenge this project with our standard tools without using additional third-party software that has its own release cycles.\n\n## Quality - range of functions and limitations\n\n[MySQL](https://www.mysql.com/) does not cover the complete DDL command set according to the requirements mentioned above.\nFor example, the command `ADD FULLTEXT INDEX` does not allow simultaneous writing.\nChanging the data type of a column is also restricted.\nThese restrictions can be partially managed via a special patch flow:\n\n{% image blog/blog-online-schema-1.jpg %}\n\nWe use an interim version for preparatory and follow-up work on the database.\n\nDuring testing, we figured out that we can leave out the options ALGORITHM (COPY or INPLACE) and LOCK (SHARED or NONE) without having any disadvantages.\nThe system is able to find the optimal variant without a measurable time delay.\nInterim conclusion: most of the DDL commands in MySQL 5.6 meet the requirements.\n\n## Quantity\n\n{% img blog/blog-online-schema-2.jpg %} Test results with small database - UPDATE or SELECT operations \n\nAs we're working with Scrum processes at ePages, we have a new software release every two weeks.\nThe database changes accordingly.\nAll performance issues first have been tested with a small database and only then have been tested again with a real database.\nThese were mainly three tables with 0.6 million, 1.4 million and 9 million  entries.\n\nTo summarise the results:\n\n* Parallel execution extends the write commands.\n* It seems as if the commands `ADD FULLTEXT INDEX` or `DROP FULLTEXT INDEX`, `ADD FOREIGN KEY` or `DROP FOREIGN KEY` and `CHANGE DATATYPE` queue the writing commands, which indicates sequential processing.\n* Parallel execution does not have a significant impact on read commands.\n* The sole exception with complex SELECT statements are the commands `ADD FOREIGN KEY` or `DROP FOREIGN KEY`.\n\nWithin a wider context we had three different test scenarios:\n\n{% img blog/blog-online-schema-3.jpg %} Test scenario - wider context \n\nThe first results show this:\n\n{% img blog/blog-online-schema-4.jpg %} Test results - execution times of DDL commands \n\nYou can see clear improvement from version 5.1 to version 5.5.\nBut only from the results there's no significant difference between MySQL 5.5 and 5.6.\nSo why definitely 5.6?\nTaking a look at the occurred errors, log entries as well as the runtimes of the user test and the patch makes things clearer:\n\n{% img blog/blog-online-schema-5.jpg %} Test results - number of errors, log entries and run times - user tests and patch \n\nIn particular, this means:\n\n* Only minimal differences in runtimes of 5.5 to 5.6, both completely and database changes individually.\n* Analysis of Selenium tests and log files: clear improvement of error behaviour from 5.5 to 5.6.\n* With regards to error behaviour, variants B and C are the best methods in 5.6.\n* With regards to run time of Selenium tests, variant C is the best alternative in 5.6.\n\n## Conclusion\n\nWith MySQL 5.6 Oracle succeeded in taking a big step forward.\nThe supported command volume as well as the performance improved significantly.\nFor some operations still some patches are required, whereas preparatory database changes are executed with an interim patch and real features are activated afterwards.\nIn order to improve the execution times the DDL commands should be combined.\nThe initially stated customer requirement to perform maintenance tasks without downtime can be met.\nAll online shops will be online at all times.\n","slug":"2016-03-08-online-schema-updates","published":1,"updated":"2016-09-20T14:42:20.000Z","comments":1,"photos":[],"link":"","_id":"ciu6nuh9g001yhqyx1phvxjry","content":"<p>Avoiding the planned downtime during software maintenance is a requirement of one of our major customers.<br>That means, all changes to the database, including schema changes, have to be done during running mode.<br>Read and write commands should be guaranteed without restricting the performance.<br>Copying tables should be avoided.</p>\n<h2 id=\"Theory-and-choice-of-solutions\"><a href=\"#Theory-and-choice-of-solutions\" class=\"headerlink\" title=\"Theory and choice of solutions\"></a>Theory and choice of solutions</h2><p>Every software release requires schema changes that have to be executed with DDL commands like <code>ADD INDEX</code> or <code>ADD COLUMN</code>.<br>At the same time, the entire functional range of the system has to be available, i.e. reading and writing to the database at a high performance.<br>Due to the scale of the data files, this should be realised without copying tables.<br>As potential approaches we evaluated Online-DDL, high-availability solutions as well as replication solutions.<br>MySQL 5.6 Online DDL turned out to be the most suitable solution.<br>This provides the advantage that we could challenge this project with our standard tools without using additional third-party software that has its own release cycles.</p>\n<h2 id=\"Quality-range-of-functions-and-limitations\"><a href=\"#Quality-range-of-functions-and-limitations\" class=\"headerlink\" title=\"Quality - range of functions and limitations\"></a>Quality - range of functions and limitations</h2><p><a href=\"https://www.mysql.com/\" target=\"_blank\" rel=\"external\">MySQL</a> does not cover the complete DDL command set according to the requirements mentioned above.<br>For example, the command <code>ADD FULLTEXT INDEX</code> does not allow simultaneous writing.<br>Changing the data type of a column is also restricted.<br>These restrictions can be partially managed via a special patch flow:</p>\n<img class=\"blog/blog-online-schema-1.jpg\">\n<p>We use an interim version for preparatory and follow-up work on the database.</p>\n<p>During testing, we figured out that we can leave out the options ALGORITHM (COPY or INPLACE) and LOCK (SHARED or NONE) without having any disadvantages.<br>The system is able to find the optimal variant without a measurable time delay.<br>Interim conclusion: most of the DDL commands in MySQL 5.6 meet the requirements.</p>\n<h2 id=\"Quantity\"><a href=\"#Quantity\" class=\"headerlink\" title=\"Quantity\"></a>Quantity</h2><p><img class=\"blog/blog-online-schema-2.jpg\"> Test results with small database - UPDATE or SELECT operations </p>\n<p>As we’re working with Scrum processes at ePages, we have a new software release every two weeks.<br>The database changes accordingly.<br>All performance issues first have been tested with a small database and only then have been tested again with a real database.<br>These were mainly three tables with 0.6 million, 1.4 million and 9 million  entries.</p>\n<p>To summarise the results:</p>\n<ul>\n<li>Parallel execution extends the write commands.</li>\n<li>It seems as if the commands <code>ADD FULLTEXT INDEX</code> or <code>DROP FULLTEXT INDEX</code>, <code>ADD FOREIGN KEY</code> or <code>DROP FOREIGN KEY</code> and <code>CHANGE DATATYPE</code> queue the writing commands, which indicates sequential processing.</li>\n<li>Parallel execution does not have a significant impact on read commands.</li>\n<li>The sole exception with complex SELECT statements are the commands <code>ADD FOREIGN KEY</code> or <code>DROP FOREIGN KEY</code>.</li>\n</ul>\n<p>Within a wider context we had three different test scenarios:</p>\n<p><img class=\"blog/blog-online-schema-3.jpg\"> Test scenario - wider context </p>\n<p>The first results show this:</p>\n<p><img class=\"blog/blog-online-schema-4.jpg\"> Test results - execution times of DDL commands </p>\n<p>You can see clear improvement from version 5.1 to version 5.5.<br>But only from the results there’s no significant difference between MySQL 5.5 and 5.6.<br>So why definitely 5.6?<br>Taking a look at the occurred errors, log entries as well as the runtimes of the user test and the patch makes things clearer:</p>\n<p><img class=\"blog/blog-online-schema-5.jpg\"> Test results - number of errors, log entries and run times - user tests and patch </p>\n<p>In particular, this means:</p>\n<ul>\n<li>Only minimal differences in runtimes of 5.5 to 5.6, both completely and database changes individually.</li>\n<li>Analysis of Selenium tests and log files: clear improvement of error behaviour from 5.5 to 5.6.</li>\n<li>With regards to error behaviour, variants B and C are the best methods in 5.6.</li>\n<li>With regards to run time of Selenium tests, variant C is the best alternative in 5.6.</li>\n</ul>\n<h2 id=\"Conclusion\"><a href=\"#Conclusion\" class=\"headerlink\" title=\"Conclusion\"></a>Conclusion</h2><p>With MySQL 5.6 Oracle succeeded in taking a big step forward.<br>The supported command volume as well as the performance improved significantly.<br>For some operations still some patches are required, whereas preparatory database changes are executed with an interim patch and real features are activated afterwards.<br>In order to improve the execution times the DDL commands should be combined.<br>The initially stated customer requirement to perform maintenance tasks without downtime can be met.<br>All online shops will be online at all times.</p>\n","excerpt":"","more":"<p>Avoiding the planned downtime during software maintenance is a requirement of one of our major customers.<br>That means, all changes to the database, including schema changes, have to be done during running mode.<br>Read and write commands should be guaranteed without restricting the performance.<br>Copying tables should be avoided.</p>\n<h2 id=\"Theory-and-choice-of-solutions\"><a href=\"#Theory-and-choice-of-solutions\" class=\"headerlink\" title=\"Theory and choice of solutions\"></a>Theory and choice of solutions</h2><p>Every software release requires schema changes that have to be executed with DDL commands like <code>ADD INDEX</code> or <code>ADD COLUMN</code>.<br>At the same time, the entire functional range of the system has to be available, i.e. reading and writing to the database at a high performance.<br>Due to the scale of the data files, this should be realised without copying tables.<br>As potential approaches we evaluated Online-DDL, high-availability solutions as well as replication solutions.<br>MySQL 5.6 Online DDL turned out to be the most suitable solution.<br>This provides the advantage that we could challenge this project with our standard tools without using additional third-party software that has its own release cycles.</p>\n<h2 id=\"Quality-range-of-functions-and-limitations\"><a href=\"#Quality-range-of-functions-and-limitations\" class=\"headerlink\" title=\"Quality - range of functions and limitations\"></a>Quality - range of functions and limitations</h2><p><a href=\"https://www.mysql.com/\">MySQL</a> does not cover the complete DDL command set according to the requirements mentioned above.<br>For example, the command <code>ADD FULLTEXT INDEX</code> does not allow simultaneous writing.<br>Changing the data type of a column is also restricted.<br>These restrictions can be partially managed via a special patch flow:</p>\n<img class=\"blog/blog-online-schema-1.jpg\">\n<p>We use an interim version for preparatory and follow-up work on the database.</p>\n<p>During testing, we figured out that we can leave out the options ALGORITHM (COPY or INPLACE) and LOCK (SHARED or NONE) without having any disadvantages.<br>The system is able to find the optimal variant without a measurable time delay.<br>Interim conclusion: most of the DDL commands in MySQL 5.6 meet the requirements.</p>\n<h2 id=\"Quantity\"><a href=\"#Quantity\" class=\"headerlink\" title=\"Quantity\"></a>Quantity</h2><p><img class=\"blog/blog-online-schema-2.jpg\"> Test results with small database - UPDATE or SELECT operations </p>\n<p>As we’re working with Scrum processes at ePages, we have a new software release every two weeks.<br>The database changes accordingly.<br>All performance issues first have been tested with a small database and only then have been tested again with a real database.<br>These were mainly three tables with 0.6 million, 1.4 million and 9 million  entries.</p>\n<p>To summarise the results:</p>\n<ul>\n<li>Parallel execution extends the write commands.</li>\n<li>It seems as if the commands <code>ADD FULLTEXT INDEX</code> or <code>DROP FULLTEXT INDEX</code>, <code>ADD FOREIGN KEY</code> or <code>DROP FOREIGN KEY</code> and <code>CHANGE DATATYPE</code> queue the writing commands, which indicates sequential processing.</li>\n<li>Parallel execution does not have a significant impact on read commands.</li>\n<li>The sole exception with complex SELECT statements are the commands <code>ADD FOREIGN KEY</code> or <code>DROP FOREIGN KEY</code>.</li>\n</ul>\n<p>Within a wider context we had three different test scenarios:</p>\n<p><img class=\"blog/blog-online-schema-3.jpg\"> Test scenario - wider context </p>\n<p>The first results show this:</p>\n<p><img class=\"blog/blog-online-schema-4.jpg\"> Test results - execution times of DDL commands </p>\n<p>You can see clear improvement from version 5.1 to version 5.5.<br>But only from the results there’s no significant difference between MySQL 5.5 and 5.6.<br>So why definitely 5.6?<br>Taking a look at the occurred errors, log entries as well as the runtimes of the user test and the patch makes things clearer:</p>\n<p><img class=\"blog/blog-online-schema-5.jpg\"> Test results - number of errors, log entries and run times - user tests and patch </p>\n<p>In particular, this means:</p>\n<ul>\n<li>Only minimal differences in runtimes of 5.5 to 5.6, both completely and database changes individually.</li>\n<li>Analysis of Selenium tests and log files: clear improvement of error behaviour from 5.5 to 5.6.</li>\n<li>With regards to error behaviour, variants B and C are the best methods in 5.6.</li>\n<li>With regards to run time of Selenium tests, variant C is the best alternative in 5.6.</li>\n</ul>\n<h2 id=\"Conclusion\"><a href=\"#Conclusion\" class=\"headerlink\" title=\"Conclusion\"></a>Conclusion</h2><p>With MySQL 5.6 Oracle succeeded in taking a big step forward.<br>The supported command volume as well as the performance improved significantly.<br>For some operations still some patches are required, whereas preparatory database changes are executed with an interim patch and real features are activated afterwards.<br>In order to improve the execution times the DDL commands should be combined.<br>The initially stated customer requirement to perform maintenance tasks without downtime can be met.<br>All online shops will be online at all times.</p>\n"},{"layout":"post","title":"A report from the eCommerceCamp in Jena","date":"2016-03-31T07:03:24.000Z","image":"blog-header/barcamp-jena.jpg","authors":["Benjamin"],"_content":"\nThis march the [eCommerceCamp](http://www.ecommerce-camp.de), an annual [BarCamp](http://barcamp.org) took place for the 4th time in Jena, Germany.\nAt this site, a lot of the magical creation of online shopping started and still happens today.\nAs always, the highly affordable tickets for the unconference were sold out upfront and around two hundred participants from near and far were expected.\nThe orga team from [TRITUM](http://www.tritum.de) and [marmalade](http://www.marmalade.de) did a terrific job by creating an inspiring environment, which let everyone look forward to up-to-date topics about shop systems, productivity habits, email marketing, new technologies, customer satisfaction and team collaboration or even juggling with circus balls.\n\n## The participants\n\nThe clientele consists mainly of UI and UX designers, frontend and backend developers, project managers, some marketing people and also a few dedicated testers from web agencies with 1 to 20 people. These agencies usually work with self-contained content management systems like [Magento](https://magento.com), [OXID](http://www.oxid-esales.com), [Shopware](https://en.shopware.com), [TYPO3](https://typo3.org) or even [WordPress](https://wordpress.com).\nAttendees from the global eCommerce players are typically represented to a lesser extend, but this doesn't mean that local matadors like ePages or [Intershop](http://www.intershop.com) do not attend.\n\n## The setting\n\nThe event started with a dinner in a famous local restaurant.\nThis was a nice ice breaker to kick off the communication and get out of our comfort zones.\n\nThe next morning, all participants met at the main BarCamp location, the auditorium at the [Ernst-Abbe-Hochschule Jena](http://www.eah-jena.de/), University of Applied Sciences.\nAfter a collective breakfast, the session planning for both days started.\nAnyone who wants may initiate an OpenSpace talk.\nThe other attendees express interest in a suggestion by raising their hands.\nThis immediate reaction allows a proper planning of the time slot and room allocation for the session.\n\n## The sessions\n\nIn order to give a better impression of the actual contents of the unconference, I'd like to outline some of the sessions.\nAs a backend developer, I will focus on the technical talks and neglect the sessions about marketing or law.\n\n{% image blog/blog-ecommerce-barcamp-jena-2.jpg %}\n\nThe first session was held by Christoph Rüger from [Synesty](http://synesty.com).\nHe is part of a small team that has built a new cloud service that reads data from files (uploaded CSV, XML, Google Drive etc.).\nThis service lets the user create workflows via drag and drop (e.g. cronjobs with conditions and scheduling) that can interact with other service providers.\nChristoph revealed, which tools his team used for internal project management, customer communication and issue tracking.\nHe also explained the process of finding the fitting frameworks for developing their service, which was a quite interesting to follow.\n\nThe following presentation dealt with the topic \"Infrastructure as Code\".\nJan Peschke and Manuel Dieckmann prepared a talk about how they automated the rollout and development of Shopware environments with [Ansible](https://www.ansible.com) and [OpenStack](https://www.openstack.org), a solution similar to [Amazon AWS](https://aws.amazon.com). Currently, this cloud technology is well on the way to, but not yet fully production ready.\nHowever, a lot of minor service providers already emphasise OpenStack in the marketing ads as a blazing part of their customer portfolio.\nIn practice, hosters support that to a varying extent so that developers should check that carefully themselves.\nNevertheless, the framework in general is very interesting and already provides a lot of functionality. It will be valuable to follow in the future.\n\n{% img blog/blog-ecommerce-barcamp-jena-4.jpg 45% right %}The orga team\n\nAnother interesting session was a guided discussion about [Magento 2](https://magento.com/developers/magento2).\nBjörn Jacob and Tobias Vogt explained in an entertaining fashion the new functio set in frequent interplay with the strongly involved audience.\nOver the whole session length, the enhancement of the productivity and performance improvement as well as the overall stability of the new major relase were questioned very often.\nThe consolidated experience of the session room concluded that serveral good architectural decisions for this release were made, e.g.: [less](http://lesscss.org/) compiler, modes (default, env, prod), stricter separation of layout and logic via templates and modules, dependency injection, service contracts, XML schema definition for config files.\nThe software project has become much more open and community driven. Another observation was that version 2.1 might finally be able to offer a sufficient performance.\n\nThe next encouraging talk — by Andreas Ziethen from [ScaleCommerce](http://www.scale.sc), an experienced DevOps engineer and self-claimed \"senior apprentice\" — focused on the usage of [GitLab](https://www.gitlab.com) for deployment in conjunction with [Rundeck](http://rundeck.org) for job scheduling and runbook automation.\nToday, the interplay of both technologies is already at a very mature quality level and typical tasks like staging and conditional build steps can be represented within versioned job descriptions.\nIf you have a small shop project with a minimal set of requirements for your CI and CD pipeline setup, the discussed cloud solution might be comparable with [Jenkins](https://jenkins-ci.org), [Bamboo](https://confluence.atlassian.com/bamboo) or [TeamCity](https://www.jetbrains.com/teamcity) in this context.\n\nOn the last day, we had three slots before the closing speech.\n\nThe first session, presented by Oliver Reißig, centered around Continuous Integration in a large-scale shop platform using [Gradle](http://gradle.org/).\nIn the second one Eimantas Kaleiva showcased frontend acceptance testing, where the test cases were written by the product owner in a [BDD](http://behaviourdriven.org/)-style webinterface similar to [Cucumber](https://cucumber.io).\nThe very last talk and [presentation](http://janpersiel.com/why-designers-and-frond-end-developers-should-talk-more-often) by Jan Persiel comprised the findings for relaunches of large shops under various key aspects like the usage of [Atomic Design](http://bradfrost.com/blog/post/atomic-web-design) for the storefront layout or the establishment of worthwhile meeting structures.\n\n## The surroundings\n\nTo brighten the mood of all participants, the facilitators supplied superb food which fulfilled multitudinous desires: crispy chicken legs, juicy steak, grilled roast beef, various soups, plenty of vegetarian food, fresh asparagus and salmon, dessert cremes, cake pops, tropical fruits and even a popcorn machine wagon was present.\nConsistently, I could spot happy foodies everywhere!\n\nAnother form of active relaxation between the session breaks could be accomplished by a short visit of the gaming corner.\nSeveral retro consoles awaited their live field-test in battle matches with Super Mario Kart and other classics.\n\n{% image blog/blog-ecommerce-barcamp-jena-3.jpg %}\n\n## Summary\n\nAll in all, the BarCamp offered a friendly and exciting atmosphere to meet new people with a big treasure trove of experience in shop systems.\nMany sessions were very enjoyable with a broad spectrum of topics, and there were some outstanding ones, too.\nFrom what I have seen, I can totally recommend this unconference. Especially for PHP developers and all sector newcomers, this event is definitely worth it.\n\nBefore the eCommerceCamp is after the eCommerceCamp, so be ready for a visit next year!\n","source":"_posts/2016-03-31-ecommerce-barcamp-jena.md","raw":"---\nlayout: post\ntitle: \"A report from the eCommerceCamp in Jena\"\ndate: \"2016-03-31 09:03:24\"\nimage: blog-header/barcamp-jena.jpg\ncategories: events\nauthors: [\"Benjamin\"]\n---\n\nThis march the [eCommerceCamp](http://www.ecommerce-camp.de), an annual [BarCamp](http://barcamp.org) took place for the 4th time in Jena, Germany.\nAt this site, a lot of the magical creation of online shopping started and still happens today.\nAs always, the highly affordable tickets for the unconference were sold out upfront and around two hundred participants from near and far were expected.\nThe orga team from [TRITUM](http://www.tritum.de) and [marmalade](http://www.marmalade.de) did a terrific job by creating an inspiring environment, which let everyone look forward to up-to-date topics about shop systems, productivity habits, email marketing, new technologies, customer satisfaction and team collaboration or even juggling with circus balls.\n\n## The participants\n\nThe clientele consists mainly of UI and UX designers, frontend and backend developers, project managers, some marketing people and also a few dedicated testers from web agencies with 1 to 20 people. These agencies usually work with self-contained content management systems like [Magento](https://magento.com), [OXID](http://www.oxid-esales.com), [Shopware](https://en.shopware.com), [TYPO3](https://typo3.org) or even [WordPress](https://wordpress.com).\nAttendees from the global eCommerce players are typically represented to a lesser extend, but this doesn't mean that local matadors like ePages or [Intershop](http://www.intershop.com) do not attend.\n\n## The setting\n\nThe event started with a dinner in a famous local restaurant.\nThis was a nice ice breaker to kick off the communication and get out of our comfort zones.\n\nThe next morning, all participants met at the main BarCamp location, the auditorium at the [Ernst-Abbe-Hochschule Jena](http://www.eah-jena.de/), University of Applied Sciences.\nAfter a collective breakfast, the session planning for both days started.\nAnyone who wants may initiate an OpenSpace talk.\nThe other attendees express interest in a suggestion by raising their hands.\nThis immediate reaction allows a proper planning of the time slot and room allocation for the session.\n\n## The sessions\n\nIn order to give a better impression of the actual contents of the unconference, I'd like to outline some of the sessions.\nAs a backend developer, I will focus on the technical talks and neglect the sessions about marketing or law.\n\n{% image blog/blog-ecommerce-barcamp-jena-2.jpg %}\n\nThe first session was held by Christoph Rüger from [Synesty](http://synesty.com).\nHe is part of a small team that has built a new cloud service that reads data from files (uploaded CSV, XML, Google Drive etc.).\nThis service lets the user create workflows via drag and drop (e.g. cronjobs with conditions and scheduling) that can interact with other service providers.\nChristoph revealed, which tools his team used for internal project management, customer communication and issue tracking.\nHe also explained the process of finding the fitting frameworks for developing their service, which was a quite interesting to follow.\n\nThe following presentation dealt with the topic \"Infrastructure as Code\".\nJan Peschke and Manuel Dieckmann prepared a talk about how they automated the rollout and development of Shopware environments with [Ansible](https://www.ansible.com) and [OpenStack](https://www.openstack.org), a solution similar to [Amazon AWS](https://aws.amazon.com). Currently, this cloud technology is well on the way to, but not yet fully production ready.\nHowever, a lot of minor service providers already emphasise OpenStack in the marketing ads as a blazing part of their customer portfolio.\nIn practice, hosters support that to a varying extent so that developers should check that carefully themselves.\nNevertheless, the framework in general is very interesting and already provides a lot of functionality. It will be valuable to follow in the future.\n\n{% img blog/blog-ecommerce-barcamp-jena-4.jpg 45% right %}The orga team\n\nAnother interesting session was a guided discussion about [Magento 2](https://magento.com/developers/magento2).\nBjörn Jacob and Tobias Vogt explained in an entertaining fashion the new functio set in frequent interplay with the strongly involved audience.\nOver the whole session length, the enhancement of the productivity and performance improvement as well as the overall stability of the new major relase were questioned very often.\nThe consolidated experience of the session room concluded that serveral good architectural decisions for this release were made, e.g.: [less](http://lesscss.org/) compiler, modes (default, env, prod), stricter separation of layout and logic via templates and modules, dependency injection, service contracts, XML schema definition for config files.\nThe software project has become much more open and community driven. Another observation was that version 2.1 might finally be able to offer a sufficient performance.\n\nThe next encouraging talk — by Andreas Ziethen from [ScaleCommerce](http://www.scale.sc), an experienced DevOps engineer and self-claimed \"senior apprentice\" — focused on the usage of [GitLab](https://www.gitlab.com) for deployment in conjunction with [Rundeck](http://rundeck.org) for job scheduling and runbook automation.\nToday, the interplay of both technologies is already at a very mature quality level and typical tasks like staging and conditional build steps can be represented within versioned job descriptions.\nIf you have a small shop project with a minimal set of requirements for your CI and CD pipeline setup, the discussed cloud solution might be comparable with [Jenkins](https://jenkins-ci.org), [Bamboo](https://confluence.atlassian.com/bamboo) or [TeamCity](https://www.jetbrains.com/teamcity) in this context.\n\nOn the last day, we had three slots before the closing speech.\n\nThe first session, presented by Oliver Reißig, centered around Continuous Integration in a large-scale shop platform using [Gradle](http://gradle.org/).\nIn the second one Eimantas Kaleiva showcased frontend acceptance testing, where the test cases were written by the product owner in a [BDD](http://behaviourdriven.org/)-style webinterface similar to [Cucumber](https://cucumber.io).\nThe very last talk and [presentation](http://janpersiel.com/why-designers-and-frond-end-developers-should-talk-more-often) by Jan Persiel comprised the findings for relaunches of large shops under various key aspects like the usage of [Atomic Design](http://bradfrost.com/blog/post/atomic-web-design) for the storefront layout or the establishment of worthwhile meeting structures.\n\n## The surroundings\n\nTo brighten the mood of all participants, the facilitators supplied superb food which fulfilled multitudinous desires: crispy chicken legs, juicy steak, grilled roast beef, various soups, plenty of vegetarian food, fresh asparagus and salmon, dessert cremes, cake pops, tropical fruits and even a popcorn machine wagon was present.\nConsistently, I could spot happy foodies everywhere!\n\nAnother form of active relaxation between the session breaks could be accomplished by a short visit of the gaming corner.\nSeveral retro consoles awaited their live field-test in battle matches with Super Mario Kart and other classics.\n\n{% image blog/blog-ecommerce-barcamp-jena-3.jpg %}\n\n## Summary\n\nAll in all, the BarCamp offered a friendly and exciting atmosphere to meet new people with a big treasure trove of experience in shop systems.\nMany sessions were very enjoyable with a broad spectrum of topics, and there were some outstanding ones, too.\nFrom what I have seen, I can totally recommend this unconference. Especially for PHP developers and all sector newcomers, this event is definitely worth it.\n\nBefore the eCommerceCamp is after the eCommerceCamp, so be ready for a visit next year!\n","slug":"2016-03-31-ecommerce-barcamp-jena","published":1,"updated":"2016-09-20T14:42:20.000Z","comments":1,"photos":[],"link":"","_id":"ciu6nuh9i0020hqyx322jtozl","content":"<p>This march the <a href=\"http://www.ecommerce-camp.de\" target=\"_blank\" rel=\"external\">eCommerceCamp</a>, an annual <a href=\"http://barcamp.org\" target=\"_blank\" rel=\"external\">BarCamp</a> took place for the 4th time in Jena, Germany.<br>At this site, a lot of the magical creation of online shopping started and still happens today.<br>As always, the highly affordable tickets for the unconference were sold out upfront and around two hundred participants from near and far were expected.<br>The orga team from <a href=\"http://www.tritum.de\" target=\"_blank\" rel=\"external\">TRITUM</a> and <a href=\"http://www.marmalade.de\" target=\"_blank\" rel=\"external\">marmalade</a> did a terrific job by creating an inspiring environment, which let everyone look forward to up-to-date topics about shop systems, productivity habits, email marketing, new technologies, customer satisfaction and team collaboration or even juggling with circus balls.</p>\n<h2 id=\"The-participants\"><a href=\"#The-participants\" class=\"headerlink\" title=\"The participants\"></a>The participants</h2><p>The clientele consists mainly of UI and UX designers, frontend and backend developers, project managers, some marketing people and also a few dedicated testers from web agencies with 1 to 20 people. These agencies usually work with self-contained content management systems like <a href=\"https://magento.com\" target=\"_blank\" rel=\"external\">Magento</a>, <a href=\"http://www.oxid-esales.com\" target=\"_blank\" rel=\"external\">OXID</a>, <a href=\"https://en.shopware.com\" target=\"_blank\" rel=\"external\">Shopware</a>, <a href=\"https://typo3.org\" target=\"_blank\" rel=\"external\">TYPO3</a> or even <a href=\"https://wordpress.com\" target=\"_blank\" rel=\"external\">WordPress</a>.<br>Attendees from the global eCommerce players are typically represented to a lesser extend, but this doesn’t mean that local matadors like ePages or <a href=\"http://www.intershop.com\" target=\"_blank\" rel=\"external\">Intershop</a> do not attend.</p>\n<h2 id=\"The-setting\"><a href=\"#The-setting\" class=\"headerlink\" title=\"The setting\"></a>The setting</h2><p>The event started with a dinner in a famous local restaurant.<br>This was a nice ice breaker to kick off the communication and get out of our comfort zones.</p>\n<p>The next morning, all participants met at the main BarCamp location, the auditorium at the <a href=\"http://www.eah-jena.de/\" target=\"_blank\" rel=\"external\">Ernst-Abbe-Hochschule Jena</a>, University of Applied Sciences.<br>After a collective breakfast, the session planning for both days started.<br>Anyone who wants may initiate an OpenSpace talk.<br>The other attendees express interest in a suggestion by raising their hands.<br>This immediate reaction allows a proper planning of the time slot and room allocation for the session.</p>\n<h2 id=\"The-sessions\"><a href=\"#The-sessions\" class=\"headerlink\" title=\"The sessions\"></a>The sessions</h2><p>In order to give a better impression of the actual contents of the unconference, I’d like to outline some of the sessions.<br>As a backend developer, I will focus on the technical talks and neglect the sessions about marketing or law.</p>\n<img class=\"blog/blog-ecommerce-barcamp-jena-2.jpg\">\n<p>The first session was held by Christoph Rüger from <a href=\"http://synesty.com\" target=\"_blank\" rel=\"external\">Synesty</a>.<br>He is part of a small team that has built a new cloud service that reads data from files (uploaded CSV, XML, Google Drive etc.).<br>This service lets the user create workflows via drag and drop (e.g. cronjobs with conditions and scheduling) that can interact with other service providers.<br>Christoph revealed, which tools his team used for internal project management, customer communication and issue tracking.<br>He also explained the process of finding the fitting frameworks for developing their service, which was a quite interesting to follow.</p>\n<p>The following presentation dealt with the topic “Infrastructure as Code”.<br>Jan Peschke and Manuel Dieckmann prepared a talk about how they automated the rollout and development of Shopware environments with <a href=\"https://www.ansible.com\" target=\"_blank\" rel=\"external\">Ansible</a> and <a href=\"https://www.openstack.org\" target=\"_blank\" rel=\"external\">OpenStack</a>, a solution similar to <a href=\"https://aws.amazon.com\" target=\"_blank\" rel=\"external\">Amazon AWS</a>. Currently, this cloud technology is well on the way to, but not yet fully production ready.<br>However, a lot of minor service providers already emphasise OpenStack in the marketing ads as a blazing part of their customer portfolio.<br>In practice, hosters support that to a varying extent so that developers should check that carefully themselves.<br>Nevertheless, the framework in general is very interesting and already provides a lot of functionality. It will be valuable to follow in the future.</p>\n<img class=\"blog/blog-ecommerce-barcamp-jena-4.jpg 45% right\">The orga team<br><br>Another interesting session was a guided discussion about <a href=\"https://magento.com/developers/magento2\" target=\"_blank\" rel=\"external\">Magento 2</a>.<br>Björn Jacob and Tobias Vogt explained in an entertaining fashion the new functio set in frequent interplay with the strongly involved audience.<br>Over the whole session length, the enhancement of the productivity and performance improvement as well as the overall stability of the new major relase were questioned very often.<br>The consolidated experience of the session room concluded that serveral good architectural decisions for this release were made, e.g.: <a href=\"http://lesscss.org/\" target=\"_blank\" rel=\"external\">less</a> compiler, modes (default, env, prod), stricter separation of layout and logic via templates and modules, dependency injection, service contracts, XML schema definition for config files.<br>The software project has become much more open and community driven. Another observation was that version 2.1 might finally be able to offer a sufficient performance.<br><br>The next encouraging talk — by Andreas Ziethen from <a href=\"http://www.scale.sc\" target=\"_blank\" rel=\"external\">ScaleCommerce</a>, an experienced DevOps engineer and self-claimed “senior apprentice” — focused on the usage of <a href=\"https://www.gitlab.com\" target=\"_blank\" rel=\"external\">GitLab</a> for deployment in conjunction with <a href=\"http://rundeck.org\" target=\"_blank\" rel=\"external\">Rundeck</a> for job scheduling and runbook automation.<br>Today, the interplay of both technologies is already at a very mature quality level and typical tasks like staging and conditional build steps can be represented within versioned job descriptions.<br>If you have a small shop project with a minimal set of requirements for your CI and CD pipeline setup, the discussed cloud solution might be comparable with <a href=\"https://jenkins-ci.org\" target=\"_blank\" rel=\"external\">Jenkins</a>, <a href=\"https://confluence.atlassian.com/bamboo\" target=\"_blank\" rel=\"external\">Bamboo</a> or <a href=\"https://www.jetbrains.com/teamcity\" target=\"_blank\" rel=\"external\">TeamCity</a> in this context.<br><br>On the last day, we had three slots before the closing speech.<br><br>The first session, presented by Oliver Reißig, centered around Continuous Integration in a large-scale shop platform using <a href=\"http://gradle.org/\" target=\"_blank\" rel=\"external\">Gradle</a>.<br>In the second one Eimantas Kaleiva showcased frontend acceptance testing, where the test cases were written by the product owner in a <a href=\"http://behaviourdriven.org/\" target=\"_blank\" rel=\"external\">BDD</a>-style webinterface similar to <a href=\"https://cucumber.io\" target=\"_blank\" rel=\"external\">Cucumber</a>.<br>The very last talk and <a href=\"http://janpersiel.com/why-designers-and-frond-end-developers-should-talk-more-often\" target=\"_blank\" rel=\"external\">presentation</a> by Jan Persiel comprised the findings for relaunches of large shops under various key aspects like the usage of <a href=\"http://bradfrost.com/blog/post/atomic-web-design\" target=\"_blank\" rel=\"external\">Atomic Design</a> for the storefront layout or the establishment of worthwhile meeting structures.<br><br>## The surroundings<br><br>To brighten the mood of all participants, the facilitators supplied superb food which fulfilled multitudinous desires: crispy chicken legs, juicy steak, grilled roast beef, various soups, plenty of vegetarian food, fresh asparagus and salmon, dessert cremes, cake pops, tropical fruits and even a popcorn machine wagon was present.<br>Consistently, I could spot happy foodies everywhere!<br><br>Another form of active relaxation between the session breaks could be accomplished by a short visit of the gaming corner.<br>Several retro consoles awaited their live field-test in battle matches with Super Mario Kart and other classics.<br><br><img class=\"blog/blog-ecommerce-barcamp-jena-3.jpg\">\n<h2 id=\"Summary\"><a href=\"#Summary\" class=\"headerlink\" title=\"Summary\"></a>Summary</h2><p>All in all, the BarCamp offered a friendly and exciting atmosphere to meet new people with a big treasure trove of experience in shop systems.<br>Many sessions were very enjoyable with a broad spectrum of topics, and there were some outstanding ones, too.<br>From what I have seen, I can totally recommend this unconference. Especially for PHP developers and all sector newcomers, this event is definitely worth it.</p>\n<p>Before the eCommerceCamp is after the eCommerceCamp, so be ready for a visit next year!</p>\n","excerpt":"","more":"<p>This march the <a href=\"http://www.ecommerce-camp.de\">eCommerceCamp</a>, an annual <a href=\"http://barcamp.org\">BarCamp</a> took place for the 4th time in Jena, Germany.<br>At this site, a lot of the magical creation of online shopping started and still happens today.<br>As always, the highly affordable tickets for the unconference were sold out upfront and around two hundred participants from near and far were expected.<br>The orga team from <a href=\"http://www.tritum.de\">TRITUM</a> and <a href=\"http://www.marmalade.de\">marmalade</a> did a terrific job by creating an inspiring environment, which let everyone look forward to up-to-date topics about shop systems, productivity habits, email marketing, new technologies, customer satisfaction and team collaboration or even juggling with circus balls.</p>\n<h2 id=\"The-participants\"><a href=\"#The-participants\" class=\"headerlink\" title=\"The participants\"></a>The participants</h2><p>The clientele consists mainly of UI and UX designers, frontend and backend developers, project managers, some marketing people and also a few dedicated testers from web agencies with 1 to 20 people. These agencies usually work with self-contained content management systems like <a href=\"https://magento.com\">Magento</a>, <a href=\"http://www.oxid-esales.com\">OXID</a>, <a href=\"https://en.shopware.com\">Shopware</a>, <a href=\"https://typo3.org\">TYPO3</a> or even <a href=\"https://wordpress.com\">WordPress</a>.<br>Attendees from the global eCommerce players are typically represented to a lesser extend, but this doesn’t mean that local matadors like ePages or <a href=\"http://www.intershop.com\">Intershop</a> do not attend.</p>\n<h2 id=\"The-setting\"><a href=\"#The-setting\" class=\"headerlink\" title=\"The setting\"></a>The setting</h2><p>The event started with a dinner in a famous local restaurant.<br>This was a nice ice breaker to kick off the communication and get out of our comfort zones.</p>\n<p>The next morning, all participants met at the main BarCamp location, the auditorium at the <a href=\"http://www.eah-jena.de/\">Ernst-Abbe-Hochschule Jena</a>, University of Applied Sciences.<br>After a collective breakfast, the session planning for both days started.<br>Anyone who wants may initiate an OpenSpace talk.<br>The other attendees express interest in a suggestion by raising their hands.<br>This immediate reaction allows a proper planning of the time slot and room allocation for the session.</p>\n<h2 id=\"The-sessions\"><a href=\"#The-sessions\" class=\"headerlink\" title=\"The sessions\"></a>The sessions</h2><p>In order to give a better impression of the actual contents of the unconference, I’d like to outline some of the sessions.<br>As a backend developer, I will focus on the technical talks and neglect the sessions about marketing or law.</p>\n<img class=\"blog/blog-ecommerce-barcamp-jena-2.jpg\">\n<p>The first session was held by Christoph Rüger from <a href=\"http://synesty.com\">Synesty</a>.<br>He is part of a small team that has built a new cloud service that reads data from files (uploaded CSV, XML, Google Drive etc.).<br>This service lets the user create workflows via drag and drop (e.g. cronjobs with conditions and scheduling) that can interact with other service providers.<br>Christoph revealed, which tools his team used for internal project management, customer communication and issue tracking.<br>He also explained the process of finding the fitting frameworks for developing their service, which was a quite interesting to follow.</p>\n<p>The following presentation dealt with the topic “Infrastructure as Code”.<br>Jan Peschke and Manuel Dieckmann prepared a talk about how they automated the rollout and development of Shopware environments with <a href=\"https://www.ansible.com\">Ansible</a> and <a href=\"https://www.openstack.org\">OpenStack</a>, a solution similar to <a href=\"https://aws.amazon.com\">Amazon AWS</a>. Currently, this cloud technology is well on the way to, but not yet fully production ready.<br>However, a lot of minor service providers already emphasise OpenStack in the marketing ads as a blazing part of their customer portfolio.<br>In practice, hosters support that to a varying extent so that developers should check that carefully themselves.<br>Nevertheless, the framework in general is very interesting and already provides a lot of functionality. It will be valuable to follow in the future.</p>\n<img class=\"blog/blog-ecommerce-barcamp-jena-4.jpg 45% right\">The orga team<br><br>Another interesting session was a guided discussion about <a href=\"https://magento.com/developers/magento2\">Magento 2</a>.<br>Björn Jacob and Tobias Vogt explained in an entertaining fashion the new functio set in frequent interplay with the strongly involved audience.<br>Over the whole session length, the enhancement of the productivity and performance improvement as well as the overall stability of the new major relase were questioned very often.<br>The consolidated experience of the session room concluded that serveral good architectural decisions for this release were made, e.g.: <a href=\"http://lesscss.org/\">less</a> compiler, modes (default, env, prod), stricter separation of layout and logic via templates and modules, dependency injection, service contracts, XML schema definition for config files.<br>The software project has become much more open and community driven. Another observation was that version 2.1 might finally be able to offer a sufficient performance.<br><br>The next encouraging talk — by Andreas Ziethen from <a href=\"http://www.scale.sc\">ScaleCommerce</a>, an experienced DevOps engineer and self-claimed “senior apprentice” — focused on the usage of <a href=\"https://www.gitlab.com\">GitLab</a> for deployment in conjunction with <a href=\"http://rundeck.org\">Rundeck</a> for job scheduling and runbook automation.<br>Today, the interplay of both technologies is already at a very mature quality level and typical tasks like staging and conditional build steps can be represented within versioned job descriptions.<br>If you have a small shop project with a minimal set of requirements for your CI and CD pipeline setup, the discussed cloud solution might be comparable with <a href=\"https://jenkins-ci.org\">Jenkins</a>, <a href=\"https://confluence.atlassian.com/bamboo\">Bamboo</a> or <a href=\"https://www.jetbrains.com/teamcity\">TeamCity</a> in this context.<br><br>On the last day, we had three slots before the closing speech.<br><br>The first session, presented by Oliver Reißig, centered around Continuous Integration in a large-scale shop platform using <a href=\"http://gradle.org/\">Gradle</a>.<br>In the second one Eimantas Kaleiva showcased frontend acceptance testing, where the test cases were written by the product owner in a <a href=\"http://behaviourdriven.org/\">BDD</a>-style webinterface similar to <a href=\"https://cucumber.io\">Cucumber</a>.<br>The very last talk and <a href=\"http://janpersiel.com/why-designers-and-frond-end-developers-should-talk-more-often\">presentation</a> by Jan Persiel comprised the findings for relaunches of large shops under various key aspects like the usage of <a href=\"http://bradfrost.com/blog/post/atomic-web-design\">Atomic Design</a> for the storefront layout or the establishment of worthwhile meeting structures.<br><br>## The surroundings<br><br>To brighten the mood of all participants, the facilitators supplied superb food which fulfilled multitudinous desires: crispy chicken legs, juicy steak, grilled roast beef, various soups, plenty of vegetarian food, fresh asparagus and salmon, dessert cremes, cake pops, tropical fruits and even a popcorn machine wagon was present.<br>Consistently, I could spot happy foodies everywhere!<br><br>Another form of active relaxation between the session breaks could be accomplished by a short visit of the gaming corner.<br>Several retro consoles awaited their live field-test in battle matches with Super Mario Kart and other classics.<br><br><img class=\"blog/blog-ecommerce-barcamp-jena-3.jpg\">\n<h2 id=\"Summary\"><a href=\"#Summary\" class=\"headerlink\" title=\"Summary\"></a>Summary</h2><p>All in all, the BarCamp offered a friendly and exciting atmosphere to meet new people with a big treasure trove of experience in shop systems.<br>Many sessions were very enjoyable with a broad spectrum of topics, and there were some outstanding ones, too.<br>From what I have seen, I can totally recommend this unconference. Especially for PHP developers and all sector newcomers, this event is definitely worth it.</p>\n<p>Before the eCommerceCamp is after the eCommerceCamp, so be ready for a visit next year!</p>\n"},{"layout":"post","title":"ePages REST API out of beta","date":"2016-01-21T08:34:28.000Z","authors":["Birgit"],"_content":"\nGreat news at the beginning of the new year: we are happy to announce that the ePages REST API is now officially out of beta!\nDuring 2015 we made great progress in the development of new REST calls which you can now use to create great apps.\n\nWith our REST API, you can build apps and expand the ePages App Store with new features.\nThis helps enrich our merchants shop administration.\n\n## Put your idea into action\n\nSign up for the ePages Developer Program with just a few clicks.\nRead further [here](page:apps-overview#registration) and receive all required information on the registration.\n\n## Use cases\n\nWe've put together some [use cases](page:apps-use-cases) that describe business scenarios that you might want to take a look at.\nMaybe that inspires you and gives some further insight of what kind of apps we're currently looking for.\n\n## Integrations\n\nTake a glance at our integrations.\nThere's already a [Ruby gem](page:apps-ruby-gem) in place that is to help you create easy and understandable code and speed up your development.\n\nUsing our [REST client SITe](https://github.com/ePages-de/site) you can easily build a plugin for a Content Management System (CMS) or blog of your choice.\n\n## We're keeping you up to date\n\nWe've implemented a change log that covers significant updates and changes to the ePages REST API.\nIn order to keep track of these changes we recommend you to follow [@epagesdevs](https://twitter.com/epagesdevs) on Twitter or subscribe to our [RSS feed for the API Change Log](https://developer.epages.com/apps/feed.xml).\n\n## Happy coding!\n\nWe're excited to have your app in the ePages App Store soon!\n","source":"_posts/2016-01-21-announce-rest-api.md","raw":"---\nlayout: post\ntitle: \"ePages REST API out of beta\"\ndate: \"2016-01-21 09:34:28\"\ncategories: api\nauthors: [\"Birgit\"]\n---\n\nGreat news at the beginning of the new year: we are happy to announce that the ePages REST API is now officially out of beta!\nDuring 2015 we made great progress in the development of new REST calls which you can now use to create great apps.\n\nWith our REST API, you can build apps and expand the ePages App Store with new features.\nThis helps enrich our merchants shop administration.\n\n## Put your idea into action\n\nSign up for the ePages Developer Program with just a few clicks.\nRead further [here](page:apps-overview#registration) and receive all required information on the registration.\n\n## Use cases\n\nWe've put together some [use cases](page:apps-use-cases) that describe business scenarios that you might want to take a look at.\nMaybe that inspires you and gives some further insight of what kind of apps we're currently looking for.\n\n## Integrations\n\nTake a glance at our integrations.\nThere's already a [Ruby gem](page:apps-ruby-gem) in place that is to help you create easy and understandable code and speed up your development.\n\nUsing our [REST client SITe](https://github.com/ePages-de/site) you can easily build a plugin for a Content Management System (CMS) or blog of your choice.\n\n## We're keeping you up to date\n\nWe've implemented a change log that covers significant updates and changes to the ePages REST API.\nIn order to keep track of these changes we recommend you to follow [@epagesdevs](https://twitter.com/epagesdevs) on Twitter or subscribe to our [RSS feed for the API Change Log](https://developer.epages.com/apps/feed.xml).\n\n## Happy coding!\n\nWe're excited to have your app in the ePages App Store soon!\n","slug":"2016-01-21-announce-rest-api","published":1,"updated":"2016-09-20T14:31:48.000Z","comments":1,"photos":[],"link":"","_id":"ciu6nuh9j0022hqyx5ahr8le2","content":"<p>Great news at the beginning of the new year: we are happy to announce that the ePages REST API is now officially out of beta!<br>During 2015 we made great progress in the development of new REST calls which you can now use to create great apps.</p>\n<p>With our REST API, you can build apps and expand the ePages App Store with new features.<br>This helps enrich our merchants shop administration.</p>\n<h2 id=\"Put-your-idea-into-action\"><a href=\"#Put-your-idea-into-action\" class=\"headerlink\" title=\"Put your idea into action\"></a>Put your idea into action</h2><p>Sign up for the ePages Developer Program with just a few clicks.<br>Read further <a href=\"page:apps-overview#registration\" target=\"_blank\" rel=\"external\">here</a> and receive all required information on the registration.</p>\n<h2 id=\"Use-cases\"><a href=\"#Use-cases\" class=\"headerlink\" title=\"Use cases\"></a>Use cases</h2><p>We’ve put together some <a href=\"page:apps-use-cases\" target=\"_blank\" rel=\"external\">use cases</a> that describe business scenarios that you might want to take a look at.<br>Maybe that inspires you and gives some further insight of what kind of apps we’re currently looking for.</p>\n<h2 id=\"Integrations\"><a href=\"#Integrations\" class=\"headerlink\" title=\"Integrations\"></a>Integrations</h2><p>Take a glance at our integrations.<br>There’s already a <a href=\"page:apps-ruby-gem\" target=\"_blank\" rel=\"external\">Ruby gem</a> in place that is to help you create easy and understandable code and speed up your development.</p>\n<p>Using our <a href=\"https://github.com/ePages-de/site\" target=\"_blank\" rel=\"external\">REST client SITe</a> you can easily build a plugin for a Content Management System (CMS) or blog of your choice.</p>\n<h2 id=\"We’re-keeping-you-up-to-date\"><a href=\"#We’re-keeping-you-up-to-date\" class=\"headerlink\" title=\"We’re keeping you up to date\"></a>We’re keeping you up to date</h2><p>We’ve implemented a change log that covers significant updates and changes to the ePages REST API.<br>In order to keep track of these changes we recommend you to follow <a href=\"https://twitter.com/epagesdevs\" target=\"_blank\" rel=\"external\">@epagesdevs</a> on Twitter or subscribe to our <a href=\"https://developer.epages.com/apps/feed.xml\" target=\"_blank\" rel=\"external\">RSS feed for the API Change Log</a>.</p>\n<h2 id=\"Happy-coding\"><a href=\"#Happy-coding\" class=\"headerlink\" title=\"Happy coding!\"></a>Happy coding!</h2><p>We’re excited to have your app in the ePages App Store soon!</p>\n","excerpt":"","more":"<p>Great news at the beginning of the new year: we are happy to announce that the ePages REST API is now officially out of beta!<br>During 2015 we made great progress in the development of new REST calls which you can now use to create great apps.</p>\n<p>With our REST API, you can build apps and expand the ePages App Store with new features.<br>This helps enrich our merchants shop administration.</p>\n<h2 id=\"Put-your-idea-into-action\"><a href=\"#Put-your-idea-into-action\" class=\"headerlink\" title=\"Put your idea into action\"></a>Put your idea into action</h2><p>Sign up for the ePages Developer Program with just a few clicks.<br>Read further <a href=\"page:apps-overview#registration\">here</a> and receive all required information on the registration.</p>\n<h2 id=\"Use-cases\"><a href=\"#Use-cases\" class=\"headerlink\" title=\"Use cases\"></a>Use cases</h2><p>We’ve put together some <a href=\"page:apps-use-cases\">use cases</a> that describe business scenarios that you might want to take a look at.<br>Maybe that inspires you and gives some further insight of what kind of apps we’re currently looking for.</p>\n<h2 id=\"Integrations\"><a href=\"#Integrations\" class=\"headerlink\" title=\"Integrations\"></a>Integrations</h2><p>Take a glance at our integrations.<br>There’s already a <a href=\"page:apps-ruby-gem\">Ruby gem</a> in place that is to help you create easy and understandable code and speed up your development.</p>\n<p>Using our <a href=\"https://github.com/ePages-de/site\">REST client SITe</a> you can easily build a plugin for a Content Management System (CMS) or blog of your choice.</p>\n<h2 id=\"We’re-keeping-you-up-to-date\"><a href=\"#We’re-keeping-you-up-to-date\" class=\"headerlink\" title=\"We’re keeping you up to date\"></a>We’re keeping you up to date</h2><p>We’ve implemented a change log that covers significant updates and changes to the ePages REST API.<br>In order to keep track of these changes we recommend you to follow <a href=\"https://twitter.com/epagesdevs\">@epagesdevs</a> on Twitter or subscribe to our <a href=\"https://developer.epages.com/apps/feed.xml\">RSS feed for the API Change Log</a>.</p>\n<h2 id=\"Happy-coding\"><a href=\"#Happy-coding\" class=\"headerlink\" title=\"Happy coding!\"></a>Happy coding!</h2><p>We’re excited to have your app in the ePages App Store soon!</p>\n"},{"layout":"post","title":"Scrum Basics: Estimating","date":"2016-01-26T06:23:00.000Z","image":"blog-header/estimation.jpg","authors":["Anja B."],"_content":"\nWelcome to part four of our Scrum Basics Series.\nToday we will have a look at estimation principles and techniques used in Scrum.\n\nThere are some basics that are completely different to estimations in waterfall projects.\nFor example, in Scrum we don’t estimate time, but effort.\nAlso tickets are estimated relative to each other or to example tickets the team created.\nIn Scrum we estimate in story points.\nBut in order to know what that means you need to be clear about what a story is.\n\n## Epics, Stories, Story Points and Velocity\n\nAn *Epic* is the ticket type used for features.\nDevelopers would not work on it directly, but through stories.\nThat means a *User Story* is a small part of a feature.\nIt must be small enough to fit into a sprint and should work and be potentially shippable by itself.\nA user story usually answers three questions: **Who** wants **what** and **why**?\nTherefore it is structured in the following way: “As … I want … to be able to…”.\nIt’s called user story because it’s normally told from an end-user's perspective.\nEach story also has acceptance criteria that have to be fulfilled to consider it done.\nIdeally, it should also cover all expert areas within a team (e.g. for a piece of software it should contain backend and frontend development as well as design).\n\nWithin the Backlog Refinement the team members estimate the stories.\nAs already said, they don’t estimate time, but effort.\nTo symbolise the effort, Scrum Teams use *Story Points*.\nThose are typically [Fibonacci numbers](https://en.wikipedia.org/wiki/Fibonacci_number): 1, 2, 3, 5, 8, 13, 21.\nAn alternative are T-shirt sizes.\nThose are usually more roughly because they only represent 4 stages: S, M, L or XL.\nTo being able have a more precise measurement, most often some of the Fibonacci numbers are assigned to the T-shirt sizes (e.g. S=2, M=5, L=13, XL=21).\nThe idea behind using Fibonacci is that the bigger a ticket is, the harder it gets to estimate it precisely.\nTherefore, the steps between the numbers will increase.\n\n{% image blog/blog-scrum4-burndown-chart.jpg %}\n\nDuring the sprint the story points of all closed tickets are counted.\nIn the end you get a number that represents how much a team is capable of solving within a sprint.\nMeasure this number across several sprints and build an average and you get the so called *Velocity* of a team.\nVelocities between different teams are not comparable, since every team has its own understanding of the effort behind a story point.\nThe Product Owner can use the velocity for long-term planning.\nTo help the team see how good they are on track within a sprint, Scrum uses so called *Burndown Charts*.\nThey show the number of closed story points on a time scale representing the sprint.\n\n## Planning Poker\n\n{% image blog/blog-scrum4-planning-poker.jpg 45% left %}\n\nPlanning Poker is probably the most used estimation technique in Scrum.\nFor this technique every team member gets a set of Planning Poker cards, which show the Fibonacci row.\nAt the beginning the Product Owner presents a ticket that needs an estimation.\nThe team then clarifies all questions regarding the ticket.\nThen each member chooses the effort they thinks fits best to this card.\nAll cards are then turned around at the same time for everyone to see.\nThe team discusses especially the highest and lowest number to understand the reasons why the team members chose those numbers.\nIn the end the team has to agree on one number.\n\nThis technique is good for teams that are new to each other.\nWith Planning Poker they get a better understanding of how their Team partners estimate.\nIt’s also good for complex tickets that need a lot of discussion by the whole team.\nOn the counter side it’s a really time intensive estimation technique, since every ticket is discussed individually.\nAlso in the discussion part people tend to just go with the suggested number of the expert on the team for the particular field of interest.\n\n## Magic Estimation\n\nWith Magic Estimation the team estimates the tickets by sorting them into buckets and shift them if necessary.\nIn detail it works as follows:\n\nAll tickets that need an estimation are spread equally amongst all team members.\nThe team members decide on their own or with the help of colleagues – discussion is very welcome – how many story points their tickets should receive and sort them into the according bucket (usually a piece of paper with the Fibonacci number or T-shirt size on it).\nAfter all tickets have been sorted, the team walks past the buckets and everyone takes a look at every ticket.\nIf a team member thinks a ticket is placed incorrectly, they can move the ticket to another bucket.\nBut they have to mark it so everyone knows the ticket has been moved.\nThen everyone walks past the tickets a second time and they can be moved again.\nIf tickets have been moved twice or more, these need to be discussed separately (e.g. with Planning Poker).\nAll other tickets are now estimated.\nThis technique is good for teams that know each other really well and for long lists of easier tickets (e.g. bug-lists).\nIt is much faster than Planning Poker but can lead to wrong estimations on complex tickets.\n\n## Related posts\n\n* [Scrum Basics: What is Scrum?](https://developer.epages.com/blog/2015/10/13/scrum-basics-1.html)\n* [Scrum Basics: Scrum Roles](https://developer.epages.com/blog/2015/11/19/scrum-basics-2.html)\n* [Scrum Basics: Scrum Meetings](https://developer.epages.com/blog/2015/12/15/scrum-basics-3.html)\n* [Scrum Basics: Principles and Values](https://developer.epages.com/blog/2016/02/25/scrum-basics-5.html)\n* [Scrum Basics: Practicing it](https://developer.epages.com/blog/2016/03/22/scrum-basics-6.html)\n","source":"_posts/2016-01-26-scrum-basics-4.md","raw":"---\nlayout: post\ntitle: \"Scrum Basics: Estimating\"\ndate: \"2016-01-26 07:23:00\"\nimage: blog-header/estimation.jpg\ncategories: agile\nauthors: [\"Anja B.\"]\n---\n\nWelcome to part four of our Scrum Basics Series.\nToday we will have a look at estimation principles and techniques used in Scrum.\n\nThere are some basics that are completely different to estimations in waterfall projects.\nFor example, in Scrum we don’t estimate time, but effort.\nAlso tickets are estimated relative to each other or to example tickets the team created.\nIn Scrum we estimate in story points.\nBut in order to know what that means you need to be clear about what a story is.\n\n## Epics, Stories, Story Points and Velocity\n\nAn *Epic* is the ticket type used for features.\nDevelopers would not work on it directly, but through stories.\nThat means a *User Story* is a small part of a feature.\nIt must be small enough to fit into a sprint and should work and be potentially shippable by itself.\nA user story usually answers three questions: **Who** wants **what** and **why**?\nTherefore it is structured in the following way: “As … I want … to be able to…”.\nIt’s called user story because it’s normally told from an end-user's perspective.\nEach story also has acceptance criteria that have to be fulfilled to consider it done.\nIdeally, it should also cover all expert areas within a team (e.g. for a piece of software it should contain backend and frontend development as well as design).\n\nWithin the Backlog Refinement the team members estimate the stories.\nAs already said, they don’t estimate time, but effort.\nTo symbolise the effort, Scrum Teams use *Story Points*.\nThose are typically [Fibonacci numbers](https://en.wikipedia.org/wiki/Fibonacci_number): 1, 2, 3, 5, 8, 13, 21.\nAn alternative are T-shirt sizes.\nThose are usually more roughly because they only represent 4 stages: S, M, L or XL.\nTo being able have a more precise measurement, most often some of the Fibonacci numbers are assigned to the T-shirt sizes (e.g. S=2, M=5, L=13, XL=21).\nThe idea behind using Fibonacci is that the bigger a ticket is, the harder it gets to estimate it precisely.\nTherefore, the steps between the numbers will increase.\n\n{% image blog/blog-scrum4-burndown-chart.jpg %}\n\nDuring the sprint the story points of all closed tickets are counted.\nIn the end you get a number that represents how much a team is capable of solving within a sprint.\nMeasure this number across several sprints and build an average and you get the so called *Velocity* of a team.\nVelocities between different teams are not comparable, since every team has its own understanding of the effort behind a story point.\nThe Product Owner can use the velocity for long-term planning.\nTo help the team see how good they are on track within a sprint, Scrum uses so called *Burndown Charts*.\nThey show the number of closed story points on a time scale representing the sprint.\n\n## Planning Poker\n\n{% image blog/blog-scrum4-planning-poker.jpg 45% left %}\n\nPlanning Poker is probably the most used estimation technique in Scrum.\nFor this technique every team member gets a set of Planning Poker cards, which show the Fibonacci row.\nAt the beginning the Product Owner presents a ticket that needs an estimation.\nThe team then clarifies all questions regarding the ticket.\nThen each member chooses the effort they thinks fits best to this card.\nAll cards are then turned around at the same time for everyone to see.\nThe team discusses especially the highest and lowest number to understand the reasons why the team members chose those numbers.\nIn the end the team has to agree on one number.\n\nThis technique is good for teams that are new to each other.\nWith Planning Poker they get a better understanding of how their Team partners estimate.\nIt’s also good for complex tickets that need a lot of discussion by the whole team.\nOn the counter side it’s a really time intensive estimation technique, since every ticket is discussed individually.\nAlso in the discussion part people tend to just go with the suggested number of the expert on the team for the particular field of interest.\n\n## Magic Estimation\n\nWith Magic Estimation the team estimates the tickets by sorting them into buckets and shift them if necessary.\nIn detail it works as follows:\n\nAll tickets that need an estimation are spread equally amongst all team members.\nThe team members decide on their own or with the help of colleagues – discussion is very welcome – how many story points their tickets should receive and sort them into the according bucket (usually a piece of paper with the Fibonacci number or T-shirt size on it).\nAfter all tickets have been sorted, the team walks past the buckets and everyone takes a look at every ticket.\nIf a team member thinks a ticket is placed incorrectly, they can move the ticket to another bucket.\nBut they have to mark it so everyone knows the ticket has been moved.\nThen everyone walks past the tickets a second time and they can be moved again.\nIf tickets have been moved twice or more, these need to be discussed separately (e.g. with Planning Poker).\nAll other tickets are now estimated.\nThis technique is good for teams that know each other really well and for long lists of easier tickets (e.g. bug-lists).\nIt is much faster than Planning Poker but can lead to wrong estimations on complex tickets.\n\n## Related posts\n\n* [Scrum Basics: What is Scrum?](https://developer.epages.com/blog/2015/10/13/scrum-basics-1.html)\n* [Scrum Basics: Scrum Roles](https://developer.epages.com/blog/2015/11/19/scrum-basics-2.html)\n* [Scrum Basics: Scrum Meetings](https://developer.epages.com/blog/2015/12/15/scrum-basics-3.html)\n* [Scrum Basics: Principles and Values](https://developer.epages.com/blog/2016/02/25/scrum-basics-5.html)\n* [Scrum Basics: Practicing it](https://developer.epages.com/blog/2016/03/22/scrum-basics-6.html)\n","slug":"2016-01-26-scrum-basics-4","published":1,"updated":"2016-09-20T14:31:48.000Z","comments":1,"photos":[],"link":"","_id":"ciu6nuh9l0024hqyx10qivexa","content":"<p>Welcome to part four of our Scrum Basics Series.<br>Today we will have a look at estimation principles and techniques used in Scrum.</p>\n<p>There are some basics that are completely different to estimations in waterfall projects.<br>For example, in Scrum we don’t estimate time, but effort.<br>Also tickets are estimated relative to each other or to example tickets the team created.<br>In Scrum we estimate in story points.<br>But in order to know what that means you need to be clear about what a story is.</p>\n<h2 id=\"Epics-Stories-Story-Points-and-Velocity\"><a href=\"#Epics-Stories-Story-Points-and-Velocity\" class=\"headerlink\" title=\"Epics, Stories, Story Points and Velocity\"></a>Epics, Stories, Story Points and Velocity</h2><p>An <em>Epic</em> is the ticket type used for features.<br>Developers would not work on it directly, but through stories.<br>That means a <em>User Story</em> is a small part of a feature.<br>It must be small enough to fit into a sprint and should work and be potentially shippable by itself.<br>A user story usually answers three questions: <strong>Who</strong> wants <strong>what</strong> and <strong>why</strong>?<br>Therefore it is structured in the following way: “As … I want … to be able to…”.<br>It’s called user story because it’s normally told from an end-user’s perspective.<br>Each story also has acceptance criteria that have to be fulfilled to consider it done.<br>Ideally, it should also cover all expert areas within a team (e.g. for a piece of software it should contain backend and frontend development as well as design).</p>\n<p>Within the Backlog Refinement the team members estimate the stories.<br>As already said, they don’t estimate time, but effort.<br>To symbolise the effort, Scrum Teams use <em>Story Points</em>.<br>Those are typically <a href=\"https://en.wikipedia.org/wiki/Fibonacci_number\" target=\"_blank\" rel=\"external\">Fibonacci numbers</a>: 1, 2, 3, 5, 8, 13, 21.<br>An alternative are T-shirt sizes.<br>Those are usually more roughly because they only represent 4 stages: S, M, L or XL.<br>To being able have a more precise measurement, most often some of the Fibonacci numbers are assigned to the T-shirt sizes (e.g. S=2, M=5, L=13, XL=21).<br>The idea behind using Fibonacci is that the bigger a ticket is, the harder it gets to estimate it precisely.<br>Therefore, the steps between the numbers will increase.</p>\n<img class=\"blog/blog-scrum4-burndown-chart.jpg\">\n<p>During the sprint the story points of all closed tickets are counted.<br>In the end you get a number that represents how much a team is capable of solving within a sprint.<br>Measure this number across several sprints and build an average and you get the so called <em>Velocity</em> of a team.<br>Velocities between different teams are not comparable, since every team has its own understanding of the effort behind a story point.<br>The Product Owner can use the velocity for long-term planning.<br>To help the team see how good they are on track within a sprint, Scrum uses so called <em>Burndown Charts</em>.<br>They show the number of closed story points on a time scale representing the sprint.</p>\n<h2 id=\"Planning-Poker\"><a href=\"#Planning-Poker\" class=\"headerlink\" title=\"Planning Poker\"></a>Planning Poker</h2><img class=\"blog/blog-scrum4-planning-poker.jpg 45% left\">\n<p>Planning Poker is probably the most used estimation technique in Scrum.<br>For this technique every team member gets a set of Planning Poker cards, which show the Fibonacci row.<br>At the beginning the Product Owner presents a ticket that needs an estimation.<br>The team then clarifies all questions regarding the ticket.<br>Then each member chooses the effort they thinks fits best to this card.<br>All cards are then turned around at the same time for everyone to see.<br>The team discusses especially the highest and lowest number to understand the reasons why the team members chose those numbers.<br>In the end the team has to agree on one number.</p>\n<p>This technique is good for teams that are new to each other.<br>With Planning Poker they get a better understanding of how their Team partners estimate.<br>It’s also good for complex tickets that need a lot of discussion by the whole team.<br>On the counter side it’s a really time intensive estimation technique, since every ticket is discussed individually.<br>Also in the discussion part people tend to just go with the suggested number of the expert on the team for the particular field of interest.</p>\n<h2 id=\"Magic-Estimation\"><a href=\"#Magic-Estimation\" class=\"headerlink\" title=\"Magic Estimation\"></a>Magic Estimation</h2><p>With Magic Estimation the team estimates the tickets by sorting them into buckets and shift them if necessary.<br>In detail it works as follows:</p>\n<p>All tickets that need an estimation are spread equally amongst all team members.<br>The team members decide on their own or with the help of colleagues – discussion is very welcome – how many story points their tickets should receive and sort them into the according bucket (usually a piece of paper with the Fibonacci number or T-shirt size on it).<br>After all tickets have been sorted, the team walks past the buckets and everyone takes a look at every ticket.<br>If a team member thinks a ticket is placed incorrectly, they can move the ticket to another bucket.<br>But they have to mark it so everyone knows the ticket has been moved.<br>Then everyone walks past the tickets a second time and they can be moved again.<br>If tickets have been moved twice or more, these need to be discussed separately (e.g. with Planning Poker).<br>All other tickets are now estimated.<br>This technique is good for teams that know each other really well and for long lists of easier tickets (e.g. bug-lists).<br>It is much faster than Planning Poker but can lead to wrong estimations on complex tickets.</p>\n<h2 id=\"Related-posts\"><a href=\"#Related-posts\" class=\"headerlink\" title=\"Related posts\"></a>Related posts</h2><ul>\n<li><a href=\"https://developer.epages.com/blog/2015/10/13/scrum-basics-1.html\" target=\"_blank\" rel=\"external\">Scrum Basics: What is Scrum?</a></li>\n<li><a href=\"https://developer.epages.com/blog/2015/11/19/scrum-basics-2.html\" target=\"_blank\" rel=\"external\">Scrum Basics: Scrum Roles</a></li>\n<li><a href=\"https://developer.epages.com/blog/2015/12/15/scrum-basics-3.html\" target=\"_blank\" rel=\"external\">Scrum Basics: Scrum Meetings</a></li>\n<li><a href=\"https://developer.epages.com/blog/2016/02/25/scrum-basics-5.html\" target=\"_blank\" rel=\"external\">Scrum Basics: Principles and Values</a></li>\n<li><a href=\"https://developer.epages.com/blog/2016/03/22/scrum-basics-6.html\" target=\"_blank\" rel=\"external\">Scrum Basics: Practicing it</a></li>\n</ul>\n","excerpt":"","more":"<p>Welcome to part four of our Scrum Basics Series.<br>Today we will have a look at estimation principles and techniques used in Scrum.</p>\n<p>There are some basics that are completely different to estimations in waterfall projects.<br>For example, in Scrum we don’t estimate time, but effort.<br>Also tickets are estimated relative to each other or to example tickets the team created.<br>In Scrum we estimate in story points.<br>But in order to know what that means you need to be clear about what a story is.</p>\n<h2 id=\"Epics-Stories-Story-Points-and-Velocity\"><a href=\"#Epics-Stories-Story-Points-and-Velocity\" class=\"headerlink\" title=\"Epics, Stories, Story Points and Velocity\"></a>Epics, Stories, Story Points and Velocity</h2><p>An <em>Epic</em> is the ticket type used for features.<br>Developers would not work on it directly, but through stories.<br>That means a <em>User Story</em> is a small part of a feature.<br>It must be small enough to fit into a sprint and should work and be potentially shippable by itself.<br>A user story usually answers three questions: <strong>Who</strong> wants <strong>what</strong> and <strong>why</strong>?<br>Therefore it is structured in the following way: “As … I want … to be able to…”.<br>It’s called user story because it’s normally told from an end-user’s perspective.<br>Each story also has acceptance criteria that have to be fulfilled to consider it done.<br>Ideally, it should also cover all expert areas within a team (e.g. for a piece of software it should contain backend and frontend development as well as design).</p>\n<p>Within the Backlog Refinement the team members estimate the stories.<br>As already said, they don’t estimate time, but effort.<br>To symbolise the effort, Scrum Teams use <em>Story Points</em>.<br>Those are typically <a href=\"https://en.wikipedia.org/wiki/Fibonacci_number\">Fibonacci numbers</a>: 1, 2, 3, 5, 8, 13, 21.<br>An alternative are T-shirt sizes.<br>Those are usually more roughly because they only represent 4 stages: S, M, L or XL.<br>To being able have a more precise measurement, most often some of the Fibonacci numbers are assigned to the T-shirt sizes (e.g. S=2, M=5, L=13, XL=21).<br>The idea behind using Fibonacci is that the bigger a ticket is, the harder it gets to estimate it precisely.<br>Therefore, the steps between the numbers will increase.</p>\n<img class=\"blog/blog-scrum4-burndown-chart.jpg\">\n<p>During the sprint the story points of all closed tickets are counted.<br>In the end you get a number that represents how much a team is capable of solving within a sprint.<br>Measure this number across several sprints and build an average and you get the so called <em>Velocity</em> of a team.<br>Velocities between different teams are not comparable, since every team has its own understanding of the effort behind a story point.<br>The Product Owner can use the velocity for long-term planning.<br>To help the team see how good they are on track within a sprint, Scrum uses so called <em>Burndown Charts</em>.<br>They show the number of closed story points on a time scale representing the sprint.</p>\n<h2 id=\"Planning-Poker\"><a href=\"#Planning-Poker\" class=\"headerlink\" title=\"Planning Poker\"></a>Planning Poker</h2><img class=\"blog/blog-scrum4-planning-poker.jpg 45% left\">\n<p>Planning Poker is probably the most used estimation technique in Scrum.<br>For this technique every team member gets a set of Planning Poker cards, which show the Fibonacci row.<br>At the beginning the Product Owner presents a ticket that needs an estimation.<br>The team then clarifies all questions regarding the ticket.<br>Then each member chooses the effort they thinks fits best to this card.<br>All cards are then turned around at the same time for everyone to see.<br>The team discusses especially the highest and lowest number to understand the reasons why the team members chose those numbers.<br>In the end the team has to agree on one number.</p>\n<p>This technique is good for teams that are new to each other.<br>With Planning Poker they get a better understanding of how their Team partners estimate.<br>It’s also good for complex tickets that need a lot of discussion by the whole team.<br>On the counter side it’s a really time intensive estimation technique, since every ticket is discussed individually.<br>Also in the discussion part people tend to just go with the suggested number of the expert on the team for the particular field of interest.</p>\n<h2 id=\"Magic-Estimation\"><a href=\"#Magic-Estimation\" class=\"headerlink\" title=\"Magic Estimation\"></a>Magic Estimation</h2><p>With Magic Estimation the team estimates the tickets by sorting them into buckets and shift them if necessary.<br>In detail it works as follows:</p>\n<p>All tickets that need an estimation are spread equally amongst all team members.<br>The team members decide on their own or with the help of colleagues – discussion is very welcome – how many story points their tickets should receive and sort them into the according bucket (usually a piece of paper with the Fibonacci number or T-shirt size on it).<br>After all tickets have been sorted, the team walks past the buckets and everyone takes a look at every ticket.<br>If a team member thinks a ticket is placed incorrectly, they can move the ticket to another bucket.<br>But they have to mark it so everyone knows the ticket has been moved.<br>Then everyone walks past the tickets a second time and they can be moved again.<br>If tickets have been moved twice or more, these need to be discussed separately (e.g. with Planning Poker).<br>All other tickets are now estimated.<br>This technique is good for teams that know each other really well and for long lists of easier tickets (e.g. bug-lists).<br>It is much faster than Planning Poker but can lead to wrong estimations on complex tickets.</p>\n<h2 id=\"Related-posts\"><a href=\"#Related-posts\" class=\"headerlink\" title=\"Related posts\"></a>Related posts</h2><ul>\n<li><a href=\"https://developer.epages.com/blog/2015/10/13/scrum-basics-1.html\">Scrum Basics: What is Scrum?</a></li>\n<li><a href=\"https://developer.epages.com/blog/2015/11/19/scrum-basics-2.html\">Scrum Basics: Scrum Roles</a></li>\n<li><a href=\"https://developer.epages.com/blog/2015/12/15/scrum-basics-3.html\">Scrum Basics: Scrum Meetings</a></li>\n<li><a href=\"https://developer.epages.com/blog/2016/02/25/scrum-basics-5.html\">Scrum Basics: Principles and Values</a></li>\n<li><a href=\"https://developer.epages.com/blog/2016/03/22/scrum-basics-6.html\">Scrum Basics: Practicing it</a></li>\n</ul>\n"},{"layout":"post","title":"Results from the first Agile Hackathon at ePages","date":"2016-04-20T07:34:28.000Z","authors":["Anja B."],"_content":"\nFor two days Scrum Masters, Product Owners and some representatives of developers met at ePages headquarter Hamburg to discuss about the status quo of how agile ePages is.\nIn particular, we clarified the roles of POs and SMs at ePages, we talked about learnings and what could be improved.\n\n## First day\n\n{% img blog/blog-role-map.jpg 38% left %} Example of Role Map \n\nWe started off in the morning with drawing so called \"Role Maps\".\nIn such a map, you draw your connections to other roles or groups in the company.\nYou also indicate, how much energy you dedicate into those connections and what's the benefit.\nIt was interesting to see, how different some connections of roles are at ePages, depending on the company location you are working at.\n\nAfterwards, we quickly checked, how agile we think ePages is.\nThe agile coach, who moderated our agile hackathon, presented us the Agile Manifesto.\nWe voted from 1 (not true) to 10 (totally true) if we think that the four directives apply for ePages.\nWhile we were pretty close together and agreed on a high number for \"Working products are more important than documentation\", our opinions differed with regards to the other three directives.\nHere again, it depended on the team and the corresponding projects.\nBut in the total overview, we are on a pretty good way.\n\n## Responsibilities\n\nThe afternoon was dedicated to really understand and agree on the responsibilities of the roles of Product Owners and Scrum Masters.\nSince the views on the roles differed a lot depending on the company location, this caused some productive discussions.\nIn the end, we came up with the following definitions of the roles for ePages:\n\n{% img blog/blog-agile-manifesto.jpg 45% right %} Agile Manifesto \n\n### Product Owner\n\n#### Responsibilities\n\n* Defining the product vision\n* Stakeholder management\n* Creating epics and stories, prioritising and managing the backlog\n* Creating the roadmap (together with stakeholders and developers)\n* Communicating the business value of epics\n\n#### Skills\n\n* Knowledge about the product\n* Courage to say \"No\"\n* Communication skills - not only talking, but also listening skills\n* Empowering the team\n* Write stories/epics from a user's perspective\n\n#### Deliverables\n\n* Prioritised backlog, user stories, roadmap\n* Defined MVP and product increments for big projects\n* Receive information from stakeholders required for development (e.g. documentation, login data…)\n\n#### Testimonial\n\nFerdinand Piech (for creating and following a big product vision)\n\n#### Expectations\n\n* Respect the team's definition of done\n* Trust in the team\n* Ensuring that the user stories fulfil the definition of ready\n* Clear product vision and being able to communicate it\n\n### Scrum Masters\n\n#### Responsibilities - Skills - Expectations\n\n* Promote Scrum throughout the company (definition/persistence)\n* Spokesman of the team (organisation, let team focus on development)\n* Mediating in the team (empathy)\n* Guiding on process improvement (teaching)\n* Individual coaching of team members (coaching skills)\n\n#### Deliverables\n\n* Highly performant team (technical, collaboration)\n* Alignment of personal goals of developers and team goals\n* Process\n\n#### Testimonial\n\nObi-Wan Kenobi\n\n## Second day\n\n{% img blog/blog-backlog.jpg 45% right %} Backlog after workshop \n\nThe second day began with a session about magic estimation.\nMost of us already knew that, but it was a nice refreshment.\nWe also had short sessions about measuring the success of the Scrum Master work, impediment backlogs, transition team and pilot team.\nThe most important point on this day was to create a backlog of tasks we wanted to take out of the workshop.\n\n### Backlog after the workshop\n\nHere are the most important tasks we are going to tackle during the next weeks:\n\n* Setting up a transition team\n* Improve cooperation within the Scrum Master team (get a Scrum Master of Scrum Masters or coach from the outside)\n* Find out, if we can create a pilot team as future lab at ePages\n* Design Thinking workshops\n* Servant leadership training for SMs, POs and Management\n","source":"_posts/2016-04-20-agile-hackathon.md","raw":"---\nlayout: post\ntitle: \"Results from the first Agile Hackathon at ePages\"\ndate: \"2016-04-20 09:34:28\"\ncategories: agile\nauthors: [\"Anja B.\"]\n---\n\nFor two days Scrum Masters, Product Owners and some representatives of developers met at ePages headquarter Hamburg to discuss about the status quo of how agile ePages is.\nIn particular, we clarified the roles of POs and SMs at ePages, we talked about learnings and what could be improved.\n\n## First day\n\n{% img blog/blog-role-map.jpg 38% left %} Example of Role Map \n\nWe started off in the morning with drawing so called \"Role Maps\".\nIn such a map, you draw your connections to other roles or groups in the company.\nYou also indicate, how much energy you dedicate into those connections and what's the benefit.\nIt was interesting to see, how different some connections of roles are at ePages, depending on the company location you are working at.\n\nAfterwards, we quickly checked, how agile we think ePages is.\nThe agile coach, who moderated our agile hackathon, presented us the Agile Manifesto.\nWe voted from 1 (not true) to 10 (totally true) if we think that the four directives apply for ePages.\nWhile we were pretty close together and agreed on a high number for \"Working products are more important than documentation\", our opinions differed with regards to the other three directives.\nHere again, it depended on the team and the corresponding projects.\nBut in the total overview, we are on a pretty good way.\n\n## Responsibilities\n\nThe afternoon was dedicated to really understand and agree on the responsibilities of the roles of Product Owners and Scrum Masters.\nSince the views on the roles differed a lot depending on the company location, this caused some productive discussions.\nIn the end, we came up with the following definitions of the roles for ePages:\n\n{% img blog/blog-agile-manifesto.jpg 45% right %} Agile Manifesto \n\n### Product Owner\n\n#### Responsibilities\n\n* Defining the product vision\n* Stakeholder management\n* Creating epics and stories, prioritising and managing the backlog\n* Creating the roadmap (together with stakeholders and developers)\n* Communicating the business value of epics\n\n#### Skills\n\n* Knowledge about the product\n* Courage to say \"No\"\n* Communication skills - not only talking, but also listening skills\n* Empowering the team\n* Write stories/epics from a user's perspective\n\n#### Deliverables\n\n* Prioritised backlog, user stories, roadmap\n* Defined MVP and product increments for big projects\n* Receive information from stakeholders required for development (e.g. documentation, login data…)\n\n#### Testimonial\n\nFerdinand Piech (for creating and following a big product vision)\n\n#### Expectations\n\n* Respect the team's definition of done\n* Trust in the team\n* Ensuring that the user stories fulfil the definition of ready\n* Clear product vision and being able to communicate it\n\n### Scrum Masters\n\n#### Responsibilities - Skills - Expectations\n\n* Promote Scrum throughout the company (definition/persistence)\n* Spokesman of the team (organisation, let team focus on development)\n* Mediating in the team (empathy)\n* Guiding on process improvement (teaching)\n* Individual coaching of team members (coaching skills)\n\n#### Deliverables\n\n* Highly performant team (technical, collaboration)\n* Alignment of personal goals of developers and team goals\n* Process\n\n#### Testimonial\n\nObi-Wan Kenobi\n\n## Second day\n\n{% img blog/blog-backlog.jpg 45% right %} Backlog after workshop \n\nThe second day began with a session about magic estimation.\nMost of us already knew that, but it was a nice refreshment.\nWe also had short sessions about measuring the success of the Scrum Master work, impediment backlogs, transition team and pilot team.\nThe most important point on this day was to create a backlog of tasks we wanted to take out of the workshop.\n\n### Backlog after the workshop\n\nHere are the most important tasks we are going to tackle during the next weeks:\n\n* Setting up a transition team\n* Improve cooperation within the Scrum Master team (get a Scrum Master of Scrum Masters or coach from the outside)\n* Find out, if we can create a pilot team as future lab at ePages\n* Design Thinking workshops\n* Servant leadership training for SMs, POs and Management\n","slug":"2016-04-20-agile-hackathon","published":1,"updated":"2016-09-20T14:42:20.000Z","comments":1,"photos":[],"link":"","_id":"ciu6nuh9m0026hqyx1zvw00tg","content":"<p>For two days Scrum Masters, Product Owners and some representatives of developers met at ePages headquarter Hamburg to discuss about the status quo of how agile ePages is.<br>In particular, we clarified the roles of POs and SMs at ePages, we talked about learnings and what could be improved.</p>\n<h2 id=\"First-day\"><a href=\"#First-day\" class=\"headerlink\" title=\"First day\"></a>First day</h2><p><img class=\"blog/blog-role-map.jpg 38% left\"> Example of Role Map </p>\n<p>We started off in the morning with drawing so called “Role Maps”.<br>In such a map, you draw your connections to other roles or groups in the company.<br>You also indicate, how much energy you dedicate into those connections and what’s the benefit.<br>It was interesting to see, how different some connections of roles are at ePages, depending on the company location you are working at.</p>\n<p>Afterwards, we quickly checked, how agile we think ePages is.<br>The agile coach, who moderated our agile hackathon, presented us the Agile Manifesto.<br>We voted from 1 (not true) to 10 (totally true) if we think that the four directives apply for ePages.<br>While we were pretty close together and agreed on a high number for “Working products are more important than documentation”, our opinions differed with regards to the other three directives.<br>Here again, it depended on the team and the corresponding projects.<br>But in the total overview, we are on a pretty good way.</p>\n<h2 id=\"Responsibilities\"><a href=\"#Responsibilities\" class=\"headerlink\" title=\"Responsibilities\"></a>Responsibilities</h2><p>The afternoon was dedicated to really understand and agree on the responsibilities of the roles of Product Owners and Scrum Masters.<br>Since the views on the roles differed a lot depending on the company location, this caused some productive discussions.<br>In the end, we came up with the following definitions of the roles for ePages:</p>\n<p><img class=\"blog/blog-agile-manifesto.jpg 45% right\"> Agile Manifesto </p>\n<h3 id=\"Product-Owner\"><a href=\"#Product-Owner\" class=\"headerlink\" title=\"Product Owner\"></a>Product Owner</h3><h4 id=\"Responsibilities-1\"><a href=\"#Responsibilities-1\" class=\"headerlink\" title=\"Responsibilities\"></a>Responsibilities</h4><ul>\n<li>Defining the product vision</li>\n<li>Stakeholder management</li>\n<li>Creating epics and stories, prioritising and managing the backlog</li>\n<li>Creating the roadmap (together with stakeholders and developers)</li>\n<li>Communicating the business value of epics</li>\n</ul>\n<h4 id=\"Skills\"><a href=\"#Skills\" class=\"headerlink\" title=\"Skills\"></a>Skills</h4><ul>\n<li>Knowledge about the product</li>\n<li>Courage to say “No”</li>\n<li>Communication skills - not only talking, but also listening skills</li>\n<li>Empowering the team</li>\n<li>Write stories/epics from a user’s perspective</li>\n</ul>\n<h4 id=\"Deliverables\"><a href=\"#Deliverables\" class=\"headerlink\" title=\"Deliverables\"></a>Deliverables</h4><ul>\n<li>Prioritised backlog, user stories, roadmap</li>\n<li>Defined MVP and product increments for big projects</li>\n<li>Receive information from stakeholders required for development (e.g. documentation, login data…)</li>\n</ul>\n<h4 id=\"Testimonial\"><a href=\"#Testimonial\" class=\"headerlink\" title=\"Testimonial\"></a>Testimonial</h4><p>Ferdinand Piech (for creating and following a big product vision)</p>\n<h4 id=\"Expectations\"><a href=\"#Expectations\" class=\"headerlink\" title=\"Expectations\"></a>Expectations</h4><ul>\n<li>Respect the team’s definition of done</li>\n<li>Trust in the team</li>\n<li>Ensuring that the user stories fulfil the definition of ready</li>\n<li>Clear product vision and being able to communicate it</li>\n</ul>\n<h3 id=\"Scrum-Masters\"><a href=\"#Scrum-Masters\" class=\"headerlink\" title=\"Scrum Masters\"></a>Scrum Masters</h3><h4 id=\"Responsibilities-Skills-Expectations\"><a href=\"#Responsibilities-Skills-Expectations\" class=\"headerlink\" title=\"Responsibilities - Skills - Expectations\"></a>Responsibilities - Skills - Expectations</h4><ul>\n<li>Promote Scrum throughout the company (definition/persistence)</li>\n<li>Spokesman of the team (organisation, let team focus on development)</li>\n<li>Mediating in the team (empathy)</li>\n<li>Guiding on process improvement (teaching)</li>\n<li>Individual coaching of team members (coaching skills)</li>\n</ul>\n<h4 id=\"Deliverables-1\"><a href=\"#Deliverables-1\" class=\"headerlink\" title=\"Deliverables\"></a>Deliverables</h4><ul>\n<li>Highly performant team (technical, collaboration)</li>\n<li>Alignment of personal goals of developers and team goals</li>\n<li>Process</li>\n</ul>\n<h4 id=\"Testimonial-1\"><a href=\"#Testimonial-1\" class=\"headerlink\" title=\"Testimonial\"></a>Testimonial</h4><p>Obi-Wan Kenobi</p>\n<h2 id=\"Second-day\"><a href=\"#Second-day\" class=\"headerlink\" title=\"Second day\"></a>Second day</h2><p><img class=\"blog/blog-backlog.jpg 45% right\"> Backlog after workshop </p>\n<p>The second day began with a session about magic estimation.<br>Most of us already knew that, but it was a nice refreshment.<br>We also had short sessions about measuring the success of the Scrum Master work, impediment backlogs, transition team and pilot team.<br>The most important point on this day was to create a backlog of tasks we wanted to take out of the workshop.</p>\n<h3 id=\"Backlog-after-the-workshop\"><a href=\"#Backlog-after-the-workshop\" class=\"headerlink\" title=\"Backlog after the workshop\"></a>Backlog after the workshop</h3><p>Here are the most important tasks we are going to tackle during the next weeks:</p>\n<ul>\n<li>Setting up a transition team</li>\n<li>Improve cooperation within the Scrum Master team (get a Scrum Master of Scrum Masters or coach from the outside)</li>\n<li>Find out, if we can create a pilot team as future lab at ePages</li>\n<li>Design Thinking workshops</li>\n<li>Servant leadership training for SMs, POs and Management</li>\n</ul>\n","excerpt":"","more":"<p>For two days Scrum Masters, Product Owners and some representatives of developers met at ePages headquarter Hamburg to discuss about the status quo of how agile ePages is.<br>In particular, we clarified the roles of POs and SMs at ePages, we talked about learnings and what could be improved.</p>\n<h2 id=\"First-day\"><a href=\"#First-day\" class=\"headerlink\" title=\"First day\"></a>First day</h2><p><img class=\"blog/blog-role-map.jpg 38% left\"> Example of Role Map </p>\n<p>We started off in the morning with drawing so called “Role Maps”.<br>In such a map, you draw your connections to other roles or groups in the company.<br>You also indicate, how much energy you dedicate into those connections and what’s the benefit.<br>It was interesting to see, how different some connections of roles are at ePages, depending on the company location you are working at.</p>\n<p>Afterwards, we quickly checked, how agile we think ePages is.<br>The agile coach, who moderated our agile hackathon, presented us the Agile Manifesto.<br>We voted from 1 (not true) to 10 (totally true) if we think that the four directives apply for ePages.<br>While we were pretty close together and agreed on a high number for “Working products are more important than documentation”, our opinions differed with regards to the other three directives.<br>Here again, it depended on the team and the corresponding projects.<br>But in the total overview, we are on a pretty good way.</p>\n<h2 id=\"Responsibilities\"><a href=\"#Responsibilities\" class=\"headerlink\" title=\"Responsibilities\"></a>Responsibilities</h2><p>The afternoon was dedicated to really understand and agree on the responsibilities of the roles of Product Owners and Scrum Masters.<br>Since the views on the roles differed a lot depending on the company location, this caused some productive discussions.<br>In the end, we came up with the following definitions of the roles for ePages:</p>\n<p><img class=\"blog/blog-agile-manifesto.jpg 45% right\"> Agile Manifesto </p>\n<h3 id=\"Product-Owner\"><a href=\"#Product-Owner\" class=\"headerlink\" title=\"Product Owner\"></a>Product Owner</h3><h4 id=\"Responsibilities-1\"><a href=\"#Responsibilities-1\" class=\"headerlink\" title=\"Responsibilities\"></a>Responsibilities</h4><ul>\n<li>Defining the product vision</li>\n<li>Stakeholder management</li>\n<li>Creating epics and stories, prioritising and managing the backlog</li>\n<li>Creating the roadmap (together with stakeholders and developers)</li>\n<li>Communicating the business value of epics</li>\n</ul>\n<h4 id=\"Skills\"><a href=\"#Skills\" class=\"headerlink\" title=\"Skills\"></a>Skills</h4><ul>\n<li>Knowledge about the product</li>\n<li>Courage to say “No”</li>\n<li>Communication skills - not only talking, but also listening skills</li>\n<li>Empowering the team</li>\n<li>Write stories/epics from a user’s perspective</li>\n</ul>\n<h4 id=\"Deliverables\"><a href=\"#Deliverables\" class=\"headerlink\" title=\"Deliverables\"></a>Deliverables</h4><ul>\n<li>Prioritised backlog, user stories, roadmap</li>\n<li>Defined MVP and product increments for big projects</li>\n<li>Receive information from stakeholders required for development (e.g. documentation, login data…)</li>\n</ul>\n<h4 id=\"Testimonial\"><a href=\"#Testimonial\" class=\"headerlink\" title=\"Testimonial\"></a>Testimonial</h4><p>Ferdinand Piech (for creating and following a big product vision)</p>\n<h4 id=\"Expectations\"><a href=\"#Expectations\" class=\"headerlink\" title=\"Expectations\"></a>Expectations</h4><ul>\n<li>Respect the team’s definition of done</li>\n<li>Trust in the team</li>\n<li>Ensuring that the user stories fulfil the definition of ready</li>\n<li>Clear product vision and being able to communicate it</li>\n</ul>\n<h3 id=\"Scrum-Masters\"><a href=\"#Scrum-Masters\" class=\"headerlink\" title=\"Scrum Masters\"></a>Scrum Masters</h3><h4 id=\"Responsibilities-Skills-Expectations\"><a href=\"#Responsibilities-Skills-Expectations\" class=\"headerlink\" title=\"Responsibilities - Skills - Expectations\"></a>Responsibilities - Skills - Expectations</h4><ul>\n<li>Promote Scrum throughout the company (definition/persistence)</li>\n<li>Spokesman of the team (organisation, let team focus on development)</li>\n<li>Mediating in the team (empathy)</li>\n<li>Guiding on process improvement (teaching)</li>\n<li>Individual coaching of team members (coaching skills)</li>\n</ul>\n<h4 id=\"Deliverables-1\"><a href=\"#Deliverables-1\" class=\"headerlink\" title=\"Deliverables\"></a>Deliverables</h4><ul>\n<li>Highly performant team (technical, collaboration)</li>\n<li>Alignment of personal goals of developers and team goals</li>\n<li>Process</li>\n</ul>\n<h4 id=\"Testimonial-1\"><a href=\"#Testimonial-1\" class=\"headerlink\" title=\"Testimonial\"></a>Testimonial</h4><p>Obi-Wan Kenobi</p>\n<h2 id=\"Second-day\"><a href=\"#Second-day\" class=\"headerlink\" title=\"Second day\"></a>Second day</h2><p><img class=\"blog/blog-backlog.jpg 45% right\"> Backlog after workshop </p>\n<p>The second day began with a session about magic estimation.<br>Most of us already knew that, but it was a nice refreshment.<br>We also had short sessions about measuring the success of the Scrum Master work, impediment backlogs, transition team and pilot team.<br>The most important point on this day was to create a backlog of tasks we wanted to take out of the workshop.</p>\n<h3 id=\"Backlog-after-the-workshop\"><a href=\"#Backlog-after-the-workshop\" class=\"headerlink\" title=\"Backlog after the workshop\"></a>Backlog after the workshop</h3><p>Here are the most important tasks we are going to tackle during the next weeks:</p>\n<ul>\n<li>Setting up a transition team</li>\n<li>Improve cooperation within the Scrum Master team (get a Scrum Master of Scrum Masters or coach from the outside)</li>\n<li>Find out, if we can create a pilot team as future lab at ePages</li>\n<li>Design Thinking workshops</li>\n<li>Servant leadership training for SMs, POs and Management</li>\n</ul>\n"},{"layout":"post","title":"Guest post: Softwerkskammer Jena shipped the Docker Party to ePages!","date":"2016-04-21T10:04:21.000Z","image":"blog-header/docker-party.jpg","authors":["Softwerkskammer Jena (Oliver and Benjamin)"],"_content":"\nThe newly founded [Softwerkskammer Jena](http://www.softwerkskammer.org/groups/jena) had its first [Developer Meetup](http://www.meetup.com/jenadevs) at the beginning of April.\nePages hosted the event and provided conference rooms, several workstations as well as a variety of snacks, pizza and beverages.\nOver 35 attendees joined the Docker Party.\nDevelopers from nearby companies, students from the local universities and even some freelancers followed the [invitation](https://github.com/jenadevs/jenadevs-meetup-001-docker-party/blob/master/orga/Softwerkskammer_Jena_Developers_Meetup_001_Docker_Party.pdf).\nWe had 4 hours of coding fun from 6 pm until nearly 10 pm with an open end at the local pub, where vivid discussions lasted until 2 am in the morning.\n\n## Agenda\n\nWe started with a short meet and greet as well as a brief introduction about the [Softwerkskammer](http://softwerkskammer.org) – the german part of the [Software Craftsmanship Community](http://manifesto.softwarecraftsmanship.org) – and its current distribution together with some helpful contact information like the [@jenadevs](https://twitter.com/jenadevs) Twitter account.\n\nThen the Docker Party was launched, and we celebrated the [3rd birthday of Docker](https://www.docker.com/community/docker-birthday-3)!\n\nThe agenda included a one hour talk along with a demo to introduce the technological foundation as well as different workshops for every skill level:\n\n  1. **Beginners:** The official Docker [birthday app project](https://github.com/jenadevs/docker-birthday-3)\n  2. **Advanced:** Build your own Dockerfile according to best practises in conjunction with integration tests\n  3. **Special:** CoresOS cluster workshop\n  4. **Easter egg:** [Orchestration workshop](https://github.com/jenadevs/orchestration-workshop) by [Jérôme Petazzoni](https://twitter.com/jpetazzo), the creator of [Docker-in-Docker](https://github.com/jpetazzo/dind)\n\n## Introduction talk with demo and best practises\n\nThe first part of the introduction talk focused on the Docker basics, the components of the Docker ecosystem and the general tooling workflow of building images, running containers and pushing them to the Docker Hub.\nWe had a demo on the basic commands along with some live coding on the terminal, where several containers were also inspected at runtime.\n\nThe second part considered some best practises for writing your own Dockerfile, based on the [official Docker recommendations](https://docs.docker.com/engine/userguide/eng-image/dockerfile_best-practices), tips by [Michael](http://crosbymichael.com/dockerfile-best-practices.html) [Crosby](http://crosbymichael.com/dockerfile-best-practices-take-2.html) as well as the experiences of [epagesdevs](http://twitter.com/epagesdevs) with developing, testing, integrating, deploying and running supportive images for the eCommerce platform.\n\nThis was a nice opportunity to also show some typical use cases at ePages, e.g. the Continuous Delivery Pipeline for integration testing, or that both, the ePages and the provider infrastructure are already based partly on [Kubernetes](http://kubernetes.io).\nThe talk finished with some typical base images as well as a discussion about official app environment images.\n\n{% image blog/blog-docker-presentation.jpg %}\n\n## Containers, containers, con... er workshops!\n\nUpfront, all necessary material and code for the workshops was hosted on the jenadevs [GitHub](https://github.com/jenadevs) account, which even offers the [complete presentation](https://github.com/jenadevs/jenadevs-meetup-001-docker-party).\nGood news: all material of [jenadevs](https://github.com/jenadevs) is free and will always be open-source!\n\n{% image blog/blog-docker-workflow.jpg 30% right %}\n\n### Beginners workshop\n\nThe goal of the beginners workshop was to setup the Docker environment, learn the basic commands, follow the common workflow and become familiar with Docker Compose.\nThe participants were guided through the official Docker birthday [tutorial](https://github.com/jenadevs/docker-birthday-3/blob/master/tutorial.md) by Benjamin Nothdurft and Kay Abendroth.\nAs a first step, the Docker newbies built a simple web application, which served random kitten pictures using the [Flask](http://flask.pocoo.org) microframework.\nIn the end, the beginners already created and customised a multi-container voting application with a Python user app, a Redis queue for buffering, a Java worker for processing, a PostgreSQL database for storage and a Javascript administration app - all running from a single `docker-compose.yml` file.\n\n{% image blog/blog-docker-beginners.jpg 40% left %}\n\n### Advanced workshop\n\nThis workshop focused on writing your own Dockerfiles, running the containers and configuring integration testing with [CircleCI](https://circleci.com).\nBastian Klein prepared an empty custom [Magento](https://magento.com) `Dockerfile` and `Circle.yml` with comments left only, where the implementation code was completely removed.\nThe attendees then had to figure out how the Dockerfile commands needed to be configured, guided by the workshop maintainer.\n\n{% image blog/blog-docker-kubernetes.jpg 30% right %}\n\n### Special workshop\n\nThe most experienced Docker users gathered together in the special workshop, where the main focus was a bit shifted.\nThree workstation laptops had been prepared to introduce [CoreOS](https://coreos.com) to the participants.\nAndreas Grohmann introduced the open-source lightweight operating system designed to provide infrastructure to clustered deployments to the each participant.\nThe goal was to [setup a cluster environment](https://developer.epages.com/blog/2016/01/19/setup-a-coreos-cluster.html#why-use-coreos) with three nodes and run Docker on it.\nEveryone succeeded.\nAfterwards, Christian Köhler gave an insight on how to configure Kubernetes with a short demonstration.\nHe also distinctly outlined the advantages of Docker Swarm.\n\n## Summary\n\nIn retrospect, this meetup was a great success.\nEvery participant had the possibility to have fun, meet other developers and learn something new.\nExcept for the beginners, who finalised their well-documented tutorial at home, all participants were able to finish all workshop tasks on time with excellent results.\nSo it was obvious, that a lot of guests joined parts of the orga team in the local bar and just talked about the experience in their developer life, their favourite editors and some \"nerdy\" stuff.\n\nThanks to all attendees and ePages coworkers for making this happen!\n\n## Next meetup\n\nThe goal of the Softwerkskammer Jena is to establish a platform for regular meetings.\nAnd we already arranged the next meetup!\nIn the course of a one-day event, we will facilitate a [coding dojo](http://codingdojo.org) consisting of a classical [Coderetreat](http://coderetreat.org) and lighting talks with demos on [TDD](https://en.wikipedia.org/wiki/Test-driven_development) concepts upfront, e.g. Unit testing with mock objects.\nAgain, the participants will be able to choose between different workshop-like groups.\nIn each group we train our coding skills on a specific kata in iterative 45-minute-rounds under certain [constraints](http://coderetreat.org/facilitating/activity-catalog) in [pairs](https://en.wikipedia.org/wiki/Pair_programming) and with different team mates in each round.\n\nWe are very happy that [Marco Emrich](https://twitter.com/marcoemrich) from the [Softwerkskammer Nürnberg](https://www.softwerkskammer.org/groups/nuernberg) will join us - a highly passionate trainer and an experienced Coderetreat facilitator.\nWe cannot think of anyone better to help the participants understand how to start with the test-first approach!\n\nSave the date: this one-day event is planned for Saturday, the 21st of May 2016 from 9:30 am until 5:30 pm!\nFeel free to already sign up for the event at the [meetup](http://www.meetup.com/jenadevs) or the [Softwerkskammer](https://www.softwerkskammer.org/groups/jena) platform.\n\nPS: The Docker shirts and stickers finally arrived yesterday after persistent negotiations with the customs office.\nYou may catch yours at the next meetup!\nSee you there.\n\n{% img blog/blog-docker-jenadevs-orga.jpg 47% left %}The orga team\n\n{% img blog/blog-docker-stickers.jpg 47% right %}The Docker shirts and stickers\n","source":"_posts/2016-04-21-jenadevs-docker-party.md","raw":"---\nlayout: post\ntitle: \"Guest post: Softwerkskammer Jena shipped the Docker Party to ePages!\"\ndate: \"2016-04-21 12:04:21\"\nimage: blog-header/docker-party.jpg\ncategories: events\nauthors: [\"Softwerkskammer Jena (Oliver and Benjamin)\"]\n---\n\nThe newly founded [Softwerkskammer Jena](http://www.softwerkskammer.org/groups/jena) had its first [Developer Meetup](http://www.meetup.com/jenadevs) at the beginning of April.\nePages hosted the event and provided conference rooms, several workstations as well as a variety of snacks, pizza and beverages.\nOver 35 attendees joined the Docker Party.\nDevelopers from nearby companies, students from the local universities and even some freelancers followed the [invitation](https://github.com/jenadevs/jenadevs-meetup-001-docker-party/blob/master/orga/Softwerkskammer_Jena_Developers_Meetup_001_Docker_Party.pdf).\nWe had 4 hours of coding fun from 6 pm until nearly 10 pm with an open end at the local pub, where vivid discussions lasted until 2 am in the morning.\n\n## Agenda\n\nWe started with a short meet and greet as well as a brief introduction about the [Softwerkskammer](http://softwerkskammer.org) – the german part of the [Software Craftsmanship Community](http://manifesto.softwarecraftsmanship.org) – and its current distribution together with some helpful contact information like the [@jenadevs](https://twitter.com/jenadevs) Twitter account.\n\nThen the Docker Party was launched, and we celebrated the [3rd birthday of Docker](https://www.docker.com/community/docker-birthday-3)!\n\nThe agenda included a one hour talk along with a demo to introduce the technological foundation as well as different workshops for every skill level:\n\n  1. **Beginners:** The official Docker [birthday app project](https://github.com/jenadevs/docker-birthday-3)\n  2. **Advanced:** Build your own Dockerfile according to best practises in conjunction with integration tests\n  3. **Special:** CoresOS cluster workshop\n  4. **Easter egg:** [Orchestration workshop](https://github.com/jenadevs/orchestration-workshop) by [Jérôme Petazzoni](https://twitter.com/jpetazzo), the creator of [Docker-in-Docker](https://github.com/jpetazzo/dind)\n\n## Introduction talk with demo and best practises\n\nThe first part of the introduction talk focused on the Docker basics, the components of the Docker ecosystem and the general tooling workflow of building images, running containers and pushing them to the Docker Hub.\nWe had a demo on the basic commands along with some live coding on the terminal, where several containers were also inspected at runtime.\n\nThe second part considered some best practises for writing your own Dockerfile, based on the [official Docker recommendations](https://docs.docker.com/engine/userguide/eng-image/dockerfile_best-practices), tips by [Michael](http://crosbymichael.com/dockerfile-best-practices.html) [Crosby](http://crosbymichael.com/dockerfile-best-practices-take-2.html) as well as the experiences of [epagesdevs](http://twitter.com/epagesdevs) with developing, testing, integrating, deploying and running supportive images for the eCommerce platform.\n\nThis was a nice opportunity to also show some typical use cases at ePages, e.g. the Continuous Delivery Pipeline for integration testing, or that both, the ePages and the provider infrastructure are already based partly on [Kubernetes](http://kubernetes.io).\nThe talk finished with some typical base images as well as a discussion about official app environment images.\n\n{% image blog/blog-docker-presentation.jpg %}\n\n## Containers, containers, con... er workshops!\n\nUpfront, all necessary material and code for the workshops was hosted on the jenadevs [GitHub](https://github.com/jenadevs) account, which even offers the [complete presentation](https://github.com/jenadevs/jenadevs-meetup-001-docker-party).\nGood news: all material of [jenadevs](https://github.com/jenadevs) is free and will always be open-source!\n\n{% image blog/blog-docker-workflow.jpg 30% right %}\n\n### Beginners workshop\n\nThe goal of the beginners workshop was to setup the Docker environment, learn the basic commands, follow the common workflow and become familiar with Docker Compose.\nThe participants were guided through the official Docker birthday [tutorial](https://github.com/jenadevs/docker-birthday-3/blob/master/tutorial.md) by Benjamin Nothdurft and Kay Abendroth.\nAs a first step, the Docker newbies built a simple web application, which served random kitten pictures using the [Flask](http://flask.pocoo.org) microframework.\nIn the end, the beginners already created and customised a multi-container voting application with a Python user app, a Redis queue for buffering, a Java worker for processing, a PostgreSQL database for storage and a Javascript administration app - all running from a single `docker-compose.yml` file.\n\n{% image blog/blog-docker-beginners.jpg 40% left %}\n\n### Advanced workshop\n\nThis workshop focused on writing your own Dockerfiles, running the containers and configuring integration testing with [CircleCI](https://circleci.com).\nBastian Klein prepared an empty custom [Magento](https://magento.com) `Dockerfile` and `Circle.yml` with comments left only, where the implementation code was completely removed.\nThe attendees then had to figure out how the Dockerfile commands needed to be configured, guided by the workshop maintainer.\n\n{% image blog/blog-docker-kubernetes.jpg 30% right %}\n\n### Special workshop\n\nThe most experienced Docker users gathered together in the special workshop, where the main focus was a bit shifted.\nThree workstation laptops had been prepared to introduce [CoreOS](https://coreos.com) to the participants.\nAndreas Grohmann introduced the open-source lightweight operating system designed to provide infrastructure to clustered deployments to the each participant.\nThe goal was to [setup a cluster environment](https://developer.epages.com/blog/2016/01/19/setup-a-coreos-cluster.html#why-use-coreos) with three nodes and run Docker on it.\nEveryone succeeded.\nAfterwards, Christian Köhler gave an insight on how to configure Kubernetes with a short demonstration.\nHe also distinctly outlined the advantages of Docker Swarm.\n\n## Summary\n\nIn retrospect, this meetup was a great success.\nEvery participant had the possibility to have fun, meet other developers and learn something new.\nExcept for the beginners, who finalised their well-documented tutorial at home, all participants were able to finish all workshop tasks on time with excellent results.\nSo it was obvious, that a lot of guests joined parts of the orga team in the local bar and just talked about the experience in their developer life, their favourite editors and some \"nerdy\" stuff.\n\nThanks to all attendees and ePages coworkers for making this happen!\n\n## Next meetup\n\nThe goal of the Softwerkskammer Jena is to establish a platform for regular meetings.\nAnd we already arranged the next meetup!\nIn the course of a one-day event, we will facilitate a [coding dojo](http://codingdojo.org) consisting of a classical [Coderetreat](http://coderetreat.org) and lighting talks with demos on [TDD](https://en.wikipedia.org/wiki/Test-driven_development) concepts upfront, e.g. Unit testing with mock objects.\nAgain, the participants will be able to choose between different workshop-like groups.\nIn each group we train our coding skills on a specific kata in iterative 45-minute-rounds under certain [constraints](http://coderetreat.org/facilitating/activity-catalog) in [pairs](https://en.wikipedia.org/wiki/Pair_programming) and with different team mates in each round.\n\nWe are very happy that [Marco Emrich](https://twitter.com/marcoemrich) from the [Softwerkskammer Nürnberg](https://www.softwerkskammer.org/groups/nuernberg) will join us - a highly passionate trainer and an experienced Coderetreat facilitator.\nWe cannot think of anyone better to help the participants understand how to start with the test-first approach!\n\nSave the date: this one-day event is planned for Saturday, the 21st of May 2016 from 9:30 am until 5:30 pm!\nFeel free to already sign up for the event at the [meetup](http://www.meetup.com/jenadevs) or the [Softwerkskammer](https://www.softwerkskammer.org/groups/jena) platform.\n\nPS: The Docker shirts and stickers finally arrived yesterday after persistent negotiations with the customs office.\nYou may catch yours at the next meetup!\nSee you there.\n\n{% img blog/blog-docker-jenadevs-orga.jpg 47% left %}The orga team\n\n{% img blog/blog-docker-stickers.jpg 47% right %}The Docker shirts and stickers\n","slug":"2016-04-21-jenadevs-docker-party","published":1,"updated":"2016-09-20T14:42:20.000Z","comments":1,"photos":[],"link":"","_id":"ciu6nuh9m0028hqyxvjdfutmo","content":"<p>The newly founded <a href=\"http://www.softwerkskammer.org/groups/jena\" target=\"_blank\" rel=\"external\">Softwerkskammer Jena</a> had its first <a href=\"http://www.meetup.com/jenadevs\" target=\"_blank\" rel=\"external\">Developer Meetup</a> at the beginning of April.<br>ePages hosted the event and provided conference rooms, several workstations as well as a variety of snacks, pizza and beverages.<br>Over 35 attendees joined the Docker Party.<br>Developers from nearby companies, students from the local universities and even some freelancers followed the <a href=\"https://github.com/jenadevs/jenadevs-meetup-001-docker-party/blob/master/orga/Softwerkskammer_Jena_Developers_Meetup_001_Docker_Party.pdf\" target=\"_blank\" rel=\"external\">invitation</a>.<br>We had 4 hours of coding fun from 6 pm until nearly 10 pm with an open end at the local pub, where vivid discussions lasted until 2 am in the morning.</p>\n<h2 id=\"Agenda\"><a href=\"#Agenda\" class=\"headerlink\" title=\"Agenda\"></a>Agenda</h2><p>We started with a short meet and greet as well as a brief introduction about the <a href=\"http://softwerkskammer.org\" target=\"_blank\" rel=\"external\">Softwerkskammer</a> – the german part of the <a href=\"http://manifesto.softwarecraftsmanship.org\" target=\"_blank\" rel=\"external\">Software Craftsmanship Community</a> – and its current distribution together with some helpful contact information like the <a href=\"https://twitter.com/jenadevs\" target=\"_blank\" rel=\"external\">@jenadevs</a> Twitter account.</p>\n<p>Then the Docker Party was launched, and we celebrated the <a href=\"https://www.docker.com/community/docker-birthday-3\" target=\"_blank\" rel=\"external\">3rd birthday of Docker</a>!</p>\n<p>The agenda included a one hour talk along with a demo to introduce the technological foundation as well as different workshops for every skill level:</p>\n<ol>\n<li><strong>Beginners:</strong> The official Docker <a href=\"https://github.com/jenadevs/docker-birthday-3\" target=\"_blank\" rel=\"external\">birthday app project</a></li>\n<li><strong>Advanced:</strong> Build your own Dockerfile according to best practises in conjunction with integration tests</li>\n<li><strong>Special:</strong> CoresOS cluster workshop</li>\n<li><strong>Easter egg:</strong> <a href=\"https://github.com/jenadevs/orchestration-workshop\" target=\"_blank\" rel=\"external\">Orchestration workshop</a> by <a href=\"https://twitter.com/jpetazzo\" target=\"_blank\" rel=\"external\">Jérôme Petazzoni</a>, the creator of <a href=\"https://github.com/jpetazzo/dind\" target=\"_blank\" rel=\"external\">Docker-in-Docker</a></li>\n</ol>\n<h2 id=\"Introduction-talk-with-demo-and-best-practises\"><a href=\"#Introduction-talk-with-demo-and-best-practises\" class=\"headerlink\" title=\"Introduction talk with demo and best practises\"></a>Introduction talk with demo and best practises</h2><p>The first part of the introduction talk focused on the Docker basics, the components of the Docker ecosystem and the general tooling workflow of building images, running containers and pushing them to the Docker Hub.<br>We had a demo on the basic commands along with some live coding on the terminal, where several containers were also inspected at runtime.</p>\n<p>The second part considered some best practises for writing your own Dockerfile, based on the <a href=\"https://docs.docker.com/engine/userguide/eng-image/dockerfile_best-practices\" target=\"_blank\" rel=\"external\">official Docker recommendations</a>, tips by <a href=\"http://crosbymichael.com/dockerfile-best-practices.html\" target=\"_blank\" rel=\"external\">Michael</a> <a href=\"http://crosbymichael.com/dockerfile-best-practices-take-2.html\" target=\"_blank\" rel=\"external\">Crosby</a> as well as the experiences of <a href=\"http://twitter.com/epagesdevs\" target=\"_blank\" rel=\"external\">epagesdevs</a> with developing, testing, integrating, deploying and running supportive images for the eCommerce platform.</p>\n<p>This was a nice opportunity to also show some typical use cases at ePages, e.g. the Continuous Delivery Pipeline for integration testing, or that both, the ePages and the provider infrastructure are already based partly on <a href=\"http://kubernetes.io\" target=\"_blank\" rel=\"external\">Kubernetes</a>.<br>The talk finished with some typical base images as well as a discussion about official app environment images.</p>\n<img class=\"blog/blog-docker-presentation.jpg\">\n<h2 id=\"Containers-containers-con…-er-workshops\"><a href=\"#Containers-containers-con…-er-workshops\" class=\"headerlink\" title=\"Containers, containers, con… er workshops!\"></a>Containers, containers, con… er workshops!</h2><p>Upfront, all necessary material and code for the workshops was hosted on the jenadevs <a href=\"https://github.com/jenadevs\" target=\"_blank\" rel=\"external\">GitHub</a> account, which even offers the <a href=\"https://github.com/jenadevs/jenadevs-meetup-001-docker-party\" target=\"_blank\" rel=\"external\">complete presentation</a>.<br>Good news: all material of <a href=\"https://github.com/jenadevs\" target=\"_blank\" rel=\"external\">jenadevs</a> is free and will always be open-source!</p>\n<img class=\"blog/blog-docker-workflow.jpg 30% right\">\n<h3 id=\"Beginners-workshop\"><a href=\"#Beginners-workshop\" class=\"headerlink\" title=\"Beginners workshop\"></a>Beginners workshop</h3><p>The goal of the beginners workshop was to setup the Docker environment, learn the basic commands, follow the common workflow and become familiar with Docker Compose.<br>The participants were guided through the official Docker birthday <a href=\"https://github.com/jenadevs/docker-birthday-3/blob/master/tutorial.md\" target=\"_blank\" rel=\"external\">tutorial</a> by Benjamin Nothdurft and Kay Abendroth.<br>As a first step, the Docker newbies built a simple web application, which served random kitten pictures using the <a href=\"http://flask.pocoo.org\" target=\"_blank\" rel=\"external\">Flask</a> microframework.<br>In the end, the beginners already created and customised a multi-container voting application with a Python user app, a Redis queue for buffering, a Java worker for processing, a PostgreSQL database for storage and a Javascript administration app - all running from a single <code>docker-compose.yml</code> file.</p>\n<img class=\"blog/blog-docker-beginners.jpg 40% left\">\n<h3 id=\"Advanced-workshop\"><a href=\"#Advanced-workshop\" class=\"headerlink\" title=\"Advanced workshop\"></a>Advanced workshop</h3><p>This workshop focused on writing your own Dockerfiles, running the containers and configuring integration testing with <a href=\"https://circleci.com\" target=\"_blank\" rel=\"external\">CircleCI</a>.<br>Bastian Klein prepared an empty custom <a href=\"https://magento.com\" target=\"_blank\" rel=\"external\">Magento</a> <code>Dockerfile</code> and <code>Circle.yml</code> with comments left only, where the implementation code was completely removed.<br>The attendees then had to figure out how the Dockerfile commands needed to be configured, guided by the workshop maintainer.</p>\n<img class=\"blog/blog-docker-kubernetes.jpg 30% right\">\n<h3 id=\"Special-workshop\"><a href=\"#Special-workshop\" class=\"headerlink\" title=\"Special workshop\"></a>Special workshop</h3><p>The most experienced Docker users gathered together in the special workshop, where the main focus was a bit shifted.<br>Three workstation laptops had been prepared to introduce <a href=\"https://coreos.com\" target=\"_blank\" rel=\"external\">CoreOS</a> to the participants.<br>Andreas Grohmann introduced the open-source lightweight operating system designed to provide infrastructure to clustered deployments to the each participant.<br>The goal was to <a href=\"https://developer.epages.com/blog/2016/01/19/setup-a-coreos-cluster.html#why-use-coreos\" target=\"_blank\" rel=\"external\">setup a cluster environment</a> with three nodes and run Docker on it.<br>Everyone succeeded.<br>Afterwards, Christian Köhler gave an insight on how to configure Kubernetes with a short demonstration.<br>He also distinctly outlined the advantages of Docker Swarm.</p>\n<h2 id=\"Summary\"><a href=\"#Summary\" class=\"headerlink\" title=\"Summary\"></a>Summary</h2><p>In retrospect, this meetup was a great success.<br>Every participant had the possibility to have fun, meet other developers and learn something new.<br>Except for the beginners, who finalised their well-documented tutorial at home, all participants were able to finish all workshop tasks on time with excellent results.<br>So it was obvious, that a lot of guests joined parts of the orga team in the local bar and just talked about the experience in their developer life, their favourite editors and some “nerdy” stuff.</p>\n<p>Thanks to all attendees and ePages coworkers for making this happen!</p>\n<h2 id=\"Next-meetup\"><a href=\"#Next-meetup\" class=\"headerlink\" title=\"Next meetup\"></a>Next meetup</h2><p>The goal of the Softwerkskammer Jena is to establish a platform for regular meetings.<br>And we already arranged the next meetup!<br>In the course of a one-day event, we will facilitate a <a href=\"http://codingdojo.org\" target=\"_blank\" rel=\"external\">coding dojo</a> consisting of a classical <a href=\"http://coderetreat.org\" target=\"_blank\" rel=\"external\">Coderetreat</a> and lighting talks with demos on <a href=\"https://en.wikipedia.org/wiki/Test-driven_development\" target=\"_blank\" rel=\"external\">TDD</a> concepts upfront, e.g. Unit testing with mock objects.<br>Again, the participants will be able to choose between different workshop-like groups.<br>In each group we train our coding skills on a specific kata in iterative 45-minute-rounds under certain <a href=\"http://coderetreat.org/facilitating/activity-catalog\" target=\"_blank\" rel=\"external\">constraints</a> in <a href=\"https://en.wikipedia.org/wiki/Pair_programming\" target=\"_blank\" rel=\"external\">pairs</a> and with different team mates in each round.</p>\n<p>We are very happy that <a href=\"https://twitter.com/marcoemrich\" target=\"_blank\" rel=\"external\">Marco Emrich</a> from the <a href=\"https://www.softwerkskammer.org/groups/nuernberg\" target=\"_blank\" rel=\"external\">Softwerkskammer Nürnberg</a> will join us - a highly passionate trainer and an experienced Coderetreat facilitator.<br>We cannot think of anyone better to help the participants understand how to start with the test-first approach!</p>\n<p>Save the date: this one-day event is planned for Saturday, the 21st of May 2016 from 9:30 am until 5:30 pm!<br>Feel free to already sign up for the event at the <a href=\"http://www.meetup.com/jenadevs\" target=\"_blank\" rel=\"external\">meetup</a> or the <a href=\"https://www.softwerkskammer.org/groups/jena\" target=\"_blank\" rel=\"external\">Softwerkskammer</a> platform.</p>\n<p>PS: The Docker shirts and stickers finally arrived yesterday after persistent negotiations with the customs office.<br>You may catch yours at the next meetup!<br>See you there.</p>\n<p><img class=\"blog/blog-docker-jenadevs-orga.jpg 47% left\">The orga team</p>\n<p><img class=\"blog/blog-docker-stickers.jpg 47% right\">The Docker shirts and stickers</p>\n","excerpt":"","more":"<p>The newly founded <a href=\"http://www.softwerkskammer.org/groups/jena\">Softwerkskammer Jena</a> had its first <a href=\"http://www.meetup.com/jenadevs\">Developer Meetup</a> at the beginning of April.<br>ePages hosted the event and provided conference rooms, several workstations as well as a variety of snacks, pizza and beverages.<br>Over 35 attendees joined the Docker Party.<br>Developers from nearby companies, students from the local universities and even some freelancers followed the <a href=\"https://github.com/jenadevs/jenadevs-meetup-001-docker-party/blob/master/orga/Softwerkskammer_Jena_Developers_Meetup_001_Docker_Party.pdf\">invitation</a>.<br>We had 4 hours of coding fun from 6 pm until nearly 10 pm with an open end at the local pub, where vivid discussions lasted until 2 am in the morning.</p>\n<h2 id=\"Agenda\"><a href=\"#Agenda\" class=\"headerlink\" title=\"Agenda\"></a>Agenda</h2><p>We started with a short meet and greet as well as a brief introduction about the <a href=\"http://softwerkskammer.org\">Softwerkskammer</a> – the german part of the <a href=\"http://manifesto.softwarecraftsmanship.org\">Software Craftsmanship Community</a> – and its current distribution together with some helpful contact information like the <a href=\"https://twitter.com/jenadevs\">@jenadevs</a> Twitter account.</p>\n<p>Then the Docker Party was launched, and we celebrated the <a href=\"https://www.docker.com/community/docker-birthday-3\">3rd birthday of Docker</a>!</p>\n<p>The agenda included a one hour talk along with a demo to introduce the technological foundation as well as different workshops for every skill level:</p>\n<ol>\n<li><strong>Beginners:</strong> The official Docker <a href=\"https://github.com/jenadevs/docker-birthday-3\">birthday app project</a></li>\n<li><strong>Advanced:</strong> Build your own Dockerfile according to best practises in conjunction with integration tests</li>\n<li><strong>Special:</strong> CoresOS cluster workshop</li>\n<li><strong>Easter egg:</strong> <a href=\"https://github.com/jenadevs/orchestration-workshop\">Orchestration workshop</a> by <a href=\"https://twitter.com/jpetazzo\">Jérôme Petazzoni</a>, the creator of <a href=\"https://github.com/jpetazzo/dind\">Docker-in-Docker</a></li>\n</ol>\n<h2 id=\"Introduction-talk-with-demo-and-best-practises\"><a href=\"#Introduction-talk-with-demo-and-best-practises\" class=\"headerlink\" title=\"Introduction talk with demo and best practises\"></a>Introduction talk with demo and best practises</h2><p>The first part of the introduction talk focused on the Docker basics, the components of the Docker ecosystem and the general tooling workflow of building images, running containers and pushing them to the Docker Hub.<br>We had a demo on the basic commands along with some live coding on the terminal, where several containers were also inspected at runtime.</p>\n<p>The second part considered some best practises for writing your own Dockerfile, based on the <a href=\"https://docs.docker.com/engine/userguide/eng-image/dockerfile_best-practices\">official Docker recommendations</a>, tips by <a href=\"http://crosbymichael.com/dockerfile-best-practices.html\">Michael</a> <a href=\"http://crosbymichael.com/dockerfile-best-practices-take-2.html\">Crosby</a> as well as the experiences of <a href=\"http://twitter.com/epagesdevs\">epagesdevs</a> with developing, testing, integrating, deploying and running supportive images for the eCommerce platform.</p>\n<p>This was a nice opportunity to also show some typical use cases at ePages, e.g. the Continuous Delivery Pipeline for integration testing, or that both, the ePages and the provider infrastructure are already based partly on <a href=\"http://kubernetes.io\">Kubernetes</a>.<br>The talk finished with some typical base images as well as a discussion about official app environment images.</p>\n<img class=\"blog/blog-docker-presentation.jpg\">\n<h2 id=\"Containers-containers-con…-er-workshops\"><a href=\"#Containers-containers-con…-er-workshops\" class=\"headerlink\" title=\"Containers, containers, con… er workshops!\"></a>Containers, containers, con… er workshops!</h2><p>Upfront, all necessary material and code for the workshops was hosted on the jenadevs <a href=\"https://github.com/jenadevs\">GitHub</a> account, which even offers the <a href=\"https://github.com/jenadevs/jenadevs-meetup-001-docker-party\">complete presentation</a>.<br>Good news: all material of <a href=\"https://github.com/jenadevs\">jenadevs</a> is free and will always be open-source!</p>\n<img class=\"blog/blog-docker-workflow.jpg 30% right\">\n<h3 id=\"Beginners-workshop\"><a href=\"#Beginners-workshop\" class=\"headerlink\" title=\"Beginners workshop\"></a>Beginners workshop</h3><p>The goal of the beginners workshop was to setup the Docker environment, learn the basic commands, follow the common workflow and become familiar with Docker Compose.<br>The participants were guided through the official Docker birthday <a href=\"https://github.com/jenadevs/docker-birthday-3/blob/master/tutorial.md\">tutorial</a> by Benjamin Nothdurft and Kay Abendroth.<br>As a first step, the Docker newbies built a simple web application, which served random kitten pictures using the <a href=\"http://flask.pocoo.org\">Flask</a> microframework.<br>In the end, the beginners already created and customised a multi-container voting application with a Python user app, a Redis queue for buffering, a Java worker for processing, a PostgreSQL database for storage and a Javascript administration app - all running from a single <code>docker-compose.yml</code> file.</p>\n<img class=\"blog/blog-docker-beginners.jpg 40% left\">\n<h3 id=\"Advanced-workshop\"><a href=\"#Advanced-workshop\" class=\"headerlink\" title=\"Advanced workshop\"></a>Advanced workshop</h3><p>This workshop focused on writing your own Dockerfiles, running the containers and configuring integration testing with <a href=\"https://circleci.com\">CircleCI</a>.<br>Bastian Klein prepared an empty custom <a href=\"https://magento.com\">Magento</a> <code>Dockerfile</code> and <code>Circle.yml</code> with comments left only, where the implementation code was completely removed.<br>The attendees then had to figure out how the Dockerfile commands needed to be configured, guided by the workshop maintainer.</p>\n<img class=\"blog/blog-docker-kubernetes.jpg 30% right\">\n<h3 id=\"Special-workshop\"><a href=\"#Special-workshop\" class=\"headerlink\" title=\"Special workshop\"></a>Special workshop</h3><p>The most experienced Docker users gathered together in the special workshop, where the main focus was a bit shifted.<br>Three workstation laptops had been prepared to introduce <a href=\"https://coreos.com\">CoreOS</a> to the participants.<br>Andreas Grohmann introduced the open-source lightweight operating system designed to provide infrastructure to clustered deployments to the each participant.<br>The goal was to <a href=\"https://developer.epages.com/blog/2016/01/19/setup-a-coreos-cluster.html#why-use-coreos\">setup a cluster environment</a> with three nodes and run Docker on it.<br>Everyone succeeded.<br>Afterwards, Christian Köhler gave an insight on how to configure Kubernetes with a short demonstration.<br>He also distinctly outlined the advantages of Docker Swarm.</p>\n<h2 id=\"Summary\"><a href=\"#Summary\" class=\"headerlink\" title=\"Summary\"></a>Summary</h2><p>In retrospect, this meetup was a great success.<br>Every participant had the possibility to have fun, meet other developers and learn something new.<br>Except for the beginners, who finalised their well-documented tutorial at home, all participants were able to finish all workshop tasks on time with excellent results.<br>So it was obvious, that a lot of guests joined parts of the orga team in the local bar and just talked about the experience in their developer life, their favourite editors and some “nerdy” stuff.</p>\n<p>Thanks to all attendees and ePages coworkers for making this happen!</p>\n<h2 id=\"Next-meetup\"><a href=\"#Next-meetup\" class=\"headerlink\" title=\"Next meetup\"></a>Next meetup</h2><p>The goal of the Softwerkskammer Jena is to establish a platform for regular meetings.<br>And we already arranged the next meetup!<br>In the course of a one-day event, we will facilitate a <a href=\"http://codingdojo.org\">coding dojo</a> consisting of a classical <a href=\"http://coderetreat.org\">Coderetreat</a> and lighting talks with demos on <a href=\"https://en.wikipedia.org/wiki/Test-driven_development\">TDD</a> concepts upfront, e.g. Unit testing with mock objects.<br>Again, the participants will be able to choose between different workshop-like groups.<br>In each group we train our coding skills on a specific kata in iterative 45-minute-rounds under certain <a href=\"http://coderetreat.org/facilitating/activity-catalog\">constraints</a> in <a href=\"https://en.wikipedia.org/wiki/Pair_programming\">pairs</a> and with different team mates in each round.</p>\n<p>We are very happy that <a href=\"https://twitter.com/marcoemrich\">Marco Emrich</a> from the <a href=\"https://www.softwerkskammer.org/groups/nuernberg\">Softwerkskammer Nürnberg</a> will join us - a highly passionate trainer and an experienced Coderetreat facilitator.<br>We cannot think of anyone better to help the participants understand how to start with the test-first approach!</p>\n<p>Save the date: this one-day event is planned for Saturday, the 21st of May 2016 from 9:30 am until 5:30 pm!<br>Feel free to already sign up for the event at the <a href=\"http://www.meetup.com/jenadevs\">meetup</a> or the <a href=\"https://www.softwerkskammer.org/groups/jena\">Softwerkskammer</a> platform.</p>\n<p>PS: The Docker shirts and stickers finally arrived yesterday after persistent negotiations with the customs office.<br>You may catch yours at the next meetup!<br>See you there.</p>\n<p><img class=\"blog/blog-docker-jenadevs-orga.jpg 47% left\">The orga team</p>\n<p><img class=\"blog/blog-docker-stickers.jpg 47% right\">The Docker shirts and stickers</p>\n"},{"layout":"post","title":"Consulting offsite meeting","date":"2016-05-18T14:03:17.000Z","image":"blog-header/consulting-offsite.jpg","authors":["Pavlo","Tobias"],"_content":"\nOn 1st of May 2016, the ePages Consulting team set off on a journey to Bad Sulzburg, Germany.\nAfter a six-hour drive from Jena, we were welcomed by the nice staff of the Waldhotel, which is situated in a quiet spot of the Black Forest.\nA good place for us to reflect on what works well in the team and what could be improved.\n\n{% image blog/blog-consulting-offsite-1.jpg %}\n\nThe purpose of this particular trip was to talk about opportunities and challenges faced by our team over time as well as to come up with strategic plans for the future.\n\n## Team building activities\n\nTo strengthen the team spirit and escape from office life, we decided to go hiking and enjoy the exceptional diversity and grandiose views of the Black Forest landscape.\n\n{% image blog/blog-consulting-offsite-2.jpg %}\n\nOn the next day, after countless meetings, we played Kubb to reduce stress and to draw fresh inspiration.\nKubb is an exciting team game from Sweden with a very long tradition.\nThe goal of each team is to overturn the wooden figures of the opposing team by throwing wooden sticks.\nThe king with the red crown in the middle of the field must be taken last.\n\n{% image blog/blog-consulting-offsite-3.jpg %}\n\n## Meetings\n\nDuring the meetings we worked together on all issues. Each topic had its own presenter.\nWe discussed many different topics, analysed the work from the previous two quarters, and developed a plan to reduce some internal expenses in order to focus on work that creates more profit.\n\n{% image blog/blog-consulting-offsite-4.jpg %}\n\nOn the next day, we had a very important meeting with a new customer.\nWe received feedback on already completed work, and set milestones for the future collaboration.\n\n{% image blog/blog-consulting-offsite-5.jpg %}\n\nAs the work of the Consulting team is to customise the standard ePages software according to customer-specific requirements, one of our topic was the continuous delivery pipeline.\nThis pipeline should ensure that, each time that a new version is released, the customer-specific adaptations still work and that no side effects occur.\n\nThe achieved results, such as redefined Consulting services and a workflow to determine business values, will bring many benefits for the company, but they still need to be reviewed and accepted.\n\n## Summary\n\nDespite the fact that Bad Sulzburg was far away, and the travel was very tiring, it was a great place to think out of the box.\nWe had a great opportunity to face challenges, come up with new ideas, and developed a plan for our future work.\n\nFrom our point of view, a team offsite is an essential part for every professional team which encourages creativity.\nThis can be especially helpful when you plan to make strategic decisions.\nWe look forward to our next offsite meeting.\n","source":"_posts/2016-05-18-offsite-consulting.md","raw":"---\nlayout: post\ntitle: \"Consulting offsite meeting\"\ndate: \"2016-05-18 16:03:17\"\nimage: blog-header/consulting-offsite.jpg\ncategories: events\nauthors: [\"Pavlo\", \"Tobias\"]\n---\n\nOn 1st of May 2016, the ePages Consulting team set off on a journey to Bad Sulzburg, Germany.\nAfter a six-hour drive from Jena, we were welcomed by the nice staff of the Waldhotel, which is situated in a quiet spot of the Black Forest.\nA good place for us to reflect on what works well in the team and what could be improved.\n\n{% image blog/blog-consulting-offsite-1.jpg %}\n\nThe purpose of this particular trip was to talk about opportunities and challenges faced by our team over time as well as to come up with strategic plans for the future.\n\n## Team building activities\n\nTo strengthen the team spirit and escape from office life, we decided to go hiking and enjoy the exceptional diversity and grandiose views of the Black Forest landscape.\n\n{% image blog/blog-consulting-offsite-2.jpg %}\n\nOn the next day, after countless meetings, we played Kubb to reduce stress and to draw fresh inspiration.\nKubb is an exciting team game from Sweden with a very long tradition.\nThe goal of each team is to overturn the wooden figures of the opposing team by throwing wooden sticks.\nThe king with the red crown in the middle of the field must be taken last.\n\n{% image blog/blog-consulting-offsite-3.jpg %}\n\n## Meetings\n\nDuring the meetings we worked together on all issues. Each topic had its own presenter.\nWe discussed many different topics, analysed the work from the previous two quarters, and developed a plan to reduce some internal expenses in order to focus on work that creates more profit.\n\n{% image blog/blog-consulting-offsite-4.jpg %}\n\nOn the next day, we had a very important meeting with a new customer.\nWe received feedback on already completed work, and set milestones for the future collaboration.\n\n{% image blog/blog-consulting-offsite-5.jpg %}\n\nAs the work of the Consulting team is to customise the standard ePages software according to customer-specific requirements, one of our topic was the continuous delivery pipeline.\nThis pipeline should ensure that, each time that a new version is released, the customer-specific adaptations still work and that no side effects occur.\n\nThe achieved results, such as redefined Consulting services and a workflow to determine business values, will bring many benefits for the company, but they still need to be reviewed and accepted.\n\n## Summary\n\nDespite the fact that Bad Sulzburg was far away, and the travel was very tiring, it was a great place to think out of the box.\nWe had a great opportunity to face challenges, come up with new ideas, and developed a plan for our future work.\n\nFrom our point of view, a team offsite is an essential part for every professional team which encourages creativity.\nThis can be especially helpful when you plan to make strategic decisions.\nWe look forward to our next offsite meeting.\n","slug":"2016-05-18-offsite-consulting","published":1,"updated":"2016-09-20T14:31:48.000Z","comments":1,"photos":[],"link":"","_id":"ciu6nuh9n002ahqyx0klopk22","content":"<p>On 1st of May 2016, the ePages Consulting team set off on a journey to Bad Sulzburg, Germany.<br>After a six-hour drive from Jena, we were welcomed by the nice staff of the Waldhotel, which is situated in a quiet spot of the Black Forest.<br>A good place for us to reflect on what works well in the team and what could be improved.</p>\n<img class=\"blog/blog-consulting-offsite-1.jpg\">\n<p>The purpose of this particular trip was to talk about opportunities and challenges faced by our team over time as well as to come up with strategic plans for the future.</p>\n<h2 id=\"Team-building-activities\"><a href=\"#Team-building-activities\" class=\"headerlink\" title=\"Team building activities\"></a>Team building activities</h2><p>To strengthen the team spirit and escape from office life, we decided to go hiking and enjoy the exceptional diversity and grandiose views of the Black Forest landscape.</p>\n<img class=\"blog/blog-consulting-offsite-2.jpg\">\n<p>On the next day, after countless meetings, we played Kubb to reduce stress and to draw fresh inspiration.<br>Kubb is an exciting team game from Sweden with a very long tradition.<br>The goal of each team is to overturn the wooden figures of the opposing team by throwing wooden sticks.<br>The king with the red crown in the middle of the field must be taken last.</p>\n<img class=\"blog/blog-consulting-offsite-3.jpg\">\n<h2 id=\"Meetings\"><a href=\"#Meetings\" class=\"headerlink\" title=\"Meetings\"></a>Meetings</h2><p>During the meetings we worked together on all issues. Each topic had its own presenter.<br>We discussed many different topics, analysed the work from the previous two quarters, and developed a plan to reduce some internal expenses in order to focus on work that creates more profit.</p>\n<img class=\"blog/blog-consulting-offsite-4.jpg\">\n<p>On the next day, we had a very important meeting with a new customer.<br>We received feedback on already completed work, and set milestones for the future collaboration.</p>\n<img class=\"blog/blog-consulting-offsite-5.jpg\">\n<p>As the work of the Consulting team is to customise the standard ePages software according to customer-specific requirements, one of our topic was the continuous delivery pipeline.<br>This pipeline should ensure that, each time that a new version is released, the customer-specific adaptations still work and that no side effects occur.</p>\n<p>The achieved results, such as redefined Consulting services and a workflow to determine business values, will bring many benefits for the company, but they still need to be reviewed and accepted.</p>\n<h2 id=\"Summary\"><a href=\"#Summary\" class=\"headerlink\" title=\"Summary\"></a>Summary</h2><p>Despite the fact that Bad Sulzburg was far away, and the travel was very tiring, it was a great place to think out of the box.<br>We had a great opportunity to face challenges, come up with new ideas, and developed a plan for our future work.</p>\n<p>From our point of view, a team offsite is an essential part for every professional team which encourages creativity.<br>This can be especially helpful when you plan to make strategic decisions.<br>We look forward to our next offsite meeting.</p>\n","excerpt":"","more":"<p>On 1st of May 2016, the ePages Consulting team set off on a journey to Bad Sulzburg, Germany.<br>After a six-hour drive from Jena, we were welcomed by the nice staff of the Waldhotel, which is situated in a quiet spot of the Black Forest.<br>A good place for us to reflect on what works well in the team and what could be improved.</p>\n<img class=\"blog/blog-consulting-offsite-1.jpg\">\n<p>The purpose of this particular trip was to talk about opportunities and challenges faced by our team over time as well as to come up with strategic plans for the future.</p>\n<h2 id=\"Team-building-activities\"><a href=\"#Team-building-activities\" class=\"headerlink\" title=\"Team building activities\"></a>Team building activities</h2><p>To strengthen the team spirit and escape from office life, we decided to go hiking and enjoy the exceptional diversity and grandiose views of the Black Forest landscape.</p>\n<img class=\"blog/blog-consulting-offsite-2.jpg\">\n<p>On the next day, after countless meetings, we played Kubb to reduce stress and to draw fresh inspiration.<br>Kubb is an exciting team game from Sweden with a very long tradition.<br>The goal of each team is to overturn the wooden figures of the opposing team by throwing wooden sticks.<br>The king with the red crown in the middle of the field must be taken last.</p>\n<img class=\"blog/blog-consulting-offsite-3.jpg\">\n<h2 id=\"Meetings\"><a href=\"#Meetings\" class=\"headerlink\" title=\"Meetings\"></a>Meetings</h2><p>During the meetings we worked together on all issues. Each topic had its own presenter.<br>We discussed many different topics, analysed the work from the previous two quarters, and developed a plan to reduce some internal expenses in order to focus on work that creates more profit.</p>\n<img class=\"blog/blog-consulting-offsite-4.jpg\">\n<p>On the next day, we had a very important meeting with a new customer.<br>We received feedback on already completed work, and set milestones for the future collaboration.</p>\n<img class=\"blog/blog-consulting-offsite-5.jpg\">\n<p>As the work of the Consulting team is to customise the standard ePages software according to customer-specific requirements, one of our topic was the continuous delivery pipeline.<br>This pipeline should ensure that, each time that a new version is released, the customer-specific adaptations still work and that no side effects occur.</p>\n<p>The achieved results, such as redefined Consulting services and a workflow to determine business values, will bring many benefits for the company, but they still need to be reviewed and accepted.</p>\n<h2 id=\"Summary\"><a href=\"#Summary\" class=\"headerlink\" title=\"Summary\"></a>Summary</h2><p>Despite the fact that Bad Sulzburg was far away, and the travel was very tiring, it was a great place to think out of the box.<br>We had a great opportunity to face challenges, come up with new ideas, and developed a plan for our future work.</p>\n<p>From our point of view, a team offsite is an essential part for every professional team which encourages creativity.<br>This can be especially helpful when you plan to make strategic decisions.<br>We look forward to our next offsite meeting.</p>\n"},{"layout":"post","title":"Why Mallorca is the perfect place for a productive team offsite","date":"2016-03-17T15:03:17.000Z","image":"blog-header/offsite.jpg","authors":["Alejandra, Benjamin and Heiko"],"_content":"\nLast week, the ePages release and test automation team was welcomed by the precious views, hearty people and refreshing atmosphere of Mallorca.\nThe purpose of this particular trip was to celebrate an offsite team event liberated from the daily tasks and routines of the business life.\nThe team set off to new shores to develop a master plan on how it could face the winds of change of the advancement of each team member.\nThe ultimate goal was to find the best way for contributing to the promising future of the whole research and development department.\n\nNow we are back and ready to briefly tell you the tale of the fearless developers' journey to a mysterious island.\nEnjoy the multifaceted report!\n\n## Travelling together\n\nWith much curiosity we first took some time off and enjoyed the amazing view over the beach skyline from the terrace of our finca, [Son Pages](http://sonpages.com).\nOn day two, we visited the [Cuevas del Drach](http://www.cuevasdeldrach.com) and the beautiful yacht harbour at [Porto Cristo](http://www.portocristo.org/) to draw fresh inspiration.\nOn the next day, we went on a road trip with the team van to Sa Calobra in the north.\nWe were impressed by the majestic mountains and the bluish tonalities of the Mediterranean Sea.\nWhen cruising along the bay area, we also found various [Geocaching](https://www.geocaching.com) possibilities to explore.\n\n{% image blog/blog-mallorca-1.jpg %}\n\n## Living as a team\n\nSharing daily life activities such as having breakfast, shopping, cooking and playing board games together was definitely a delightful way to become closer.\nEvery morning we even had a wonderful one hour wake-up fitness workout by a fun-loving and very disciplined personal trainer.\nThis kick-starting routine often blended nicely into the warming sunrise over the palm island – what a sight!\n\nThat's why the offsite time was a **BIG** chance to gain trust into the capabilities of our team.\nWe totally adopted this magical present. Unsurprisingly, we soon recognised that living the team spirit can be a lot of fun!\n\n{% image blog/blog-mallorca-2.jpg %}\n\n## Learning from your peers\n\nDuring our time on Mallorca, we of course had lots of time to work on our technological and business challenges, too.\n\nWe accomplished two knowledge sharing sessions.\nOne session was held by our continuous delivery pipeline expert in order to understand and explain the tool chain mechanisms that have not been shared equally amongst each team member yet.\nAnother session focused on our evolved know-how and the established workflows around the translation process including language handling and building of language packs for internationalisation.\n\nWe also played two rounds of [Coding Dojo](http://codingdojo.org), where we focused on solving the **Kata of Conway’s Game of Life**.\nIn the first round we tried to apply the constraints _“TDD as if you meant it”_ and _“Driver & Navigator”_, which strictly separates the roles in pair programming.\nThe second round focused on shaping distinct, comprehensive and sustainable test cases.\nTherefore, one ePagee had to implement a unit test.\nNext, the coding partner should lean into the position of an _“evil programmer”_ and hence only implement as little as possible to make the test pass.\nAfterwards he gives back the keyboard to the radically stressed writer of the unit test, who has to enforce the desired implementation with the addition of another test case.\nIn this rotary principle we trained our sense for writing high quality tests. This hands-on approach delivered a lot of amusements as well as practical benefits for our programming skills.\n\n{% image blog/blog-mallorca-3.jpg %}\n\n## Inspiring one another\n\nWe also planned one day for a hackathon, that accelerated our ingenious chains of thoughts.\nFrom the early afternoon until late into the night three pairs of programmers took the opportunity to delve into topics of their interest – which fortunately often matched the team's scope of duties.\nOne team evaluated the [Jenkins Pipeline Plugin](https://wiki.jenkins-ci.org/display/JENKINS/Pipeline+Plugin) and built a rapid prototype with multiple continuous delivery stages.\nOthers engineered the ground-breaking steps for an automated translation process.\nThe third team developed a new concept on how to deal with failing tests – of course not without a working prototype that considered a quarantine test group.\nPresenting the results to the others the next morning showed how quick ideas can grow into applicable solutions.\n\nTwo [Design Thinking](http://hpi.de/school-of-design-thinking.html) sessions took us beyond the mental barrier of longsome beaten paths.\nThe consistent execution of this method over and over again rapidly helped us to find the desired ideas for our current team mission.\nFirstly, we want to return a lot of responsibilities to those teams that strongly depend on us these days.\nSecondly, we would like to establish a fast and secure mechanism to permanently keep the latest build of the next ePages version in a releasable state.\n\n{% image blog/blog-mallorca-4.jpg %}\n\n## Summary\n\nIn retrospective, Tierra Buena (“Good Land”) was indeed a very good place to come up with new ideas and to think out of the box, reviving the technological perspective for each team member and filling the last gaps in our built-on automation landscape.\nWe have returned to the office fueled by visionary understanding, but we also conjured up a brand new continuous delivery pipeline mascot, Wall-E, which self-assembled in Lego, of course.\n\nTo sum up, we can definitely recommend this team-bonding experience for every professional team.\nSuch intense moments can sharpen your focus and broaden your horizons at once, but most importantly keep you ahead of the competition.\n","source":"_posts/2016-03-17-team-orange-mallorca.md","raw":"---\nlayout: post\ntitle: \"Why Mallorca is the perfect place for a productive team offsite\"\ndate: \"2016-03-17 16:03:17\"\nimage: blog-header/offsite.jpg\ncategories: events\nauthors: [\"Alejandra, Benjamin and Heiko\"]\n---\n\nLast week, the ePages release and test automation team was welcomed by the precious views, hearty people and refreshing atmosphere of Mallorca.\nThe purpose of this particular trip was to celebrate an offsite team event liberated from the daily tasks and routines of the business life.\nThe team set off to new shores to develop a master plan on how it could face the winds of change of the advancement of each team member.\nThe ultimate goal was to find the best way for contributing to the promising future of the whole research and development department.\n\nNow we are back and ready to briefly tell you the tale of the fearless developers' journey to a mysterious island.\nEnjoy the multifaceted report!\n\n## Travelling together\n\nWith much curiosity we first took some time off and enjoyed the amazing view over the beach skyline from the terrace of our finca, [Son Pages](http://sonpages.com).\nOn day two, we visited the [Cuevas del Drach](http://www.cuevasdeldrach.com) and the beautiful yacht harbour at [Porto Cristo](http://www.portocristo.org/) to draw fresh inspiration.\nOn the next day, we went on a road trip with the team van to Sa Calobra in the north.\nWe were impressed by the majestic mountains and the bluish tonalities of the Mediterranean Sea.\nWhen cruising along the bay area, we also found various [Geocaching](https://www.geocaching.com) possibilities to explore.\n\n{% image blog/blog-mallorca-1.jpg %}\n\n## Living as a team\n\nSharing daily life activities such as having breakfast, shopping, cooking and playing board games together was definitely a delightful way to become closer.\nEvery morning we even had a wonderful one hour wake-up fitness workout by a fun-loving and very disciplined personal trainer.\nThis kick-starting routine often blended nicely into the warming sunrise over the palm island – what a sight!\n\nThat's why the offsite time was a **BIG** chance to gain trust into the capabilities of our team.\nWe totally adopted this magical present. Unsurprisingly, we soon recognised that living the team spirit can be a lot of fun!\n\n{% image blog/blog-mallorca-2.jpg %}\n\n## Learning from your peers\n\nDuring our time on Mallorca, we of course had lots of time to work on our technological and business challenges, too.\n\nWe accomplished two knowledge sharing sessions.\nOne session was held by our continuous delivery pipeline expert in order to understand and explain the tool chain mechanisms that have not been shared equally amongst each team member yet.\nAnother session focused on our evolved know-how and the established workflows around the translation process including language handling and building of language packs for internationalisation.\n\nWe also played two rounds of [Coding Dojo](http://codingdojo.org), where we focused on solving the **Kata of Conway’s Game of Life**.\nIn the first round we tried to apply the constraints _“TDD as if you meant it”_ and _“Driver & Navigator”_, which strictly separates the roles in pair programming.\nThe second round focused on shaping distinct, comprehensive and sustainable test cases.\nTherefore, one ePagee had to implement a unit test.\nNext, the coding partner should lean into the position of an _“evil programmer”_ and hence only implement as little as possible to make the test pass.\nAfterwards he gives back the keyboard to the radically stressed writer of the unit test, who has to enforce the desired implementation with the addition of another test case.\nIn this rotary principle we trained our sense for writing high quality tests. This hands-on approach delivered a lot of amusements as well as practical benefits for our programming skills.\n\n{% image blog/blog-mallorca-3.jpg %}\n\n## Inspiring one another\n\nWe also planned one day for a hackathon, that accelerated our ingenious chains of thoughts.\nFrom the early afternoon until late into the night three pairs of programmers took the opportunity to delve into topics of their interest – which fortunately often matched the team's scope of duties.\nOne team evaluated the [Jenkins Pipeline Plugin](https://wiki.jenkins-ci.org/display/JENKINS/Pipeline+Plugin) and built a rapid prototype with multiple continuous delivery stages.\nOthers engineered the ground-breaking steps for an automated translation process.\nThe third team developed a new concept on how to deal with failing tests – of course not without a working prototype that considered a quarantine test group.\nPresenting the results to the others the next morning showed how quick ideas can grow into applicable solutions.\n\nTwo [Design Thinking](http://hpi.de/school-of-design-thinking.html) sessions took us beyond the mental barrier of longsome beaten paths.\nThe consistent execution of this method over and over again rapidly helped us to find the desired ideas for our current team mission.\nFirstly, we want to return a lot of responsibilities to those teams that strongly depend on us these days.\nSecondly, we would like to establish a fast and secure mechanism to permanently keep the latest build of the next ePages version in a releasable state.\n\n{% image blog/blog-mallorca-4.jpg %}\n\n## Summary\n\nIn retrospective, Tierra Buena (“Good Land”) was indeed a very good place to come up with new ideas and to think out of the box, reviving the technological perspective for each team member and filling the last gaps in our built-on automation landscape.\nWe have returned to the office fueled by visionary understanding, but we also conjured up a brand new continuous delivery pipeline mascot, Wall-E, which self-assembled in Lego, of course.\n\nTo sum up, we can definitely recommend this team-bonding experience for every professional team.\nSuch intense moments can sharpen your focus and broaden your horizons at once, but most importantly keep you ahead of the competition.\n","slug":"2016-03-17-team-orange-mallorca","published":1,"updated":"2016-09-20T14:31:48.000Z","comments":1,"photos":[],"link":"","_id":"ciu6nuh9o002chqyxf6s5hgsz","content":"<p>Last week, the ePages release and test automation team was welcomed by the precious views, hearty people and refreshing atmosphere of Mallorca.<br>The purpose of this particular trip was to celebrate an offsite team event liberated from the daily tasks and routines of the business life.<br>The team set off to new shores to develop a master plan on how it could face the winds of change of the advancement of each team member.<br>The ultimate goal was to find the best way for contributing to the promising future of the whole research and development department.</p>\n<p>Now we are back and ready to briefly tell you the tale of the fearless developers’ journey to a mysterious island.<br>Enjoy the multifaceted report!</p>\n<h2 id=\"Travelling-together\"><a href=\"#Travelling-together\" class=\"headerlink\" title=\"Travelling together\"></a>Travelling together</h2><p>With much curiosity we first took some time off and enjoyed the amazing view over the beach skyline from the terrace of our finca, <a href=\"http://sonpages.com\" target=\"_blank\" rel=\"external\">Son Pages</a>.<br>On day two, we visited the <a href=\"http://www.cuevasdeldrach.com\" target=\"_blank\" rel=\"external\">Cuevas del Drach</a> and the beautiful yacht harbour at <a href=\"http://www.portocristo.org/\" target=\"_blank\" rel=\"external\">Porto Cristo</a> to draw fresh inspiration.<br>On the next day, we went on a road trip with the team van to Sa Calobra in the north.<br>We were impressed by the majestic mountains and the bluish tonalities of the Mediterranean Sea.<br>When cruising along the bay area, we also found various <a href=\"https://www.geocaching.com\" target=\"_blank\" rel=\"external\">Geocaching</a> possibilities to explore.</p>\n<img class=\"blog/blog-mallorca-1.jpg\">\n<h2 id=\"Living-as-a-team\"><a href=\"#Living-as-a-team\" class=\"headerlink\" title=\"Living as a team\"></a>Living as a team</h2><p>Sharing daily life activities such as having breakfast, shopping, cooking and playing board games together was definitely a delightful way to become closer.<br>Every morning we even had a wonderful one hour wake-up fitness workout by a fun-loving and very disciplined personal trainer.<br>This kick-starting routine often blended nicely into the warming sunrise over the palm island – what a sight!</p>\n<p>That’s why the offsite time was a <strong>BIG</strong> chance to gain trust into the capabilities of our team.<br>We totally adopted this magical present. Unsurprisingly, we soon recognised that living the team spirit can be a lot of fun!</p>\n<img class=\"blog/blog-mallorca-2.jpg\">\n<h2 id=\"Learning-from-your-peers\"><a href=\"#Learning-from-your-peers\" class=\"headerlink\" title=\"Learning from your peers\"></a>Learning from your peers</h2><p>During our time on Mallorca, we of course had lots of time to work on our technological and business challenges, too.</p>\n<p>We accomplished two knowledge sharing sessions.<br>One session was held by our continuous delivery pipeline expert in order to understand and explain the tool chain mechanisms that have not been shared equally amongst each team member yet.<br>Another session focused on our evolved know-how and the established workflows around the translation process including language handling and building of language packs for internationalisation.</p>\n<p>We also played two rounds of <a href=\"http://codingdojo.org\" target=\"_blank\" rel=\"external\">Coding Dojo</a>, where we focused on solving the <strong>Kata of Conway’s Game of Life</strong>.<br>In the first round we tried to apply the constraints <em>“TDD as if you meant it”</em> and <em>“Driver &amp; Navigator”</em>, which strictly separates the roles in pair programming.<br>The second round focused on shaping distinct, comprehensive and sustainable test cases.<br>Therefore, one ePagee had to implement a unit test.<br>Next, the coding partner should lean into the position of an <em>“evil programmer”</em> and hence only implement as little as possible to make the test pass.<br>Afterwards he gives back the keyboard to the radically stressed writer of the unit test, who has to enforce the desired implementation with the addition of another test case.<br>In this rotary principle we trained our sense for writing high quality tests. This hands-on approach delivered a lot of amusements as well as practical benefits for our programming skills.</p>\n<img class=\"blog/blog-mallorca-3.jpg\">\n<h2 id=\"Inspiring-one-another\"><a href=\"#Inspiring-one-another\" class=\"headerlink\" title=\"Inspiring one another\"></a>Inspiring one another</h2><p>We also planned one day for a hackathon, that accelerated our ingenious chains of thoughts.<br>From the early afternoon until late into the night three pairs of programmers took the opportunity to delve into topics of their interest – which fortunately often matched the team’s scope of duties.<br>One team evaluated the <a href=\"https://wiki.jenkins-ci.org/display/JENKINS/Pipeline+Plugin\" target=\"_blank\" rel=\"external\">Jenkins Pipeline Plugin</a> and built a rapid prototype with multiple continuous delivery stages.<br>Others engineered the ground-breaking steps for an automated translation process.<br>The third team developed a new concept on how to deal with failing tests – of course not without a working prototype that considered a quarantine test group.<br>Presenting the results to the others the next morning showed how quick ideas can grow into applicable solutions.</p>\n<p>Two <a href=\"http://hpi.de/school-of-design-thinking.html\" target=\"_blank\" rel=\"external\">Design Thinking</a> sessions took us beyond the mental barrier of longsome beaten paths.<br>The consistent execution of this method over and over again rapidly helped us to find the desired ideas for our current team mission.<br>Firstly, we want to return a lot of responsibilities to those teams that strongly depend on us these days.<br>Secondly, we would like to establish a fast and secure mechanism to permanently keep the latest build of the next ePages version in a releasable state.</p>\n<img class=\"blog/blog-mallorca-4.jpg\">\n<h2 id=\"Summary\"><a href=\"#Summary\" class=\"headerlink\" title=\"Summary\"></a>Summary</h2><p>In retrospective, Tierra Buena (“Good Land”) was indeed a very good place to come up with new ideas and to think out of the box, reviving the technological perspective for each team member and filling the last gaps in our built-on automation landscape.<br>We have returned to the office fueled by visionary understanding, but we also conjured up a brand new continuous delivery pipeline mascot, Wall-E, which self-assembled in Lego, of course.</p>\n<p>To sum up, we can definitely recommend this team-bonding experience for every professional team.<br>Such intense moments can sharpen your focus and broaden your horizons at once, but most importantly keep you ahead of the competition.</p>\n","excerpt":"","more":"<p>Last week, the ePages release and test automation team was welcomed by the precious views, hearty people and refreshing atmosphere of Mallorca.<br>The purpose of this particular trip was to celebrate an offsite team event liberated from the daily tasks and routines of the business life.<br>The team set off to new shores to develop a master plan on how it could face the winds of change of the advancement of each team member.<br>The ultimate goal was to find the best way for contributing to the promising future of the whole research and development department.</p>\n<p>Now we are back and ready to briefly tell you the tale of the fearless developers’ journey to a mysterious island.<br>Enjoy the multifaceted report!</p>\n<h2 id=\"Travelling-together\"><a href=\"#Travelling-together\" class=\"headerlink\" title=\"Travelling together\"></a>Travelling together</h2><p>With much curiosity we first took some time off and enjoyed the amazing view over the beach skyline from the terrace of our finca, <a href=\"http://sonpages.com\">Son Pages</a>.<br>On day two, we visited the <a href=\"http://www.cuevasdeldrach.com\">Cuevas del Drach</a> and the beautiful yacht harbour at <a href=\"http://www.portocristo.org/\">Porto Cristo</a> to draw fresh inspiration.<br>On the next day, we went on a road trip with the team van to Sa Calobra in the north.<br>We were impressed by the majestic mountains and the bluish tonalities of the Mediterranean Sea.<br>When cruising along the bay area, we also found various <a href=\"https://www.geocaching.com\">Geocaching</a> possibilities to explore.</p>\n<img class=\"blog/blog-mallorca-1.jpg\">\n<h2 id=\"Living-as-a-team\"><a href=\"#Living-as-a-team\" class=\"headerlink\" title=\"Living as a team\"></a>Living as a team</h2><p>Sharing daily life activities such as having breakfast, shopping, cooking and playing board games together was definitely a delightful way to become closer.<br>Every morning we even had a wonderful one hour wake-up fitness workout by a fun-loving and very disciplined personal trainer.<br>This kick-starting routine often blended nicely into the warming sunrise over the palm island – what a sight!</p>\n<p>That’s why the offsite time was a <strong>BIG</strong> chance to gain trust into the capabilities of our team.<br>We totally adopted this magical present. Unsurprisingly, we soon recognised that living the team spirit can be a lot of fun!</p>\n<img class=\"blog/blog-mallorca-2.jpg\">\n<h2 id=\"Learning-from-your-peers\"><a href=\"#Learning-from-your-peers\" class=\"headerlink\" title=\"Learning from your peers\"></a>Learning from your peers</h2><p>During our time on Mallorca, we of course had lots of time to work on our technological and business challenges, too.</p>\n<p>We accomplished two knowledge sharing sessions.<br>One session was held by our continuous delivery pipeline expert in order to understand and explain the tool chain mechanisms that have not been shared equally amongst each team member yet.<br>Another session focused on our evolved know-how and the established workflows around the translation process including language handling and building of language packs for internationalisation.</p>\n<p>We also played two rounds of <a href=\"http://codingdojo.org\">Coding Dojo</a>, where we focused on solving the <strong>Kata of Conway’s Game of Life</strong>.<br>In the first round we tried to apply the constraints <em>“TDD as if you meant it”</em> and <em>“Driver &amp; Navigator”</em>, which strictly separates the roles in pair programming.<br>The second round focused on shaping distinct, comprehensive and sustainable test cases.<br>Therefore, one ePagee had to implement a unit test.<br>Next, the coding partner should lean into the position of an <em>“evil programmer”</em> and hence only implement as little as possible to make the test pass.<br>Afterwards he gives back the keyboard to the radically stressed writer of the unit test, who has to enforce the desired implementation with the addition of another test case.<br>In this rotary principle we trained our sense for writing high quality tests. This hands-on approach delivered a lot of amusements as well as practical benefits for our programming skills.</p>\n<img class=\"blog/blog-mallorca-3.jpg\">\n<h2 id=\"Inspiring-one-another\"><a href=\"#Inspiring-one-another\" class=\"headerlink\" title=\"Inspiring one another\"></a>Inspiring one another</h2><p>We also planned one day for a hackathon, that accelerated our ingenious chains of thoughts.<br>From the early afternoon until late into the night three pairs of programmers took the opportunity to delve into topics of their interest – which fortunately often matched the team’s scope of duties.<br>One team evaluated the <a href=\"https://wiki.jenkins-ci.org/display/JENKINS/Pipeline+Plugin\">Jenkins Pipeline Plugin</a> and built a rapid prototype with multiple continuous delivery stages.<br>Others engineered the ground-breaking steps for an automated translation process.<br>The third team developed a new concept on how to deal with failing tests – of course not without a working prototype that considered a quarantine test group.<br>Presenting the results to the others the next morning showed how quick ideas can grow into applicable solutions.</p>\n<p>Two <a href=\"http://hpi.de/school-of-design-thinking.html\">Design Thinking</a> sessions took us beyond the mental barrier of longsome beaten paths.<br>The consistent execution of this method over and over again rapidly helped us to find the desired ideas for our current team mission.<br>Firstly, we want to return a lot of responsibilities to those teams that strongly depend on us these days.<br>Secondly, we would like to establish a fast and secure mechanism to permanently keep the latest build of the next ePages version in a releasable state.</p>\n<img class=\"blog/blog-mallorca-4.jpg\">\n<h2 id=\"Summary\"><a href=\"#Summary\" class=\"headerlink\" title=\"Summary\"></a>Summary</h2><p>In retrospective, Tierra Buena (“Good Land”) was indeed a very good place to come up with new ideas and to think out of the box, reviving the technological perspective for each team member and filling the last gaps in our built-on automation landscape.<br>We have returned to the office fueled by visionary understanding, but we also conjured up a brand new continuous delivery pipeline mascot, Wall-E, which self-assembled in Lego, of course.</p>\n<p>To sum up, we can definitely recommend this team-bonding experience for every professional team.<br>Such intense moments can sharpen your focus and broaden your horizons at once, but most importantly keep you ahead of the competition.</p>\n"},{"layout":"post","title":"App development: ePages Partner Training in Hamburg","date":"2016-04-01T09:13:24.000Z","image":"blog-header/partner-training.jpg","authors":["Birgit"],"_content":"\nYou are an ePages partner already?\nOr you're interested developing an app for ePages?\nYou're very welcome to sign up for our next ePages Partner Training.\nIf you're curious about the agenda, here's a quick overview:\n\nExtract from agenda:\n\n* Merchant Basics\n* Introduction to ePages REST API\n* Developing an app with PHP and ePages REST API\n* Cartridge Basics\n* Q&A session\n\nDate & Time: 25th to 29th of April 2016\n\nTrainer: David Pauli (Software Developer)\n\nLocation: ePages headquarter, Pilatuspool 2, 20355 Hamburg\n\nSign up at [training@epages.com](mailto:training@epages.com) until 14th of April 2016.\nWe're looking forward to see you there!\n","source":"_posts/2016-04-01-partner-training.md","raw":"---\nlayout: post\ntitle: \"App development: ePages Partner Training in Hamburg\"\ndate: \"2016-04-01 11:13:24\"\nimage: blog-header/partner-training.jpg\ncategories: events\nauthors: [\"Birgit\"]\n---\n\nYou are an ePages partner already?\nOr you're interested developing an app for ePages?\nYou're very welcome to sign up for our next ePages Partner Training.\nIf you're curious about the agenda, here's a quick overview:\n\nExtract from agenda:\n\n* Merchant Basics\n* Introduction to ePages REST API\n* Developing an app with PHP and ePages REST API\n* Cartridge Basics\n* Q&A session\n\nDate & Time: 25th to 29th of April 2016\n\nTrainer: David Pauli (Software Developer)\n\nLocation: ePages headquarter, Pilatuspool 2, 20355 Hamburg\n\nSign up at [training@epages.com](mailto:training@epages.com) until 14th of April 2016.\nWe're looking forward to see you there!\n","slug":"2016-04-01-partner-training","published":1,"updated":"2016-09-20T14:31:48.000Z","comments":1,"photos":[],"link":"","_id":"ciu6nuh9p002ehqyxemm59zrg","content":"<p>You are an ePages partner already?<br>Or you’re interested developing an app for ePages?<br>You’re very welcome to sign up for our next ePages Partner Training.<br>If you’re curious about the agenda, here’s a quick overview:</p>\n<p>Extract from agenda:</p>\n<ul>\n<li>Merchant Basics</li>\n<li>Introduction to ePages REST API</li>\n<li>Developing an app with PHP and ePages REST API</li>\n<li>Cartridge Basics</li>\n<li>Q&amp;A session</li>\n</ul>\n<p>Date &amp; Time: 25th to 29th of April 2016</p>\n<p>Trainer: David Pauli (Software Developer)</p>\n<p>Location: ePages headquarter, Pilatuspool 2, 20355 Hamburg</p>\n<p>Sign up at <a href=\"mailto:training@epages.com\" target=\"_blank\" rel=\"external\">training@epages.com</a> until 14th of April 2016.<br>We’re looking forward to see you there!</p>\n","excerpt":"","more":"<p>You are an ePages partner already?<br>Or you’re interested developing an app for ePages?<br>You’re very welcome to sign up for our next ePages Partner Training.<br>If you’re curious about the agenda, here’s a quick overview:</p>\n<p>Extract from agenda:</p>\n<ul>\n<li>Merchant Basics</li>\n<li>Introduction to ePages REST API</li>\n<li>Developing an app with PHP and ePages REST API</li>\n<li>Cartridge Basics</li>\n<li>Q&amp;A session</li>\n</ul>\n<p>Date &amp; Time: 25th to 29th of April 2016</p>\n<p>Trainer: David Pauli (Software Developer)</p>\n<p>Location: ePages headquarter, Pilatuspool 2, 20355 Hamburg</p>\n<p>Sign up at <a href=\"mailto:training@epages.com\">training@epages.com</a> until 14th of April 2016.<br>We’re looking forward to see you there!</p>\n"},{"layout":"post","title":"Test-driven development with Java","date":"2016-04-05T06:00:00.000Z","image":"blog-header/java.jpg","authors":["Jan M."],"_content":"\nTest-driven development is a programming technique in which the validation of the correctness of the source code is implemented before the actual source code itself.\nThis blog post is a summary of the lessons learned from a \"Test-driven development with Java\" training by [lp-it](http://www.lp-it.de/schulungen/java-test-driven-development-schulung.php3).\nIn order to increase the readability, it also includes some additional research.\n\n## Introduction\n\n> Experience is a hard teacher because she gives the test first, the lesson afterward. (*Chinese proverb*)\n\nIn Test-driven development (TDD), the first step of a programmer is to write a failing unit test, a script which makes the absence of a system feature explicit.\nIn the second step the minimum amount of source code is implemented which is needed to fulfil this requirement.\nThe third step is to refactor the implementation.\nThis cycle is intended to be repeated in short iterations of a few minutes.\n\nTDD became popular [in around 2002](http://c2.com/cgi/wiki?TenYearsOfTestDrivenDevelopment) along with the rise of [Extreme Programming](http://www.extremeprogramming.org/map/project.html) and other agile software processes.\nToday it is successfully applied in [big software projects](http://programmers.stackexchange.com/questions/74580/looking-for-case-studies-of-how-tdd-improved-quality-and-or-speed-of-development) and sold as a best practice by many consulting companies, e.g. [it-agile](https://www.it-agile.de/schulungen/agile-entwicklungspraktiken/tdd-camp/), [ThoughtWorks](https://www.thoughtworks.com/de/insights/blog/building-vibrant-software-testing-community-africa) and [LeSS](https://less.works/less/technical-excellence/test-driven-development.html).\n\n### Motivation\n\nThe application of TDD promises a number of advantages.\nIt helps to:\n\n* get a clear understanding of the requirements\n* decompose complex problems\n* deliver high quality code even under time pressure\n* have regular success experiences.\n\n### Challenges\n\nTDD is [not uncontroversial](http://martinfowler.com/articles/is-tdd-dead/) for the following reasons:\n\n* It is counter-intuitive like the [Monty Hall Problem](https://github.com/jmewes/MontyHallProblem).\n* It takes about [two to three years](http://developeronfire.com/episode-114-robert-martin-master-craftsman) practice to do it well.\n\nActually, there are passionate [advocates](http://blog.cleancoder.com/uncle-bob/2016/03/19/GivingUpOnTDD.html) and [opponents](http://beust.com/weblog/2014/05/11/the-pitfalls-of-test-driven-development/) for this practice in the software community.\n\n## Software Design\n\nThe most important lesson for me in the TDD training was, that the testability of the source code can be improved by the application of the following design principles:\n\n| Principle     | Description  |\n|---------------|---------------|\n| Loose coupling     | The dependencies between modules should be minimised. |\n| High cohesion     | Modules should be grouped by the data they are working with. |\n\nFind more information about this subject using the keywords \"[SOLID design principles](https://www.google.com/search?q%3Dsolid%2Bdesign%2Bprinciples)\".\n\n### Design Pattern\n\nLoose coupling can be achieved by the application of the design pattern [Abstract Factory](http://www.tutorialspoint.com/design_pattern/abstract_factory_pattern.htm), [Bridge](http://www.tutorialspoint.com/design_pattern/bridge_pattern.htm), [Chain of Responsibility](http://www.tutorialspoint.com/design_pattern/chain_of_responsibility_pattern.htm), [Command](http://www.tutorialspoint.com/design_pattern/command_pattern.htm), [Facade](http://www.tutorialspoint.com/design_pattern/facade_pattern.htm), [Mediator](http://www.tutorialspoint.com/design_pattern/mediator_pattern.htm) and [Observer](http://www.tutorialspoint.com/design_pattern/observer_pattern.htm).\n\n### Refactoring\n\nHigh cohesion can be reached by the application of the refactoring pattern [Extract Class](http://refactoring.com/catalog/extractClass.html), [Extract Module](http://refactoring.com/catalog/extractModule.html), [Extract Subclass](http://refactoring.com/catalog/extractSubclass.html), [Extract Superclass](http://refactoring.com/catalog/extractSuperclass.html), [Pull Up Method](http://refactoring.com/catalog/pullUpMethod.html), [Push Down Method](http://refactoring.com/catalog/pushDownMethod.html), [Pull Up Field](http://refactoring.com/catalog/pullUpField.html), [Push Down Field](http://refactoring.com/catalog/pushDownField.html), [Move Field](http://refactoring.com/catalog/moveField.html) and [Move Method](http://refactoring.com/catalog/moveMethod.html).\n\n## Practical tips\n\nThe advantage of training courses over books and videos is, that they can include personalised, practical advice:\n\n* Start working on a ticket by writing unit tests, always.\n* Example is better than precept.\n* The [Boy Scout Rule](http://programmer.97things.oreilly.com/wiki/index.php/The_Boy_Scout_Rule) can help to get started.\n* At least 70% of the source code should be covered by unit tests, 80% is very good and more than 95% is perfect.\n* TDD should be applied in a pragmatic way and not necessarily by the book.\n\n## Java tools\n\nAs TDD is all about writing unit tests, here is an overview of the most commonly used Java tools for testing:\n\n| Framework     | Description  |\n|---------------|---------------|\n| [JUnit](http://junit.org)      | The de-facto standard framework for unit tests. |\n| [TestNG](http://testng.org)      | An alternative for JUnit. |\n| [Mockito](http://mockito.org/)   | A library for the creation of mock and stub objects. |\n| [EasyMock](http://easymock.org/)   | An alternative for Mockito. |\n| [PowerMock](https://github.com/jayway/powermock)   | Extends Mockito and Easymock to be able to test untestable code. |\n| [WireMock](http://wiremock.org/)   |Can be used for stubbing and mocking web services. |\n\n## Conclusion\n\nIt is a common saying that no complex software system is free from defects.\nThe reason is, that even the best developers [sometimes](http://programmers.stackexchange.com/questions/185660/is-the-average-number-of-bugs-per-loc-the-same-for-different-programming-languag) rely on false assumptions.\nAs long as we cannot prove the correctness of our code mathematically, it needs to be tested thoroughly before it can be delivered to the customer.\nAs the release cycles tend to be shorter and shorter, these tests need to be automated.\nThe [Test Pyramid](http://martinfowler.com/bliki/TestPyramid.html) model implies that unit tests should be the foundation of the test automation.\nWhether these tests are written before or after the source code seems to be a matter of taste.\nWriting the tests first can lead to a number of advantages and from my perspective is thus worth learning.\n","source":"_posts/2016-04-05-tdd-with-java.md","raw":"---\nlayout: post\ntitle: \"Test-driven development with Java\"\ndate: \"2016-04-05 08:00:00\"\nimage: blog-header/java.jpg\ncategories: tech-stories\nauthors: [\"Jan M.\"]\n---\n\nTest-driven development is a programming technique in which the validation of the correctness of the source code is implemented before the actual source code itself.\nThis blog post is a summary of the lessons learned from a \"Test-driven development with Java\" training by [lp-it](http://www.lp-it.de/schulungen/java-test-driven-development-schulung.php3).\nIn order to increase the readability, it also includes some additional research.\n\n## Introduction\n\n> Experience is a hard teacher because she gives the test first, the lesson afterward. (*Chinese proverb*)\n\nIn Test-driven development (TDD), the first step of a programmer is to write a failing unit test, a script which makes the absence of a system feature explicit.\nIn the second step the minimum amount of source code is implemented which is needed to fulfil this requirement.\nThe third step is to refactor the implementation.\nThis cycle is intended to be repeated in short iterations of a few minutes.\n\nTDD became popular [in around 2002](http://c2.com/cgi/wiki?TenYearsOfTestDrivenDevelopment) along with the rise of [Extreme Programming](http://www.extremeprogramming.org/map/project.html) and other agile software processes.\nToday it is successfully applied in [big software projects](http://programmers.stackexchange.com/questions/74580/looking-for-case-studies-of-how-tdd-improved-quality-and-or-speed-of-development) and sold as a best practice by many consulting companies, e.g. [it-agile](https://www.it-agile.de/schulungen/agile-entwicklungspraktiken/tdd-camp/), [ThoughtWorks](https://www.thoughtworks.com/de/insights/blog/building-vibrant-software-testing-community-africa) and [LeSS](https://less.works/less/technical-excellence/test-driven-development.html).\n\n### Motivation\n\nThe application of TDD promises a number of advantages.\nIt helps to:\n\n* get a clear understanding of the requirements\n* decompose complex problems\n* deliver high quality code even under time pressure\n* have regular success experiences.\n\n### Challenges\n\nTDD is [not uncontroversial](http://martinfowler.com/articles/is-tdd-dead/) for the following reasons:\n\n* It is counter-intuitive like the [Monty Hall Problem](https://github.com/jmewes/MontyHallProblem).\n* It takes about [two to three years](http://developeronfire.com/episode-114-robert-martin-master-craftsman) practice to do it well.\n\nActually, there are passionate [advocates](http://blog.cleancoder.com/uncle-bob/2016/03/19/GivingUpOnTDD.html) and [opponents](http://beust.com/weblog/2014/05/11/the-pitfalls-of-test-driven-development/) for this practice in the software community.\n\n## Software Design\n\nThe most important lesson for me in the TDD training was, that the testability of the source code can be improved by the application of the following design principles:\n\n| Principle     | Description  |\n|---------------|---------------|\n| Loose coupling     | The dependencies between modules should be minimised. |\n| High cohesion     | Modules should be grouped by the data they are working with. |\n\nFind more information about this subject using the keywords \"[SOLID design principles](https://www.google.com/search?q%3Dsolid%2Bdesign%2Bprinciples)\".\n\n### Design Pattern\n\nLoose coupling can be achieved by the application of the design pattern [Abstract Factory](http://www.tutorialspoint.com/design_pattern/abstract_factory_pattern.htm), [Bridge](http://www.tutorialspoint.com/design_pattern/bridge_pattern.htm), [Chain of Responsibility](http://www.tutorialspoint.com/design_pattern/chain_of_responsibility_pattern.htm), [Command](http://www.tutorialspoint.com/design_pattern/command_pattern.htm), [Facade](http://www.tutorialspoint.com/design_pattern/facade_pattern.htm), [Mediator](http://www.tutorialspoint.com/design_pattern/mediator_pattern.htm) and [Observer](http://www.tutorialspoint.com/design_pattern/observer_pattern.htm).\n\n### Refactoring\n\nHigh cohesion can be reached by the application of the refactoring pattern [Extract Class](http://refactoring.com/catalog/extractClass.html), [Extract Module](http://refactoring.com/catalog/extractModule.html), [Extract Subclass](http://refactoring.com/catalog/extractSubclass.html), [Extract Superclass](http://refactoring.com/catalog/extractSuperclass.html), [Pull Up Method](http://refactoring.com/catalog/pullUpMethod.html), [Push Down Method](http://refactoring.com/catalog/pushDownMethod.html), [Pull Up Field](http://refactoring.com/catalog/pullUpField.html), [Push Down Field](http://refactoring.com/catalog/pushDownField.html), [Move Field](http://refactoring.com/catalog/moveField.html) and [Move Method](http://refactoring.com/catalog/moveMethod.html).\n\n## Practical tips\n\nThe advantage of training courses over books and videos is, that they can include personalised, practical advice:\n\n* Start working on a ticket by writing unit tests, always.\n* Example is better than precept.\n* The [Boy Scout Rule](http://programmer.97things.oreilly.com/wiki/index.php/The_Boy_Scout_Rule) can help to get started.\n* At least 70% of the source code should be covered by unit tests, 80% is very good and more than 95% is perfect.\n* TDD should be applied in a pragmatic way and not necessarily by the book.\n\n## Java tools\n\nAs TDD is all about writing unit tests, here is an overview of the most commonly used Java tools for testing:\n\n| Framework     | Description  |\n|---------------|---------------|\n| [JUnit](http://junit.org)      | The de-facto standard framework for unit tests. |\n| [TestNG](http://testng.org)      | An alternative for JUnit. |\n| [Mockito](http://mockito.org/)   | A library for the creation of mock and stub objects. |\n| [EasyMock](http://easymock.org/)   | An alternative for Mockito. |\n| [PowerMock](https://github.com/jayway/powermock)   | Extends Mockito and Easymock to be able to test untestable code. |\n| [WireMock](http://wiremock.org/)   |Can be used for stubbing and mocking web services. |\n\n## Conclusion\n\nIt is a common saying that no complex software system is free from defects.\nThe reason is, that even the best developers [sometimes](http://programmers.stackexchange.com/questions/185660/is-the-average-number-of-bugs-per-loc-the-same-for-different-programming-languag) rely on false assumptions.\nAs long as we cannot prove the correctness of our code mathematically, it needs to be tested thoroughly before it can be delivered to the customer.\nAs the release cycles tend to be shorter and shorter, these tests need to be automated.\nThe [Test Pyramid](http://martinfowler.com/bliki/TestPyramid.html) model implies that unit tests should be the foundation of the test automation.\nWhether these tests are written before or after the source code seems to be a matter of taste.\nWriting the tests first can lead to a number of advantages and from my perspective is thus worth learning.\n","slug":"2016-04-05-tdd-with-java","published":1,"updated":"2016-09-20T14:31:48.000Z","comments":1,"photos":[],"link":"","_id":"ciu6nuh9q002ghqyx5b0dy2p6","content":"<p>Test-driven development is a programming technique in which the validation of the correctness of the source code is implemented before the actual source code itself.<br>This blog post is a summary of the lessons learned from a “Test-driven development with Java” training by <a href=\"http://www.lp-it.de/schulungen/java-test-driven-development-schulung.php3\" target=\"_blank\" rel=\"external\">lp-it</a>.<br>In order to increase the readability, it also includes some additional research.</p>\n<h2 id=\"Introduction\"><a href=\"#Introduction\" class=\"headerlink\" title=\"Introduction\"></a>Introduction</h2><blockquote>\n<p>Experience is a hard teacher because she gives the test first, the lesson afterward. (<em>Chinese proverb</em>)</p>\n</blockquote>\n<p>In Test-driven development (TDD), the first step of a programmer is to write a failing unit test, a script which makes the absence of a system feature explicit.<br>In the second step the minimum amount of source code is implemented which is needed to fulfil this requirement.<br>The third step is to refactor the implementation.<br>This cycle is intended to be repeated in short iterations of a few minutes.</p>\n<p>TDD became popular <a href=\"http://c2.com/cgi/wiki?TenYearsOfTestDrivenDevelopment\" target=\"_blank\" rel=\"external\">in around 2002</a> along with the rise of <a href=\"http://www.extremeprogramming.org/map/project.html\" target=\"_blank\" rel=\"external\">Extreme Programming</a> and other agile software processes.<br>Today it is successfully applied in <a href=\"http://programmers.stackexchange.com/questions/74580/looking-for-case-studies-of-how-tdd-improved-quality-and-or-speed-of-development\" target=\"_blank\" rel=\"external\">big software projects</a> and sold as a best practice by many consulting companies, e.g. <a href=\"https://www.it-agile.de/schulungen/agile-entwicklungspraktiken/tdd-camp/\" target=\"_blank\" rel=\"external\">it-agile</a>, <a href=\"https://www.thoughtworks.com/de/insights/blog/building-vibrant-software-testing-community-africa\" target=\"_blank\" rel=\"external\">ThoughtWorks</a> and <a href=\"https://less.works/less/technical-excellence/test-driven-development.html\" target=\"_blank\" rel=\"external\">LeSS</a>.</p>\n<h3 id=\"Motivation\"><a href=\"#Motivation\" class=\"headerlink\" title=\"Motivation\"></a>Motivation</h3><p>The application of TDD promises a number of advantages.<br>It helps to:</p>\n<ul>\n<li>get a clear understanding of the requirements</li>\n<li>decompose complex problems</li>\n<li>deliver high quality code even under time pressure</li>\n<li>have regular success experiences.</li>\n</ul>\n<h3 id=\"Challenges\"><a href=\"#Challenges\" class=\"headerlink\" title=\"Challenges\"></a>Challenges</h3><p>TDD is <a href=\"http://martinfowler.com/articles/is-tdd-dead/\" target=\"_blank\" rel=\"external\">not uncontroversial</a> for the following reasons:</p>\n<ul>\n<li>It is counter-intuitive like the <a href=\"https://github.com/jmewes/MontyHallProblem\" target=\"_blank\" rel=\"external\">Monty Hall Problem</a>.</li>\n<li>It takes about <a href=\"http://developeronfire.com/episode-114-robert-martin-master-craftsman\" target=\"_blank\" rel=\"external\">two to three years</a> practice to do it well.</li>\n</ul>\n<p>Actually, there are passionate <a href=\"http://blog.cleancoder.com/uncle-bob/2016/03/19/GivingUpOnTDD.html\" target=\"_blank\" rel=\"external\">advocates</a> and <a href=\"http://beust.com/weblog/2014/05/11/the-pitfalls-of-test-driven-development/\" target=\"_blank\" rel=\"external\">opponents</a> for this practice in the software community.</p>\n<h2 id=\"Software-Design\"><a href=\"#Software-Design\" class=\"headerlink\" title=\"Software Design\"></a>Software Design</h2><p>The most important lesson for me in the TDD training was, that the testability of the source code can be improved by the application of the following design principles:</p>\n<table>\n<thead>\n<tr>\n<th>Principle</th>\n<th>Description</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td>Loose coupling</td>\n<td>The dependencies between modules should be minimised.</td>\n</tr>\n<tr>\n<td>High cohesion</td>\n<td>Modules should be grouped by the data they are working with.</td>\n</tr>\n</tbody>\n</table>\n<p>Find more information about this subject using the keywords “<a href=\"https://www.google.com/search?q%3Dsolid%2Bdesign%2Bprinciples\" target=\"_blank\" rel=\"external\">SOLID design principles</a>“.</p>\n<h3 id=\"Design-Pattern\"><a href=\"#Design-Pattern\" class=\"headerlink\" title=\"Design Pattern\"></a>Design Pattern</h3><p>Loose coupling can be achieved by the application of the design pattern <a href=\"http://www.tutorialspoint.com/design_pattern/abstract_factory_pattern.htm\" target=\"_blank\" rel=\"external\">Abstract Factory</a>, <a href=\"http://www.tutorialspoint.com/design_pattern/bridge_pattern.htm\" target=\"_blank\" rel=\"external\">Bridge</a>, <a href=\"http://www.tutorialspoint.com/design_pattern/chain_of_responsibility_pattern.htm\" target=\"_blank\" rel=\"external\">Chain of Responsibility</a>, <a href=\"http://www.tutorialspoint.com/design_pattern/command_pattern.htm\" target=\"_blank\" rel=\"external\">Command</a>, <a href=\"http://www.tutorialspoint.com/design_pattern/facade_pattern.htm\" target=\"_blank\" rel=\"external\">Facade</a>, <a href=\"http://www.tutorialspoint.com/design_pattern/mediator_pattern.htm\" target=\"_blank\" rel=\"external\">Mediator</a> and <a href=\"http://www.tutorialspoint.com/design_pattern/observer_pattern.htm\" target=\"_blank\" rel=\"external\">Observer</a>.</p>\n<h3 id=\"Refactoring\"><a href=\"#Refactoring\" class=\"headerlink\" title=\"Refactoring\"></a>Refactoring</h3><p>High cohesion can be reached by the application of the refactoring pattern <a href=\"http://refactoring.com/catalog/extractClass.html\" target=\"_blank\" rel=\"external\">Extract Class</a>, <a href=\"http://refactoring.com/catalog/extractModule.html\" target=\"_blank\" rel=\"external\">Extract Module</a>, <a href=\"http://refactoring.com/catalog/extractSubclass.html\" target=\"_blank\" rel=\"external\">Extract Subclass</a>, <a href=\"http://refactoring.com/catalog/extractSuperclass.html\" target=\"_blank\" rel=\"external\">Extract Superclass</a>, <a href=\"http://refactoring.com/catalog/pullUpMethod.html\" target=\"_blank\" rel=\"external\">Pull Up Method</a>, <a href=\"http://refactoring.com/catalog/pushDownMethod.html\" target=\"_blank\" rel=\"external\">Push Down Method</a>, <a href=\"http://refactoring.com/catalog/pullUpField.html\" target=\"_blank\" rel=\"external\">Pull Up Field</a>, <a href=\"http://refactoring.com/catalog/pushDownField.html\" target=\"_blank\" rel=\"external\">Push Down Field</a>, <a href=\"http://refactoring.com/catalog/moveField.html\" target=\"_blank\" rel=\"external\">Move Field</a> and <a href=\"http://refactoring.com/catalog/moveMethod.html\" target=\"_blank\" rel=\"external\">Move Method</a>.</p>\n<h2 id=\"Practical-tips\"><a href=\"#Practical-tips\" class=\"headerlink\" title=\"Practical tips\"></a>Practical tips</h2><p>The advantage of training courses over books and videos is, that they can include personalised, practical advice:</p>\n<ul>\n<li>Start working on a ticket by writing unit tests, always.</li>\n<li>Example is better than precept.</li>\n<li>The <a href=\"http://programmer.97things.oreilly.com/wiki/index.php/The_Boy_Scout_Rule\" target=\"_blank\" rel=\"external\">Boy Scout Rule</a> can help to get started.</li>\n<li>At least 70% of the source code should be covered by unit tests, 80% is very good and more than 95% is perfect.</li>\n<li>TDD should be applied in a pragmatic way and not necessarily by the book.</li>\n</ul>\n<h2 id=\"Java-tools\"><a href=\"#Java-tools\" class=\"headerlink\" title=\"Java tools\"></a>Java tools</h2><p>As TDD is all about writing unit tests, here is an overview of the most commonly used Java tools for testing:</p>\n<table>\n<thead>\n<tr>\n<th>Framework</th>\n<th>Description</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td><a href=\"http://junit.org\" target=\"_blank\" rel=\"external\">JUnit</a></td>\n<td>The de-facto standard framework for unit tests.</td>\n</tr>\n<tr>\n<td><a href=\"http://testng.org\" target=\"_blank\" rel=\"external\">TestNG</a></td>\n<td>An alternative for JUnit.</td>\n</tr>\n<tr>\n<td><a href=\"http://mockito.org/\" target=\"_blank\" rel=\"external\">Mockito</a></td>\n<td>A library for the creation of mock and stub objects.</td>\n</tr>\n<tr>\n<td><a href=\"http://easymock.org/\" target=\"_blank\" rel=\"external\">EasyMock</a></td>\n<td>An alternative for Mockito.</td>\n</tr>\n<tr>\n<td><a href=\"https://github.com/jayway/powermock\" target=\"_blank\" rel=\"external\">PowerMock</a></td>\n<td>Extends Mockito and Easymock to be able to test untestable code.</td>\n</tr>\n<tr>\n<td><a href=\"http://wiremock.org/\" target=\"_blank\" rel=\"external\">WireMock</a></td>\n<td>Can be used for stubbing and mocking web services.</td>\n</tr>\n</tbody>\n</table>\n<h2 id=\"Conclusion\"><a href=\"#Conclusion\" class=\"headerlink\" title=\"Conclusion\"></a>Conclusion</h2><p>It is a common saying that no complex software system is free from defects.<br>The reason is, that even the best developers <a href=\"http://programmers.stackexchange.com/questions/185660/is-the-average-number-of-bugs-per-loc-the-same-for-different-programming-languag\" target=\"_blank\" rel=\"external\">sometimes</a> rely on false assumptions.<br>As long as we cannot prove the correctness of our code mathematically, it needs to be tested thoroughly before it can be delivered to the customer.<br>As the release cycles tend to be shorter and shorter, these tests need to be automated.<br>The <a href=\"http://martinfowler.com/bliki/TestPyramid.html\" target=\"_blank\" rel=\"external\">Test Pyramid</a> model implies that unit tests should be the foundation of the test automation.<br>Whether these tests are written before or after the source code seems to be a matter of taste.<br>Writing the tests first can lead to a number of advantages and from my perspective is thus worth learning.</p>\n","excerpt":"","more":"<p>Test-driven development is a programming technique in which the validation of the correctness of the source code is implemented before the actual source code itself.<br>This blog post is a summary of the lessons learned from a “Test-driven development with Java” training by <a href=\"http://www.lp-it.de/schulungen/java-test-driven-development-schulung.php3\">lp-it</a>.<br>In order to increase the readability, it also includes some additional research.</p>\n<h2 id=\"Introduction\"><a href=\"#Introduction\" class=\"headerlink\" title=\"Introduction\"></a>Introduction</h2><blockquote>\n<p>Experience is a hard teacher because she gives the test first, the lesson afterward. (<em>Chinese proverb</em>)</p>\n</blockquote>\n<p>In Test-driven development (TDD), the first step of a programmer is to write a failing unit test, a script which makes the absence of a system feature explicit.<br>In the second step the minimum amount of source code is implemented which is needed to fulfil this requirement.<br>The third step is to refactor the implementation.<br>This cycle is intended to be repeated in short iterations of a few minutes.</p>\n<p>TDD became popular <a href=\"http://c2.com/cgi/wiki?TenYearsOfTestDrivenDevelopment\">in around 2002</a> along with the rise of <a href=\"http://www.extremeprogramming.org/map/project.html\">Extreme Programming</a> and other agile software processes.<br>Today it is successfully applied in <a href=\"http://programmers.stackexchange.com/questions/74580/looking-for-case-studies-of-how-tdd-improved-quality-and-or-speed-of-development\">big software projects</a> and sold as a best practice by many consulting companies, e.g. <a href=\"https://www.it-agile.de/schulungen/agile-entwicklungspraktiken/tdd-camp/\">it-agile</a>, <a href=\"https://www.thoughtworks.com/de/insights/blog/building-vibrant-software-testing-community-africa\">ThoughtWorks</a> and <a href=\"https://less.works/less/technical-excellence/test-driven-development.html\">LeSS</a>.</p>\n<h3 id=\"Motivation\"><a href=\"#Motivation\" class=\"headerlink\" title=\"Motivation\"></a>Motivation</h3><p>The application of TDD promises a number of advantages.<br>It helps to:</p>\n<ul>\n<li>get a clear understanding of the requirements</li>\n<li>decompose complex problems</li>\n<li>deliver high quality code even under time pressure</li>\n<li>have regular success experiences.</li>\n</ul>\n<h3 id=\"Challenges\"><a href=\"#Challenges\" class=\"headerlink\" title=\"Challenges\"></a>Challenges</h3><p>TDD is <a href=\"http://martinfowler.com/articles/is-tdd-dead/\">not uncontroversial</a> for the following reasons:</p>\n<ul>\n<li>It is counter-intuitive like the <a href=\"https://github.com/jmewes/MontyHallProblem\">Monty Hall Problem</a>.</li>\n<li>It takes about <a href=\"http://developeronfire.com/episode-114-robert-martin-master-craftsman\">two to three years</a> practice to do it well.</li>\n</ul>\n<p>Actually, there are passionate <a href=\"http://blog.cleancoder.com/uncle-bob/2016/03/19/GivingUpOnTDD.html\">advocates</a> and <a href=\"http://beust.com/weblog/2014/05/11/the-pitfalls-of-test-driven-development/\">opponents</a> for this practice in the software community.</p>\n<h2 id=\"Software-Design\"><a href=\"#Software-Design\" class=\"headerlink\" title=\"Software Design\"></a>Software Design</h2><p>The most important lesson for me in the TDD training was, that the testability of the source code can be improved by the application of the following design principles:</p>\n<table>\n<thead>\n<tr>\n<th>Principle</th>\n<th>Description</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td>Loose coupling</td>\n<td>The dependencies between modules should be minimised.</td>\n</tr>\n<tr>\n<td>High cohesion</td>\n<td>Modules should be grouped by the data they are working with.</td>\n</tr>\n</tbody>\n</table>\n<p>Find more information about this subject using the keywords “<a href=\"https://www.google.com/search?q%3Dsolid%2Bdesign%2Bprinciples\">SOLID design principles</a>“.</p>\n<h3 id=\"Design-Pattern\"><a href=\"#Design-Pattern\" class=\"headerlink\" title=\"Design Pattern\"></a>Design Pattern</h3><p>Loose coupling can be achieved by the application of the design pattern <a href=\"http://www.tutorialspoint.com/design_pattern/abstract_factory_pattern.htm\">Abstract Factory</a>, <a href=\"http://www.tutorialspoint.com/design_pattern/bridge_pattern.htm\">Bridge</a>, <a href=\"http://www.tutorialspoint.com/design_pattern/chain_of_responsibility_pattern.htm\">Chain of Responsibility</a>, <a href=\"http://www.tutorialspoint.com/design_pattern/command_pattern.htm\">Command</a>, <a href=\"http://www.tutorialspoint.com/design_pattern/facade_pattern.htm\">Facade</a>, <a href=\"http://www.tutorialspoint.com/design_pattern/mediator_pattern.htm\">Mediator</a> and <a href=\"http://www.tutorialspoint.com/design_pattern/observer_pattern.htm\">Observer</a>.</p>\n<h3 id=\"Refactoring\"><a href=\"#Refactoring\" class=\"headerlink\" title=\"Refactoring\"></a>Refactoring</h3><p>High cohesion can be reached by the application of the refactoring pattern <a href=\"http://refactoring.com/catalog/extractClass.html\">Extract Class</a>, <a href=\"http://refactoring.com/catalog/extractModule.html\">Extract Module</a>, <a href=\"http://refactoring.com/catalog/extractSubclass.html\">Extract Subclass</a>, <a href=\"http://refactoring.com/catalog/extractSuperclass.html\">Extract Superclass</a>, <a href=\"http://refactoring.com/catalog/pullUpMethod.html\">Pull Up Method</a>, <a href=\"http://refactoring.com/catalog/pushDownMethod.html\">Push Down Method</a>, <a href=\"http://refactoring.com/catalog/pullUpField.html\">Pull Up Field</a>, <a href=\"http://refactoring.com/catalog/pushDownField.html\">Push Down Field</a>, <a href=\"http://refactoring.com/catalog/moveField.html\">Move Field</a> and <a href=\"http://refactoring.com/catalog/moveMethod.html\">Move Method</a>.</p>\n<h2 id=\"Practical-tips\"><a href=\"#Practical-tips\" class=\"headerlink\" title=\"Practical tips\"></a>Practical tips</h2><p>The advantage of training courses over books and videos is, that they can include personalised, practical advice:</p>\n<ul>\n<li>Start working on a ticket by writing unit tests, always.</li>\n<li>Example is better than precept.</li>\n<li>The <a href=\"http://programmer.97things.oreilly.com/wiki/index.php/The_Boy_Scout_Rule\">Boy Scout Rule</a> can help to get started.</li>\n<li>At least 70% of the source code should be covered by unit tests, 80% is very good and more than 95% is perfect.</li>\n<li>TDD should be applied in a pragmatic way and not necessarily by the book.</li>\n</ul>\n<h2 id=\"Java-tools\"><a href=\"#Java-tools\" class=\"headerlink\" title=\"Java tools\"></a>Java tools</h2><p>As TDD is all about writing unit tests, here is an overview of the most commonly used Java tools for testing:</p>\n<table>\n<thead>\n<tr>\n<th>Framework</th>\n<th>Description</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td><a href=\"http://junit.org\">JUnit</a></td>\n<td>The de-facto standard framework for unit tests.</td>\n</tr>\n<tr>\n<td><a href=\"http://testng.org\">TestNG</a></td>\n<td>An alternative for JUnit.</td>\n</tr>\n<tr>\n<td><a href=\"http://mockito.org/\">Mockito</a></td>\n<td>A library for the creation of mock and stub objects.</td>\n</tr>\n<tr>\n<td><a href=\"http://easymock.org/\">EasyMock</a></td>\n<td>An alternative for Mockito.</td>\n</tr>\n<tr>\n<td><a href=\"https://github.com/jayway/powermock\">PowerMock</a></td>\n<td>Extends Mockito and Easymock to be able to test untestable code.</td>\n</tr>\n<tr>\n<td><a href=\"http://wiremock.org/\">WireMock</a></td>\n<td>Can be used for stubbing and mocking web services.</td>\n</tr>\n</tbody>\n</table>\n<h2 id=\"Conclusion\"><a href=\"#Conclusion\" class=\"headerlink\" title=\"Conclusion\"></a>Conclusion</h2><p>It is a common saying that no complex software system is free from defects.<br>The reason is, that even the best developers <a href=\"http://programmers.stackexchange.com/questions/185660/is-the-average-number-of-bugs-per-loc-the-same-for-different-programming-languag\">sometimes</a> rely on false assumptions.<br>As long as we cannot prove the correctness of our code mathematically, it needs to be tested thoroughly before it can be delivered to the customer.<br>As the release cycles tend to be shorter and shorter, these tests need to be automated.<br>The <a href=\"http://martinfowler.com/bliki/TestPyramid.html\">Test Pyramid</a> model implies that unit tests should be the foundation of the test automation.<br>Whether these tests are written before or after the source code seems to be a matter of taste.<br>Writing the tests first can lead to a number of advantages and from my perspective is thus worth learning.</p>\n"},{"layout":"post","title":"Magdeburger Developer Days","date":"2016-05-26T06:30:20.000Z","image":"blog-header/magdeburg-dev.jpg","authors":["Bastian and Benjamin"],"_content":"\nOn May, 18th 2016, the first [Developer Days](http://md-devdays.de/) took place in the exhibition halls of Magdeburg, Germany.\nAlthough this Java and .NET developer conference was organised for the first time, many developers from across Germany participated and followed the invitation from the [Twitter](https://twitter.com/MiB_MD_DevDays) channel of Michael Blume, the initiator and organiser.\n\n{% image blog/blog-magdeburg-1.jpg %}\n\n## The setting\n\nThe exhibition hall was parted into four large rooms, named after famous pioneers of the Information Technologies, like [Konrad Zuse](https://en.wikipedia.org/wiki/Konrad_Zuse) and [Bjarne Stroustrup](https://en.wikipedia.org/wiki/Bjarne_Stroustrup).\nThe lobby offered bar tables and an open space that could consistently be used for interesting discussions about the latest technologies, side projects, and networking.\nBesides the catering with snacks and a variety of beverages, the orga team also delivered a conference booklet with over 40 pages, where each speaker and session was listed in depth on individual pages.\nAnother noteworthy subject was the affectionate designed certificates for the participants that were handed over at the entrance area in addition to the welcome bag.\n\n{% image blog/blog-magdeburg-2.jpg %}\n\n## The sessions\n\nAfter the two introduction talks, the sessions began. The main topics were frontend and backend technologies, as well as a mixture of agile topics, requirements documentation, and programming technologies.\n\n{% image blog/blog-magdeburg-3.jpg %}\n\nThe first session was a dive into [TypeScript](https://www.typescriptlang.org) by Rainer Stropek.\nTypeScript is a JavaScript similar language and can be compiled into JavaScript.\nIt is a strictly typed and object-oriented programming language.\nWe learned how to compile and use TypeScript.\nRainer Stropek showed examples via live coding at the TypeScript [Playground](https://www.typescriptlang.org/play/index.html), which directly generates the resulting JavaScript.\nHe also showed how to use common JS libraries within TypeScript.\n\n{% image blog/blog-magdeburg-4.jpg %}\n\nOur second session was all about \"What's still new in [Java SE 8](https://docs.oracle.com/javase/8/docs/api)?\".\nBernd Gronostay, who works closely together with the author of \"Java ist auch ein Insel\", talked about a lot of new features and API changes.\nNot only did he talk about the modifications, but also showed a lot of examples which illustrated these features very well.\nThe perhaps most interesting part in this session were the various show cases of lambda functions and streams.\nThis enables developers to write Java in a functional syntax.\n\n{% image blog/blog-magdeburg-5.jpg %}\n\nAfter lunch there was a talk with a topic which was completely new to us:\nFunctional Domain Driven Design (DDD) with F# held by Marco Heimeshoff.\nHe is one of the cofounders of the [DDD community](http://dddcommunity.org) in Germany.\nHis introduction showed a new idea of how the software models should look like.\nThe mapping between the Requirement Space (Domain) and the Implementation Space (Code) is usually a gap that needs to be bridged.\nThe difficulty is to have the code representing exactly the real domain.\nBut often developers have to check that there is no possibility to represent an illegal state.\nThe simple solution with DDD is: Make illegal states unrepresentable!\nThis is only a little extract of this session with a lot of new, interesting ideas and patterns for solving things in a deterministically different way that makes intense unit testing obsolete.\n\n{% image blog/blog-magdeburg-6.jpg %}\n\nThe next session was an introduction into the JavaScript framework [React](https://facebook.github.io/react) by Oliver Zeigermann, who is the author of several JavaScript books.\nHe showed and explained the principals of React.\nOne feature of React is that it reperesents only the View in a Model-View-Controller (MVC) model.\nSo it is typical to have a mixture of JavaScript and HTML code in one file.\nAnother feature is that the Document Object Model (DOM) tree is virtualized.\nThat means, when a webpage flow is establihed only the objects that have change are updated via the calculation of a `diff` between the webpage states.\nThe interesting thing about React is, that due to that technique websites are always very fast.\n\n{% image blog/blog-magdeburg-7.jpg %}\n\nThe last session of the day was \"Architekturdokumentation leicht gemacht\" (architecture documentation for dummies) by Andreas Richter, the organiser of the [Softwerkskammer Magdeburg](https://www.softwerkskammer.org/groups/magdeburg).\nHe introduced the [arc42](http://arc42.org) template and its most important parts.\nThe main benefits of such an architectural templates is that there is always the same structure.\n\n## Summary\n\nThe Magdeburger Developer Days offered a lot of very interesting talks in a broad range of topics.\nWe were stunned from the professionel level that orga team could establish.\nThe speakers were well-choosen and the quality of talks was absolutely extraordinary.\nThe experience of the conference was very great and a visit next year is definitely reasonable.\n","source":"_posts/2016-05-26-magdeburger-developer-days.md","raw":"---\nlayout: post\ntitle: \"Magdeburger Developer Days\"\ndate: \"2016-05-26 08:30:20\"\nimage: blog-header/magdeburg-dev.jpg\ncategories: events\nauthors: [\"Bastian and Benjamin\"]\n---\n\nOn May, 18th 2016, the first [Developer Days](http://md-devdays.de/) took place in the exhibition halls of Magdeburg, Germany.\nAlthough this Java and .NET developer conference was organised for the first time, many developers from across Germany participated and followed the invitation from the [Twitter](https://twitter.com/MiB_MD_DevDays) channel of Michael Blume, the initiator and organiser.\n\n{% image blog/blog-magdeburg-1.jpg %}\n\n## The setting\n\nThe exhibition hall was parted into four large rooms, named after famous pioneers of the Information Technologies, like [Konrad Zuse](https://en.wikipedia.org/wiki/Konrad_Zuse) and [Bjarne Stroustrup](https://en.wikipedia.org/wiki/Bjarne_Stroustrup).\nThe lobby offered bar tables and an open space that could consistently be used for interesting discussions about the latest technologies, side projects, and networking.\nBesides the catering with snacks and a variety of beverages, the orga team also delivered a conference booklet with over 40 pages, where each speaker and session was listed in depth on individual pages.\nAnother noteworthy subject was the affectionate designed certificates for the participants that were handed over at the entrance area in addition to the welcome bag.\n\n{% image blog/blog-magdeburg-2.jpg %}\n\n## The sessions\n\nAfter the two introduction talks, the sessions began. The main topics were frontend and backend technologies, as well as a mixture of agile topics, requirements documentation, and programming technologies.\n\n{% image blog/blog-magdeburg-3.jpg %}\n\nThe first session was a dive into [TypeScript](https://www.typescriptlang.org) by Rainer Stropek.\nTypeScript is a JavaScript similar language and can be compiled into JavaScript.\nIt is a strictly typed and object-oriented programming language.\nWe learned how to compile and use TypeScript.\nRainer Stropek showed examples via live coding at the TypeScript [Playground](https://www.typescriptlang.org/play/index.html), which directly generates the resulting JavaScript.\nHe also showed how to use common JS libraries within TypeScript.\n\n{% image blog/blog-magdeburg-4.jpg %}\n\nOur second session was all about \"What's still new in [Java SE 8](https://docs.oracle.com/javase/8/docs/api)?\".\nBernd Gronostay, who works closely together with the author of \"Java ist auch ein Insel\", talked about a lot of new features and API changes.\nNot only did he talk about the modifications, but also showed a lot of examples which illustrated these features very well.\nThe perhaps most interesting part in this session were the various show cases of lambda functions and streams.\nThis enables developers to write Java in a functional syntax.\n\n{% image blog/blog-magdeburg-5.jpg %}\n\nAfter lunch there was a talk with a topic which was completely new to us:\nFunctional Domain Driven Design (DDD) with F# held by Marco Heimeshoff.\nHe is one of the cofounders of the [DDD community](http://dddcommunity.org) in Germany.\nHis introduction showed a new idea of how the software models should look like.\nThe mapping between the Requirement Space (Domain) and the Implementation Space (Code) is usually a gap that needs to be bridged.\nThe difficulty is to have the code representing exactly the real domain.\nBut often developers have to check that there is no possibility to represent an illegal state.\nThe simple solution with DDD is: Make illegal states unrepresentable!\nThis is only a little extract of this session with a lot of new, interesting ideas and patterns for solving things in a deterministically different way that makes intense unit testing obsolete.\n\n{% image blog/blog-magdeburg-6.jpg %}\n\nThe next session was an introduction into the JavaScript framework [React](https://facebook.github.io/react) by Oliver Zeigermann, who is the author of several JavaScript books.\nHe showed and explained the principals of React.\nOne feature of React is that it reperesents only the View in a Model-View-Controller (MVC) model.\nSo it is typical to have a mixture of JavaScript and HTML code in one file.\nAnother feature is that the Document Object Model (DOM) tree is virtualized.\nThat means, when a webpage flow is establihed only the objects that have change are updated via the calculation of a `diff` between the webpage states.\nThe interesting thing about React is, that due to that technique websites are always very fast.\n\n{% image blog/blog-magdeburg-7.jpg %}\n\nThe last session of the day was \"Architekturdokumentation leicht gemacht\" (architecture documentation for dummies) by Andreas Richter, the organiser of the [Softwerkskammer Magdeburg](https://www.softwerkskammer.org/groups/magdeburg).\nHe introduced the [arc42](http://arc42.org) template and its most important parts.\nThe main benefits of such an architectural templates is that there is always the same structure.\n\n## Summary\n\nThe Magdeburger Developer Days offered a lot of very interesting talks in a broad range of topics.\nWe were stunned from the professionel level that orga team could establish.\nThe speakers were well-choosen and the quality of talks was absolutely extraordinary.\nThe experience of the conference was very great and a visit next year is definitely reasonable.\n","slug":"2016-05-26-magdeburger-developer-days","published":1,"updated":"2016-09-20T14:31:48.000Z","comments":1,"photos":[],"link":"","_id":"ciu6nuh9s002ihqyxjj35capj","content":"<p>On May, 18th 2016, the first <a href=\"http://md-devdays.de/\" target=\"_blank\" rel=\"external\">Developer Days</a> took place in the exhibition halls of Magdeburg, Germany.<br>Although this Java and .NET developer conference was organised for the first time, many developers from across Germany participated and followed the invitation from the <a href=\"https://twitter.com/MiB_MD_DevDays\" target=\"_blank\" rel=\"external\">Twitter</a> channel of Michael Blume, the initiator and organiser.</p>\n<img class=\"blog/blog-magdeburg-1.jpg\">\n<h2 id=\"The-setting\"><a href=\"#The-setting\" class=\"headerlink\" title=\"The setting\"></a>The setting</h2><p>The exhibition hall was parted into four large rooms, named after famous pioneers of the Information Technologies, like <a href=\"https://en.wikipedia.org/wiki/Konrad_Zuse\" target=\"_blank\" rel=\"external\">Konrad Zuse</a> and <a href=\"https://en.wikipedia.org/wiki/Bjarne_Stroustrup\" target=\"_blank\" rel=\"external\">Bjarne Stroustrup</a>.<br>The lobby offered bar tables and an open space that could consistently be used for interesting discussions about the latest technologies, side projects, and networking.<br>Besides the catering with snacks and a variety of beverages, the orga team also delivered a conference booklet with over 40 pages, where each speaker and session was listed in depth on individual pages.<br>Another noteworthy subject was the affectionate designed certificates for the participants that were handed over at the entrance area in addition to the welcome bag.</p>\n<img class=\"blog/blog-magdeburg-2.jpg\">\n<h2 id=\"The-sessions\"><a href=\"#The-sessions\" class=\"headerlink\" title=\"The sessions\"></a>The sessions</h2><p>After the two introduction talks, the sessions began. The main topics were frontend and backend technologies, as well as a mixture of agile topics, requirements documentation, and programming technologies.</p>\n<img class=\"blog/blog-magdeburg-3.jpg\">\n<p>The first session was a dive into <a href=\"https://www.typescriptlang.org\" target=\"_blank\" rel=\"external\">TypeScript</a> by Rainer Stropek.<br>TypeScript is a JavaScript similar language and can be compiled into JavaScript.<br>It is a strictly typed and object-oriented programming language.<br>We learned how to compile and use TypeScript.<br>Rainer Stropek showed examples via live coding at the TypeScript <a href=\"https://www.typescriptlang.org/play/index.html\" target=\"_blank\" rel=\"external\">Playground</a>, which directly generates the resulting JavaScript.<br>He also showed how to use common JS libraries within TypeScript.</p>\n<img class=\"blog/blog-magdeburg-4.jpg\">\n<p>Our second session was all about “What’s still new in <a href=\"https://docs.oracle.com/javase/8/docs/api\" target=\"_blank\" rel=\"external\">Java SE 8</a>?”.<br>Bernd Gronostay, who works closely together with the author of “Java ist auch ein Insel”, talked about a lot of new features and API changes.<br>Not only did he talk about the modifications, but also showed a lot of examples which illustrated these features very well.<br>The perhaps most interesting part in this session were the various show cases of lambda functions and streams.<br>This enables developers to write Java in a functional syntax.</p>\n<img class=\"blog/blog-magdeburg-5.jpg\">\n<p>After lunch there was a talk with a topic which was completely new to us:<br>Functional Domain Driven Design (DDD) with F# held by Marco Heimeshoff.<br>He is one of the cofounders of the <a href=\"http://dddcommunity.org\" target=\"_blank\" rel=\"external\">DDD community</a> in Germany.<br>His introduction showed a new idea of how the software models should look like.<br>The mapping between the Requirement Space (Domain) and the Implementation Space (Code) is usually a gap that needs to be bridged.<br>The difficulty is to have the code representing exactly the real domain.<br>But often developers have to check that there is no possibility to represent an illegal state.<br>The simple solution with DDD is: Make illegal states unrepresentable!<br>This is only a little extract of this session with a lot of new, interesting ideas and patterns for solving things in a deterministically different way that makes intense unit testing obsolete.</p>\n<img class=\"blog/blog-magdeburg-6.jpg\">\n<p>The next session was an introduction into the JavaScript framework <a href=\"https://facebook.github.io/react\" target=\"_blank\" rel=\"external\">React</a> by Oliver Zeigermann, who is the author of several JavaScript books.<br>He showed and explained the principals of React.<br>One feature of React is that it reperesents only the View in a Model-View-Controller (MVC) model.<br>So it is typical to have a mixture of JavaScript and HTML code in one file.<br>Another feature is that the Document Object Model (DOM) tree is virtualized.<br>That means, when a webpage flow is establihed only the objects that have change are updated via the calculation of a <code>diff</code> between the webpage states.<br>The interesting thing about React is, that due to that technique websites are always very fast.</p>\n<img class=\"blog/blog-magdeburg-7.jpg\">\n<p>The last session of the day was “Architekturdokumentation leicht gemacht” (architecture documentation for dummies) by Andreas Richter, the organiser of the <a href=\"https://www.softwerkskammer.org/groups/magdeburg\" target=\"_blank\" rel=\"external\">Softwerkskammer Magdeburg</a>.<br>He introduced the <a href=\"http://arc42.org\" target=\"_blank\" rel=\"external\">arc42</a> template and its most important parts.<br>The main benefits of such an architectural templates is that there is always the same structure.</p>\n<h2 id=\"Summary\"><a href=\"#Summary\" class=\"headerlink\" title=\"Summary\"></a>Summary</h2><p>The Magdeburger Developer Days offered a lot of very interesting talks in a broad range of topics.<br>We were stunned from the professionel level that orga team could establish.<br>The speakers were well-choosen and the quality of talks was absolutely extraordinary.<br>The experience of the conference was very great and a visit next year is definitely reasonable.</p>\n","excerpt":"","more":"<p>On May, 18th 2016, the first <a href=\"http://md-devdays.de/\">Developer Days</a> took place in the exhibition halls of Magdeburg, Germany.<br>Although this Java and .NET developer conference was organised for the first time, many developers from across Germany participated and followed the invitation from the <a href=\"https://twitter.com/MiB_MD_DevDays\">Twitter</a> channel of Michael Blume, the initiator and organiser.</p>\n<img class=\"blog/blog-magdeburg-1.jpg\">\n<h2 id=\"The-setting\"><a href=\"#The-setting\" class=\"headerlink\" title=\"The setting\"></a>The setting</h2><p>The exhibition hall was parted into four large rooms, named after famous pioneers of the Information Technologies, like <a href=\"https://en.wikipedia.org/wiki/Konrad_Zuse\">Konrad Zuse</a> and <a href=\"https://en.wikipedia.org/wiki/Bjarne_Stroustrup\">Bjarne Stroustrup</a>.<br>The lobby offered bar tables and an open space that could consistently be used for interesting discussions about the latest technologies, side projects, and networking.<br>Besides the catering with snacks and a variety of beverages, the orga team also delivered a conference booklet with over 40 pages, where each speaker and session was listed in depth on individual pages.<br>Another noteworthy subject was the affectionate designed certificates for the participants that were handed over at the entrance area in addition to the welcome bag.</p>\n<img class=\"blog/blog-magdeburg-2.jpg\">\n<h2 id=\"The-sessions\"><a href=\"#The-sessions\" class=\"headerlink\" title=\"The sessions\"></a>The sessions</h2><p>After the two introduction talks, the sessions began. The main topics were frontend and backend technologies, as well as a mixture of agile topics, requirements documentation, and programming technologies.</p>\n<img class=\"blog/blog-magdeburg-3.jpg\">\n<p>The first session was a dive into <a href=\"https://www.typescriptlang.org\">TypeScript</a> by Rainer Stropek.<br>TypeScript is a JavaScript similar language and can be compiled into JavaScript.<br>It is a strictly typed and object-oriented programming language.<br>We learned how to compile and use TypeScript.<br>Rainer Stropek showed examples via live coding at the TypeScript <a href=\"https://www.typescriptlang.org/play/index.html\">Playground</a>, which directly generates the resulting JavaScript.<br>He also showed how to use common JS libraries within TypeScript.</p>\n<img class=\"blog/blog-magdeburg-4.jpg\">\n<p>Our second session was all about “What’s still new in <a href=\"https://docs.oracle.com/javase/8/docs/api\">Java SE 8</a>?”.<br>Bernd Gronostay, who works closely together with the author of “Java ist auch ein Insel”, talked about a lot of new features and API changes.<br>Not only did he talk about the modifications, but also showed a lot of examples which illustrated these features very well.<br>The perhaps most interesting part in this session were the various show cases of lambda functions and streams.<br>This enables developers to write Java in a functional syntax.</p>\n<img class=\"blog/blog-magdeburg-5.jpg\">\n<p>After lunch there was a talk with a topic which was completely new to us:<br>Functional Domain Driven Design (DDD) with F# held by Marco Heimeshoff.<br>He is one of the cofounders of the <a href=\"http://dddcommunity.org\">DDD community</a> in Germany.<br>His introduction showed a new idea of how the software models should look like.<br>The mapping between the Requirement Space (Domain) and the Implementation Space (Code) is usually a gap that needs to be bridged.<br>The difficulty is to have the code representing exactly the real domain.<br>But often developers have to check that there is no possibility to represent an illegal state.<br>The simple solution with DDD is: Make illegal states unrepresentable!<br>This is only a little extract of this session with a lot of new, interesting ideas and patterns for solving things in a deterministically different way that makes intense unit testing obsolete.</p>\n<img class=\"blog/blog-magdeburg-6.jpg\">\n<p>The next session was an introduction into the JavaScript framework <a href=\"https://facebook.github.io/react\">React</a> by Oliver Zeigermann, who is the author of several JavaScript books.<br>He showed and explained the principals of React.<br>One feature of React is that it reperesents only the View in a Model-View-Controller (MVC) model.<br>So it is typical to have a mixture of JavaScript and HTML code in one file.<br>Another feature is that the Document Object Model (DOM) tree is virtualized.<br>That means, when a webpage flow is establihed only the objects that have change are updated via the calculation of a <code>diff</code> between the webpage states.<br>The interesting thing about React is, that due to that technique websites are always very fast.</p>\n<img class=\"blog/blog-magdeburg-7.jpg\">\n<p>The last session of the day was “Architekturdokumentation leicht gemacht” (architecture documentation for dummies) by Andreas Richter, the organiser of the <a href=\"https://www.softwerkskammer.org/groups/magdeburg\">Softwerkskammer Magdeburg</a>.<br>He introduced the <a href=\"http://arc42.org\">arc42</a> template and its most important parts.<br>The main benefits of such an architectural templates is that there is always the same structure.</p>\n<h2 id=\"Summary\"><a href=\"#Summary\" class=\"headerlink\" title=\"Summary\"></a>Summary</h2><p>The Magdeburger Developer Days offered a lot of very interesting talks in a broad range of topics.<br>We were stunned from the professionel level that orga team could establish.<br>The speakers were well-choosen and the quality of talks was absolutely extraordinary.<br>The experience of the conference was very great and a visit next year is definitely reasonable.</p>\n"},{"layout":"post","title":"Why UX and TechWriting make a dream team","date":"2016-06-16T09:16:17.000Z","image":"blog-header/dream-team.jpg","authors":["Birgit"],"_content":"\nTechnical communication is an essential part of UX.\nAnything that involves a user interacting with an interface is inherently part of the user's experience.\nUnfortunately, in many organisations, technical communicators are often the last to know about the UX team's projects.\nInterestingly enough though, technical communicators are usually the first ones to explain usability aspects.\n\nIn order for technical communicators to explain certain facts to somebody else they need to understand how things work.\nWhen they're involved at the end of the process they don't have a chance to give valuable input and feedback as they should.\n\nSo, how do we tackle this at ePages?\n\n## Team constellation\n\nOur Usability Expert Anja is part of Product Management.\nHer position enables first-hand knowledge of business goals and user requirements, while allowing her to focus on delivering a product with an excellent UX.\nAdditionally, she is closely connected with the development teams within R&D by participating in reviews and plannings.\nShe also attends meetings with the UI designers.\n\nI'm the Technical Writer and am part of R&D.\nThus, I'm automatically in close contact with the development teams.\nI join their reviews, and sometimes their plannings, and daily standups.\nIn order to stay informed about the latest plans and changes, I have regular meetings with the Product Owners.\n\n## At a loss for words\n\nWe are adding new features: error messages and tooltips.\nBoth need wording for the users to understand the software.\nFor our developers this is a challenge.\nThey write great code, but they are neither linguists nor usability experts.\nThis is why, for many of them, I'm the primary contact on these matters.\nThe developers provide me with a draft text, or a rough context, and I then put every effort into understanding the topic.\nIn many cases, I'm at a loss for words because it is not just the plain text I need.\nI need a bigger picture, the whole context, a UI.\nWith the help of a virtual machine, or detailed screenshots, I can get a better idea and see how things fit together.\nThat way I can come up with a meaningful wording.\n\n## In the same boat\n\nBy now it's pretty obvious why UX and Technical Communicators should work closely together, isn't it?\nIn the last paragraph, the keywords **user**, **usability**, **wording**, and **UI** appeared at frequent intervals.\n\nWith each wording request from one of the development teams it got even clearer to me that this is Anja's and my own common challenge.\nI started contacting her with several questions and comments that were related to the UI.\nAnd soon we worked together hand in hand.\n\nUsually, I'm informed by the PO or one of the team members that they're working on a new feature and need wording support.\nSometimes the PO invites Anja and me for a short info session to explain the context, and what exactly the team requires from us.\nI will ask the team for detailed screenshots, or access to a virtual machine.\nAnja will prepare UI mocks, if not already available.\nSubsequently, I will create the needed texts, and we will discuss the whole thing together.\nThis is sometimes quite time-consuming, as we raise new questions, or question one or other thing in general.\nIn the end, we have a text that matches the UI, is agreed with the Product Owner, and then shared with team.\n\n## Looking ahead\n\nWe have a brand new software product in the pipeline.\nUX and Technical Communication are an inherent part of the development process from the very beginning.\nIn order to have consistent and high-quality texts, we are currently establishing a Terminology Database where we track all the new terms, and make them available to the company.\nFurthermore, we're working on an Editorial Guide to define standards for producing UI texts.\n\n## Dream team\n\nWorking together on all those tasks is really great fun, and we learn a lot about the software.\nOur continuous and close cooperation make us a well-functioning team.\nWe will rock on!\n","source":"_posts/2016-06-16-ux-tw-cooperation.md","raw":"---\nlayout: post\ntitle: \"Why UX and TechWriting make a dream team\"\ndate: \"2016-06-16 11:16:17\"\nimage: blog-header/dream-team.jpg\ncategories: tech-stories\nauthors: [\"Birgit\"]\n---\n\nTechnical communication is an essential part of UX.\nAnything that involves a user interacting with an interface is inherently part of the user's experience.\nUnfortunately, in many organisations, technical communicators are often the last to know about the UX team's projects.\nInterestingly enough though, technical communicators are usually the first ones to explain usability aspects.\n\nIn order for technical communicators to explain certain facts to somebody else they need to understand how things work.\nWhen they're involved at the end of the process they don't have a chance to give valuable input and feedback as they should.\n\nSo, how do we tackle this at ePages?\n\n## Team constellation\n\nOur Usability Expert Anja is part of Product Management.\nHer position enables first-hand knowledge of business goals and user requirements, while allowing her to focus on delivering a product with an excellent UX.\nAdditionally, she is closely connected with the development teams within R&D by participating in reviews and plannings.\nShe also attends meetings with the UI designers.\n\nI'm the Technical Writer and am part of R&D.\nThus, I'm automatically in close contact with the development teams.\nI join their reviews, and sometimes their plannings, and daily standups.\nIn order to stay informed about the latest plans and changes, I have regular meetings with the Product Owners.\n\n## At a loss for words\n\nWe are adding new features: error messages and tooltips.\nBoth need wording for the users to understand the software.\nFor our developers this is a challenge.\nThey write great code, but they are neither linguists nor usability experts.\nThis is why, for many of them, I'm the primary contact on these matters.\nThe developers provide me with a draft text, or a rough context, and I then put every effort into understanding the topic.\nIn many cases, I'm at a loss for words because it is not just the plain text I need.\nI need a bigger picture, the whole context, a UI.\nWith the help of a virtual machine, or detailed screenshots, I can get a better idea and see how things fit together.\nThat way I can come up with a meaningful wording.\n\n## In the same boat\n\nBy now it's pretty obvious why UX and Technical Communicators should work closely together, isn't it?\nIn the last paragraph, the keywords **user**, **usability**, **wording**, and **UI** appeared at frequent intervals.\n\nWith each wording request from one of the development teams it got even clearer to me that this is Anja's and my own common challenge.\nI started contacting her with several questions and comments that were related to the UI.\nAnd soon we worked together hand in hand.\n\nUsually, I'm informed by the PO or one of the team members that they're working on a new feature and need wording support.\nSometimes the PO invites Anja and me for a short info session to explain the context, and what exactly the team requires from us.\nI will ask the team for detailed screenshots, or access to a virtual machine.\nAnja will prepare UI mocks, if not already available.\nSubsequently, I will create the needed texts, and we will discuss the whole thing together.\nThis is sometimes quite time-consuming, as we raise new questions, or question one or other thing in general.\nIn the end, we have a text that matches the UI, is agreed with the Product Owner, and then shared with team.\n\n## Looking ahead\n\nWe have a brand new software product in the pipeline.\nUX and Technical Communication are an inherent part of the development process from the very beginning.\nIn order to have consistent and high-quality texts, we are currently establishing a Terminology Database where we track all the new terms, and make them available to the company.\nFurthermore, we're working on an Editorial Guide to define standards for producing UI texts.\n\n## Dream team\n\nWorking together on all those tasks is really great fun, and we learn a lot about the software.\nOur continuous and close cooperation make us a well-functioning team.\nWe will rock on!\n","slug":"2016-06-16-ux-tw-cooperation","published":1,"updated":"2016-09-20T14:31:48.000Z","comments":1,"photos":[],"link":"","_id":"ciu6nuh9t002khqyxdlh7eiy1","content":"<p>Technical communication is an essential part of UX.<br>Anything that involves a user interacting with an interface is inherently part of the user’s experience.<br>Unfortunately, in many organisations, technical communicators are often the last to know about the UX team’s projects.<br>Interestingly enough though, technical communicators are usually the first ones to explain usability aspects.</p>\n<p>In order for technical communicators to explain certain facts to somebody else they need to understand how things work.<br>When they’re involved at the end of the process they don’t have a chance to give valuable input and feedback as they should.</p>\n<p>So, how do we tackle this at ePages?</p>\n<h2 id=\"Team-constellation\"><a href=\"#Team-constellation\" class=\"headerlink\" title=\"Team constellation\"></a>Team constellation</h2><p>Our Usability Expert Anja is part of Product Management.<br>Her position enables first-hand knowledge of business goals and user requirements, while allowing her to focus on delivering a product with an excellent UX.<br>Additionally, she is closely connected with the development teams within R&amp;D by participating in reviews and plannings.<br>She also attends meetings with the UI designers.</p>\n<p>I’m the Technical Writer and am part of R&amp;D.<br>Thus, I’m automatically in close contact with the development teams.<br>I join their reviews, and sometimes their plannings, and daily standups.<br>In order to stay informed about the latest plans and changes, I have regular meetings with the Product Owners.</p>\n<h2 id=\"At-a-loss-for-words\"><a href=\"#At-a-loss-for-words\" class=\"headerlink\" title=\"At a loss for words\"></a>At a loss for words</h2><p>We are adding new features: error messages and tooltips.<br>Both need wording for the users to understand the software.<br>For our developers this is a challenge.<br>They write great code, but they are neither linguists nor usability experts.<br>This is why, for many of them, I’m the primary contact on these matters.<br>The developers provide me with a draft text, or a rough context, and I then put every effort into understanding the topic.<br>In many cases, I’m at a loss for words because it is not just the plain text I need.<br>I need a bigger picture, the whole context, a UI.<br>With the help of a virtual machine, or detailed screenshots, I can get a better idea and see how things fit together.<br>That way I can come up with a meaningful wording.</p>\n<h2 id=\"In-the-same-boat\"><a href=\"#In-the-same-boat\" class=\"headerlink\" title=\"In the same boat\"></a>In the same boat</h2><p>By now it’s pretty obvious why UX and Technical Communicators should work closely together, isn’t it?<br>In the last paragraph, the keywords <strong>user</strong>, <strong>usability</strong>, <strong>wording</strong>, and <strong>UI</strong> appeared at frequent intervals.</p>\n<p>With each wording request from one of the development teams it got even clearer to me that this is Anja’s and my own common challenge.<br>I started contacting her with several questions and comments that were related to the UI.<br>And soon we worked together hand in hand.</p>\n<p>Usually, I’m informed by the PO or one of the team members that they’re working on a new feature and need wording support.<br>Sometimes the PO invites Anja and me for a short info session to explain the context, and what exactly the team requires from us.<br>I will ask the team for detailed screenshots, or access to a virtual machine.<br>Anja will prepare UI mocks, if not already available.<br>Subsequently, I will create the needed texts, and we will discuss the whole thing together.<br>This is sometimes quite time-consuming, as we raise new questions, or question one or other thing in general.<br>In the end, we have a text that matches the UI, is agreed with the Product Owner, and then shared with team.</p>\n<h2 id=\"Looking-ahead\"><a href=\"#Looking-ahead\" class=\"headerlink\" title=\"Looking ahead\"></a>Looking ahead</h2><p>We have a brand new software product in the pipeline.<br>UX and Technical Communication are an inherent part of the development process from the very beginning.<br>In order to have consistent and high-quality texts, we are currently establishing a Terminology Database where we track all the new terms, and make them available to the company.<br>Furthermore, we’re working on an Editorial Guide to define standards for producing UI texts.</p>\n<h2 id=\"Dream-team\"><a href=\"#Dream-team\" class=\"headerlink\" title=\"Dream team\"></a>Dream team</h2><p>Working together on all those tasks is really great fun, and we learn a lot about the software.<br>Our continuous and close cooperation make us a well-functioning team.<br>We will rock on!</p>\n","excerpt":"","more":"<p>Technical communication is an essential part of UX.<br>Anything that involves a user interacting with an interface is inherently part of the user’s experience.<br>Unfortunately, in many organisations, technical communicators are often the last to know about the UX team’s projects.<br>Interestingly enough though, technical communicators are usually the first ones to explain usability aspects.</p>\n<p>In order for technical communicators to explain certain facts to somebody else they need to understand how things work.<br>When they’re involved at the end of the process they don’t have a chance to give valuable input and feedback as they should.</p>\n<p>So, how do we tackle this at ePages?</p>\n<h2 id=\"Team-constellation\"><a href=\"#Team-constellation\" class=\"headerlink\" title=\"Team constellation\"></a>Team constellation</h2><p>Our Usability Expert Anja is part of Product Management.<br>Her position enables first-hand knowledge of business goals and user requirements, while allowing her to focus on delivering a product with an excellent UX.<br>Additionally, she is closely connected with the development teams within R&amp;D by participating in reviews and plannings.<br>She also attends meetings with the UI designers.</p>\n<p>I’m the Technical Writer and am part of R&amp;D.<br>Thus, I’m automatically in close contact with the development teams.<br>I join their reviews, and sometimes their plannings, and daily standups.<br>In order to stay informed about the latest plans and changes, I have regular meetings with the Product Owners.</p>\n<h2 id=\"At-a-loss-for-words\"><a href=\"#At-a-loss-for-words\" class=\"headerlink\" title=\"At a loss for words\"></a>At a loss for words</h2><p>We are adding new features: error messages and tooltips.<br>Both need wording for the users to understand the software.<br>For our developers this is a challenge.<br>They write great code, but they are neither linguists nor usability experts.<br>This is why, for many of them, I’m the primary contact on these matters.<br>The developers provide me with a draft text, or a rough context, and I then put every effort into understanding the topic.<br>In many cases, I’m at a loss for words because it is not just the plain text I need.<br>I need a bigger picture, the whole context, a UI.<br>With the help of a virtual machine, or detailed screenshots, I can get a better idea and see how things fit together.<br>That way I can come up with a meaningful wording.</p>\n<h2 id=\"In-the-same-boat\"><a href=\"#In-the-same-boat\" class=\"headerlink\" title=\"In the same boat\"></a>In the same boat</h2><p>By now it’s pretty obvious why UX and Technical Communicators should work closely together, isn’t it?<br>In the last paragraph, the keywords <strong>user</strong>, <strong>usability</strong>, <strong>wording</strong>, and <strong>UI</strong> appeared at frequent intervals.</p>\n<p>With each wording request from one of the development teams it got even clearer to me that this is Anja’s and my own common challenge.<br>I started contacting her with several questions and comments that were related to the UI.<br>And soon we worked together hand in hand.</p>\n<p>Usually, I’m informed by the PO or one of the team members that they’re working on a new feature and need wording support.<br>Sometimes the PO invites Anja and me for a short info session to explain the context, and what exactly the team requires from us.<br>I will ask the team for detailed screenshots, or access to a virtual machine.<br>Anja will prepare UI mocks, if not already available.<br>Subsequently, I will create the needed texts, and we will discuss the whole thing together.<br>This is sometimes quite time-consuming, as we raise new questions, or question one or other thing in general.<br>In the end, we have a text that matches the UI, is agreed with the Product Owner, and then shared with team.</p>\n<h2 id=\"Looking-ahead\"><a href=\"#Looking-ahead\" class=\"headerlink\" title=\"Looking ahead\"></a>Looking ahead</h2><p>We have a brand new software product in the pipeline.<br>UX and Technical Communication are an inherent part of the development process from the very beginning.<br>In order to have consistent and high-quality texts, we are currently establishing a Terminology Database where we track all the new terms, and make them available to the company.<br>Furthermore, we’re working on an Editorial Guide to define standards for producing UI texts.</p>\n<h2 id=\"Dream-team\"><a href=\"#Dream-team\" class=\"headerlink\" title=\"Dream team\"></a>Dream team</h2><p>Working together on all those tasks is really great fun, and we learn a lot about the software.<br>Our continuous and close cooperation make us a well-functioning team.<br>We will rock on!</p>\n"},{"layout":"post","title":"Team offsite meeting: workshops, focus, and fun","date":"2016-07-04T11:37:42.000Z","image":"blog-header/ep6offsite2016.jpg","authors":["Sandra","Oliver Z."],"_content":"\nMid June, the ePages 6 team went on a two-day offsite meeting -- in Jena! How is it an offsite if you stay in the city you work in? Well, due to the size of the team and various team members having family obligations it was difficult to find a date and a location for this offsite.\nTherefore, we agreed to stay in Jena. To avoid the usual office interruptions we booked the [Creative Room of the Volkshochschule Jena](https://www.vhs-jena.de/de/service/raumvermietung/649482#/collapse4) for two days. Additionally, we organised a cool team event in the forest area in Camburg. But let us tackle the serious issues first!\n\n## Team constellation and focus\n\nJust recently, our team was restructured. New team members were added, whereas some colleagues moved to other teams. Doing a team offsite was just the right setting to get to know each other better, and boost the team spirit. As we are facing new challenges, one big topic was focusing on our new tasks.\n\n## Workshops\n\n{% image blog/blog-team-ep6.jpg 50% right %}\n\nIn order to spread knowledge and improve our [T-shaped skills](https://en.wikipedia.org/wiki/T-shaped_skills) we prepared various workshops.\nIn advance we identified topics that are relevant to everyone in the team and topics that are only relevant to a certain guild.\nTo make best use of the limited time we held some workshops on parallel tracks.\n\nOf interest to everyone was the \"JavaScript in our current ePages shop system\" session chaired by Markus. He explained in detail how different JavaScript frameworks are integrated in our e-commerce solution and what to consider when writing JavaScript in this environment. Using live coding he demonstrated how the template engine, localisation, and JavaScript compression work.\n\n{% image blog/blog-ep6-frontend-workshop.jpg 50% left %}\n\nOliver explained selected [OWASP threats](https://www.owasp.org/index.php/Cheat_Sheets). Afterwards we tried to exploit our software. While we identified some problems, we also concluded that current version is pretty resilient against the most common attacks: injections and cross-site scripting.\n\nPeter outlined our current development pipeline process used primarily for QA and collaboration on more complex features.\nAdditionally, he clarified the different build and configuration setups on our team VMs.\n\nOn the second day we started with the parallel sessions: UI development and tax calculation in our current shop software.\nFor the frontend developers and designers Björn presented the various HTML template sections of a typical ePages shop webpage. In addition to that he documented the directory and file structure used for styling as well as the style guide itself.\nThe backend folks attended the tax calculation lecture by Michael. He explained in detail how to alter tax settings and which constraints to consider when customers and merchants from different countries do business together.\n\nLast but not least Tobias emphasised unit testing and best practices like the [Test Pyramid](http://martinfowler.com/bliki/TestPyramid.html). Using multiple code examples he demonstrated how mocking can be used for integration tests.\n\n## Bow and arrow action\n\n{% image blog/blog-ep6offsite-bow.jpg 50% right %}\n\nAfter one and a half day of intense workshops, we had our recreational team event on Wednesday afternoon. We went to the [archery site](http://camburger-bogenschuetzen.de/) located in the forest area in Camburg.\n\nBefore starting our tour through the forest, we had some training shots. Equipped with bows, arrows, quivers, and protection gear, we were prepared for small and big game! We picked the \"lesser\" route, which resulted in shooting at around 27 animal models in three hours. Besides the typical forest animals we hunted gigantic turtles, cobras and even dinosaurs! :)\n\nWhen the sun had set and it was hard to spot any further targets, we gathered for a barbecue to end the day, share our hunting stories, and compare our scores.\n\n## Back at the office\n\nIt was an awesome team event! We learned a lot during the workshops, prepared ourselves for the upcoming team changes, and embraced the nature near Camburg.\nWhile we lost and broke some arrows in the thicket, no living animals were harmed and nobody took an arrow to the knee!\n\n{% image blog/blog-ep6offsite-yummy.jpg %}\n","source":"_posts/2016-07-04-ep6-offsite.md","raw":"---\nlayout: post\ntitle: \"Team offsite meeting: workshops, focus, and fun\"\ndate: \"2016-07-04 13:37:42\"\nimage: blog-header/ep6offsite2016.jpg\ncategories: events\nauthors: [\"Sandra\", \"Oliver Z.\"]\n---\n\nMid June, the ePages 6 team went on a two-day offsite meeting -- in Jena! How is it an offsite if you stay in the city you work in? Well, due to the size of the team and various team members having family obligations it was difficult to find a date and a location for this offsite.\nTherefore, we agreed to stay in Jena. To avoid the usual office interruptions we booked the [Creative Room of the Volkshochschule Jena](https://www.vhs-jena.de/de/service/raumvermietung/649482#/collapse4) for two days. Additionally, we organised a cool team event in the forest area in Camburg. But let us tackle the serious issues first!\n\n## Team constellation and focus\n\nJust recently, our team was restructured. New team members were added, whereas some colleagues moved to other teams. Doing a team offsite was just the right setting to get to know each other better, and boost the team spirit. As we are facing new challenges, one big topic was focusing on our new tasks.\n\n## Workshops\n\n{% image blog/blog-team-ep6.jpg 50% right %}\n\nIn order to spread knowledge and improve our [T-shaped skills](https://en.wikipedia.org/wiki/T-shaped_skills) we prepared various workshops.\nIn advance we identified topics that are relevant to everyone in the team and topics that are only relevant to a certain guild.\nTo make best use of the limited time we held some workshops on parallel tracks.\n\nOf interest to everyone was the \"JavaScript in our current ePages shop system\" session chaired by Markus. He explained in detail how different JavaScript frameworks are integrated in our e-commerce solution and what to consider when writing JavaScript in this environment. Using live coding he demonstrated how the template engine, localisation, and JavaScript compression work.\n\n{% image blog/blog-ep6-frontend-workshop.jpg 50% left %}\n\nOliver explained selected [OWASP threats](https://www.owasp.org/index.php/Cheat_Sheets). Afterwards we tried to exploit our software. While we identified some problems, we also concluded that current version is pretty resilient against the most common attacks: injections and cross-site scripting.\n\nPeter outlined our current development pipeline process used primarily for QA and collaboration on more complex features.\nAdditionally, he clarified the different build and configuration setups on our team VMs.\n\nOn the second day we started with the parallel sessions: UI development and tax calculation in our current shop software.\nFor the frontend developers and designers Björn presented the various HTML template sections of a typical ePages shop webpage. In addition to that he documented the directory and file structure used for styling as well as the style guide itself.\nThe backend folks attended the tax calculation lecture by Michael. He explained in detail how to alter tax settings and which constraints to consider when customers and merchants from different countries do business together.\n\nLast but not least Tobias emphasised unit testing and best practices like the [Test Pyramid](http://martinfowler.com/bliki/TestPyramid.html). Using multiple code examples he demonstrated how mocking can be used for integration tests.\n\n## Bow and arrow action\n\n{% image blog/blog-ep6offsite-bow.jpg 50% right %}\n\nAfter one and a half day of intense workshops, we had our recreational team event on Wednesday afternoon. We went to the [archery site](http://camburger-bogenschuetzen.de/) located in the forest area in Camburg.\n\nBefore starting our tour through the forest, we had some training shots. Equipped with bows, arrows, quivers, and protection gear, we were prepared for small and big game! We picked the \"lesser\" route, which resulted in shooting at around 27 animal models in three hours. Besides the typical forest animals we hunted gigantic turtles, cobras and even dinosaurs! :)\n\nWhen the sun had set and it was hard to spot any further targets, we gathered for a barbecue to end the day, share our hunting stories, and compare our scores.\n\n## Back at the office\n\nIt was an awesome team event! We learned a lot during the workshops, prepared ourselves for the upcoming team changes, and embraced the nature near Camburg.\nWhile we lost and broke some arrows in the thicket, no living animals were harmed and nobody took an arrow to the knee!\n\n{% image blog/blog-ep6offsite-yummy.jpg %}\n","slug":"2016-07-04-ep6-offsite","published":1,"updated":"2016-09-20T14:31:48.000Z","comments":1,"photos":[],"link":"","_id":"ciu6nuh9u002mhqyxjhpqovvd","content":"<p>Mid June, the ePages 6 team went on a two-day offsite meeting – in Jena! How is it an offsite if you stay in the city you work in? Well, due to the size of the team and various team members having family obligations it was difficult to find a date and a location for this offsite.<br>Therefore, we agreed to stay in Jena. To avoid the usual office interruptions we booked the <a href=\"https://www.vhs-jena.de/de/service/raumvermietung/649482#/collapse4\" target=\"_blank\" rel=\"external\">Creative Room of the Volkshochschule Jena</a> for two days. Additionally, we organised a cool team event in the forest area in Camburg. But let us tackle the serious issues first!</p>\n<h2 id=\"Team-constellation-and-focus\"><a href=\"#Team-constellation-and-focus\" class=\"headerlink\" title=\"Team constellation and focus\"></a>Team constellation and focus</h2><p>Just recently, our team was restructured. New team members were added, whereas some colleagues moved to other teams. Doing a team offsite was just the right setting to get to know each other better, and boost the team spirit. As we are facing new challenges, one big topic was focusing on our new tasks.</p>\n<h2 id=\"Workshops\"><a href=\"#Workshops\" class=\"headerlink\" title=\"Workshops\"></a>Workshops</h2><img class=\"blog/blog-team-ep6.jpg 50% right\">\n<p>In order to spread knowledge and improve our <a href=\"https://en.wikipedia.org/wiki/T-shaped_skills\" target=\"_blank\" rel=\"external\">T-shaped skills</a> we prepared various workshops.<br>In advance we identified topics that are relevant to everyone in the team and topics that are only relevant to a certain guild.<br>To make best use of the limited time we held some workshops on parallel tracks.</p>\n<p>Of interest to everyone was the “JavaScript in our current ePages shop system” session chaired by Markus. He explained in detail how different JavaScript frameworks are integrated in our e-commerce solution and what to consider when writing JavaScript in this environment. Using live coding he demonstrated how the template engine, localisation, and JavaScript compression work.</p>\n<img class=\"blog/blog-ep6-frontend-workshop.jpg 50% left\">\n<p>Oliver explained selected <a href=\"https://www.owasp.org/index.php/Cheat_Sheets\" target=\"_blank\" rel=\"external\">OWASP threats</a>. Afterwards we tried to exploit our software. While we identified some problems, we also concluded that current version is pretty resilient against the most common attacks: injections and cross-site scripting.</p>\n<p>Peter outlined our current development pipeline process used primarily for QA and collaboration on more complex features.<br>Additionally, he clarified the different build and configuration setups on our team VMs.</p>\n<p>On the second day we started with the parallel sessions: UI development and tax calculation in our current shop software.<br>For the frontend developers and designers Björn presented the various HTML template sections of a typical ePages shop webpage. In addition to that he documented the directory and file structure used for styling as well as the style guide itself.<br>The backend folks attended the tax calculation lecture by Michael. He explained in detail how to alter tax settings and which constraints to consider when customers and merchants from different countries do business together.</p>\n<p>Last but not least Tobias emphasised unit testing and best practices like the <a href=\"http://martinfowler.com/bliki/TestPyramid.html\" target=\"_blank\" rel=\"external\">Test Pyramid</a>. Using multiple code examples he demonstrated how mocking can be used for integration tests.</p>\n<h2 id=\"Bow-and-arrow-action\"><a href=\"#Bow-and-arrow-action\" class=\"headerlink\" title=\"Bow and arrow action\"></a>Bow and arrow action</h2><img class=\"blog/blog-ep6offsite-bow.jpg 50% right\">\n<p>After one and a half day of intense workshops, we had our recreational team event on Wednesday afternoon. We went to the <a href=\"http://camburger-bogenschuetzen.de/\" target=\"_blank\" rel=\"external\">archery site</a> located in the forest area in Camburg.</p>\n<p>Before starting our tour through the forest, we had some training shots. Equipped with bows, arrows, quivers, and protection gear, we were prepared for small and big game! We picked the “lesser” route, which resulted in shooting at around 27 animal models in three hours. Besides the typical forest animals we hunted gigantic turtles, cobras and even dinosaurs! :)</p>\n<p>When the sun had set and it was hard to spot any further targets, we gathered for a barbecue to end the day, share our hunting stories, and compare our scores.</p>\n<h2 id=\"Back-at-the-office\"><a href=\"#Back-at-the-office\" class=\"headerlink\" title=\"Back at the office\"></a>Back at the office</h2><p>It was an awesome team event! We learned a lot during the workshops, prepared ourselves for the upcoming team changes, and embraced the nature near Camburg.<br>While we lost and broke some arrows in the thicket, no living animals were harmed and nobody took an arrow to the knee!</p>\n<img class=\"blog/blog-ep6offsite-yummy.jpg\">\n","excerpt":"","more":"<p>Mid June, the ePages 6 team went on a two-day offsite meeting – in Jena! How is it an offsite if you stay in the city you work in? Well, due to the size of the team and various team members having family obligations it was difficult to find a date and a location for this offsite.<br>Therefore, we agreed to stay in Jena. To avoid the usual office interruptions we booked the <a href=\"https://www.vhs-jena.de/de/service/raumvermietung/649482#/collapse4\">Creative Room of the Volkshochschule Jena</a> for two days. Additionally, we organised a cool team event in the forest area in Camburg. But let us tackle the serious issues first!</p>\n<h2 id=\"Team-constellation-and-focus\"><a href=\"#Team-constellation-and-focus\" class=\"headerlink\" title=\"Team constellation and focus\"></a>Team constellation and focus</h2><p>Just recently, our team was restructured. New team members were added, whereas some colleagues moved to other teams. Doing a team offsite was just the right setting to get to know each other better, and boost the team spirit. As we are facing new challenges, one big topic was focusing on our new tasks.</p>\n<h2 id=\"Workshops\"><a href=\"#Workshops\" class=\"headerlink\" title=\"Workshops\"></a>Workshops</h2><img class=\"blog/blog-team-ep6.jpg 50% right\">\n<p>In order to spread knowledge and improve our <a href=\"https://en.wikipedia.org/wiki/T-shaped_skills\">T-shaped skills</a> we prepared various workshops.<br>In advance we identified topics that are relevant to everyone in the team and topics that are only relevant to a certain guild.<br>To make best use of the limited time we held some workshops on parallel tracks.</p>\n<p>Of interest to everyone was the “JavaScript in our current ePages shop system” session chaired by Markus. He explained in detail how different JavaScript frameworks are integrated in our e-commerce solution and what to consider when writing JavaScript in this environment. Using live coding he demonstrated how the template engine, localisation, and JavaScript compression work.</p>\n<img class=\"blog/blog-ep6-frontend-workshop.jpg 50% left\">\n<p>Oliver explained selected <a href=\"https://www.owasp.org/index.php/Cheat_Sheets\">OWASP threats</a>. Afterwards we tried to exploit our software. While we identified some problems, we also concluded that current version is pretty resilient against the most common attacks: injections and cross-site scripting.</p>\n<p>Peter outlined our current development pipeline process used primarily for QA and collaboration on more complex features.<br>Additionally, he clarified the different build and configuration setups on our team VMs.</p>\n<p>On the second day we started with the parallel sessions: UI development and tax calculation in our current shop software.<br>For the frontend developers and designers Björn presented the various HTML template sections of a typical ePages shop webpage. In addition to that he documented the directory and file structure used for styling as well as the style guide itself.<br>The backend folks attended the tax calculation lecture by Michael. He explained in detail how to alter tax settings and which constraints to consider when customers and merchants from different countries do business together.</p>\n<p>Last but not least Tobias emphasised unit testing and best practices like the <a href=\"http://martinfowler.com/bliki/TestPyramid.html\">Test Pyramid</a>. Using multiple code examples he demonstrated how mocking can be used for integration tests.</p>\n<h2 id=\"Bow-and-arrow-action\"><a href=\"#Bow-and-arrow-action\" class=\"headerlink\" title=\"Bow and arrow action\"></a>Bow and arrow action</h2><img class=\"blog/blog-ep6offsite-bow.jpg 50% right\">\n<p>After one and a half day of intense workshops, we had our recreational team event on Wednesday afternoon. We went to the <a href=\"http://camburger-bogenschuetzen.de/\">archery site</a> located in the forest area in Camburg.</p>\n<p>Before starting our tour through the forest, we had some training shots. Equipped with bows, arrows, quivers, and protection gear, we were prepared for small and big game! We picked the “lesser” route, which resulted in shooting at around 27 animal models in three hours. Besides the typical forest animals we hunted gigantic turtles, cobras and even dinosaurs! :)</p>\n<p>When the sun had set and it was hard to spot any further targets, we gathered for a barbecue to end the day, share our hunting stories, and compare our scores.</p>\n<h2 id=\"Back-at-the-office\"><a href=\"#Back-at-the-office\" class=\"headerlink\" title=\"Back at the office\"></a>Back at the office</h2><p>It was an awesome team event! We learned a lot during the workshops, prepared ourselves for the upcoming team changes, and embraced the nature near Camburg.<br>While we lost and broke some arrows in the thicket, no living animals were harmed and nobody took an arrow to the knee!</p>\n<img class=\"blog/blog-ep6offsite-yummy.jpg\">\n"},{"layout":"post","title":"ContainerDays Hamburg","date":"2016-07-05T08:16:17.000Z","image":"blog-header/container2.jpg","authors":["Christian K."],"_content":"\nOn the 27th and 28th of June 2016, the first ContainerDays took place in the Port of Hamburg, Germany.\nThe main goal of this event was to:\n\n> \"[..] provide the European container community with the necessary platform to promote and professionalize the thriving container movement.\"\n\nThe event was divided into a conference day and a workshop day.\nThe first day was dedicated to workshops that focused on the practical use of container technologies like [Docker](https://www.docker.com/), [Kubernetes](http://kubernetes.io/), and [Mesosphere](https://mesosphere.com/).\nThe workshops were followed by a Meetup session in the evening.\nThe second day focused on talks from experts within the container community.\nThey presented their insights and experiences in the field of the IT infrastructure of the future.\n\nIn this post, I share some notes that I took from the various sessions I was particularly interested in.\n\n## Meetup\n\n### Tobias Schneck - [ConSol Software GmbH](https://www.consol.com/): Containerized End-2-End-Testing\n\nThe main point of this talk was about putting a VNC-Server and Selenium-like testing software ([sakuli](https://github.com/ConSol/sakuli)) in a container, and run UI tests with it.\nThey also integrated the E2E test in [Nagios](https://www.nagios.org/) and got some nice graphs and error reports out of it.\n\n[Slides](https://rawgit.com/toschneck/presentation/docker-meetup-container-days/index.html#/)\n\n### [Aaron Huslage](https://twitter.com/huslage) - [Docker](https://www.docker.com/): New Stuff in Docker 1.12\n\nAaron showed the new features of the upcoming docker release. The biggest part was the new orchestration framework (see [blog post](https://blog.docker.com/2016/06/docker-1-12-built-in-orchestration/)).\n\nSome main points:\n\n* Swarm Clustering, self healing.\n* Build in PKI, rotation, revoke ...\n* Routing Mesh: overlay network, load balancing, DNS based service discovery, IPVS\n* Service API: scheduling, scaling, rolling upgrades, health checks\n\n## Conference Day\n\n### [Mandy Waite](https://twitter.com/tekgrrl) - [Google](https://www.google.de) : From Borg to Kubernetes: The history and future of container orchestration\n\nThis talk was mainly about efficient usage of cluster resources in Borg and with Kubernetes:\n\n* New Feature in 1.3: Federated Cluster\n{% youtube 86jZdmAjWns %}\n\n### [Boyan Dimitrov](https://twitter.com/nathariel) - [Sixt](https://www.sixt.de/): Enterprise Microservice Adoption\n\nThe talk was about the first services developed as a microservice.\n\n* Old solution: 95% developed in house and run in own datacenter\n* Challenges: dependencies between teams, faster automation, enable teams to innovate and deliver\n\nThe approach:\n\n* Bootstrap full stack team with archivable task\n* Communicate a lot\n* Create API, self contained databases, service should be killable, fail fast, define success\n* Service template, new repos, Jenkins Jobs, Makefile\n* Continuous delivery track: simple and repeatable\n* Use [Micro](https://blog.micro.mu/) (microservice toolkit)\n* Scale the pilot\n\nThe already have production traffic on Kubernetes.\n\n### Erkan Yanar (Freelancer): Linuxkernel features building my $container\n\nErkan showed some basic commands how to interact with the kernel features that build the container.\n\nBuilding blocks of container:\n\n* chroot\n* Capabilities: cat /proc/self/status, capsh --decode\n* cgroups: examples: devices memory freeze\n* Namespaces: cmd tool unshare\n\n### Rainer Sträter - [1&1 Internet SE](http://www.1und1.de/): Application deployment and management at scale with 1&1\n\n* Motivation for container: Web hosting stacks, new demands from customers, complex updates\n* Everything is a container (mysql, php, ...)\n* GlusterFS storage layer\n* Kubernetes Cluster Size: 1000 Nodes, 1000 Container per Node\n* Cluster running on CoreOS\n* Open vSwitch for routing traffic\n* Automation of container build with [drone.io](https://drone.io/). Watch for changes, build, test push.\n* Applications need to support immutable updates\n* Currently no own container\n* Shortly publicly available as \"Managed Hosting\"\n\n### [Mathias Lafeldt](https://twitter.com/mlafeldt) - [Jimdo](http://www.jimdo.com/index.php): A journey through wonderland\n\n* Cloud migration took 5 years, now running on AWS\n* Every team did their own monitoring, deployment, test, and other stuff\n* Toolsmith team created Wonderland environment\n* They run dockerised applications and one off tasks\n* Provide APIs for logs, deployment, ...\n* Toolsmith team as internal service provider: SLA, workshops, documentation, ....\n* Tools in use: Docker registry, Vault, Chat bot, CoreOS (no SSH for devs)\n\n[Slides](https://speakerdeck.com/mlafeldt/a-journey-through-wonderland)\n\n### [Henning Jacobs](https://twitter.com/try_except_) - [Zalando](https://tech.zalando.de/): Plan B: Service to Service authentication with OAuth\n\nAbout the dev environment:\n\n* Shift to radical agility, autonomous teams, no team lead\n* One datacenter per Team (AWS)\n* All traffic is external traffic\n\nWhat else?\n\n* IAM on S3 for authorisation management\n* S3 holds user and password, with that you can get Bearer tokens\n* Token validation is tricky\n* JWT for authentication with ES256 algorithm\n* Validate via HTTP \"Token Info\" method or new OAuth RFC Token Introspective Endpoint\n* Implemented revoke single token and revoke tokens by claim\n* Revocation service gets revoked list every 30 seconds\n* Service user needs to know credentials and token URL\n* Service provider needs to know token info URL\n* Cassandra for token storage\n* 0.5 ms for validation + 8ms token info\n\n[Documentation](http://planb.readthedocs.io/en/latest/)\n\n[Slides](http://de.slideshare.net/try_except_/plan-b-service-to-service-authentication-with-oauth)\n\n### [Florian Leibert](https://twitter.com/flo) - [Mesosphere](https://mesosphere.com/): Lightning Talk\n\n* Helped Twitter and Airbnb to containerize their appilcations\n* Presented Mesos as OS for the data centre\n* Live example of Apache Spark with Zeppelin for analytics\n\n### [Tobias Schmidt](https://twitter.com/dagrobie) - [Soundcloud](https://soundcloud.com/): Efficient monitoring in modern environments\n\nWhy Monitor?\n\n* automatic alerting\n* long term trends\n* validate new features/experiments\n* debugging\n\nPoints to check:\n\n* Metrics: Host(CPU, memory, I/O, network, file system)\n* Container (CPU, memory, restarts, OOM, throttling)\n* Application (throughput, latency, queues)\n\nFour golden signals to monitor:\n\n1. Latency: time to serve a request; median doesn't reflect the user experience\n2. Traffic: Demand placed on the system\n3. Errors: Failure responses to user requests\n4. Saturation & Utilisation: Consumption on constraint resources\n\n* Alerting: optimise mean time to react and mean time to repair\n* Symptom vs. Cause based monitoring\n* Monitor/Alert for your users\n* Only page if something needs immediate human intervention\n\n* Prevent alert fatigue with:\n  * Alert grouping, batch alerts\n  * easy silencing\n  * dependencies between services\n  * static thresholds\n\nWhat else?\n\n* Use ticketing system for tracking non critical errors\n* Critical(sms),warn(ticket), info(log only)\n* Use run books, playbooks, and link them in the alerts\n* Practice outages \"game days\"\n\n[Slides](https://speakerdeck.com/grobie/efficient-monitoring-in-modern-environments)\n\n### [Florian Sellmayr](https://twitter.com/fsellmayr) - [ThoughtWorks](https://www.thoughtworks.com/): A web shop in containers - Building the microservice platform for otto.de\n\n* Running on Apache Mesos\n* 600 VMs running live shop\n* 10, 20 or 50 new services per year\n* Plain docker is w/o fun, only glorified rpm\n* Goals: freedom and responsibilities to the devs, new services without ops interaction, increase standardisation\n* Distributed Systems are hard!\n* Mesos a moving target. (frequent updates) → Keep on top of your tools\n* Service discovery is hard in mesos\n* Multi-Tenancy, shield teams from each other\n* Managing Secrets, people find ways to work around shitty secret systems\n* Task isolation, shop part vs. batch part\n* Container isolation, mesos and docker isolation does not match\n* Learn how to manage the chance in your cluster\n* Work for 4-5 people one year\n","source":"_posts/2016-07-05-containerdays.md","raw":"---\nlayout: post\ntitle: \"ContainerDays Hamburg\"\ndate: \"2016-07-05 10:16:17\"\nimage: blog-header/container2.jpg\ncategories: events\nauthors: [\"Christian K.\"]\n---\n\nOn the 27th and 28th of June 2016, the first ContainerDays took place in the Port of Hamburg, Germany.\nThe main goal of this event was to:\n\n> \"[..] provide the European container community with the necessary platform to promote and professionalize the thriving container movement.\"\n\nThe event was divided into a conference day and a workshop day.\nThe first day was dedicated to workshops that focused on the practical use of container technologies like [Docker](https://www.docker.com/), [Kubernetes](http://kubernetes.io/), and [Mesosphere](https://mesosphere.com/).\nThe workshops were followed by a Meetup session in the evening.\nThe second day focused on talks from experts within the container community.\nThey presented their insights and experiences in the field of the IT infrastructure of the future.\n\nIn this post, I share some notes that I took from the various sessions I was particularly interested in.\n\n## Meetup\n\n### Tobias Schneck - [ConSol Software GmbH](https://www.consol.com/): Containerized End-2-End-Testing\n\nThe main point of this talk was about putting a VNC-Server and Selenium-like testing software ([sakuli](https://github.com/ConSol/sakuli)) in a container, and run UI tests with it.\nThey also integrated the E2E test in [Nagios](https://www.nagios.org/) and got some nice graphs and error reports out of it.\n\n[Slides](https://rawgit.com/toschneck/presentation/docker-meetup-container-days/index.html#/)\n\n### [Aaron Huslage](https://twitter.com/huslage) - [Docker](https://www.docker.com/): New Stuff in Docker 1.12\n\nAaron showed the new features of the upcoming docker release. The biggest part was the new orchestration framework (see [blog post](https://blog.docker.com/2016/06/docker-1-12-built-in-orchestration/)).\n\nSome main points:\n\n* Swarm Clustering, self healing.\n* Build in PKI, rotation, revoke ...\n* Routing Mesh: overlay network, load balancing, DNS based service discovery, IPVS\n* Service API: scheduling, scaling, rolling upgrades, health checks\n\n## Conference Day\n\n### [Mandy Waite](https://twitter.com/tekgrrl) - [Google](https://www.google.de) : From Borg to Kubernetes: The history and future of container orchestration\n\nThis talk was mainly about efficient usage of cluster resources in Borg and with Kubernetes:\n\n* New Feature in 1.3: Federated Cluster\n{% youtube 86jZdmAjWns %}\n\n### [Boyan Dimitrov](https://twitter.com/nathariel) - [Sixt](https://www.sixt.de/): Enterprise Microservice Adoption\n\nThe talk was about the first services developed as a microservice.\n\n* Old solution: 95% developed in house and run in own datacenter\n* Challenges: dependencies between teams, faster automation, enable teams to innovate and deliver\n\nThe approach:\n\n* Bootstrap full stack team with archivable task\n* Communicate a lot\n* Create API, self contained databases, service should be killable, fail fast, define success\n* Service template, new repos, Jenkins Jobs, Makefile\n* Continuous delivery track: simple and repeatable\n* Use [Micro](https://blog.micro.mu/) (microservice toolkit)\n* Scale the pilot\n\nThe already have production traffic on Kubernetes.\n\n### Erkan Yanar (Freelancer): Linuxkernel features building my $container\n\nErkan showed some basic commands how to interact with the kernel features that build the container.\n\nBuilding blocks of container:\n\n* chroot\n* Capabilities: cat /proc/self/status, capsh --decode\n* cgroups: examples: devices memory freeze\n* Namespaces: cmd tool unshare\n\n### Rainer Sträter - [1&1 Internet SE](http://www.1und1.de/): Application deployment and management at scale with 1&1\n\n* Motivation for container: Web hosting stacks, new demands from customers, complex updates\n* Everything is a container (mysql, php, ...)\n* GlusterFS storage layer\n* Kubernetes Cluster Size: 1000 Nodes, 1000 Container per Node\n* Cluster running on CoreOS\n* Open vSwitch for routing traffic\n* Automation of container build with [drone.io](https://drone.io/). Watch for changes, build, test push.\n* Applications need to support immutable updates\n* Currently no own container\n* Shortly publicly available as \"Managed Hosting\"\n\n### [Mathias Lafeldt](https://twitter.com/mlafeldt) - [Jimdo](http://www.jimdo.com/index.php): A journey through wonderland\n\n* Cloud migration took 5 years, now running on AWS\n* Every team did their own monitoring, deployment, test, and other stuff\n* Toolsmith team created Wonderland environment\n* They run dockerised applications and one off tasks\n* Provide APIs for logs, deployment, ...\n* Toolsmith team as internal service provider: SLA, workshops, documentation, ....\n* Tools in use: Docker registry, Vault, Chat bot, CoreOS (no SSH for devs)\n\n[Slides](https://speakerdeck.com/mlafeldt/a-journey-through-wonderland)\n\n### [Henning Jacobs](https://twitter.com/try_except_) - [Zalando](https://tech.zalando.de/): Plan B: Service to Service authentication with OAuth\n\nAbout the dev environment:\n\n* Shift to radical agility, autonomous teams, no team lead\n* One datacenter per Team (AWS)\n* All traffic is external traffic\n\nWhat else?\n\n* IAM on S3 for authorisation management\n* S3 holds user and password, with that you can get Bearer tokens\n* Token validation is tricky\n* JWT for authentication with ES256 algorithm\n* Validate via HTTP \"Token Info\" method or new OAuth RFC Token Introspective Endpoint\n* Implemented revoke single token and revoke tokens by claim\n* Revocation service gets revoked list every 30 seconds\n* Service user needs to know credentials and token URL\n* Service provider needs to know token info URL\n* Cassandra for token storage\n* 0.5 ms for validation + 8ms token info\n\n[Documentation](http://planb.readthedocs.io/en/latest/)\n\n[Slides](http://de.slideshare.net/try_except_/plan-b-service-to-service-authentication-with-oauth)\n\n### [Florian Leibert](https://twitter.com/flo) - [Mesosphere](https://mesosphere.com/): Lightning Talk\n\n* Helped Twitter and Airbnb to containerize their appilcations\n* Presented Mesos as OS for the data centre\n* Live example of Apache Spark with Zeppelin for analytics\n\n### [Tobias Schmidt](https://twitter.com/dagrobie) - [Soundcloud](https://soundcloud.com/): Efficient monitoring in modern environments\n\nWhy Monitor?\n\n* automatic alerting\n* long term trends\n* validate new features/experiments\n* debugging\n\nPoints to check:\n\n* Metrics: Host(CPU, memory, I/O, network, file system)\n* Container (CPU, memory, restarts, OOM, throttling)\n* Application (throughput, latency, queues)\n\nFour golden signals to monitor:\n\n1. Latency: time to serve a request; median doesn't reflect the user experience\n2. Traffic: Demand placed on the system\n3. Errors: Failure responses to user requests\n4. Saturation & Utilisation: Consumption on constraint resources\n\n* Alerting: optimise mean time to react and mean time to repair\n* Symptom vs. Cause based monitoring\n* Monitor/Alert for your users\n* Only page if something needs immediate human intervention\n\n* Prevent alert fatigue with:\n  * Alert grouping, batch alerts\n  * easy silencing\n  * dependencies between services\n  * static thresholds\n\nWhat else?\n\n* Use ticketing system for tracking non critical errors\n* Critical(sms),warn(ticket), info(log only)\n* Use run books, playbooks, and link them in the alerts\n* Practice outages \"game days\"\n\n[Slides](https://speakerdeck.com/grobie/efficient-monitoring-in-modern-environments)\n\n### [Florian Sellmayr](https://twitter.com/fsellmayr) - [ThoughtWorks](https://www.thoughtworks.com/): A web shop in containers - Building the microservice platform for otto.de\n\n* Running on Apache Mesos\n* 600 VMs running live shop\n* 10, 20 or 50 new services per year\n* Plain docker is w/o fun, only glorified rpm\n* Goals: freedom and responsibilities to the devs, new services without ops interaction, increase standardisation\n* Distributed Systems are hard!\n* Mesos a moving target. (frequent updates) → Keep on top of your tools\n* Service discovery is hard in mesos\n* Multi-Tenancy, shield teams from each other\n* Managing Secrets, people find ways to work around shitty secret systems\n* Task isolation, shop part vs. batch part\n* Container isolation, mesos and docker isolation does not match\n* Learn how to manage the chance in your cluster\n* Work for 4-5 people one year\n","slug":"2016-07-05-containerdays","published":1,"updated":"2016-09-20T14:31:48.000Z","comments":1,"photos":[],"link":"","_id":"ciu6nuh9v002ohqyxahvfxjan","content":"<p>On the 27th and 28th of June 2016, the first ContainerDays took place in the Port of Hamburg, Germany.<br>The main goal of this event was to:</p>\n<blockquote>\n<p>“[..] provide the European container community with the necessary platform to promote and professionalize the thriving container movement.”</p>\n</blockquote>\n<p>The event was divided into a conference day and a workshop day.<br>The first day was dedicated to workshops that focused on the practical use of container technologies like <a href=\"https://www.docker.com/\" target=\"_blank\" rel=\"external\">Docker</a>, <a href=\"http://kubernetes.io/\" target=\"_blank\" rel=\"external\">Kubernetes</a>, and <a href=\"https://mesosphere.com/\" target=\"_blank\" rel=\"external\">Mesosphere</a>.<br>The workshops were followed by a Meetup session in the evening.<br>The second day focused on talks from experts within the container community.<br>They presented their insights and experiences in the field of the IT infrastructure of the future.</p>\n<p>In this post, I share some notes that I took from the various sessions I was particularly interested in.</p>\n<h2 id=\"Meetup\"><a href=\"#Meetup\" class=\"headerlink\" title=\"Meetup\"></a>Meetup</h2><h3 id=\"Tobias-Schneck-ConSol-Software-GmbH-Containerized-End-2-End-Testing\"><a href=\"#Tobias-Schneck-ConSol-Software-GmbH-Containerized-End-2-End-Testing\" class=\"headerlink\" title=\"Tobias Schneck - ConSol Software GmbH: Containerized End-2-End-Testing\"></a>Tobias Schneck - <a href=\"https://www.consol.com/\" target=\"_blank\" rel=\"external\">ConSol Software GmbH</a>: Containerized End-2-End-Testing</h3><p>The main point of this talk was about putting a VNC-Server and Selenium-like testing software (<a href=\"https://github.com/ConSol/sakuli\" target=\"_blank\" rel=\"external\">sakuli</a>) in a container, and run UI tests with it.<br>They also integrated the E2E test in <a href=\"https://www.nagios.org/\" target=\"_blank\" rel=\"external\">Nagios</a> and got some nice graphs and error reports out of it.</p>\n<p><a href=\"https://rawgit.com/toschneck/presentation/docker-meetup-container-days/index.html#/\" target=\"_blank\" rel=\"external\">Slides</a></p>\n<h3 id=\"Aaron-Huslage-Docker-New-Stuff-in-Docker-1-12\"><a href=\"#Aaron-Huslage-Docker-New-Stuff-in-Docker-1-12\" class=\"headerlink\" title=\"Aaron Huslage - Docker: New Stuff in Docker 1.12\"></a><a href=\"https://twitter.com/huslage\" target=\"_blank\" rel=\"external\">Aaron Huslage</a> - <a href=\"https://www.docker.com/\" target=\"_blank\" rel=\"external\">Docker</a>: New Stuff in Docker 1.12</h3><p>Aaron showed the new features of the upcoming docker release. The biggest part was the new orchestration framework (see <a href=\"https://blog.docker.com/2016/06/docker-1-12-built-in-orchestration/\" target=\"_blank\" rel=\"external\">blog post</a>).</p>\n<p>Some main points:</p>\n<ul>\n<li>Swarm Clustering, self healing.</li>\n<li>Build in PKI, rotation, revoke …</li>\n<li>Routing Mesh: overlay network, load balancing, DNS based service discovery, IPVS</li>\n<li>Service API: scheduling, scaling, rolling upgrades, health checks</li>\n</ul>\n<h2 id=\"Conference-Day\"><a href=\"#Conference-Day\" class=\"headerlink\" title=\"Conference Day\"></a>Conference Day</h2><h3 id=\"Mandy-Waite-Google-From-Borg-to-Kubernetes-The-history-and-future-of-container-orchestration\"><a href=\"#Mandy-Waite-Google-From-Borg-to-Kubernetes-The-history-and-future-of-container-orchestration\" class=\"headerlink\" title=\"Mandy Waite - Google : From Borg to Kubernetes: The history and future of container orchestration\"></a><a href=\"https://twitter.com/tekgrrl\" target=\"_blank\" rel=\"external\">Mandy Waite</a> - <a href=\"https://www.google.de\" target=\"_blank\" rel=\"external\">Google</a> : From Borg to Kubernetes: The history and future of container orchestration</h3><p>This talk was mainly about efficient usage of cluster resources in Borg and with Kubernetes:</p>\n<ul>\n<li>New Feature in 1.3: Federated Cluster<div class=\"video-container\"><iframe src=\"//www.youtube.com/embed/86jZdmAjWns\" frameborder=\"0\" allowfullscreen></iframe></div>\n</li>\n</ul>\n<h3 id=\"Boyan-Dimitrov-Sixt-Enterprise-Microservice-Adoption\"><a href=\"#Boyan-Dimitrov-Sixt-Enterprise-Microservice-Adoption\" class=\"headerlink\" title=\"Boyan Dimitrov - Sixt: Enterprise Microservice Adoption\"></a><a href=\"https://twitter.com/nathariel\" target=\"_blank\" rel=\"external\">Boyan Dimitrov</a> - <a href=\"https://www.sixt.de/\" target=\"_blank\" rel=\"external\">Sixt</a>: Enterprise Microservice Adoption</h3><p>The talk was about the first services developed as a microservice.</p>\n<ul>\n<li>Old solution: 95% developed in house and run in own datacenter</li>\n<li>Challenges: dependencies between teams, faster automation, enable teams to innovate and deliver</li>\n</ul>\n<p>The approach:</p>\n<ul>\n<li>Bootstrap full stack team with archivable task</li>\n<li>Communicate a lot</li>\n<li>Create API, self contained databases, service should be killable, fail fast, define success</li>\n<li>Service template, new repos, Jenkins Jobs, Makefile</li>\n<li>Continuous delivery track: simple and repeatable</li>\n<li>Use <a href=\"https://blog.micro.mu/\" target=\"_blank\" rel=\"external\">Micro</a> (microservice toolkit)</li>\n<li>Scale the pilot</li>\n</ul>\n<p>The already have production traffic on Kubernetes.</p>\n<h3 id=\"Erkan-Yanar-Freelancer-Linuxkernel-features-building-my-container\"><a href=\"#Erkan-Yanar-Freelancer-Linuxkernel-features-building-my-container\" class=\"headerlink\" title=\"Erkan Yanar (Freelancer): Linuxkernel features building my $container\"></a>Erkan Yanar (Freelancer): Linuxkernel features building my $container</h3><p>Erkan showed some basic commands how to interact with the kernel features that build the container.</p>\n<p>Building blocks of container:</p>\n<ul>\n<li>chroot</li>\n<li>Capabilities: cat /proc/self/status, capsh –decode</li>\n<li>cgroups: examples: devices memory freeze</li>\n<li>Namespaces: cmd tool unshare</li>\n</ul>\n<h3 id=\"Rainer-Strater-1-amp-1-Internet-SE-Application-deployment-and-management-at-scale-with-1-amp-1\"><a href=\"#Rainer-Strater-1-amp-1-Internet-SE-Application-deployment-and-management-at-scale-with-1-amp-1\" class=\"headerlink\" title=\"Rainer Sträter - 1&amp;1 Internet SE: Application deployment and management at scale with 1&amp;1\"></a>Rainer Sträter - <a href=\"http://www.1und1.de/\" target=\"_blank\" rel=\"external\">1&amp;1 Internet SE</a>: Application deployment and management at scale with 1&amp;1</h3><ul>\n<li>Motivation for container: Web hosting stacks, new demands from customers, complex updates</li>\n<li>Everything is a container (mysql, php, …)</li>\n<li>GlusterFS storage layer</li>\n<li>Kubernetes Cluster Size: 1000 Nodes, 1000 Container per Node</li>\n<li>Cluster running on CoreOS</li>\n<li>Open vSwitch for routing traffic</li>\n<li>Automation of container build with <a href=\"https://drone.io/\" target=\"_blank\" rel=\"external\">drone.io</a>. Watch for changes, build, test push.</li>\n<li>Applications need to support immutable updates</li>\n<li>Currently no own container</li>\n<li>Shortly publicly available as “Managed Hosting”</li>\n</ul>\n<h3 id=\"Mathias-Lafeldt-Jimdo-A-journey-through-wonderland\"><a href=\"#Mathias-Lafeldt-Jimdo-A-journey-through-wonderland\" class=\"headerlink\" title=\"Mathias Lafeldt - Jimdo: A journey through wonderland\"></a><a href=\"https://twitter.com/mlafeldt\" target=\"_blank\" rel=\"external\">Mathias Lafeldt</a> - <a href=\"http://www.jimdo.com/index.php\" target=\"_blank\" rel=\"external\">Jimdo</a>: A journey through wonderland</h3><ul>\n<li>Cloud migration took 5 years, now running on AWS</li>\n<li>Every team did their own monitoring, deployment, test, and other stuff</li>\n<li>Toolsmith team created Wonderland environment</li>\n<li>They run dockerised applications and one off tasks</li>\n<li>Provide APIs for logs, deployment, …</li>\n<li>Toolsmith team as internal service provider: SLA, workshops, documentation, ….</li>\n<li>Tools in use: Docker registry, Vault, Chat bot, CoreOS (no SSH for devs)</li>\n</ul>\n<p><a href=\"https://speakerdeck.com/mlafeldt/a-journey-through-wonderland\" target=\"_blank\" rel=\"external\">Slides</a></p>\n<h3 id=\"Henning-Jacobs-Zalando-Plan-B-Service-to-Service-authentication-with-OAuth\"><a href=\"#Henning-Jacobs-Zalando-Plan-B-Service-to-Service-authentication-with-OAuth\" class=\"headerlink\" title=\"Henning Jacobs - Zalando: Plan B: Service to Service authentication with OAuth\"></a><a href=\"https://twitter.com/try_except_\" target=\"_blank\" rel=\"external\">Henning Jacobs</a> - <a href=\"https://tech.zalando.de/\" target=\"_blank\" rel=\"external\">Zalando</a>: Plan B: Service to Service authentication with OAuth</h3><p>About the dev environment:</p>\n<ul>\n<li>Shift to radical agility, autonomous teams, no team lead</li>\n<li>One datacenter per Team (AWS)</li>\n<li>All traffic is external traffic</li>\n</ul>\n<p>What else?</p>\n<ul>\n<li>IAM on S3 for authorisation management</li>\n<li>S3 holds user and password, with that you can get Bearer tokens</li>\n<li>Token validation is tricky</li>\n<li>JWT for authentication with ES256 algorithm</li>\n<li>Validate via HTTP “Token Info” method or new OAuth RFC Token Introspective Endpoint</li>\n<li>Implemented revoke single token and revoke tokens by claim</li>\n<li>Revocation service gets revoked list every 30 seconds</li>\n<li>Service user needs to know credentials and token URL</li>\n<li>Service provider needs to know token info URL</li>\n<li>Cassandra for token storage</li>\n<li>0.5 ms for validation + 8ms token info</li>\n</ul>\n<p><a href=\"http://planb.readthedocs.io/en/latest/\" target=\"_blank\" rel=\"external\">Documentation</a></p>\n<p><a href=\"http://de.slideshare.net/try_except_/plan-b-service-to-service-authentication-with-oauth\" target=\"_blank\" rel=\"external\">Slides</a></p>\n<h3 id=\"Florian-Leibert-Mesosphere-Lightning-Talk\"><a href=\"#Florian-Leibert-Mesosphere-Lightning-Talk\" class=\"headerlink\" title=\"Florian Leibert - Mesosphere: Lightning Talk\"></a><a href=\"https://twitter.com/flo\" target=\"_blank\" rel=\"external\">Florian Leibert</a> - <a href=\"https://mesosphere.com/\" target=\"_blank\" rel=\"external\">Mesosphere</a>: Lightning Talk</h3><ul>\n<li>Helped Twitter and Airbnb to containerize their appilcations</li>\n<li>Presented Mesos as OS for the data centre</li>\n<li>Live example of Apache Spark with Zeppelin for analytics</li>\n</ul>\n<h3 id=\"Tobias-Schmidt-Soundcloud-Efficient-monitoring-in-modern-environments\"><a href=\"#Tobias-Schmidt-Soundcloud-Efficient-monitoring-in-modern-environments\" class=\"headerlink\" title=\"Tobias Schmidt - Soundcloud: Efficient monitoring in modern environments\"></a><a href=\"https://twitter.com/dagrobie\" target=\"_blank\" rel=\"external\">Tobias Schmidt</a> - <a href=\"https://soundcloud.com/\" target=\"_blank\" rel=\"external\">Soundcloud</a>: Efficient monitoring in modern environments</h3><p>Why Monitor?</p>\n<ul>\n<li>automatic alerting</li>\n<li>long term trends</li>\n<li>validate new features/experiments</li>\n<li>debugging</li>\n</ul>\n<p>Points to check:</p>\n<ul>\n<li>Metrics: Host(CPU, memory, I/O, network, file system)</li>\n<li>Container (CPU, memory, restarts, OOM, throttling)</li>\n<li>Application (throughput, latency, queues)</li>\n</ul>\n<p>Four golden signals to monitor:</p>\n<ol>\n<li>Latency: time to serve a request; median doesn’t reflect the user experience</li>\n<li>Traffic: Demand placed on the system</li>\n<li>Errors: Failure responses to user requests</li>\n<li>Saturation &amp; Utilisation: Consumption on constraint resources</li>\n</ol>\n<ul>\n<li>Alerting: optimise mean time to react and mean time to repair</li>\n<li>Symptom vs. Cause based monitoring</li>\n<li>Monitor/Alert for your users</li>\n<li><p>Only page if something needs immediate human intervention</p>\n</li>\n<li><p>Prevent alert fatigue with:</p>\n<ul>\n<li>Alert grouping, batch alerts</li>\n<li>easy silencing</li>\n<li>dependencies between services</li>\n<li>static thresholds</li>\n</ul>\n</li>\n</ul>\n<p>What else?</p>\n<ul>\n<li>Use ticketing system for tracking non critical errors</li>\n<li>Critical(sms),warn(ticket), info(log only)</li>\n<li>Use run books, playbooks, and link them in the alerts</li>\n<li>Practice outages “game days”</li>\n</ul>\n<p><a href=\"https://speakerdeck.com/grobie/efficient-monitoring-in-modern-environments\" target=\"_blank\" rel=\"external\">Slides</a></p>\n<h3 id=\"Florian-Sellmayr-ThoughtWorks-A-web-shop-in-containers-Building-the-microservice-platform-for-otto-de\"><a href=\"#Florian-Sellmayr-ThoughtWorks-A-web-shop-in-containers-Building-the-microservice-platform-for-otto-de\" class=\"headerlink\" title=\"Florian Sellmayr - ThoughtWorks: A web shop in containers - Building the microservice platform for otto.de\"></a><a href=\"https://twitter.com/fsellmayr\" target=\"_blank\" rel=\"external\">Florian Sellmayr</a> - <a href=\"https://www.thoughtworks.com/\" target=\"_blank\" rel=\"external\">ThoughtWorks</a>: A web shop in containers - Building the microservice platform for otto.de</h3><ul>\n<li>Running on Apache Mesos</li>\n<li>600 VMs running live shop</li>\n<li>10, 20 or 50 new services per year</li>\n<li>Plain docker is w/o fun, only glorified rpm</li>\n<li>Goals: freedom and responsibilities to the devs, new services without ops interaction, increase standardisation</li>\n<li>Distributed Systems are hard!</li>\n<li>Mesos a moving target. (frequent updates) → Keep on top of your tools</li>\n<li>Service discovery is hard in mesos</li>\n<li>Multi-Tenancy, shield teams from each other</li>\n<li>Managing Secrets, people find ways to work around shitty secret systems</li>\n<li>Task isolation, shop part vs. batch part</li>\n<li>Container isolation, mesos and docker isolation does not match</li>\n<li>Learn how to manage the chance in your cluster</li>\n<li>Work for 4-5 people one year</li>\n</ul>\n","excerpt":"","more":"<p>On the 27th and 28th of June 2016, the first ContainerDays took place in the Port of Hamburg, Germany.<br>The main goal of this event was to:</p>\n<blockquote>\n<p>“[..] provide the European container community with the necessary platform to promote and professionalize the thriving container movement.”</p>\n</blockquote>\n<p>The event was divided into a conference day and a workshop day.<br>The first day was dedicated to workshops that focused on the practical use of container technologies like <a href=\"https://www.docker.com/\">Docker</a>, <a href=\"http://kubernetes.io/\">Kubernetes</a>, and <a href=\"https://mesosphere.com/\">Mesosphere</a>.<br>The workshops were followed by a Meetup session in the evening.<br>The second day focused on talks from experts within the container community.<br>They presented their insights and experiences in the field of the IT infrastructure of the future.</p>\n<p>In this post, I share some notes that I took from the various sessions I was particularly interested in.</p>\n<h2 id=\"Meetup\"><a href=\"#Meetup\" class=\"headerlink\" title=\"Meetup\"></a>Meetup</h2><h3 id=\"Tobias-Schneck-ConSol-Software-GmbH-Containerized-End-2-End-Testing\"><a href=\"#Tobias-Schneck-ConSol-Software-GmbH-Containerized-End-2-End-Testing\" class=\"headerlink\" title=\"Tobias Schneck - ConSol Software GmbH: Containerized End-2-End-Testing\"></a>Tobias Schneck - <a href=\"https://www.consol.com/\">ConSol Software GmbH</a>: Containerized End-2-End-Testing</h3><p>The main point of this talk was about putting a VNC-Server and Selenium-like testing software (<a href=\"https://github.com/ConSol/sakuli\">sakuli</a>) in a container, and run UI tests with it.<br>They also integrated the E2E test in <a href=\"https://www.nagios.org/\">Nagios</a> and got some nice graphs and error reports out of it.</p>\n<p><a href=\"https://rawgit.com/toschneck/presentation/docker-meetup-container-days/index.html#/\">Slides</a></p>\n<h3 id=\"Aaron-Huslage-Docker-New-Stuff-in-Docker-1-12\"><a href=\"#Aaron-Huslage-Docker-New-Stuff-in-Docker-1-12\" class=\"headerlink\" title=\"Aaron Huslage - Docker: New Stuff in Docker 1.12\"></a><a href=\"https://twitter.com/huslage\">Aaron Huslage</a> - <a href=\"https://www.docker.com/\">Docker</a>: New Stuff in Docker 1.12</h3><p>Aaron showed the new features of the upcoming docker release. The biggest part was the new orchestration framework (see <a href=\"https://blog.docker.com/2016/06/docker-1-12-built-in-orchestration/\">blog post</a>).</p>\n<p>Some main points:</p>\n<ul>\n<li>Swarm Clustering, self healing.</li>\n<li>Build in PKI, rotation, revoke …</li>\n<li>Routing Mesh: overlay network, load balancing, DNS based service discovery, IPVS</li>\n<li>Service API: scheduling, scaling, rolling upgrades, health checks</li>\n</ul>\n<h2 id=\"Conference-Day\"><a href=\"#Conference-Day\" class=\"headerlink\" title=\"Conference Day\"></a>Conference Day</h2><h3 id=\"Mandy-Waite-Google-From-Borg-to-Kubernetes-The-history-and-future-of-container-orchestration\"><a href=\"#Mandy-Waite-Google-From-Borg-to-Kubernetes-The-history-and-future-of-container-orchestration\" class=\"headerlink\" title=\"Mandy Waite - Google : From Borg to Kubernetes: The history and future of container orchestration\"></a><a href=\"https://twitter.com/tekgrrl\">Mandy Waite</a> - <a href=\"https://www.google.de\">Google</a> : From Borg to Kubernetes: The history and future of container orchestration</h3><p>This talk was mainly about efficient usage of cluster resources in Borg and with Kubernetes:</p>\n<ul>\n<li>New Feature in 1.3: Federated Cluster<div class=\"video-container\"><iframe src=\"//www.youtube.com/embed/86jZdmAjWns\" frameborder=\"0\" allowfullscreen></iframe></div>\n</li>\n</ul>\n<h3 id=\"Boyan-Dimitrov-Sixt-Enterprise-Microservice-Adoption\"><a href=\"#Boyan-Dimitrov-Sixt-Enterprise-Microservice-Adoption\" class=\"headerlink\" title=\"Boyan Dimitrov - Sixt: Enterprise Microservice Adoption\"></a><a href=\"https://twitter.com/nathariel\">Boyan Dimitrov</a> - <a href=\"https://www.sixt.de/\">Sixt</a>: Enterprise Microservice Adoption</h3><p>The talk was about the first services developed as a microservice.</p>\n<ul>\n<li>Old solution: 95% developed in house and run in own datacenter</li>\n<li>Challenges: dependencies between teams, faster automation, enable teams to innovate and deliver</li>\n</ul>\n<p>The approach:</p>\n<ul>\n<li>Bootstrap full stack team with archivable task</li>\n<li>Communicate a lot</li>\n<li>Create API, self contained databases, service should be killable, fail fast, define success</li>\n<li>Service template, new repos, Jenkins Jobs, Makefile</li>\n<li>Continuous delivery track: simple and repeatable</li>\n<li>Use <a href=\"https://blog.micro.mu/\">Micro</a> (microservice toolkit)</li>\n<li>Scale the pilot</li>\n</ul>\n<p>The already have production traffic on Kubernetes.</p>\n<h3 id=\"Erkan-Yanar-Freelancer-Linuxkernel-features-building-my-container\"><a href=\"#Erkan-Yanar-Freelancer-Linuxkernel-features-building-my-container\" class=\"headerlink\" title=\"Erkan Yanar (Freelancer): Linuxkernel features building my $container\"></a>Erkan Yanar (Freelancer): Linuxkernel features building my $container</h3><p>Erkan showed some basic commands how to interact with the kernel features that build the container.</p>\n<p>Building blocks of container:</p>\n<ul>\n<li>chroot</li>\n<li>Capabilities: cat /proc/self/status, capsh –decode</li>\n<li>cgroups: examples: devices memory freeze</li>\n<li>Namespaces: cmd tool unshare</li>\n</ul>\n<h3 id=\"Rainer-Strater-1-amp-1-Internet-SE-Application-deployment-and-management-at-scale-with-1-amp-1\"><a href=\"#Rainer-Strater-1-amp-1-Internet-SE-Application-deployment-and-management-at-scale-with-1-amp-1\" class=\"headerlink\" title=\"Rainer Sträter - 1&amp;1 Internet SE: Application deployment and management at scale with 1&amp;1\"></a>Rainer Sträter - <a href=\"http://www.1und1.de/\">1&amp;1 Internet SE</a>: Application deployment and management at scale with 1&amp;1</h3><ul>\n<li>Motivation for container: Web hosting stacks, new demands from customers, complex updates</li>\n<li>Everything is a container (mysql, php, …)</li>\n<li>GlusterFS storage layer</li>\n<li>Kubernetes Cluster Size: 1000 Nodes, 1000 Container per Node</li>\n<li>Cluster running on CoreOS</li>\n<li>Open vSwitch for routing traffic</li>\n<li>Automation of container build with <a href=\"https://drone.io/\">drone.io</a>. Watch for changes, build, test push.</li>\n<li>Applications need to support immutable updates</li>\n<li>Currently no own container</li>\n<li>Shortly publicly available as “Managed Hosting”</li>\n</ul>\n<h3 id=\"Mathias-Lafeldt-Jimdo-A-journey-through-wonderland\"><a href=\"#Mathias-Lafeldt-Jimdo-A-journey-through-wonderland\" class=\"headerlink\" title=\"Mathias Lafeldt - Jimdo: A journey through wonderland\"></a><a href=\"https://twitter.com/mlafeldt\">Mathias Lafeldt</a> - <a href=\"http://www.jimdo.com/index.php\">Jimdo</a>: A journey through wonderland</h3><ul>\n<li>Cloud migration took 5 years, now running on AWS</li>\n<li>Every team did their own monitoring, deployment, test, and other stuff</li>\n<li>Toolsmith team created Wonderland environment</li>\n<li>They run dockerised applications and one off tasks</li>\n<li>Provide APIs for logs, deployment, …</li>\n<li>Toolsmith team as internal service provider: SLA, workshops, documentation, ….</li>\n<li>Tools in use: Docker registry, Vault, Chat bot, CoreOS (no SSH for devs)</li>\n</ul>\n<p><a href=\"https://speakerdeck.com/mlafeldt/a-journey-through-wonderland\">Slides</a></p>\n<h3 id=\"Henning-Jacobs-Zalando-Plan-B-Service-to-Service-authentication-with-OAuth\"><a href=\"#Henning-Jacobs-Zalando-Plan-B-Service-to-Service-authentication-with-OAuth\" class=\"headerlink\" title=\"Henning Jacobs - Zalando: Plan B: Service to Service authentication with OAuth\"></a><a href=\"https://twitter.com/try_except_\">Henning Jacobs</a> - <a href=\"https://tech.zalando.de/\">Zalando</a>: Plan B: Service to Service authentication with OAuth</h3><p>About the dev environment:</p>\n<ul>\n<li>Shift to radical agility, autonomous teams, no team lead</li>\n<li>One datacenter per Team (AWS)</li>\n<li>All traffic is external traffic</li>\n</ul>\n<p>What else?</p>\n<ul>\n<li>IAM on S3 for authorisation management</li>\n<li>S3 holds user and password, with that you can get Bearer tokens</li>\n<li>Token validation is tricky</li>\n<li>JWT for authentication with ES256 algorithm</li>\n<li>Validate via HTTP “Token Info” method or new OAuth RFC Token Introspective Endpoint</li>\n<li>Implemented revoke single token and revoke tokens by claim</li>\n<li>Revocation service gets revoked list every 30 seconds</li>\n<li>Service user needs to know credentials and token URL</li>\n<li>Service provider needs to know token info URL</li>\n<li>Cassandra for token storage</li>\n<li>0.5 ms for validation + 8ms token info</li>\n</ul>\n<p><a href=\"http://planb.readthedocs.io/en/latest/\">Documentation</a></p>\n<p><a href=\"http://de.slideshare.net/try_except_/plan-b-service-to-service-authentication-with-oauth\">Slides</a></p>\n<h3 id=\"Florian-Leibert-Mesosphere-Lightning-Talk\"><a href=\"#Florian-Leibert-Mesosphere-Lightning-Talk\" class=\"headerlink\" title=\"Florian Leibert - Mesosphere: Lightning Talk\"></a><a href=\"https://twitter.com/flo\">Florian Leibert</a> - <a href=\"https://mesosphere.com/\">Mesosphere</a>: Lightning Talk</h3><ul>\n<li>Helped Twitter and Airbnb to containerize their appilcations</li>\n<li>Presented Mesos as OS for the data centre</li>\n<li>Live example of Apache Spark with Zeppelin for analytics</li>\n</ul>\n<h3 id=\"Tobias-Schmidt-Soundcloud-Efficient-monitoring-in-modern-environments\"><a href=\"#Tobias-Schmidt-Soundcloud-Efficient-monitoring-in-modern-environments\" class=\"headerlink\" title=\"Tobias Schmidt - Soundcloud: Efficient monitoring in modern environments\"></a><a href=\"https://twitter.com/dagrobie\">Tobias Schmidt</a> - <a href=\"https://soundcloud.com/\">Soundcloud</a>: Efficient monitoring in modern environments</h3><p>Why Monitor?</p>\n<ul>\n<li>automatic alerting</li>\n<li>long term trends</li>\n<li>validate new features/experiments</li>\n<li>debugging</li>\n</ul>\n<p>Points to check:</p>\n<ul>\n<li>Metrics: Host(CPU, memory, I/O, network, file system)</li>\n<li>Container (CPU, memory, restarts, OOM, throttling)</li>\n<li>Application (throughput, latency, queues)</li>\n</ul>\n<p>Four golden signals to monitor:</p>\n<ol>\n<li>Latency: time to serve a request; median doesn’t reflect the user experience</li>\n<li>Traffic: Demand placed on the system</li>\n<li>Errors: Failure responses to user requests</li>\n<li>Saturation &amp; Utilisation: Consumption on constraint resources</li>\n</ol>\n<ul>\n<li>Alerting: optimise mean time to react and mean time to repair</li>\n<li>Symptom vs. Cause based monitoring</li>\n<li>Monitor/Alert for your users</li>\n<li><p>Only page if something needs immediate human intervention</p>\n</li>\n<li><p>Prevent alert fatigue with:</p>\n<ul>\n<li>Alert grouping, batch alerts</li>\n<li>easy silencing</li>\n<li>dependencies between services</li>\n<li>static thresholds</li>\n</ul>\n</li>\n</ul>\n<p>What else?</p>\n<ul>\n<li>Use ticketing system for tracking non critical errors</li>\n<li>Critical(sms),warn(ticket), info(log only)</li>\n<li>Use run books, playbooks, and link them in the alerts</li>\n<li>Practice outages “game days”</li>\n</ul>\n<p><a href=\"https://speakerdeck.com/grobie/efficient-monitoring-in-modern-environments\">Slides</a></p>\n<h3 id=\"Florian-Sellmayr-ThoughtWorks-A-web-shop-in-containers-Building-the-microservice-platform-for-otto-de\"><a href=\"#Florian-Sellmayr-ThoughtWorks-A-web-shop-in-containers-Building-the-microservice-platform-for-otto-de\" class=\"headerlink\" title=\"Florian Sellmayr - ThoughtWorks: A web shop in containers - Building the microservice platform for otto.de\"></a><a href=\"https://twitter.com/fsellmayr\">Florian Sellmayr</a> - <a href=\"https://www.thoughtworks.com/\">ThoughtWorks</a>: A web shop in containers - Building the microservice platform for otto.de</h3><ul>\n<li>Running on Apache Mesos</li>\n<li>600 VMs running live shop</li>\n<li>10, 20 or 50 new services per year</li>\n<li>Plain docker is w/o fun, only glorified rpm</li>\n<li>Goals: freedom and responsibilities to the devs, new services without ops interaction, increase standardisation</li>\n<li>Distributed Systems are hard!</li>\n<li>Mesos a moving target. (frequent updates) → Keep on top of your tools</li>\n<li>Service discovery is hard in mesos</li>\n<li>Multi-Tenancy, shield teams from each other</li>\n<li>Managing Secrets, people find ways to work around shitty secret systems</li>\n<li>Task isolation, shop part vs. batch part</li>\n<li>Container isolation, mesos and docker isolation does not match</li>\n<li>Learn how to manage the chance in your cluster</li>\n<li>Work for 4-5 people one year</li>\n</ul>\n"},{"layout":"post","title":"How to make microservice testing great again","date":"2016-07-14T10:00:00.000Z","image":"/blog-header/balls-of-mud.jpg","authors":["Oliver T."],"_content":"\nThere is a lot of buzz about microservices these days, and here is our take on managing decoupled microservices, while still keeping confident in REST API compatibility.\n\nOne of the SOA missteps was trying to enforce a canonical domain model, which lead to bloated domain objects, that still would not fit all use cases and needed some sort of central management.\nJust try to come up with a common model of any real-world object and you'll know that this does not scale the more people are involved.\nIn a more abstract sense, it is our strive to perfection and the strive of perfect modelling of our problem domain that drove us into the wrong direction.\nDavid Dawson phrased this as \"Perfection and How It Ruined The World\" in his talk [\"Philosophical Architecture in Grails\"](https://www.youtube.com/watch?v=nx8XMY7evbA)\nHe also illustrated brilliantly why monoliths are doomed to fail ultimately.\n\nClient SDKs would be just another way of a shared domain model, and additionally would force the consumer to be using one specific client library.\nThis brings in tight coupling, which should be avoided, unless all consumers are under your own control.\nIn that case [gRPC](http://www.grpc.io/) might be an interesting alternative to using REST.\n\nSo, instead of managing a globally shared domain model, slowing down our development, we would rather let every service define its own view of the domain model in order to achieve loose coupling.\nCoupling, as Oliver Gierke correctly stated, is not binary.\n\n{% image blog/blog-wiremock-quote-gierke.jpg 100% left %}\n\n> \"If you don't want no coupling at all, don't let your systems\n> talk to each other\". [@olivergierke](https://twitter.com/olivergierke/status/733603527549931520)\n\nOf course you need communication between your services, and of course this introduces some coupling.\nBut, when opening an API to external consumers, it becomes a shared concern that you need to manage.\nAnd it implies, that the producer cannot introduce breaking changes without the possibility of breaking the consumer's API integration.\nIt actually doesn't matter if it is asynchronous communication or synchronous communication via REST.\nIn both cases you need to share a common API \"vocabulary\".\nAnd, you need to verify the contract defined within the API.\n\nThere are three ways of dealing with it.\nLet's start with the most obvious, but most brittle one: Integration testing.\nLet's test our microservices in integration, allowing us to verify the complete system behaviour from an outside point of view.\nThis of course requires all services and their infrastructure to be up and running simultaneously.\nThink of integration tests failing mysteriously every few weeks...\n\n{% image blog/blog-wiremock-quote-honestupdate.jpg 100% left %}\n\n> \"We replaced our monolithic app with micro services so that every outage\n> could be more like a murder mystery\" [@honest_update](https://twitter.com/honest_update/status/651897353889259520)\n\nA better way would be trying to test your client against actual responses of the server without the server having to be up and running.\nHow can you achieve this?\nInterestingly, the solution is not too hard.\nMartin Fowler calls this test method [\"Integration Contract Testing\"](http://martinfowler.com/bliki/IntegrationContractTest.html).\nFor integration contract testing the producer is replaced with a \"test double\" and pre-recorded responses would be replayed for the test scenario.\n\nIt is one level before [\"Consumer-driven contract testing\"](https://www.thoughtworks.com/radar/techniques/consumer-driven-contract-testing), where the consumer provides its test scenarios to the producer, which allows checking consumer compatibility even before introducing a potentially breaking API change.\nBut this has the down-side of off-loading all the testing effort to the producing side.\n\nMartin Fowler still sees the [*\"[..] danger that the test doubles get out of sync with the real supplier service\"*](http://martinfowler.com/bliki/IntegrationContractTest.html).\nHow can we avoid getting out of sync, ideally without extra effort?\nFirst of all, we shouldn't let the client define the test double's responses.\nAnd, we make sure the pre-recorded responses are shared artifacts, which get updated whenever we release a new version of the producer.\n\nThere is another artifact which should never become out of date with the implementation: Our API documentation.\nWhy not kill two birds with one stone and produce both human-readable REST documentation and API stubs directly as part of testing your producing service?\nFor doing this we came up with a small utility library, that we decided to [share as open source on GitHub](https://github.com/ePages-de/restdocs-wiremock).\nIt combines the goodness of [Spring REST Docs](http://projects.spring.io/spring-restdocs/) for producing documentation, and [WireMock](http://wiremock.org/), a tool for mocking a webserver during testing.\nIn the end, the WireMock stubs become just another part of our service documentation, which happen to be machine-readable.\n\nLet's look at some code.\nAssume you have a note-collection service written with Spring WebMVC, and you want to document your API with Spring REST Docs, which would look similar to this code:\n\n```java\n@RunWith(SpringJUnit4ClassRunner.class)\nclass ApiDocumentation {\n    // ... the usual test setup.\n    void should_retrieve_single_note() {\n        this.mockMvc.perform(get(\"/notes/1\")) // (1)\n        .andExpect(status().isOk()) // (2)\n        .andDo(document(\"get-note\", // (3)\n          responseFields( ... ), // (4)\n          wiremockJson() // (5)\n        ));\n    }\n}\n```\n\nIn the example above we would test retrieving a given note via our REST API (1) and first validate the response (2) from the server.\nNext, we document the findings (3), generating request and response snippets, that we can include in our API documentation.\nThis also asserts that all fields within the communication (4) are documented.\nIf we, for example, introduce a new response field and forget to document it, this test would start failing.\nFinally, we save the input and output of the communication as WireMock stub (5).\n\nWhen you're at that point, it becomes trivial to publish the WireMock stubs into your artifact repository to share them with your consumers.\nOn the consumer side you need to pick up those stubs by including them on the test class-path and loading them into a locally running WireMock server.\nWe have a [dedicated Spring Boot Starter](https://github.com/ePages-de/restdocs-wiremock#configuring-your-test-to-use-the-wiremock-stubs) that simplifies this process.\nUltimately it boils down to one additional annotation on the test case.\n\n```java\n@RunWith(SpringJUnit4ClassRunner.class)\n@WireMockTest(stubPath = \"wiremock/notes-service\") // (1)\npublic class NoteServiceConsumerTest {\n\n  @Value(\"http://localhost:${wiremock.port}/\") // (2)\n  String wiremockUrl;\n\n}\n```\n\nIn the code example we annotate our consumer test with an annotation to start a WireMock server along with our test environment (1).\nBy default WireMock gets started on a random port, and we need to point our API consumer to it, for example by using a Spring expression (2).\nWireMock would happily serve all pre-recorded responses from the producer, given the same inputs and resource paths.\n\n**Happy microservice testing!**\n\n","source":"_posts/2016-07-14-wiremock.md","raw":"---\nlayout: post\ntitle: \"How to make microservice testing great again\"\ndate: \"2016-07-14 12:00:00\"\nimage: /blog-header/balls-of-mud.jpg\ncategories: tech-stories\nauthors: [\"Oliver T.\"]\n---\n\nThere is a lot of buzz about microservices these days, and here is our take on managing decoupled microservices, while still keeping confident in REST API compatibility.\n\nOne of the SOA missteps was trying to enforce a canonical domain model, which lead to bloated domain objects, that still would not fit all use cases and needed some sort of central management.\nJust try to come up with a common model of any real-world object and you'll know that this does not scale the more people are involved.\nIn a more abstract sense, it is our strive to perfection and the strive of perfect modelling of our problem domain that drove us into the wrong direction.\nDavid Dawson phrased this as \"Perfection and How It Ruined The World\" in his talk [\"Philosophical Architecture in Grails\"](https://www.youtube.com/watch?v=nx8XMY7evbA)\nHe also illustrated brilliantly why monoliths are doomed to fail ultimately.\n\nClient SDKs would be just another way of a shared domain model, and additionally would force the consumer to be using one specific client library.\nThis brings in tight coupling, which should be avoided, unless all consumers are under your own control.\nIn that case [gRPC](http://www.grpc.io/) might be an interesting alternative to using REST.\n\nSo, instead of managing a globally shared domain model, slowing down our development, we would rather let every service define its own view of the domain model in order to achieve loose coupling.\nCoupling, as Oliver Gierke correctly stated, is not binary.\n\n{% image blog/blog-wiremock-quote-gierke.jpg 100% left %}\n\n> \"If you don't want no coupling at all, don't let your systems\n> talk to each other\". [@olivergierke](https://twitter.com/olivergierke/status/733603527549931520)\n\nOf course you need communication between your services, and of course this introduces some coupling.\nBut, when opening an API to external consumers, it becomes a shared concern that you need to manage.\nAnd it implies, that the producer cannot introduce breaking changes without the possibility of breaking the consumer's API integration.\nIt actually doesn't matter if it is asynchronous communication or synchronous communication via REST.\nIn both cases you need to share a common API \"vocabulary\".\nAnd, you need to verify the contract defined within the API.\n\nThere are three ways of dealing with it.\nLet's start with the most obvious, but most brittle one: Integration testing.\nLet's test our microservices in integration, allowing us to verify the complete system behaviour from an outside point of view.\nThis of course requires all services and their infrastructure to be up and running simultaneously.\nThink of integration tests failing mysteriously every few weeks...\n\n{% image blog/blog-wiremock-quote-honestupdate.jpg 100% left %}\n\n> \"We replaced our monolithic app with micro services so that every outage\n> could be more like a murder mystery\" [@honest_update](https://twitter.com/honest_update/status/651897353889259520)\n\nA better way would be trying to test your client against actual responses of the server without the server having to be up and running.\nHow can you achieve this?\nInterestingly, the solution is not too hard.\nMartin Fowler calls this test method [\"Integration Contract Testing\"](http://martinfowler.com/bliki/IntegrationContractTest.html).\nFor integration contract testing the producer is replaced with a \"test double\" and pre-recorded responses would be replayed for the test scenario.\n\nIt is one level before [\"Consumer-driven contract testing\"](https://www.thoughtworks.com/radar/techniques/consumer-driven-contract-testing), where the consumer provides its test scenarios to the producer, which allows checking consumer compatibility even before introducing a potentially breaking API change.\nBut this has the down-side of off-loading all the testing effort to the producing side.\n\nMartin Fowler still sees the [*\"[..] danger that the test doubles get out of sync with the real supplier service\"*](http://martinfowler.com/bliki/IntegrationContractTest.html).\nHow can we avoid getting out of sync, ideally without extra effort?\nFirst of all, we shouldn't let the client define the test double's responses.\nAnd, we make sure the pre-recorded responses are shared artifacts, which get updated whenever we release a new version of the producer.\n\nThere is another artifact which should never become out of date with the implementation: Our API documentation.\nWhy not kill two birds with one stone and produce both human-readable REST documentation and API stubs directly as part of testing your producing service?\nFor doing this we came up with a small utility library, that we decided to [share as open source on GitHub](https://github.com/ePages-de/restdocs-wiremock).\nIt combines the goodness of [Spring REST Docs](http://projects.spring.io/spring-restdocs/) for producing documentation, and [WireMock](http://wiremock.org/), a tool for mocking a webserver during testing.\nIn the end, the WireMock stubs become just another part of our service documentation, which happen to be machine-readable.\n\nLet's look at some code.\nAssume you have a note-collection service written with Spring WebMVC, and you want to document your API with Spring REST Docs, which would look similar to this code:\n\n```java\n@RunWith(SpringJUnit4ClassRunner.class)\nclass ApiDocumentation {\n    // ... the usual test setup.\n    void should_retrieve_single_note() {\n        this.mockMvc.perform(get(\"/notes/1\")) // (1)\n        .andExpect(status().isOk()) // (2)\n        .andDo(document(\"get-note\", // (3)\n          responseFields( ... ), // (4)\n          wiremockJson() // (5)\n        ));\n    }\n}\n```\n\nIn the example above we would test retrieving a given note via our REST API (1) and first validate the response (2) from the server.\nNext, we document the findings (3), generating request and response snippets, that we can include in our API documentation.\nThis also asserts that all fields within the communication (4) are documented.\nIf we, for example, introduce a new response field and forget to document it, this test would start failing.\nFinally, we save the input and output of the communication as WireMock stub (5).\n\nWhen you're at that point, it becomes trivial to publish the WireMock stubs into your artifact repository to share them with your consumers.\nOn the consumer side you need to pick up those stubs by including them on the test class-path and loading them into a locally running WireMock server.\nWe have a [dedicated Spring Boot Starter](https://github.com/ePages-de/restdocs-wiremock#configuring-your-test-to-use-the-wiremock-stubs) that simplifies this process.\nUltimately it boils down to one additional annotation on the test case.\n\n```java\n@RunWith(SpringJUnit4ClassRunner.class)\n@WireMockTest(stubPath = \"wiremock/notes-service\") // (1)\npublic class NoteServiceConsumerTest {\n\n  @Value(\"http://localhost:${wiremock.port}/\") // (2)\n  String wiremockUrl;\n\n}\n```\n\nIn the code example we annotate our consumer test with an annotation to start a WireMock server along with our test environment (1).\nBy default WireMock gets started on a random port, and we need to point our API consumer to it, for example by using a Spring expression (2).\nWireMock would happily serve all pre-recorded responses from the producer, given the same inputs and resource paths.\n\n**Happy microservice testing!**\n\n","slug":"2016-07-14-wiremock","published":1,"updated":"2016-09-20T14:31:48.000Z","comments":1,"photos":[],"link":"","_id":"ciu6nuh9w002qhqyx6tmz9mg1","content":"<p>There is a lot of buzz about microservices these days, and here is our take on managing decoupled microservices, while still keeping confident in REST API compatibility.</p>\n<p>One of the SOA missteps was trying to enforce a canonical domain model, which lead to bloated domain objects, that still would not fit all use cases and needed some sort of central management.<br>Just try to come up with a common model of any real-world object and you’ll know that this does not scale the more people are involved.<br>In a more abstract sense, it is our strive to perfection and the strive of perfect modelling of our problem domain that drove us into the wrong direction.<br>David Dawson phrased this as “Perfection and How It Ruined The World” in his talk <a href=\"https://www.youtube.com/watch?v=nx8XMY7evbA\" target=\"_blank\" rel=\"external\">“Philosophical Architecture in Grails”</a><br>He also illustrated brilliantly why monoliths are doomed to fail ultimately.</p>\n<p>Client SDKs would be just another way of a shared domain model, and additionally would force the consumer to be using one specific client library.<br>This brings in tight coupling, which should be avoided, unless all consumers are under your own control.<br>In that case <a href=\"http://www.grpc.io/\" target=\"_blank\" rel=\"external\">gRPC</a> might be an interesting alternative to using REST.</p>\n<p>So, instead of managing a globally shared domain model, slowing down our development, we would rather let every service define its own view of the domain model in order to achieve loose coupling.<br>Coupling, as Oliver Gierke correctly stated, is not binary.</p>\n<img class=\"blog/blog-wiremock-quote-gierke.jpg 100% left\">\n<blockquote>\n<p>“If you don’t want no coupling at all, don’t let your systems<br>talk to each other”. <a href=\"https://twitter.com/olivergierke/status/733603527549931520\" target=\"_blank\" rel=\"external\">@olivergierke</a></p>\n</blockquote>\n<p>Of course you need communication between your services, and of course this introduces some coupling.<br>But, when opening an API to external consumers, it becomes a shared concern that you need to manage.<br>And it implies, that the producer cannot introduce breaking changes without the possibility of breaking the consumer’s API integration.<br>It actually doesn’t matter if it is asynchronous communication or synchronous communication via REST.<br>In both cases you need to share a common API “vocabulary”.<br>And, you need to verify the contract defined within the API.</p>\n<p>There are three ways of dealing with it.<br>Let’s start with the most obvious, but most brittle one: Integration testing.<br>Let’s test our microservices in integration, allowing us to verify the complete system behaviour from an outside point of view.<br>This of course requires all services and their infrastructure to be up and running simultaneously.<br>Think of integration tests failing mysteriously every few weeks…</p>\n<img class=\"blog/blog-wiremock-quote-honestupdate.jpg 100% left\">\n<blockquote>\n<p>“We replaced our monolithic app with micro services so that every outage<br>could be more like a murder mystery” <a href=\"https://twitter.com/honest_update/status/651897353889259520\" target=\"_blank\" rel=\"external\">@honest_update</a></p>\n</blockquote>\n<p>A better way would be trying to test your client against actual responses of the server without the server having to be up and running.<br>How can you achieve this?<br>Interestingly, the solution is not too hard.<br>Martin Fowler calls this test method <a href=\"http://martinfowler.com/bliki/IntegrationContractTest.html\" target=\"_blank\" rel=\"external\">“Integration Contract Testing”</a>.<br>For integration contract testing the producer is replaced with a “test double” and pre-recorded responses would be replayed for the test scenario.</p>\n<p>It is one level before <a href=\"https://www.thoughtworks.com/radar/techniques/consumer-driven-contract-testing\" target=\"_blank\" rel=\"external\">“Consumer-driven contract testing”</a>, where the consumer provides its test scenarios to the producer, which allows checking consumer compatibility even before introducing a potentially breaking API change.<br>But this has the down-side of off-loading all the testing effort to the producing side.</p>\n<p>Martin Fowler still sees the <a href=\"http://martinfowler.com/bliki/IntegrationContractTest.html\" target=\"_blank\" rel=\"external\"><em>“[..] danger that the test doubles get out of sync with the real supplier service”</em></a>.<br>How can we avoid getting out of sync, ideally without extra effort?<br>First of all, we shouldn’t let the client define the test double’s responses.<br>And, we make sure the pre-recorded responses are shared artifacts, which get updated whenever we release a new version of the producer.</p>\n<p>There is another artifact which should never become out of date with the implementation: Our API documentation.<br>Why not kill two birds with one stone and produce both human-readable REST documentation and API stubs directly as part of testing your producing service?<br>For doing this we came up with a small utility library, that we decided to <a href=\"https://github.com/ePages-de/restdocs-wiremock\" target=\"_blank\" rel=\"external\">share as open source on GitHub</a>.<br>It combines the goodness of <a href=\"http://projects.spring.io/spring-restdocs/\" target=\"_blank\" rel=\"external\">Spring REST Docs</a> for producing documentation, and <a href=\"http://wiremock.org/\" target=\"_blank\" rel=\"external\">WireMock</a>, a tool for mocking a webserver during testing.<br>In the end, the WireMock stubs become just another part of our service documentation, which happen to be machine-readable.</p>\n<p>Let’s look at some code.<br>Assume you have a note-collection service written with Spring WebMVC, and you want to document your API with Spring REST Docs, which would look similar to this code:</p>\n<figure class=\"highlight java\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div><div class=\"line\">7</div><div class=\"line\">8</div><div class=\"line\">9</div><div class=\"line\">10</div><div class=\"line\">11</div><div class=\"line\">12</div></pre></td><td class=\"code\"><pre><div class=\"line\"><span class=\"meta\">@RunWith</span>(SpringJUnit4ClassRunner.class)</div><div class=\"line\"><span class=\"class\"><span class=\"keyword\">class</span> <span class=\"title\">ApiDocumentation</span> </span>&#123;</div><div class=\"line\">    <span class=\"comment\">// ... the usual test setup.</span></div><div class=\"line\">    <span class=\"function\"><span class=\"keyword\">void</span> <span class=\"title\">should_retrieve_single_note</span><span class=\"params\">()</span> </span>&#123;</div><div class=\"line\">        <span class=\"keyword\">this</span>.mockMvc.perform(get(<span class=\"string\">\"/notes/1\"</span>)) <span class=\"comment\">// (1)</span></div><div class=\"line\">        .andExpect(status().isOk()) <span class=\"comment\">// (2)</span></div><div class=\"line\">        .andDo(document(<span class=\"string\">\"get-note\"</span>, <span class=\"comment\">// (3)</span></div><div class=\"line\">          responseFields( ... ), <span class=\"comment\">// (4)</span></div><div class=\"line\">          wiremockJson() <span class=\"comment\">// (5)</span></div><div class=\"line\">        ));</div><div class=\"line\">    &#125;</div><div class=\"line\">&#125;</div></pre></td></tr></table></figure>\n<p>In the example above we would test retrieving a given note via our REST API (1) and first validate the response (2) from the server.<br>Next, we document the findings (3), generating request and response snippets, that we can include in our API documentation.<br>This also asserts that all fields within the communication (4) are documented.<br>If we, for example, introduce a new response field and forget to document it, this test would start failing.<br>Finally, we save the input and output of the communication as WireMock stub (5).</p>\n<p>When you’re at that point, it becomes trivial to publish the WireMock stubs into your artifact repository to share them with your consumers.<br>On the consumer side you need to pick up those stubs by including them on the test class-path and loading them into a locally running WireMock server.<br>We have a <a href=\"https://github.com/ePages-de/restdocs-wiremock#configuring-your-test-to-use-the-wiremock-stubs\" target=\"_blank\" rel=\"external\">dedicated Spring Boot Starter</a> that simplifies this process.<br>Ultimately it boils down to one additional annotation on the test case.</p>\n<figure class=\"highlight java\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div><div class=\"line\">7</div><div class=\"line\">8</div></pre></td><td class=\"code\"><pre><div class=\"line\"><span class=\"meta\">@RunWith</span>(SpringJUnit4ClassRunner.class)</div><div class=\"line\"><span class=\"meta\">@WireMockTest</span>(stubPath = <span class=\"string\">\"wiremock/notes-service\"</span>) <span class=\"comment\">// (1)</span></div><div class=\"line\"><span class=\"keyword\">public</span> <span class=\"class\"><span class=\"keyword\">class</span> <span class=\"title\">NoteServiceConsumerTest</span> </span>&#123;</div><div class=\"line\"></div><div class=\"line\">  <span class=\"meta\">@Value</span>(<span class=\"string\">\"http://localhost:$&#123;wiremock.port&#125;/\"</span>) <span class=\"comment\">// (2)</span></div><div class=\"line\">  String wiremockUrl;</div><div class=\"line\"></div><div class=\"line\">&#125;</div></pre></td></tr></table></figure>\n<p>In the code example we annotate our consumer test with an annotation to start a WireMock server along with our test environment (1).<br>By default WireMock gets started on a random port, and we need to point our API consumer to it, for example by using a Spring expression (2).<br>WireMock would happily serve all pre-recorded responses from the producer, given the same inputs and resource paths.</p>\n<p><strong>Happy microservice testing!</strong></p>\n","excerpt":"","more":"<p>There is a lot of buzz about microservices these days, and here is our take on managing decoupled microservices, while still keeping confident in REST API compatibility.</p>\n<p>One of the SOA missteps was trying to enforce a canonical domain model, which lead to bloated domain objects, that still would not fit all use cases and needed some sort of central management.<br>Just try to come up with a common model of any real-world object and you’ll know that this does not scale the more people are involved.<br>In a more abstract sense, it is our strive to perfection and the strive of perfect modelling of our problem domain that drove us into the wrong direction.<br>David Dawson phrased this as “Perfection and How It Ruined The World” in his talk <a href=\"https://www.youtube.com/watch?v=nx8XMY7evbA\">“Philosophical Architecture in Grails”</a><br>He also illustrated brilliantly why monoliths are doomed to fail ultimately.</p>\n<p>Client SDKs would be just another way of a shared domain model, and additionally would force the consumer to be using one specific client library.<br>This brings in tight coupling, which should be avoided, unless all consumers are under your own control.<br>In that case <a href=\"http://www.grpc.io/\">gRPC</a> might be an interesting alternative to using REST.</p>\n<p>So, instead of managing a globally shared domain model, slowing down our development, we would rather let every service define its own view of the domain model in order to achieve loose coupling.<br>Coupling, as Oliver Gierke correctly stated, is not binary.</p>\n<img class=\"blog/blog-wiremock-quote-gierke.jpg 100% left\">\n<blockquote>\n<p>“If you don’t want no coupling at all, don’t let your systems<br>talk to each other”. <a href=\"https://twitter.com/olivergierke/status/733603527549931520\">@olivergierke</a></p>\n</blockquote>\n<p>Of course you need communication between your services, and of course this introduces some coupling.<br>But, when opening an API to external consumers, it becomes a shared concern that you need to manage.<br>And it implies, that the producer cannot introduce breaking changes without the possibility of breaking the consumer’s API integration.<br>It actually doesn’t matter if it is asynchronous communication or synchronous communication via REST.<br>In both cases you need to share a common API “vocabulary”.<br>And, you need to verify the contract defined within the API.</p>\n<p>There are three ways of dealing with it.<br>Let’s start with the most obvious, but most brittle one: Integration testing.<br>Let’s test our microservices in integration, allowing us to verify the complete system behaviour from an outside point of view.<br>This of course requires all services and their infrastructure to be up and running simultaneously.<br>Think of integration tests failing mysteriously every few weeks…</p>\n<img class=\"blog/blog-wiremock-quote-honestupdate.jpg 100% left\">\n<blockquote>\n<p>“We replaced our monolithic app with micro services so that every outage<br>could be more like a murder mystery” <a href=\"https://twitter.com/honest_update/status/651897353889259520\">@honest_update</a></p>\n</blockquote>\n<p>A better way would be trying to test your client against actual responses of the server without the server having to be up and running.<br>How can you achieve this?<br>Interestingly, the solution is not too hard.<br>Martin Fowler calls this test method <a href=\"http://martinfowler.com/bliki/IntegrationContractTest.html\">“Integration Contract Testing”</a>.<br>For integration contract testing the producer is replaced with a “test double” and pre-recorded responses would be replayed for the test scenario.</p>\n<p>It is one level before <a href=\"https://www.thoughtworks.com/radar/techniques/consumer-driven-contract-testing\">“Consumer-driven contract testing”</a>, where the consumer provides its test scenarios to the producer, which allows checking consumer compatibility even before introducing a potentially breaking API change.<br>But this has the down-side of off-loading all the testing effort to the producing side.</p>\n<p>Martin Fowler still sees the <a href=\"http://martinfowler.com/bliki/IntegrationContractTest.html\"><em>“[..] danger that the test doubles get out of sync with the real supplier service”</em></a>.<br>How can we avoid getting out of sync, ideally without extra effort?<br>First of all, we shouldn’t let the client define the test double’s responses.<br>And, we make sure the pre-recorded responses are shared artifacts, which get updated whenever we release a new version of the producer.</p>\n<p>There is another artifact which should never become out of date with the implementation: Our API documentation.<br>Why not kill two birds with one stone and produce both human-readable REST documentation and API stubs directly as part of testing your producing service?<br>For doing this we came up with a small utility library, that we decided to <a href=\"https://github.com/ePages-de/restdocs-wiremock\">share as open source on GitHub</a>.<br>It combines the goodness of <a href=\"http://projects.spring.io/spring-restdocs/\">Spring REST Docs</a> for producing documentation, and <a href=\"http://wiremock.org/\">WireMock</a>, a tool for mocking a webserver during testing.<br>In the end, the WireMock stubs become just another part of our service documentation, which happen to be machine-readable.</p>\n<p>Let’s look at some code.<br>Assume you have a note-collection service written with Spring WebMVC, and you want to document your API with Spring REST Docs, which would look similar to this code:</p>\n<figure class=\"highlight java\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div><div class=\"line\">7</div><div class=\"line\">8</div><div class=\"line\">9</div><div class=\"line\">10</div><div class=\"line\">11</div><div class=\"line\">12</div></pre></td><td class=\"code\"><pre><div class=\"line\"><span class=\"meta\">@RunWith</span>(SpringJUnit4ClassRunner.class)</div><div class=\"line\"><span class=\"class\"><span class=\"keyword\">class</span> <span class=\"title\">ApiDocumentation</span> </span>&#123;</div><div class=\"line\">    <span class=\"comment\">// ... the usual test setup.</span></div><div class=\"line\">    <span class=\"function\"><span class=\"keyword\">void</span> <span class=\"title\">should_retrieve_single_note</span><span class=\"params\">()</span> </span>&#123;</div><div class=\"line\">        <span class=\"keyword\">this</span>.mockMvc.perform(get(<span class=\"string\">\"/notes/1\"</span>)) <span class=\"comment\">// (1)</span></div><div class=\"line\">        .andExpect(status().isOk()) <span class=\"comment\">// (2)</span></div><div class=\"line\">        .andDo(document(<span class=\"string\">\"get-note\"</span>, <span class=\"comment\">// (3)</span></div><div class=\"line\">          responseFields( ... ), <span class=\"comment\">// (4)</span></div><div class=\"line\">          wiremockJson() <span class=\"comment\">// (5)</span></div><div class=\"line\">        ));</div><div class=\"line\">    &#125;</div><div class=\"line\">&#125;</div></pre></td></tr></table></figure>\n<p>In the example above we would test retrieving a given note via our REST API (1) and first validate the response (2) from the server.<br>Next, we document the findings (3), generating request and response snippets, that we can include in our API documentation.<br>This also asserts that all fields within the communication (4) are documented.<br>If we, for example, introduce a new response field and forget to document it, this test would start failing.<br>Finally, we save the input and output of the communication as WireMock stub (5).</p>\n<p>When you’re at that point, it becomes trivial to publish the WireMock stubs into your artifact repository to share them with your consumers.<br>On the consumer side you need to pick up those stubs by including them on the test class-path and loading them into a locally running WireMock server.<br>We have a <a href=\"https://github.com/ePages-de/restdocs-wiremock#configuring-your-test-to-use-the-wiremock-stubs\">dedicated Spring Boot Starter</a> that simplifies this process.<br>Ultimately it boils down to one additional annotation on the test case.</p>\n<figure class=\"highlight java\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div><div class=\"line\">7</div><div class=\"line\">8</div></pre></td><td class=\"code\"><pre><div class=\"line\"><span class=\"meta\">@RunWith</span>(SpringJUnit4ClassRunner.class)</div><div class=\"line\"><span class=\"meta\">@WireMockTest</span>(stubPath = <span class=\"string\">\"wiremock/notes-service\"</span>) <span class=\"comment\">// (1)</span></div><div class=\"line\"><span class=\"keyword\">public</span> <span class=\"class\"><span class=\"keyword\">class</span> <span class=\"title\">NoteServiceConsumerTest</span> </span>&#123;</div><div class=\"line\"></div><div class=\"line\">  <span class=\"meta\">@Value</span>(<span class=\"string\">\"http://localhost:$&#123;wiremock.port&#125;/\"</span>) <span class=\"comment\">// (2)</span></div><div class=\"line\">  String wiremockUrl;</div><div class=\"line\"></div><div class=\"line\">&#125;</div></pre></td></tr></table></figure>\n<p>In the code example we annotate our consumer test with an annotation to start a WireMock server along with our test environment (1).<br>By default WireMock gets started on a random port, and we need to point our API consumer to it, for example by using a Spring expression (2).<br>WireMock would happily serve all pre-recorded responses from the producer, given the same inputs and resource paths.</p>\n<p><strong>Happy microservice testing!</strong></p>\n"},{"layout":"post","title":"Review of XConf 2016 Hamburg","date":"2016-07-25T22:00:00.000Z","image":"blog-header/lego.jpg","authors":["Oleksandr","Renato"],"_content":"\nIt was not long ago, in one of those few sunny days in Hamburg, that we had the opportunity to visit the\n[XConf](https://info.thoughtworks.com/Xconf-hamburg-2016.html). At ePages, developers have a great support of the company in terms of further education.\nThe XConf took place on the 12th of July in a cozy place called the [Betahaus](http://hamburg.betahaus.de/) in Hamburg.\nThis one-day conference covered a broad range of technology topics.\nThanks to the great job of [ThoughtWorks](https://www.thoughtworks.com/) Renato and I had a blast.\n\n## Keynote\n\n[James Lewis](https://twitter.com/boicy) presented the keynote talking about Lean Software Engineering, [LEGO](http://lego.com), and [Star Wars](http://www.starwars.com/).\nSometimes, when people present processes, they make their presentation too abstract, and might lose the audience on the way.\n\nJames presented the keynote in form of a story. With help of [LEGO](http://lego.com), he and his crew built a Millennium Falcon.\nAt the presentation, he described processes problems that appear during the project construction, and discussed tools and ways of solving them.\nWith such presentation techniques he was able to explain several concepts including cycle-time and throughput, as well as continuous process improvement to people who are not familiar with the topic.\n\n## Presentations\n\nEvery participant could choose one of the two tracks running in parallel.\nWe decided to visit Track 1 as it included lots of topics where we could get more insights about how other companies deal with specific technologies.\n\nContent of Track 1:\n\n - Containerizing a web shop - Building the microservice platform for otto.de\n - Implementing Infrastructure as Code\n - A High-Performance Solution to Microservice UI Composition\n - Serverless Architecture - Tales from a world without servers\n - Alert overload: How to adopt a MS architecture without being...\n\n## Impression\n\nIn general, all presentations were really nice: well-structured content, experienced speakers, and interesting topics.\nOne good thing I was able to take away with me, was to see that many companies use and apply the same techniques and tools, that we also use at ePages.\n\nIt was especially interesting to hear about the experience of introducing microservice architecture on such giant environment like [otto.de](http://otto.de)\nIt is good to know that one of the leaders of the German e-commerce market follows the same principles as we are following in our team.\n\n{% image blog/blog-twitter-xconf-3.png %}\n\nAnother interesting topic was the infrastructure.\nAt ePages, we have a quite sophisticated environmental structure.\nTo manage this, we are already applying many techniques and tools described by  [Kief Morris](https://twitter.com/kief) in his presentation.\n\n{% image blog/blog-twitter-xconf-4.png %}\n\nIt was a nice day at the conference with a lot of input that can make our work more efficient.\n","source":"_posts/2016-07-26-xconf-2016.md","raw":"---\nlayout: post\ntitle: \"Review of XConf 2016 Hamburg\"\ndate: \"2016-07-26 00:00:00\"\nimage: blog-header/lego.jpg\ncategories: events\nauthors: [\"Oleksandr\", \"Renato\"]\n---\n\nIt was not long ago, in one of those few sunny days in Hamburg, that we had the opportunity to visit the\n[XConf](https://info.thoughtworks.com/Xconf-hamburg-2016.html). At ePages, developers have a great support of the company in terms of further education.\nThe XConf took place on the 12th of July in a cozy place called the [Betahaus](http://hamburg.betahaus.de/) in Hamburg.\nThis one-day conference covered a broad range of technology topics.\nThanks to the great job of [ThoughtWorks](https://www.thoughtworks.com/) Renato and I had a blast.\n\n## Keynote\n\n[James Lewis](https://twitter.com/boicy) presented the keynote talking about Lean Software Engineering, [LEGO](http://lego.com), and [Star Wars](http://www.starwars.com/).\nSometimes, when people present processes, they make their presentation too abstract, and might lose the audience on the way.\n\nJames presented the keynote in form of a story. With help of [LEGO](http://lego.com), he and his crew built a Millennium Falcon.\nAt the presentation, he described processes problems that appear during the project construction, and discussed tools and ways of solving them.\nWith such presentation techniques he was able to explain several concepts including cycle-time and throughput, as well as continuous process improvement to people who are not familiar with the topic.\n\n## Presentations\n\nEvery participant could choose one of the two tracks running in parallel.\nWe decided to visit Track 1 as it included lots of topics where we could get more insights about how other companies deal with specific technologies.\n\nContent of Track 1:\n\n - Containerizing a web shop - Building the microservice platform for otto.de\n - Implementing Infrastructure as Code\n - A High-Performance Solution to Microservice UI Composition\n - Serverless Architecture - Tales from a world without servers\n - Alert overload: How to adopt a MS architecture without being...\n\n## Impression\n\nIn general, all presentations were really nice: well-structured content, experienced speakers, and interesting topics.\nOne good thing I was able to take away with me, was to see that many companies use and apply the same techniques and tools, that we also use at ePages.\n\nIt was especially interesting to hear about the experience of introducing microservice architecture on such giant environment like [otto.de](http://otto.de)\nIt is good to know that one of the leaders of the German e-commerce market follows the same principles as we are following in our team.\n\n{% image blog/blog-twitter-xconf-3.png %}\n\nAnother interesting topic was the infrastructure.\nAt ePages, we have a quite sophisticated environmental structure.\nTo manage this, we are already applying many techniques and tools described by  [Kief Morris](https://twitter.com/kief) in his presentation.\n\n{% image blog/blog-twitter-xconf-4.png %}\n\nIt was a nice day at the conference with a lot of input that can make our work more efficient.\n","slug":"2016-07-26-xconf-2016","published":1,"updated":"2016-09-20T14:31:48.000Z","comments":1,"photos":[],"link":"","_id":"ciu6nuh9y002shqyxtsi6hqem","content":"<p>It was not long ago, in one of those few sunny days in Hamburg, that we had the opportunity to visit the<br><a href=\"https://info.thoughtworks.com/Xconf-hamburg-2016.html\" target=\"_blank\" rel=\"external\">XConf</a>. At ePages, developers have a great support of the company in terms of further education.<br>The XConf took place on the 12th of July in a cozy place called the <a href=\"http://hamburg.betahaus.de/\" target=\"_blank\" rel=\"external\">Betahaus</a> in Hamburg.<br>This one-day conference covered a broad range of technology topics.<br>Thanks to the great job of <a href=\"https://www.thoughtworks.com/\" target=\"_blank\" rel=\"external\">ThoughtWorks</a> Renato and I had a blast.</p>\n<h2 id=\"Keynote\"><a href=\"#Keynote\" class=\"headerlink\" title=\"Keynote\"></a>Keynote</h2><p><a href=\"https://twitter.com/boicy\" target=\"_blank\" rel=\"external\">James Lewis</a> presented the keynote talking about Lean Software Engineering, <a href=\"http://lego.com\" target=\"_blank\" rel=\"external\">LEGO</a>, and <a href=\"http://www.starwars.com/\" target=\"_blank\" rel=\"external\">Star Wars</a>.<br>Sometimes, when people present processes, they make their presentation too abstract, and might lose the audience on the way.</p>\n<p>James presented the keynote in form of a story. With help of <a href=\"http://lego.com\" target=\"_blank\" rel=\"external\">LEGO</a>, he and his crew built a Millennium Falcon.<br>At the presentation, he described processes problems that appear during the project construction, and discussed tools and ways of solving them.<br>With such presentation techniques he was able to explain several concepts including cycle-time and throughput, as well as continuous process improvement to people who are not familiar with the topic.</p>\n<h2 id=\"Presentations\"><a href=\"#Presentations\" class=\"headerlink\" title=\"Presentations\"></a>Presentations</h2><p>Every participant could choose one of the two tracks running in parallel.<br>We decided to visit Track 1 as it included lots of topics where we could get more insights about how other companies deal with specific technologies.</p>\n<p>Content of Track 1:</p>\n<ul>\n<li>Containerizing a web shop - Building the microservice platform for otto.de</li>\n<li>Implementing Infrastructure as Code</li>\n<li>A High-Performance Solution to Microservice UI Composition</li>\n<li>Serverless Architecture - Tales from a world without servers</li>\n<li>Alert overload: How to adopt a MS architecture without being…</li>\n</ul>\n<h2 id=\"Impression\"><a href=\"#Impression\" class=\"headerlink\" title=\"Impression\"></a>Impression</h2><p>In general, all presentations were really nice: well-structured content, experienced speakers, and interesting topics.<br>One good thing I was able to take away with me, was to see that many companies use and apply the same techniques and tools, that we also use at ePages.</p>\n<p>It was especially interesting to hear about the experience of introducing microservice architecture on such giant environment like <a href=\"http://otto.de\" target=\"_blank\" rel=\"external\">otto.de</a><br>It is good to know that one of the leaders of the German e-commerce market follows the same principles as we are following in our team.</p>\n<img class=\"blog/blog-twitter-xconf-3.png\">\n<p>Another interesting topic was the infrastructure.<br>At ePages, we have a quite sophisticated environmental structure.<br>To manage this, we are already applying many techniques and tools described by  <a href=\"https://twitter.com/kief\" target=\"_blank\" rel=\"external\">Kief Morris</a> in his presentation.</p>\n<img class=\"blog/blog-twitter-xconf-4.png\">\n<p>It was a nice day at the conference with a lot of input that can make our work more efficient.</p>\n","excerpt":"","more":"<p>It was not long ago, in one of those few sunny days in Hamburg, that we had the opportunity to visit the<br><a href=\"https://info.thoughtworks.com/Xconf-hamburg-2016.html\">XConf</a>. At ePages, developers have a great support of the company in terms of further education.<br>The XConf took place on the 12th of July in a cozy place called the <a href=\"http://hamburg.betahaus.de/\">Betahaus</a> in Hamburg.<br>This one-day conference covered a broad range of technology topics.<br>Thanks to the great job of <a href=\"https://www.thoughtworks.com/\">ThoughtWorks</a> Renato and I had a blast.</p>\n<h2 id=\"Keynote\"><a href=\"#Keynote\" class=\"headerlink\" title=\"Keynote\"></a>Keynote</h2><p><a href=\"https://twitter.com/boicy\">James Lewis</a> presented the keynote talking about Lean Software Engineering, <a href=\"http://lego.com\">LEGO</a>, and <a href=\"http://www.starwars.com/\">Star Wars</a>.<br>Sometimes, when people present processes, they make their presentation too abstract, and might lose the audience on the way.</p>\n<p>James presented the keynote in form of a story. With help of <a href=\"http://lego.com\">LEGO</a>, he and his crew built a Millennium Falcon.<br>At the presentation, he described processes problems that appear during the project construction, and discussed tools and ways of solving them.<br>With such presentation techniques he was able to explain several concepts including cycle-time and throughput, as well as continuous process improvement to people who are not familiar with the topic.</p>\n<h2 id=\"Presentations\"><a href=\"#Presentations\" class=\"headerlink\" title=\"Presentations\"></a>Presentations</h2><p>Every participant could choose one of the two tracks running in parallel.<br>We decided to visit Track 1 as it included lots of topics where we could get more insights about how other companies deal with specific technologies.</p>\n<p>Content of Track 1:</p>\n<ul>\n<li>Containerizing a web shop - Building the microservice platform for otto.de</li>\n<li>Implementing Infrastructure as Code</li>\n<li>A High-Performance Solution to Microservice UI Composition</li>\n<li>Serverless Architecture - Tales from a world without servers</li>\n<li>Alert overload: How to adopt a MS architecture without being…</li>\n</ul>\n<h2 id=\"Impression\"><a href=\"#Impression\" class=\"headerlink\" title=\"Impression\"></a>Impression</h2><p>In general, all presentations were really nice: well-structured content, experienced speakers, and interesting topics.<br>One good thing I was able to take away with me, was to see that many companies use and apply the same techniques and tools, that we also use at ePages.</p>\n<p>It was especially interesting to hear about the experience of introducing microservice architecture on such giant environment like <a href=\"http://otto.de\">otto.de</a><br>It is good to know that one of the leaders of the German e-commerce market follows the same principles as we are following in our team.</p>\n<img class=\"blog/blog-twitter-xconf-3.png\">\n<p>Another interesting topic was the infrastructure.<br>At ePages, we have a quite sophisticated environmental structure.<br>To manage this, we are already applying many techniques and tools described by  <a href=\"https://twitter.com/kief\">Kief Morris</a> in his presentation.</p>\n<img class=\"blog/blog-twitter-xconf-4.png\">\n<p>It was a nice day at the conference with a lot of input that can make our work more efficient.</p>\n"},{"layout":"post","title":"5 steps to make you feel comfortable in your new job","date":"2016-08-04T05:00:28.000Z","image":"blog-header/onboarding.jpg","authors":["Birgit, Leana","Serena"],"_content":"\nYou've spent days and weeks perfecting your resume, preparing for interviews, and making a good impression at personal meetings.\nNow that the application process is over, and you've landed the job, it's definitely time to throw confetti.\nBut when the first working day at the new company approaches, you wonder what your first days, weeks, and months will be like.\nBeing nicely welcomed and appreciated ensures that we fondly remember our first working day.\n\nHere's what we do at ePages to make you feel comfortable in your new job:\n\n## 1. Coffee and croissants\n\nYour first working day starts with a breakfast.\nYou'll receive a little welcome present, as well as a USB stick with all required company-related information.\n\nIn a relaxed atmosphere, we introduce ourselves and break the ice with a quick Q&A, for example:\n\n* What did you do before working at ePages?\n* What's your native language?\n* What are your favorite movie and food?\n* What was the last concert you attended?\n\nHR will give you a comprehensive introduction about ePages and how we do things here.\nYou'll receive a product overview, and a short demo of our software.\nOur scrum masters explain our workflows and team structures.\n\n{% image blog/blog-onboarding.jpg %}\n\nYou will be assigned a buddy, who will give you a helping hand during your first days and months at ePages.\nThey will go to lunch with you, answer organizational questions, or anything that you're not comfortable asking your team or supervisor.\nWe will take you for a tour around our offices to introduce you to your team members and other colleagues from various departments.\n\n## 2. \"Thank god it's Friday\"-talk\n\nAt the end of the first week, you'll have a relaxed meeting with your manager.\nYou will have the chance to clarify open questions and give feedback.\nYour manager will reassure that you settle in well and have everything you need for your work.\nOf course, we're also interested in your first days experience working together with your team.\n\n## 3. HR coffee\n\nAfter your first month with us, HR will invite you for a coffee talk, which is a good opportunity to tackle questions like these:\n\n* Does the job meet your expectations?\n* Do you feel comfy and appreciated?\n* Do you have any open questions, or need advice or support?\n* Is there anything that can be improved?\n\n## 4. 100 days feedback\n\nWell-done!\nYou've passed half of your probation which is an important milestone.\nOur HR and your manager will sit together with you for a detailed feedback session with the help of a feedback form.\nYou will self-assess your performance, and possibly identify areas for improvement.\nHR and your manager will do the same and you'll then discuss the results together.\n\n## 5. Final review\n\nYou're about to complete your probation!\nOne month before your probation ends, we'll again review your development.\nAt this point, we will have a look at the results from the 100 days feedback as well as your development within the past months.\nSubsequently, we will agree on your further career at ePages\n\nNow you have an overview of what will happen during the first months with us.\nOur focus is to make you feel welcome and comfortable, and we want you to be part of our team, organization, and culture as soon as possible.\n","source":"_posts/2016-08-04-dev-onboarding.md","raw":"---\nlayout: post\ntitle: \"5 steps to make you feel comfortable in your new job\"\ndate: \"2016-08-04 07:00:28\"\nimage: blog-header/onboarding.jpg\ncategories: working-at-epages\nauthors: [\"Birgit, Leana\", \"Serena\"]\n---\n\nYou've spent days and weeks perfecting your resume, preparing for interviews, and making a good impression at personal meetings.\nNow that the application process is over, and you've landed the job, it's definitely time to throw confetti.\nBut when the first working day at the new company approaches, you wonder what your first days, weeks, and months will be like.\nBeing nicely welcomed and appreciated ensures that we fondly remember our first working day.\n\nHere's what we do at ePages to make you feel comfortable in your new job:\n\n## 1. Coffee and croissants\n\nYour first working day starts with a breakfast.\nYou'll receive a little welcome present, as well as a USB stick with all required company-related information.\n\nIn a relaxed atmosphere, we introduce ourselves and break the ice with a quick Q&A, for example:\n\n* What did you do before working at ePages?\n* What's your native language?\n* What are your favorite movie and food?\n* What was the last concert you attended?\n\nHR will give you a comprehensive introduction about ePages and how we do things here.\nYou'll receive a product overview, and a short demo of our software.\nOur scrum masters explain our workflows and team structures.\n\n{% image blog/blog-onboarding.jpg %}\n\nYou will be assigned a buddy, who will give you a helping hand during your first days and months at ePages.\nThey will go to lunch with you, answer organizational questions, or anything that you're not comfortable asking your team or supervisor.\nWe will take you for a tour around our offices to introduce you to your team members and other colleagues from various departments.\n\n## 2. \"Thank god it's Friday\"-talk\n\nAt the end of the first week, you'll have a relaxed meeting with your manager.\nYou will have the chance to clarify open questions and give feedback.\nYour manager will reassure that you settle in well and have everything you need for your work.\nOf course, we're also interested in your first days experience working together with your team.\n\n## 3. HR coffee\n\nAfter your first month with us, HR will invite you for a coffee talk, which is a good opportunity to tackle questions like these:\n\n* Does the job meet your expectations?\n* Do you feel comfy and appreciated?\n* Do you have any open questions, or need advice or support?\n* Is there anything that can be improved?\n\n## 4. 100 days feedback\n\nWell-done!\nYou've passed half of your probation which is an important milestone.\nOur HR and your manager will sit together with you for a detailed feedback session with the help of a feedback form.\nYou will self-assess your performance, and possibly identify areas for improvement.\nHR and your manager will do the same and you'll then discuss the results together.\n\n## 5. Final review\n\nYou're about to complete your probation!\nOne month before your probation ends, we'll again review your development.\nAt this point, we will have a look at the results from the 100 days feedback as well as your development within the past months.\nSubsequently, we will agree on your further career at ePages\n\nNow you have an overview of what will happen during the first months with us.\nOur focus is to make you feel welcome and comfortable, and we want you to be part of our team, organization, and culture as soon as possible.\n","slug":"2016-08-04-dev-onboarding","published":1,"updated":"2016-09-20T14:31:48.000Z","comments":1,"photos":[],"link":"","_id":"ciu6nuh9z002uhqyxenholys8","content":"<p>You’ve spent days and weeks perfecting your resume, preparing for interviews, and making a good impression at personal meetings.<br>Now that the application process is over, and you’ve landed the job, it’s definitely time to throw confetti.<br>But when the first working day at the new company approaches, you wonder what your first days, weeks, and months will be like.<br>Being nicely welcomed and appreciated ensures that we fondly remember our first working day.</p>\n<p>Here’s what we do at ePages to make you feel comfortable in your new job:</p>\n<h2 id=\"1-Coffee-and-croissants\"><a href=\"#1-Coffee-and-croissants\" class=\"headerlink\" title=\"1. Coffee and croissants\"></a>1. Coffee and croissants</h2><p>Your first working day starts with a breakfast.<br>You’ll receive a little welcome present, as well as a USB stick with all required company-related information.</p>\n<p>In a relaxed atmosphere, we introduce ourselves and break the ice with a quick Q&amp;A, for example:</p>\n<ul>\n<li>What did you do before working at ePages?</li>\n<li>What’s your native language?</li>\n<li>What are your favorite movie and food?</li>\n<li>What was the last concert you attended?</li>\n</ul>\n<p>HR will give you a comprehensive introduction about ePages and how we do things here.<br>You’ll receive a product overview, and a short demo of our software.<br>Our scrum masters explain our workflows and team structures.</p>\n<img class=\"blog/blog-onboarding.jpg\">\n<p>You will be assigned a buddy, who will give you a helping hand during your first days and months at ePages.<br>They will go to lunch with you, answer organizational questions, or anything that you’re not comfortable asking your team or supervisor.<br>We will take you for a tour around our offices to introduce you to your team members and other colleagues from various departments.</p>\n<h2 id=\"2-“Thank-god-it’s-Friday”-talk\"><a href=\"#2-“Thank-god-it’s-Friday”-talk\" class=\"headerlink\" title=\"2. “Thank god it’s Friday”-talk\"></a>2. “Thank god it’s Friday”-talk</h2><p>At the end of the first week, you’ll have a relaxed meeting with your manager.<br>You will have the chance to clarify open questions and give feedback.<br>Your manager will reassure that you settle in well and have everything you need for your work.<br>Of course, we’re also interested in your first days experience working together with your team.</p>\n<h2 id=\"3-HR-coffee\"><a href=\"#3-HR-coffee\" class=\"headerlink\" title=\"3. HR coffee\"></a>3. HR coffee</h2><p>After your first month with us, HR will invite you for a coffee talk, which is a good opportunity to tackle questions like these:</p>\n<ul>\n<li>Does the job meet your expectations?</li>\n<li>Do you feel comfy and appreciated?</li>\n<li>Do you have any open questions, or need advice or support?</li>\n<li>Is there anything that can be improved?</li>\n</ul>\n<h2 id=\"4-100-days-feedback\"><a href=\"#4-100-days-feedback\" class=\"headerlink\" title=\"4. 100 days feedback\"></a>4. 100 days feedback</h2><p>Well-done!<br>You’ve passed half of your probation which is an important milestone.<br>Our HR and your manager will sit together with you for a detailed feedback session with the help of a feedback form.<br>You will self-assess your performance, and possibly identify areas for improvement.<br>HR and your manager will do the same and you’ll then discuss the results together.</p>\n<h2 id=\"5-Final-review\"><a href=\"#5-Final-review\" class=\"headerlink\" title=\"5. Final review\"></a>5. Final review</h2><p>You’re about to complete your probation!<br>One month before your probation ends, we’ll again review your development.<br>At this point, we will have a look at the results from the 100 days feedback as well as your development within the past months.<br>Subsequently, we will agree on your further career at ePages</p>\n<p>Now you have an overview of what will happen during the first months with us.<br>Our focus is to make you feel welcome and comfortable, and we want you to be part of our team, organization, and culture as soon as possible.</p>\n","excerpt":"","more":"<p>You’ve spent days and weeks perfecting your resume, preparing for interviews, and making a good impression at personal meetings.<br>Now that the application process is over, and you’ve landed the job, it’s definitely time to throw confetti.<br>But when the first working day at the new company approaches, you wonder what your first days, weeks, and months will be like.<br>Being nicely welcomed and appreciated ensures that we fondly remember our first working day.</p>\n<p>Here’s what we do at ePages to make you feel comfortable in your new job:</p>\n<h2 id=\"1-Coffee-and-croissants\"><a href=\"#1-Coffee-and-croissants\" class=\"headerlink\" title=\"1. Coffee and croissants\"></a>1. Coffee and croissants</h2><p>Your first working day starts with a breakfast.<br>You’ll receive a little welcome present, as well as a USB stick with all required company-related information.</p>\n<p>In a relaxed atmosphere, we introduce ourselves and break the ice with a quick Q&amp;A, for example:</p>\n<ul>\n<li>What did you do before working at ePages?</li>\n<li>What’s your native language?</li>\n<li>What are your favorite movie and food?</li>\n<li>What was the last concert you attended?</li>\n</ul>\n<p>HR will give you a comprehensive introduction about ePages and how we do things here.<br>You’ll receive a product overview, and a short demo of our software.<br>Our scrum masters explain our workflows and team structures.</p>\n<img class=\"blog/blog-onboarding.jpg\">\n<p>You will be assigned a buddy, who will give you a helping hand during your first days and months at ePages.<br>They will go to lunch with you, answer organizational questions, or anything that you’re not comfortable asking your team or supervisor.<br>We will take you for a tour around our offices to introduce you to your team members and other colleagues from various departments.</p>\n<h2 id=\"2-“Thank-god-it’s-Friday”-talk\"><a href=\"#2-“Thank-god-it’s-Friday”-talk\" class=\"headerlink\" title=\"2. “Thank god it’s Friday”-talk\"></a>2. “Thank god it’s Friday”-talk</h2><p>At the end of the first week, you’ll have a relaxed meeting with your manager.<br>You will have the chance to clarify open questions and give feedback.<br>Your manager will reassure that you settle in well and have everything you need for your work.<br>Of course, we’re also interested in your first days experience working together with your team.</p>\n<h2 id=\"3-HR-coffee\"><a href=\"#3-HR-coffee\" class=\"headerlink\" title=\"3. HR coffee\"></a>3. HR coffee</h2><p>After your first month with us, HR will invite you for a coffee talk, which is a good opportunity to tackle questions like these:</p>\n<ul>\n<li>Does the job meet your expectations?</li>\n<li>Do you feel comfy and appreciated?</li>\n<li>Do you have any open questions, or need advice or support?</li>\n<li>Is there anything that can be improved?</li>\n</ul>\n<h2 id=\"4-100-days-feedback\"><a href=\"#4-100-days-feedback\" class=\"headerlink\" title=\"4. 100 days feedback\"></a>4. 100 days feedback</h2><p>Well-done!<br>You’ve passed half of your probation which is an important milestone.<br>Our HR and your manager will sit together with you for a detailed feedback session with the help of a feedback form.<br>You will self-assess your performance, and possibly identify areas for improvement.<br>HR and your manager will do the same and you’ll then discuss the results together.</p>\n<h2 id=\"5-Final-review\"><a href=\"#5-Final-review\" class=\"headerlink\" title=\"5. Final review\"></a>5. Final review</h2><p>You’re about to complete your probation!<br>One month before your probation ends, we’ll again review your development.<br>At this point, we will have a look at the results from the 100 days feedback as well as your development within the past months.<br>Subsequently, we will agree on your further career at ePages</p>\n<p>Now you have an overview of what will happen during the first months with us.<br>Our focus is to make you feel welcome and comfortable, and we want you to be part of our team, organization, and culture as soon as possible.</p>\n"},{"layout":"post","title":"Elastic Meetup at ePages","date":"2016-07-08T09:11:11.000Z","image":"blog-header/elastic-meetup.jpg","authors":["Christian K., Jens","Benjamin"],"_content":"\nOn the 30th of June the third [jenadevs](http://www.meetup.com/jenadevs/events/230859746) meetup took place at the ePages office in Jena.\nA video conference with our office in Hamburg was also established to give more people the option to attend remotely.\n\n{% image blog/blog-elastic-meetup-1.jpg %}\n\nApproximately 30 participants were interested in the topic and showed up at 6 pm.\nAfter a short general introduction the presentations started:\n\n### Elastic Stack 5.0\n\n[Pere Urbón-Bayes](http://www.purbon.com/) ([elastic](https://www.elastic.co)) walked through the new features of the Elastic 5 stack and explained for every component what's new and what changed.\nFurther information on this topic: [elastic v5](https://www.elastic.co/de/v5).\n\n{% image blog/blog-elastic-meetup-2.jpg %}\n\n### Visualisation and analysis of Open Data\n\n[Achim Friedland](https://twitter.com/ahzf) ([OK Lab Jena](http://codefor.de/jena/)) presented the [CODE for Germany](http://codefor.de/) project and how it uses open data to visualise and solve problems.\nHe showed some examples of visualised Open Data.\n\n### Elastic Stack @ePages\n\n[Christian Köhler](https://twitter.com/epagesdevs) ([ePages](http://www.epages.com/)) presented the current Elastic stack at ePages.\nHe explained the approach and the lessons learned to build the centralised logging framework.\n\n### Regression Test Analysis with Elasticsearch in a Delivery Pipeline\n\n[Benjamin Nothdurft](https://twitter.com/dataduke) and [Bastian Klein](https://twitter.com/Dastianoro) ([epages](http://www.epages.com/)) presented a short version of their implementation of the ElasticSearch, Logstash and Docker integration for aggregation and collection of integration test results from various systems in the delivery pipeline ([slides](https://speakerdeck.com/dataduke/automated-test-evaluation-short-version)).\n\n### Lightning Talk: How Elasticsearch was used in former projects\n\n[Jens Fischer](https://twitter.com/jensfischerhh) ([ePages](http://www.epages.com/)) talked about [deploying the Elastic stack](https://slidr.io/jensfischerhh/deploying-the-elastic-stack) in one of his former projects and the adoption of the new technology.\n\nIn the end delivering all this content took about one hour longer than planned,\nbut even the UEFA EM 2016 match Poland vs. Portugal was gladly skipped by all participants.\n\nAfter the presentations we had some nice discussions about the usage of Elasticsearch with some pizza and beer.\n","source":"_posts/2016-07-07-elastic-meetup.md","raw":"---\nlayout: post\ntitle: \"Elastic Meetup at ePages\"\ndate: \"2016-07-08 11:11:11\"\nimage: blog-header/elastic-meetup.jpg\ncategories: events\nauthors: [\"Christian K., Jens\", \"Benjamin\"]\n---\n\nOn the 30th of June the third [jenadevs](http://www.meetup.com/jenadevs/events/230859746) meetup took place at the ePages office in Jena.\nA video conference with our office in Hamburg was also established to give more people the option to attend remotely.\n\n{% image blog/blog-elastic-meetup-1.jpg %}\n\nApproximately 30 participants were interested in the topic and showed up at 6 pm.\nAfter a short general introduction the presentations started:\n\n### Elastic Stack 5.0\n\n[Pere Urbón-Bayes](http://www.purbon.com/) ([elastic](https://www.elastic.co)) walked through the new features of the Elastic 5 stack and explained for every component what's new and what changed.\nFurther information on this topic: [elastic v5](https://www.elastic.co/de/v5).\n\n{% image blog/blog-elastic-meetup-2.jpg %}\n\n### Visualisation and analysis of Open Data\n\n[Achim Friedland](https://twitter.com/ahzf) ([OK Lab Jena](http://codefor.de/jena/)) presented the [CODE for Germany](http://codefor.de/) project and how it uses open data to visualise and solve problems.\nHe showed some examples of visualised Open Data.\n\n### Elastic Stack @ePages\n\n[Christian Köhler](https://twitter.com/epagesdevs) ([ePages](http://www.epages.com/)) presented the current Elastic stack at ePages.\nHe explained the approach and the lessons learned to build the centralised logging framework.\n\n### Regression Test Analysis with Elasticsearch in a Delivery Pipeline\n\n[Benjamin Nothdurft](https://twitter.com/dataduke) and [Bastian Klein](https://twitter.com/Dastianoro) ([epages](http://www.epages.com/)) presented a short version of their implementation of the ElasticSearch, Logstash and Docker integration for aggregation and collection of integration test results from various systems in the delivery pipeline ([slides](https://speakerdeck.com/dataduke/automated-test-evaluation-short-version)).\n\n### Lightning Talk: How Elasticsearch was used in former projects\n\n[Jens Fischer](https://twitter.com/jensfischerhh) ([ePages](http://www.epages.com/)) talked about [deploying the Elastic stack](https://slidr.io/jensfischerhh/deploying-the-elastic-stack) in one of his former projects and the adoption of the new technology.\n\nIn the end delivering all this content took about one hour longer than planned,\nbut even the UEFA EM 2016 match Poland vs. Portugal was gladly skipped by all participants.\n\nAfter the presentations we had some nice discussions about the usage of Elasticsearch with some pizza and beer.\n","slug":"2016-07-07-elastic-meetup","published":1,"updated":"2016-09-20T14:31:48.000Z","comments":1,"photos":[],"link":"","_id":"ciu6nuha1002whqyxcjqmhg2k","content":"<p>On the 30th of June the third <a href=\"http://www.meetup.com/jenadevs/events/230859746\" target=\"_blank\" rel=\"external\">jenadevs</a> meetup took place at the ePages office in Jena.<br>A video conference with our office in Hamburg was also established to give more people the option to attend remotely.</p>\n<img class=\"blog/blog-elastic-meetup-1.jpg\">\n<p>Approximately 30 participants were interested in the topic and showed up at 6 pm.<br>After a short general introduction the presentations started:</p>\n<h3 id=\"Elastic-Stack-5-0\"><a href=\"#Elastic-Stack-5-0\" class=\"headerlink\" title=\"Elastic Stack 5.0\"></a>Elastic Stack 5.0</h3><p><a href=\"http://www.purbon.com/\" target=\"_blank\" rel=\"external\">Pere Urbón-Bayes</a> (<a href=\"https://www.elastic.co\" target=\"_blank\" rel=\"external\">elastic</a>) walked through the new features of the Elastic 5 stack and explained for every component what’s new and what changed.<br>Further information on this topic: <a href=\"https://www.elastic.co/de/v5\" target=\"_blank\" rel=\"external\">elastic v5</a>.</p>\n<img class=\"blog/blog-elastic-meetup-2.jpg\">\n<h3 id=\"Visualisation-and-analysis-of-Open-Data\"><a href=\"#Visualisation-and-analysis-of-Open-Data\" class=\"headerlink\" title=\"Visualisation and analysis of Open Data\"></a>Visualisation and analysis of Open Data</h3><p><a href=\"https://twitter.com/ahzf\" target=\"_blank\" rel=\"external\">Achim Friedland</a> (<a href=\"http://codefor.de/jena/\" target=\"_blank\" rel=\"external\">OK Lab Jena</a>) presented the <a href=\"http://codefor.de/\" target=\"_blank\" rel=\"external\">CODE for Germany</a> project and how it uses open data to visualise and solve problems.<br>He showed some examples of visualised Open Data.</p>\n<h3 id=\"Elastic-Stack-ePages\"><a href=\"#Elastic-Stack-ePages\" class=\"headerlink\" title=\"Elastic Stack @ePages\"></a>Elastic Stack @ePages</h3><p><a href=\"https://twitter.com/epagesdevs\" target=\"_blank\" rel=\"external\">Christian Köhler</a> (<a href=\"http://www.epages.com/\" target=\"_blank\" rel=\"external\">ePages</a>) presented the current Elastic stack at ePages.<br>He explained the approach and the lessons learned to build the centralised logging framework.</p>\n<h3 id=\"Regression-Test-Analysis-with-Elasticsearch-in-a-Delivery-Pipeline\"><a href=\"#Regression-Test-Analysis-with-Elasticsearch-in-a-Delivery-Pipeline\" class=\"headerlink\" title=\"Regression Test Analysis with Elasticsearch in a Delivery Pipeline\"></a>Regression Test Analysis with Elasticsearch in a Delivery Pipeline</h3><p><a href=\"https://twitter.com/dataduke\" target=\"_blank\" rel=\"external\">Benjamin Nothdurft</a> and <a href=\"https://twitter.com/Dastianoro\" target=\"_blank\" rel=\"external\">Bastian Klein</a> (<a href=\"http://www.epages.com/\" target=\"_blank\" rel=\"external\">epages</a>) presented a short version of their implementation of the ElasticSearch, Logstash and Docker integration for aggregation and collection of integration test results from various systems in the delivery pipeline (<a href=\"https://speakerdeck.com/dataduke/automated-test-evaluation-short-version\" target=\"_blank\" rel=\"external\">slides</a>).</p>\n<h3 id=\"Lightning-Talk-How-Elasticsearch-was-used-in-former-projects\"><a href=\"#Lightning-Talk-How-Elasticsearch-was-used-in-former-projects\" class=\"headerlink\" title=\"Lightning Talk: How Elasticsearch was used in former projects\"></a>Lightning Talk: How Elasticsearch was used in former projects</h3><p><a href=\"https://twitter.com/jensfischerhh\" target=\"_blank\" rel=\"external\">Jens Fischer</a> (<a href=\"http://www.epages.com/\" target=\"_blank\" rel=\"external\">ePages</a>) talked about <a href=\"https://slidr.io/jensfischerhh/deploying-the-elastic-stack\" target=\"_blank\" rel=\"external\">deploying the Elastic stack</a> in one of his former projects and the adoption of the new technology.</p>\n<p>In the end delivering all this content took about one hour longer than planned,<br>but even the UEFA EM 2016 match Poland vs. Portugal was gladly skipped by all participants.</p>\n<p>After the presentations we had some nice discussions about the usage of Elasticsearch with some pizza and beer.</p>\n","excerpt":"","more":"<p>On the 30th of June the third <a href=\"http://www.meetup.com/jenadevs/events/230859746\">jenadevs</a> meetup took place at the ePages office in Jena.<br>A video conference with our office in Hamburg was also established to give more people the option to attend remotely.</p>\n<img class=\"blog/blog-elastic-meetup-1.jpg\">\n<p>Approximately 30 participants were interested in the topic and showed up at 6 pm.<br>After a short general introduction the presentations started:</p>\n<h3 id=\"Elastic-Stack-5-0\"><a href=\"#Elastic-Stack-5-0\" class=\"headerlink\" title=\"Elastic Stack 5.0\"></a>Elastic Stack 5.0</h3><p><a href=\"http://www.purbon.com/\">Pere Urbón-Bayes</a> (<a href=\"https://www.elastic.co\">elastic</a>) walked through the new features of the Elastic 5 stack and explained for every component what’s new and what changed.<br>Further information on this topic: <a href=\"https://www.elastic.co/de/v5\">elastic v5</a>.</p>\n<img class=\"blog/blog-elastic-meetup-2.jpg\">\n<h3 id=\"Visualisation-and-analysis-of-Open-Data\"><a href=\"#Visualisation-and-analysis-of-Open-Data\" class=\"headerlink\" title=\"Visualisation and analysis of Open Data\"></a>Visualisation and analysis of Open Data</h3><p><a href=\"https://twitter.com/ahzf\">Achim Friedland</a> (<a href=\"http://codefor.de/jena/\">OK Lab Jena</a>) presented the <a href=\"http://codefor.de/\">CODE for Germany</a> project and how it uses open data to visualise and solve problems.<br>He showed some examples of visualised Open Data.</p>\n<h3 id=\"Elastic-Stack-ePages\"><a href=\"#Elastic-Stack-ePages\" class=\"headerlink\" title=\"Elastic Stack @ePages\"></a>Elastic Stack @ePages</h3><p><a href=\"https://twitter.com/epagesdevs\">Christian Köhler</a> (<a href=\"http://www.epages.com/\">ePages</a>) presented the current Elastic stack at ePages.<br>He explained the approach and the lessons learned to build the centralised logging framework.</p>\n<h3 id=\"Regression-Test-Analysis-with-Elasticsearch-in-a-Delivery-Pipeline\"><a href=\"#Regression-Test-Analysis-with-Elasticsearch-in-a-Delivery-Pipeline\" class=\"headerlink\" title=\"Regression Test Analysis with Elasticsearch in a Delivery Pipeline\"></a>Regression Test Analysis with Elasticsearch in a Delivery Pipeline</h3><p><a href=\"https://twitter.com/dataduke\">Benjamin Nothdurft</a> and <a href=\"https://twitter.com/Dastianoro\">Bastian Klein</a> (<a href=\"http://www.epages.com/\">epages</a>) presented a short version of their implementation of the ElasticSearch, Logstash and Docker integration for aggregation and collection of integration test results from various systems in the delivery pipeline (<a href=\"https://speakerdeck.com/dataduke/automated-test-evaluation-short-version\">slides</a>).</p>\n<h3 id=\"Lightning-Talk-How-Elasticsearch-was-used-in-former-projects\"><a href=\"#Lightning-Talk-How-Elasticsearch-was-used-in-former-projects\" class=\"headerlink\" title=\"Lightning Talk: How Elasticsearch was used in former projects\"></a>Lightning Talk: How Elasticsearch was used in former projects</h3><p><a href=\"https://twitter.com/jensfischerhh\">Jens Fischer</a> (<a href=\"http://www.epages.com/\">ePages</a>) talked about <a href=\"https://slidr.io/jensfischerhh/deploying-the-elastic-stack\">deploying the Elastic stack</a> in one of his former projects and the adoption of the new technology.</p>\n<p>In the end delivering all this content took about one hour longer than planned,<br>but even the UEFA EM 2016 match Poland vs. Portugal was gladly skipped by all participants.</p>\n<p>After the presentations we had some nice discussions about the usage of Elasticsearch with some pizza and beer.</p>\n"},{"layout":"post","title":"How to easily connect payment and shipping with online shops","date":"2016-08-02T05:11:11.000Z","image":"blog-header/next-gen-webservices.jpg","authors":["Manel"],"_content":"\nIn a [previous blog post](https://developer.epages.com/blog/2015/11/03/payment-integrations.html), Xavi explained the standard payment flow model that we use for a long time.\nIn fact, flows between different payments or shippings have differences in architecture (SOAP or REST), as well as the requested data, and even the steps required.\n\n## Standard flow for payments and shipping\n\nBut all of them have something in common:\n\n*The online shop has to contact the web services from the final payment or shipping company, and provide the required information to make the payment or shipping.*\n\n{% image blog/blog-next-gen-webservices-1.png %}\n\nFrom a development point of view, this approach can be OK if there are only a few payments and shippings to offer.\nBut this is not the case for ePages.\nWe're targeted to small and medium businesses.\nWe have many different merchants with different needs in many countries, and want to offer a broad range of payment and shipping options to fulfill their needs.\nThis can be a daunting task, because it means a lot of payments and shippings to integrate into ePages.\nFurthermore, every single payment and shipping developed solution that we integrate needs to be adapted to changes performed by their companies because of improvements and/or new features offered by their web services.\n\n## New approach available\n\nNow, a new approach to connecting with payments and shippings for online shops is available.\nThat new model is being offered by a few startup companies, and the idea is as follows:\n\n*The online shop has to contact the web services from the payment or shipping provider company, which is responsible to offer a portfolio of payment gateways/logistics.*\n\n{% image blog/blog-next-gen-webservices-2.png %}\n\nEven though the basic idea for both, payment and shipping, is the same, they use different approaches to better fit merchant needs.\n\n### Payments\n\nThree asynchronous processes are required:\n\n1. Merchant registers with final payment gateway in order to get credentials.\n2. Merchant provides payment gateway credentials to payments provider company. Provider can then request payments to final payment gateway in the name of the merchant.\n3. End users payment to final payment gateway through payment provider.\n\nSteps one and two are onboarding tasks that have to be done only once.\nStep three is the real payment process and includes many steps.\n\nThis is the flow of step 3:\n\n{% image blog/blog-next-gen-webservices-3.png %}\n\nAs you can see, the Payment Card Industry (PCI) compliance is guaranteed by the payments provider, and no matter the final payment gateway used, payment flow remains the same.\n\n### Shipping\n\nProcesses and associated data flows for shipping are quite different than the ones for payments.\n\n1. Merchant registers with shipping provider.\n2. Shipping provider collects orders from merchant's shop.\n3. Merchant requests offers to shipping provider for shipping an order from different logistics.\n4. Merchant selects logistic offer and launches the shipping task.\n\nBecause there's no required contract between merchants and logistics, the onboarding process is simpler.\nIt only involves the merchant registration with the shipping provider.\nBut from the other side, three asynchronous shipping processes are required.\n\nThis is the flow of step 2:\n\n{% image blog/blog-next-gen-webservices-4.png %}\n\nAnd the process for the merchants to make shipping requests to logistics from the shop's administration area, - step 4 - looks like this:\n\n{% image blog/blog-next-gen-webservices-5.png %}\n\n## Summary\n\nBecause Logistic and Payment Gateway Companies don't have a standardized web services architecture, Payment and Shipping provider startup companies add great value, and probably this is why they are growing rapidly.\n\nFor ePages, it means that we can integrate a lot of payment methods and logistics very quickly, since there's minor or no effort at all in integrating additional payment gateways or logistics offered in their portfolios.\n","source":"_posts/2016-08-02-next-gen-webservices.md","raw":"---\nlayout: post\ntitle: \"How to easily connect payment and shipping with online shops\"\ndate: \"2016-08-02 07:11:11\"\nimage: blog-header/next-gen-webservices.jpg\ncategories: tech-stories\nauthors: [\"Manel\"]\n---\n\nIn a [previous blog post](https://developer.epages.com/blog/2015/11/03/payment-integrations.html), Xavi explained the standard payment flow model that we use for a long time.\nIn fact, flows between different payments or shippings have differences in architecture (SOAP or REST), as well as the requested data, and even the steps required.\n\n## Standard flow for payments and shipping\n\nBut all of them have something in common:\n\n*The online shop has to contact the web services from the final payment or shipping company, and provide the required information to make the payment or shipping.*\n\n{% image blog/blog-next-gen-webservices-1.png %}\n\nFrom a development point of view, this approach can be OK if there are only a few payments and shippings to offer.\nBut this is not the case for ePages.\nWe're targeted to small and medium businesses.\nWe have many different merchants with different needs in many countries, and want to offer a broad range of payment and shipping options to fulfill their needs.\nThis can be a daunting task, because it means a lot of payments and shippings to integrate into ePages.\nFurthermore, every single payment and shipping developed solution that we integrate needs to be adapted to changes performed by their companies because of improvements and/or new features offered by their web services.\n\n## New approach available\n\nNow, a new approach to connecting with payments and shippings for online shops is available.\nThat new model is being offered by a few startup companies, and the idea is as follows:\n\n*The online shop has to contact the web services from the payment or shipping provider company, which is responsible to offer a portfolio of payment gateways/logistics.*\n\n{% image blog/blog-next-gen-webservices-2.png %}\n\nEven though the basic idea for both, payment and shipping, is the same, they use different approaches to better fit merchant needs.\n\n### Payments\n\nThree asynchronous processes are required:\n\n1. Merchant registers with final payment gateway in order to get credentials.\n2. Merchant provides payment gateway credentials to payments provider company. Provider can then request payments to final payment gateway in the name of the merchant.\n3. End users payment to final payment gateway through payment provider.\n\nSteps one and two are onboarding tasks that have to be done only once.\nStep three is the real payment process and includes many steps.\n\nThis is the flow of step 3:\n\n{% image blog/blog-next-gen-webservices-3.png %}\n\nAs you can see, the Payment Card Industry (PCI) compliance is guaranteed by the payments provider, and no matter the final payment gateway used, payment flow remains the same.\n\n### Shipping\n\nProcesses and associated data flows for shipping are quite different than the ones for payments.\n\n1. Merchant registers with shipping provider.\n2. Shipping provider collects orders from merchant's shop.\n3. Merchant requests offers to shipping provider for shipping an order from different logistics.\n4. Merchant selects logistic offer and launches the shipping task.\n\nBecause there's no required contract between merchants and logistics, the onboarding process is simpler.\nIt only involves the merchant registration with the shipping provider.\nBut from the other side, three asynchronous shipping processes are required.\n\nThis is the flow of step 2:\n\n{% image blog/blog-next-gen-webservices-4.png %}\n\nAnd the process for the merchants to make shipping requests to logistics from the shop's administration area, - step 4 - looks like this:\n\n{% image blog/blog-next-gen-webservices-5.png %}\n\n## Summary\n\nBecause Logistic and Payment Gateway Companies don't have a standardized web services architecture, Payment and Shipping provider startup companies add great value, and probably this is why they are growing rapidly.\n\nFor ePages, it means that we can integrate a lot of payment methods and logistics very quickly, since there's minor or no effort at all in integrating additional payment gateways or logistics offered in their portfolios.\n","slug":"2016-08-02-next-gen-webservices","published":1,"updated":"2016-09-20T14:31:48.000Z","comments":1,"photos":[],"link":"","_id":"ciu6nuha2002yhqyxe0oykkv5","content":"<p>In a <a href=\"https://developer.epages.com/blog/2015/11/03/payment-integrations.html\" target=\"_blank\" rel=\"external\">previous blog post</a>, Xavi explained the standard payment flow model that we use for a long time.<br>In fact, flows between different payments or shippings have differences in architecture (SOAP or REST), as well as the requested data, and even the steps required.</p>\n<h2 id=\"Standard-flow-for-payments-and-shipping\"><a href=\"#Standard-flow-for-payments-and-shipping\" class=\"headerlink\" title=\"Standard flow for payments and shipping\"></a>Standard flow for payments and shipping</h2><p>But all of them have something in common:</p>\n<p><em>The online shop has to contact the web services from the final payment or shipping company, and provide the required information to make the payment or shipping.</em></p>\n<img class=\"blog/blog-next-gen-webservices-1.png\">\n<p>From a development point of view, this approach can be OK if there are only a few payments and shippings to offer.<br>But this is not the case for ePages.<br>We’re targeted to small and medium businesses.<br>We have many different merchants with different needs in many countries, and want to offer a broad range of payment and shipping options to fulfill their needs.<br>This can be a daunting task, because it means a lot of payments and shippings to integrate into ePages.<br>Furthermore, every single payment and shipping developed solution that we integrate needs to be adapted to changes performed by their companies because of improvements and/or new features offered by their web services.</p>\n<h2 id=\"New-approach-available\"><a href=\"#New-approach-available\" class=\"headerlink\" title=\"New approach available\"></a>New approach available</h2><p>Now, a new approach to connecting with payments and shippings for online shops is available.<br>That new model is being offered by a few startup companies, and the idea is as follows:</p>\n<p><em>The online shop has to contact the web services from the payment or shipping provider company, which is responsible to offer a portfolio of payment gateways/logistics.</em></p>\n<img class=\"blog/blog-next-gen-webservices-2.png\">\n<p>Even though the basic idea for both, payment and shipping, is the same, they use different approaches to better fit merchant needs.</p>\n<h3 id=\"Payments\"><a href=\"#Payments\" class=\"headerlink\" title=\"Payments\"></a>Payments</h3><p>Three asynchronous processes are required:</p>\n<ol>\n<li>Merchant registers with final payment gateway in order to get credentials.</li>\n<li>Merchant provides payment gateway credentials to payments provider company. Provider can then request payments to final payment gateway in the name of the merchant.</li>\n<li>End users payment to final payment gateway through payment provider.</li>\n</ol>\n<p>Steps one and two are onboarding tasks that have to be done only once.<br>Step three is the real payment process and includes many steps.</p>\n<p>This is the flow of step 3:</p>\n<img class=\"blog/blog-next-gen-webservices-3.png\">\n<p>As you can see, the Payment Card Industry (PCI) compliance is guaranteed by the payments provider, and no matter the final payment gateway used, payment flow remains the same.</p>\n<h3 id=\"Shipping\"><a href=\"#Shipping\" class=\"headerlink\" title=\"Shipping\"></a>Shipping</h3><p>Processes and associated data flows for shipping are quite different than the ones for payments.</p>\n<ol>\n<li>Merchant registers with shipping provider.</li>\n<li>Shipping provider collects orders from merchant’s shop.</li>\n<li>Merchant requests offers to shipping provider for shipping an order from different logistics.</li>\n<li>Merchant selects logistic offer and launches the shipping task.</li>\n</ol>\n<p>Because there’s no required contract between merchants and logistics, the onboarding process is simpler.<br>It only involves the merchant registration with the shipping provider.<br>But from the other side, three asynchronous shipping processes are required.</p>\n<p>This is the flow of step 2:</p>\n<img class=\"blog/blog-next-gen-webservices-4.png\">\n<p>And the process for the merchants to make shipping requests to logistics from the shop’s administration area, - step 4 - looks like this:</p>\n<img class=\"blog/blog-next-gen-webservices-5.png\">\n<h2 id=\"Summary\"><a href=\"#Summary\" class=\"headerlink\" title=\"Summary\"></a>Summary</h2><p>Because Logistic and Payment Gateway Companies don’t have a standardized web services architecture, Payment and Shipping provider startup companies add great value, and probably this is why they are growing rapidly.</p>\n<p>For ePages, it means that we can integrate a lot of payment methods and logistics very quickly, since there’s minor or no effort at all in integrating additional payment gateways or logistics offered in their portfolios.</p>\n","excerpt":"","more":"<p>In a <a href=\"https://developer.epages.com/blog/2015/11/03/payment-integrations.html\">previous blog post</a>, Xavi explained the standard payment flow model that we use for a long time.<br>In fact, flows between different payments or shippings have differences in architecture (SOAP or REST), as well as the requested data, and even the steps required.</p>\n<h2 id=\"Standard-flow-for-payments-and-shipping\"><a href=\"#Standard-flow-for-payments-and-shipping\" class=\"headerlink\" title=\"Standard flow for payments and shipping\"></a>Standard flow for payments and shipping</h2><p>But all of them have something in common:</p>\n<p><em>The online shop has to contact the web services from the final payment or shipping company, and provide the required information to make the payment or shipping.</em></p>\n<img class=\"blog/blog-next-gen-webservices-1.png\">\n<p>From a development point of view, this approach can be OK if there are only a few payments and shippings to offer.<br>But this is not the case for ePages.<br>We’re targeted to small and medium businesses.<br>We have many different merchants with different needs in many countries, and want to offer a broad range of payment and shipping options to fulfill their needs.<br>This can be a daunting task, because it means a lot of payments and shippings to integrate into ePages.<br>Furthermore, every single payment and shipping developed solution that we integrate needs to be adapted to changes performed by their companies because of improvements and/or new features offered by their web services.</p>\n<h2 id=\"New-approach-available\"><a href=\"#New-approach-available\" class=\"headerlink\" title=\"New approach available\"></a>New approach available</h2><p>Now, a new approach to connecting with payments and shippings for online shops is available.<br>That new model is being offered by a few startup companies, and the idea is as follows:</p>\n<p><em>The online shop has to contact the web services from the payment or shipping provider company, which is responsible to offer a portfolio of payment gateways/logistics.</em></p>\n<img class=\"blog/blog-next-gen-webservices-2.png\">\n<p>Even though the basic idea for both, payment and shipping, is the same, they use different approaches to better fit merchant needs.</p>\n<h3 id=\"Payments\"><a href=\"#Payments\" class=\"headerlink\" title=\"Payments\"></a>Payments</h3><p>Three asynchronous processes are required:</p>\n<ol>\n<li>Merchant registers with final payment gateway in order to get credentials.</li>\n<li>Merchant provides payment gateway credentials to payments provider company. Provider can then request payments to final payment gateway in the name of the merchant.</li>\n<li>End users payment to final payment gateway through payment provider.</li>\n</ol>\n<p>Steps one and two are onboarding tasks that have to be done only once.<br>Step three is the real payment process and includes many steps.</p>\n<p>This is the flow of step 3:</p>\n<img class=\"blog/blog-next-gen-webservices-3.png\">\n<p>As you can see, the Payment Card Industry (PCI) compliance is guaranteed by the payments provider, and no matter the final payment gateway used, payment flow remains the same.</p>\n<h3 id=\"Shipping\"><a href=\"#Shipping\" class=\"headerlink\" title=\"Shipping\"></a>Shipping</h3><p>Processes and associated data flows for shipping are quite different than the ones for payments.</p>\n<ol>\n<li>Merchant registers with shipping provider.</li>\n<li>Shipping provider collects orders from merchant’s shop.</li>\n<li>Merchant requests offers to shipping provider for shipping an order from different logistics.</li>\n<li>Merchant selects logistic offer and launches the shipping task.</li>\n</ol>\n<p>Because there’s no required contract between merchants and logistics, the onboarding process is simpler.<br>It only involves the merchant registration with the shipping provider.<br>But from the other side, three asynchronous shipping processes are required.</p>\n<p>This is the flow of step 2:</p>\n<img class=\"blog/blog-next-gen-webservices-4.png\">\n<p>And the process for the merchants to make shipping requests to logistics from the shop’s administration area, - step 4 - looks like this:</p>\n<img class=\"blog/blog-next-gen-webservices-5.png\">\n<h2 id=\"Summary\"><a href=\"#Summary\" class=\"headerlink\" title=\"Summary\"></a>Summary</h2><p>Because Logistic and Payment Gateway Companies don’t have a standardized web services architecture, Payment and Shipping provider startup companies add great value, and probably this is why they are growing rapidly.</p>\n<p>For ePages, it means that we can integrate a lot of payment methods and logistics very quickly, since there’s minor or no effort at all in integrating additional payment gateways or logistics offered in their portfolios.</p>\n"},{"layout":"post","title":"How we connected Sage One with ePages","date":"2016-08-12T12:00:28.000Z","image":"blog-header/bridge.jpg","authors":["Mats"],"_content":"\nIn my team the recent and still ongoing project is the implementation of an application serving as a connector between the ePages e-commerce solution and [Sage One](https://developer.sageone.com).\nSage One is an ERP solution.\nThe main purpose of this connector-application is to transfer the orders being created in the ePages shop into the Sage One accounting application.\n\n## The initial plan\n\nOur initial plan was to build a standalone application using the [ePages REST API](https://developer.epages.com/apps) to obtain the order information that have to be transferred to Sage One.\nSoon the requirement of a deeper integration into the ePages administration area came up.\nSo we had to find a different approach.\nIn our recent payment integration PayPal Plus introduced a “thin layer”-approach.\nThat means, we used a Java application as a layer between the ePages Perl code and the [PayPal API](https://developer.paypal.com).\nIn this approach we used the Java layer as a plain communication adapter in order to be able to use the PayPal Java SDK. Understanding the Java layer as a plain communication adapter we were strictly avoiding any business logic there.\nThe Java layer is only transferring information between the ePages Perl core and the Paypal API.\n\n{% image blog/paypalplus-approach.jpg %}\n\nThe main reason to keep all the business logic in the ePages Perl core was that PayPal Plus as a payment required a deep integration in the checkout process.\nWe also wanted to avoid spreading business logic over two systems.\n\n## The approach\n\nFor the Sage One connector there is no need for an integration into the checkout process.\nTherefore, we chose a slightly different approach.\nThis time we were shifting the entire business logic to the Java layer.\nThe Perl part serves as the view, only containing view-related logic.\nAs an error handling strategy we decided to use an approach of status reflection.\nThe Java layer exposes the status of each individual shop and order through an internal REST API.\nThis way the view-layer can obtain the status to provide feedback on the outcome of a certain operation.\n\n{% image blog/sageone-approach.jpg %}\n\nShifting the business logic to Java had big advantages.\nEspecially in terms of coding speed, test-coverage and maintainability, since the refactoring facilities in Java are way superior compared to Perl.\nThis approach also gave us a clear separation of concerns, assigning each application layer a specific task.\nThe Java layer is responsible for all business logic, holding all controller and model code.\nIt exposes the status of each shop and order through REST.\nThe Perl layer is only responsible for view-related functionality.\nIt uses the REST endpoints of the Java layer in order to obtain status information or trigger synchronization procedures.\n\n## The other side of the coin\n\nThe downside of this approach is that we have an additional dependency in our solution.\nThis makes the entire solution a bit more complex, especially in terms of debugging.\nAbstracting the business logic to Java requires also some special solutions in order to achieve certain functionality that would be classified as ‘basic’ in a Perl standalone cartridge.\nThe reason is that we are not able to use a lot of the Perl core functionality because our business data is stored in the Java layer.\n","source":"_posts/2016-08-12-sageone-approach.md","raw":"---\nlayout: post\ntitle: \"How we connected Sage One with ePages\"\ndate: \"2016-08-12 14:00:28\"\nimage: blog-header/bridge.jpg\ncategories: tech-stories\nauthors: [\"Mats\"]\n---\n\nIn my team the recent and still ongoing project is the implementation of an application serving as a connector between the ePages e-commerce solution and [Sage One](https://developer.sageone.com).\nSage One is an ERP solution.\nThe main purpose of this connector-application is to transfer the orders being created in the ePages shop into the Sage One accounting application.\n\n## The initial plan\n\nOur initial plan was to build a standalone application using the [ePages REST API](https://developer.epages.com/apps) to obtain the order information that have to be transferred to Sage One.\nSoon the requirement of a deeper integration into the ePages administration area came up.\nSo we had to find a different approach.\nIn our recent payment integration PayPal Plus introduced a “thin layer”-approach.\nThat means, we used a Java application as a layer between the ePages Perl code and the [PayPal API](https://developer.paypal.com).\nIn this approach we used the Java layer as a plain communication adapter in order to be able to use the PayPal Java SDK. Understanding the Java layer as a plain communication adapter we were strictly avoiding any business logic there.\nThe Java layer is only transferring information between the ePages Perl core and the Paypal API.\n\n{% image blog/paypalplus-approach.jpg %}\n\nThe main reason to keep all the business logic in the ePages Perl core was that PayPal Plus as a payment required a deep integration in the checkout process.\nWe also wanted to avoid spreading business logic over two systems.\n\n## The approach\n\nFor the Sage One connector there is no need for an integration into the checkout process.\nTherefore, we chose a slightly different approach.\nThis time we were shifting the entire business logic to the Java layer.\nThe Perl part serves as the view, only containing view-related logic.\nAs an error handling strategy we decided to use an approach of status reflection.\nThe Java layer exposes the status of each individual shop and order through an internal REST API.\nThis way the view-layer can obtain the status to provide feedback on the outcome of a certain operation.\n\n{% image blog/sageone-approach.jpg %}\n\nShifting the business logic to Java had big advantages.\nEspecially in terms of coding speed, test-coverage and maintainability, since the refactoring facilities in Java are way superior compared to Perl.\nThis approach also gave us a clear separation of concerns, assigning each application layer a specific task.\nThe Java layer is responsible for all business logic, holding all controller and model code.\nIt exposes the status of each shop and order through REST.\nThe Perl layer is only responsible for view-related functionality.\nIt uses the REST endpoints of the Java layer in order to obtain status information or trigger synchronization procedures.\n\n## The other side of the coin\n\nThe downside of this approach is that we have an additional dependency in our solution.\nThis makes the entire solution a bit more complex, especially in terms of debugging.\nAbstracting the business logic to Java requires also some special solutions in order to achieve certain functionality that would be classified as ‘basic’ in a Perl standalone cartridge.\nThe reason is that we are not able to use a lot of the Perl core functionality because our business data is stored in the Java layer.\n","slug":"2016-08-12-sageone-approach","published":1,"updated":"2016-09-20T14:31:48.000Z","comments":1,"photos":[],"link":"","_id":"ciu6nuha30030hqyxmv8pk6nu","content":"<p>In my team the recent and still ongoing project is the implementation of an application serving as a connector between the ePages e-commerce solution and <a href=\"https://developer.sageone.com\" target=\"_blank\" rel=\"external\">Sage One</a>.<br>Sage One is an ERP solution.<br>The main purpose of this connector-application is to transfer the orders being created in the ePages shop into the Sage One accounting application.</p>\n<h2 id=\"The-initial-plan\"><a href=\"#The-initial-plan\" class=\"headerlink\" title=\"The initial plan\"></a>The initial plan</h2><p>Our initial plan was to build a standalone application using the <a href=\"https://developer.epages.com/apps\" target=\"_blank\" rel=\"external\">ePages REST API</a> to obtain the order information that have to be transferred to Sage One.<br>Soon the requirement of a deeper integration into the ePages administration area came up.<br>So we had to find a different approach.<br>In our recent payment integration PayPal Plus introduced a “thin layer”-approach.<br>That means, we used a Java application as a layer between the ePages Perl code and the <a href=\"https://developer.paypal.com\" target=\"_blank\" rel=\"external\">PayPal API</a>.<br>In this approach we used the Java layer as a plain communication adapter in order to be able to use the PayPal Java SDK. Understanding the Java layer as a plain communication adapter we were strictly avoiding any business logic there.<br>The Java layer is only transferring information between the ePages Perl core and the Paypal API.</p>\n<img class=\"blog/paypalplus-approach.jpg\">\n<p>The main reason to keep all the business logic in the ePages Perl core was that PayPal Plus as a payment required a deep integration in the checkout process.<br>We also wanted to avoid spreading business logic over two systems.</p>\n<h2 id=\"The-approach\"><a href=\"#The-approach\" class=\"headerlink\" title=\"The approach\"></a>The approach</h2><p>For the Sage One connector there is no need for an integration into the checkout process.<br>Therefore, we chose a slightly different approach.<br>This time we were shifting the entire business logic to the Java layer.<br>The Perl part serves as the view, only containing view-related logic.<br>As an error handling strategy we decided to use an approach of status reflection.<br>The Java layer exposes the status of each individual shop and order through an internal REST API.<br>This way the view-layer can obtain the status to provide feedback on the outcome of a certain operation.</p>\n<img class=\"blog/sageone-approach.jpg\">\n<p>Shifting the business logic to Java had big advantages.<br>Especially in terms of coding speed, test-coverage and maintainability, since the refactoring facilities in Java are way superior compared to Perl.<br>This approach also gave us a clear separation of concerns, assigning each application layer a specific task.<br>The Java layer is responsible for all business logic, holding all controller and model code.<br>It exposes the status of each shop and order through REST.<br>The Perl layer is only responsible for view-related functionality.<br>It uses the REST endpoints of the Java layer in order to obtain status information or trigger synchronization procedures.</p>\n<h2 id=\"The-other-side-of-the-coin\"><a href=\"#The-other-side-of-the-coin\" class=\"headerlink\" title=\"The other side of the coin\"></a>The other side of the coin</h2><p>The downside of this approach is that we have an additional dependency in our solution.<br>This makes the entire solution a bit more complex, especially in terms of debugging.<br>Abstracting the business logic to Java requires also some special solutions in order to achieve certain functionality that would be classified as ‘basic’ in a Perl standalone cartridge.<br>The reason is that we are not able to use a lot of the Perl core functionality because our business data is stored in the Java layer.</p>\n","excerpt":"","more":"<p>In my team the recent and still ongoing project is the implementation of an application serving as a connector between the ePages e-commerce solution and <a href=\"https://developer.sageone.com\">Sage One</a>.<br>Sage One is an ERP solution.<br>The main purpose of this connector-application is to transfer the orders being created in the ePages shop into the Sage One accounting application.</p>\n<h2 id=\"The-initial-plan\"><a href=\"#The-initial-plan\" class=\"headerlink\" title=\"The initial plan\"></a>The initial plan</h2><p>Our initial plan was to build a standalone application using the <a href=\"https://developer.epages.com/apps\">ePages REST API</a> to obtain the order information that have to be transferred to Sage One.<br>Soon the requirement of a deeper integration into the ePages administration area came up.<br>So we had to find a different approach.<br>In our recent payment integration PayPal Plus introduced a “thin layer”-approach.<br>That means, we used a Java application as a layer between the ePages Perl code and the <a href=\"https://developer.paypal.com\">PayPal API</a>.<br>In this approach we used the Java layer as a plain communication adapter in order to be able to use the PayPal Java SDK. Understanding the Java layer as a plain communication adapter we were strictly avoiding any business logic there.<br>The Java layer is only transferring information between the ePages Perl core and the Paypal API.</p>\n<img class=\"blog/paypalplus-approach.jpg\">\n<p>The main reason to keep all the business logic in the ePages Perl core was that PayPal Plus as a payment required a deep integration in the checkout process.<br>We also wanted to avoid spreading business logic over two systems.</p>\n<h2 id=\"The-approach\"><a href=\"#The-approach\" class=\"headerlink\" title=\"The approach\"></a>The approach</h2><p>For the Sage One connector there is no need for an integration into the checkout process.<br>Therefore, we chose a slightly different approach.<br>This time we were shifting the entire business logic to the Java layer.<br>The Perl part serves as the view, only containing view-related logic.<br>As an error handling strategy we decided to use an approach of status reflection.<br>The Java layer exposes the status of each individual shop and order through an internal REST API.<br>This way the view-layer can obtain the status to provide feedback on the outcome of a certain operation.</p>\n<img class=\"blog/sageone-approach.jpg\">\n<p>Shifting the business logic to Java had big advantages.<br>Especially in terms of coding speed, test-coverage and maintainability, since the refactoring facilities in Java are way superior compared to Perl.<br>This approach also gave us a clear separation of concerns, assigning each application layer a specific task.<br>The Java layer is responsible for all business logic, holding all controller and model code.<br>It exposes the status of each shop and order through REST.<br>The Perl layer is only responsible for view-related functionality.<br>It uses the REST endpoints of the Java layer in order to obtain status information or trigger synchronization procedures.</p>\n<h2 id=\"The-other-side-of-the-coin\"><a href=\"#The-other-side-of-the-coin\" class=\"headerlink\" title=\"The other side of the coin\"></a>The other side of the coin</h2><p>The downside of this approach is that we have an additional dependency in our solution.<br>This makes the entire solution a bit more complex, especially in terms of debugging.<br>Abstracting the business logic to Java requires also some special solutions in order to achieve certain functionality that would be classified as ‘basic’ in a Perl standalone cartridge.<br>The reason is that we are not able to use a lot of the Perl core functionality because our business data is stored in the Java layer.</p>\n"},{"layout":"post","title":"How to find out what your target group needs","date":"2016-08-23T06:00:21.000Z","image":"blog-header/target.jpg","authors":["Birgit"],"_content":"\nCan we assume that technical writers know the target audience they are writing for?\nAre they aware of the causes and purposes for their documentation?\nAnd how can they know which information should be provided and in which level of detail?\nIn this blog post, I'd like to share my experience on how I tried to find out.\n\n## Starting a documentation from scratch\n\nWhen I started my job at ePages, I had to come up with a complete new structure as well as all relevant content for a brand new [API documentation](https://developer.epages.com/apps).\nAs a technical writer I found this position very comfortable as I could really start from scratch.\nFrom our developers in-house, I found out pretty quickly, that opinions, views, and also tastes differ on what an API documentation must look like and how it should be structured.\nBut I had to identify the requirements of my **real** target group.\n\nHow to find that out?\n\n* *Google: How should API documentation be structured?\nHow do \"the others do it\"?*\n* *Dear Product Management, what is the persona, I should write for?*\n* *Hey developer colleagues, what type of documentation do you use, and what do you usually dismiss?*\n\nI drafted out a documentation scheme, discussed it internally, nixed it, drafted out again.\nYou know how that works.\n\nAt the end, I had a version I could launch with.\nBut I was not yet 100% sure it would be the perfect fit for my target group.\n\n## Test on the living object\n\nI was convinced, that I needed to test this \"on the living object\".\nFortunately, I work closely together with our Usability Expert Anja who offered to support me.\nWe agreed to conduct an online survey amongst the users of our API documentation.\nThe survey was published internally, communicated to our partners, announced on the [ePages developer blog](https://developer.epages.com/blog) as well as via [Twitter](https://twitter.com/epagesdevs).\n\n### Categorizing the audience\n\nAs we expected differences in the required information with regards to interest in using our API, professional experience, and background knowledge, we asked some general questions to better categorize our audience:\n\n* What is your relationship with ePages?\n* Please rate your knowledge.\n* In which occupational field do you work?\n\n### Importance of content\n\nThen we got right down to business and tackled questions regarding the content.\nHere's an excerpt of what that looked like:\n\n{% image blog/blog-api-survey-1.png %}\n\n{% image blog/blog-api-survey-2.png %}\n\n{% image blog/blog-api-survey-3.png %}\n\n{% image blog/blog-api-survey-4.png %}\n\n## Enlightened\n\nIn the last part of the survey we put a link to the current documentation version.\nWe asked how they would rate the ePages REST API documentation.\nThe result made me jump for joy as it showed that I was already on a good way:\n\n{% image blog/blog-api-survey-5.png %}\n\nPeople were also asked to give us a hint of what could be improved.\nAmongst others they'd like to see:\n\n* Code examples in the most popular programming languages\n* SDKs\n* Detailed information on responses\n\nI learned about good API documentation that developers really like to work with, as:\n\n* [PayPal API](https://developer.paypal.com/docs/api/)\n* [Twitter API](https://dev.twitter.com/overview/documentation)\n* [GitHub API](https://developer.github.com/)\n* [Node.js](https://nodejs.org/api/all.html)\n\n## Summary\n\nAlthough we had just 26 participants, with this survey I was able to identify the informational needs of the readers of our API documentation.\nIt helped me to rework my first version of the docs, to better assess documentation change requests, as well as prioritize upcoming documentation tasks.\n","source":"_posts/2016-08-23-api-target-group.md","raw":"---\nlayout: post\ntitle: \"How to find out what your target group needs\"\ndate: \"2016-08-23 08:00:21\"\nimage: blog-header/target.jpg\ncategories: api\nauthors: [\"Birgit\"]\n---\n\nCan we assume that technical writers know the target audience they are writing for?\nAre they aware of the causes and purposes for their documentation?\nAnd how can they know which information should be provided and in which level of detail?\nIn this blog post, I'd like to share my experience on how I tried to find out.\n\n## Starting a documentation from scratch\n\nWhen I started my job at ePages, I had to come up with a complete new structure as well as all relevant content for a brand new [API documentation](https://developer.epages.com/apps).\nAs a technical writer I found this position very comfortable as I could really start from scratch.\nFrom our developers in-house, I found out pretty quickly, that opinions, views, and also tastes differ on what an API documentation must look like and how it should be structured.\nBut I had to identify the requirements of my **real** target group.\n\nHow to find that out?\n\n* *Google: How should API documentation be structured?\nHow do \"the others do it\"?*\n* *Dear Product Management, what is the persona, I should write for?*\n* *Hey developer colleagues, what type of documentation do you use, and what do you usually dismiss?*\n\nI drafted out a documentation scheme, discussed it internally, nixed it, drafted out again.\nYou know how that works.\n\nAt the end, I had a version I could launch with.\nBut I was not yet 100% sure it would be the perfect fit for my target group.\n\n## Test on the living object\n\nI was convinced, that I needed to test this \"on the living object\".\nFortunately, I work closely together with our Usability Expert Anja who offered to support me.\nWe agreed to conduct an online survey amongst the users of our API documentation.\nThe survey was published internally, communicated to our partners, announced on the [ePages developer blog](https://developer.epages.com/blog) as well as via [Twitter](https://twitter.com/epagesdevs).\n\n### Categorizing the audience\n\nAs we expected differences in the required information with regards to interest in using our API, professional experience, and background knowledge, we asked some general questions to better categorize our audience:\n\n* What is your relationship with ePages?\n* Please rate your knowledge.\n* In which occupational field do you work?\n\n### Importance of content\n\nThen we got right down to business and tackled questions regarding the content.\nHere's an excerpt of what that looked like:\n\n{% image blog/blog-api-survey-1.png %}\n\n{% image blog/blog-api-survey-2.png %}\n\n{% image blog/blog-api-survey-3.png %}\n\n{% image blog/blog-api-survey-4.png %}\n\n## Enlightened\n\nIn the last part of the survey we put a link to the current documentation version.\nWe asked how they would rate the ePages REST API documentation.\nThe result made me jump for joy as it showed that I was already on a good way:\n\n{% image blog/blog-api-survey-5.png %}\n\nPeople were also asked to give us a hint of what could be improved.\nAmongst others they'd like to see:\n\n* Code examples in the most popular programming languages\n* SDKs\n* Detailed information on responses\n\nI learned about good API documentation that developers really like to work with, as:\n\n* [PayPal API](https://developer.paypal.com/docs/api/)\n* [Twitter API](https://dev.twitter.com/overview/documentation)\n* [GitHub API](https://developer.github.com/)\n* [Node.js](https://nodejs.org/api/all.html)\n\n## Summary\n\nAlthough we had just 26 participants, with this survey I was able to identify the informational needs of the readers of our API documentation.\nIt helped me to rework my first version of the docs, to better assess documentation change requests, as well as prioritize upcoming documentation tasks.\n","slug":"2016-08-23-api-target-group","published":1,"updated":"2016-09-20T14:31:48.000Z","comments":1,"photos":[],"link":"","_id":"ciu6nuha40032hqyx1woyelwy","content":"<p>Can we assume that technical writers know the target audience they are writing for?<br>Are they aware of the causes and purposes for their documentation?<br>And how can they know which information should be provided and in which level of detail?<br>In this blog post, I’d like to share my experience on how I tried to find out.</p>\n<h2 id=\"Starting-a-documentation-from-scratch\"><a href=\"#Starting-a-documentation-from-scratch\" class=\"headerlink\" title=\"Starting a documentation from scratch\"></a>Starting a documentation from scratch</h2><p>When I started my job at ePages, I had to come up with a complete new structure as well as all relevant content for a brand new <a href=\"https://developer.epages.com/apps\" target=\"_blank\" rel=\"external\">API documentation</a>.<br>As a technical writer I found this position very comfortable as I could really start from scratch.<br>From our developers in-house, I found out pretty quickly, that opinions, views, and also tastes differ on what an API documentation must look like and how it should be structured.<br>But I had to identify the requirements of my <strong>real</strong> target group.</p>\n<p>How to find that out?</p>\n<ul>\n<li><em>Google: How should API documentation be structured?<br>How do “the others do it”?</em></li>\n<li><em>Dear Product Management, what is the persona, I should write for?</em></li>\n<li><em>Hey developer colleagues, what type of documentation do you use, and what do you usually dismiss?</em></li>\n</ul>\n<p>I drafted out a documentation scheme, discussed it internally, nixed it, drafted out again.<br>You know how that works.</p>\n<p>At the end, I had a version I could launch with.<br>But I was not yet 100% sure it would be the perfect fit for my target group.</p>\n<h2 id=\"Test-on-the-living-object\"><a href=\"#Test-on-the-living-object\" class=\"headerlink\" title=\"Test on the living object\"></a>Test on the living object</h2><p>I was convinced, that I needed to test this “on the living object”.<br>Fortunately, I work closely together with our Usability Expert Anja who offered to support me.<br>We agreed to conduct an online survey amongst the users of our API documentation.<br>The survey was published internally, communicated to our partners, announced on the <a href=\"https://developer.epages.com/blog\" target=\"_blank\" rel=\"external\">ePages developer blog</a> as well as via <a href=\"https://twitter.com/epagesdevs\" target=\"_blank\" rel=\"external\">Twitter</a>.</p>\n<h3 id=\"Categorizing-the-audience\"><a href=\"#Categorizing-the-audience\" class=\"headerlink\" title=\"Categorizing the audience\"></a>Categorizing the audience</h3><p>As we expected differences in the required information with regards to interest in using our API, professional experience, and background knowledge, we asked some general questions to better categorize our audience:</p>\n<ul>\n<li>What is your relationship with ePages?</li>\n<li>Please rate your knowledge.</li>\n<li>In which occupational field do you work?</li>\n</ul>\n<h3 id=\"Importance-of-content\"><a href=\"#Importance-of-content\" class=\"headerlink\" title=\"Importance of content\"></a>Importance of content</h3><p>Then we got right down to business and tackled questions regarding the content.<br>Here’s an excerpt of what that looked like:</p>\n<img class=\"blog/blog-api-survey-1.png\">\n<img class=\"blog/blog-api-survey-2.png\">\n<img class=\"blog/blog-api-survey-3.png\">\n<img class=\"blog/blog-api-survey-4.png\">\n<h2 id=\"Enlightened\"><a href=\"#Enlightened\" class=\"headerlink\" title=\"Enlightened\"></a>Enlightened</h2><p>In the last part of the survey we put a link to the current documentation version.<br>We asked how they would rate the ePages REST API documentation.<br>The result made me jump for joy as it showed that I was already on a good way:</p>\n<img class=\"blog/blog-api-survey-5.png\">\n<p>People were also asked to give us a hint of what could be improved.<br>Amongst others they’d like to see:</p>\n<ul>\n<li>Code examples in the most popular programming languages</li>\n<li>SDKs</li>\n<li>Detailed information on responses</li>\n</ul>\n<p>I learned about good API documentation that developers really like to work with, as:</p>\n<ul>\n<li><a href=\"https://developer.paypal.com/docs/api/\" target=\"_blank\" rel=\"external\">PayPal API</a></li>\n<li><a href=\"https://dev.twitter.com/overview/documentation\" target=\"_blank\" rel=\"external\">Twitter API</a></li>\n<li><a href=\"https://developer.github.com/\" target=\"_blank\" rel=\"external\">GitHub API</a></li>\n<li><a href=\"https://nodejs.org/api/all.html\" target=\"_blank\" rel=\"external\">Node.js</a></li>\n</ul>\n<h2 id=\"Summary\"><a href=\"#Summary\" class=\"headerlink\" title=\"Summary\"></a>Summary</h2><p>Although we had just 26 participants, with this survey I was able to identify the informational needs of the readers of our API documentation.<br>It helped me to rework my first version of the docs, to better assess documentation change requests, as well as prioritize upcoming documentation tasks.</p>\n","excerpt":"","more":"<p>Can we assume that technical writers know the target audience they are writing for?<br>Are they aware of the causes and purposes for their documentation?<br>And how can they know which information should be provided and in which level of detail?<br>In this blog post, I’d like to share my experience on how I tried to find out.</p>\n<h2 id=\"Starting-a-documentation-from-scratch\"><a href=\"#Starting-a-documentation-from-scratch\" class=\"headerlink\" title=\"Starting a documentation from scratch\"></a>Starting a documentation from scratch</h2><p>When I started my job at ePages, I had to come up with a complete new structure as well as all relevant content for a brand new <a href=\"https://developer.epages.com/apps\">API documentation</a>.<br>As a technical writer I found this position very comfortable as I could really start from scratch.<br>From our developers in-house, I found out pretty quickly, that opinions, views, and also tastes differ on what an API documentation must look like and how it should be structured.<br>But I had to identify the requirements of my <strong>real</strong> target group.</p>\n<p>How to find that out?</p>\n<ul>\n<li><em>Google: How should API documentation be structured?<br>How do “the others do it”?</em></li>\n<li><em>Dear Product Management, what is the persona, I should write for?</em></li>\n<li><em>Hey developer colleagues, what type of documentation do you use, and what do you usually dismiss?</em></li>\n</ul>\n<p>I drafted out a documentation scheme, discussed it internally, nixed it, drafted out again.<br>You know how that works.</p>\n<p>At the end, I had a version I could launch with.<br>But I was not yet 100% sure it would be the perfect fit for my target group.</p>\n<h2 id=\"Test-on-the-living-object\"><a href=\"#Test-on-the-living-object\" class=\"headerlink\" title=\"Test on the living object\"></a>Test on the living object</h2><p>I was convinced, that I needed to test this “on the living object”.<br>Fortunately, I work closely together with our Usability Expert Anja who offered to support me.<br>We agreed to conduct an online survey amongst the users of our API documentation.<br>The survey was published internally, communicated to our partners, announced on the <a href=\"https://developer.epages.com/blog\">ePages developer blog</a> as well as via <a href=\"https://twitter.com/epagesdevs\">Twitter</a>.</p>\n<h3 id=\"Categorizing-the-audience\"><a href=\"#Categorizing-the-audience\" class=\"headerlink\" title=\"Categorizing the audience\"></a>Categorizing the audience</h3><p>As we expected differences in the required information with regards to interest in using our API, professional experience, and background knowledge, we asked some general questions to better categorize our audience:</p>\n<ul>\n<li>What is your relationship with ePages?</li>\n<li>Please rate your knowledge.</li>\n<li>In which occupational field do you work?</li>\n</ul>\n<h3 id=\"Importance-of-content\"><a href=\"#Importance-of-content\" class=\"headerlink\" title=\"Importance of content\"></a>Importance of content</h3><p>Then we got right down to business and tackled questions regarding the content.<br>Here’s an excerpt of what that looked like:</p>\n<img class=\"blog/blog-api-survey-1.png\">\n<img class=\"blog/blog-api-survey-2.png\">\n<img class=\"blog/blog-api-survey-3.png\">\n<img class=\"blog/blog-api-survey-4.png\">\n<h2 id=\"Enlightened\"><a href=\"#Enlightened\" class=\"headerlink\" title=\"Enlightened\"></a>Enlightened</h2><p>In the last part of the survey we put a link to the current documentation version.<br>We asked how they would rate the ePages REST API documentation.<br>The result made me jump for joy as it showed that I was already on a good way:</p>\n<img class=\"blog/blog-api-survey-5.png\">\n<p>People were also asked to give us a hint of what could be improved.<br>Amongst others they’d like to see:</p>\n<ul>\n<li>Code examples in the most popular programming languages</li>\n<li>SDKs</li>\n<li>Detailed information on responses</li>\n</ul>\n<p>I learned about good API documentation that developers really like to work with, as:</p>\n<ul>\n<li><a href=\"https://developer.paypal.com/docs/api/\">PayPal API</a></li>\n<li><a href=\"https://dev.twitter.com/overview/documentation\">Twitter API</a></li>\n<li><a href=\"https://developer.github.com/\">GitHub API</a></li>\n<li><a href=\"https://nodejs.org/api/all.html\">Node.js</a></li>\n</ul>\n<h2 id=\"Summary\"><a href=\"#Summary\" class=\"headerlink\" title=\"Summary\"></a>Summary</h2><p>Although we had just 26 participants, with this survey I was able to identify the informational needs of the readers of our API documentation.<br>It helped me to rework my first version of the docs, to better assess documentation change requests, as well as prioritize upcoming documentation tasks.</p>\n"},{"layout":"post","title":"App development: ePages Partner Training in Hamburg","date":"2016-08-30T07:13:24.000Z","image":"blog-header/partner-training-2.jpg","authors":["Birgit"],"_content":"\nYou are an ePages partner already?\nOr you're interested in developing an app for ePages?\nYou're very welcome to sign up for our next ePages Partner Training.\n\nQuick overview of the agenda:\n\n* Developer Basics\n* Development of ePages internal modules\n* The ePages [REST API](https://developer.epages.com/apps)\n* Developing an app via REST\n* Introduction to our new responsive storefront and optimized administration area\n* Q&A session\n\nDate & Time: 24th to 28th of October 2016\n\nTrainers: Oliver Zscheyge and Friedrich Gehring (Software Developers)\n\nLocation: ePages headquarter, Pilatuspool 2, 20355 Hamburg\n\nSign up at [training@epages.com](mailto:training@epages.com).\nWe're looking forward to see you there!\n","source":"_posts/2016-08-30-partner-training.md","raw":"---\nlayout: post\ntitle: \"App development: ePages Partner Training in Hamburg\"\ndate: \"2016-08-30 09:13:24\"\nimage: blog-header/partner-training-2.jpg\ncategories: events\nauthors: [\"Birgit\"]\n---\n\nYou are an ePages partner already?\nOr you're interested in developing an app for ePages?\nYou're very welcome to sign up for our next ePages Partner Training.\n\nQuick overview of the agenda:\n\n* Developer Basics\n* Development of ePages internal modules\n* The ePages [REST API](https://developer.epages.com/apps)\n* Developing an app via REST\n* Introduction to our new responsive storefront and optimized administration area\n* Q&A session\n\nDate & Time: 24th to 28th of October 2016\n\nTrainers: Oliver Zscheyge and Friedrich Gehring (Software Developers)\n\nLocation: ePages headquarter, Pilatuspool 2, 20355 Hamburg\n\nSign up at [training@epages.com](mailto:training@epages.com).\nWe're looking forward to see you there!\n","slug":"2016-08-30-partner-training","published":1,"updated":"2016-09-20T14:31:48.000Z","comments":1,"photos":[],"link":"","_id":"ciu6nuha50034hqyxrjwzqan5","content":"<p>You are an ePages partner already?<br>Or you’re interested in developing an app for ePages?<br>You’re very welcome to sign up for our next ePages Partner Training.</p>\n<p>Quick overview of the agenda:</p>\n<ul>\n<li>Developer Basics</li>\n<li>Development of ePages internal modules</li>\n<li>The ePages <a href=\"https://developer.epages.com/apps\" target=\"_blank\" rel=\"external\">REST API</a></li>\n<li>Developing an app via REST</li>\n<li>Introduction to our new responsive storefront and optimized administration area</li>\n<li>Q&amp;A session</li>\n</ul>\n<p>Date &amp; Time: 24th to 28th of October 2016</p>\n<p>Trainers: Oliver Zscheyge and Friedrich Gehring (Software Developers)</p>\n<p>Location: ePages headquarter, Pilatuspool 2, 20355 Hamburg</p>\n<p>Sign up at <a href=\"mailto:training@epages.com\" target=\"_blank\" rel=\"external\">training@epages.com</a>.<br>We’re looking forward to see you there!</p>\n","excerpt":"","more":"<p>You are an ePages partner already?<br>Or you’re interested in developing an app for ePages?<br>You’re very welcome to sign up for our next ePages Partner Training.</p>\n<p>Quick overview of the agenda:</p>\n<ul>\n<li>Developer Basics</li>\n<li>Development of ePages internal modules</li>\n<li>The ePages <a href=\"https://developer.epages.com/apps\">REST API</a></li>\n<li>Developing an app via REST</li>\n<li>Introduction to our new responsive storefront and optimized administration area</li>\n<li>Q&amp;A session</li>\n</ul>\n<p>Date &amp; Time: 24th to 28th of October 2016</p>\n<p>Trainers: Oliver Zscheyge and Friedrich Gehring (Software Developers)</p>\n<p>Location: ePages headquarter, Pilatuspool 2, 20355 Hamburg</p>\n<p>Sign up at <a href=\"mailto:training@epages.com\">training@epages.com</a>.<br>We’re looking forward to see you there!</p>\n"},{"layout":"post","title":"SoCraTes 2016","date":"2016-09-01T05:11:21.000Z","image":"blog-header/craftsmanship.jpg","authors":["Benjamin","Oliver Z."],"_content":"\nFrom the 25th until the 28th of August 2016 the 6th International [Software Craftsmanship and Testing Conference (SoCraTes)](https://www.socrates-conference.de/) took place in Soltau, Germany.\nBoth of us were lucky to attend such a great event.\nAnd even one of the sponsors was [ePages](http://www.epages.com/en/).\nThis conference has a quite unique format and you can't really tell what you will get beforehand.\nHere's our wrap-up of 4 awesome days.\n\n## Warm-up\n\nHow do you get 226 people, software developers and non-developers alike, to show up at one place where you don't even have mobile coverage?\nObserving \"normal\" conferences, usually the most interesting slots are the coffee breaks where people connect, share inside knowledge, ideas, and inspiration.\nThe actual talks become a second thought.\nSo why not make a conference that is one big coffee break?\n\nRight after the initial kick-off meeting on Thursday evening we met in a [World Cafe](https://en.wikipedia.org/wiki/World_Caf%C3%A9_(conversational_process)).\nWe sat together in small groups with other people we did not know.\nWe introduced ourselves and explained what made us come here, which expectations we have, what we'd like to learn, and what sessions we could provide.\nAt the end of this ice breaker there was a pretty precise idea of what people are interested in, and what could be provided as conference sessions for the next two days.\n\n## Conference days\n\n{% image blog/blog-socrates.jpg 50% right %}\n\nFriday and Saturday were [open spaces](https://en.wikipedia.org/wiki/Open_Space_Technology).\nUpfront around 15 meeting locations with initially empty time schedules (6x1 hour slots) were prepared as a supportive sessions' frame by the organization team.\nThere was a \"marketplace\" every morning where people could pitch sessions and distribute those among the time slots and rooms.\nBeing an open space the \"Law of Two Feet\" applies: You can join or walk out of any session at any time.\nAt each day before dinner, everyone gathered in the hall again and shared what they had learned during the day.\n\nWe attended lots of those open spaces, so here's just an extract of some of them accompanied by our notes:\n\n### Deep dive into Git internals\n\n* How does Git store files and track changes internally?\n* Types of Git objects\n* Use of low-level \"plumbing\" commands. Git users normally just use the high-level \"porcelain\" commands.\n* Git does not store any diffs.\nThis is very ineffective on binary data.\n* The validation of hashes is disabled by default, so if you want to check the integrity of a repository you need to set a flag to validate (this is a huge performance impact in bigger projects).\n\n### Can monitoring be used for integration testing?\n\n* Using a test bot and monitoring to detect problems\n* Thresholds for monitoring are bad.\nBetter: track velocity or do a baseline comparison\n* Use an alert hierarchy/alert conditions/alert dependencies\n* Also test your monitoring.\n\n### Property-based testing in Java\n\nSolving the [FizzBuzz Kata](http://codingdojo.org/cgi-bin/index.pl?KataFizzBuzz) multiple times revealed the concepts of property-based testing (PBT) step by step.\nFirst we started writing normal unit tests in TDD-as-if-you-meant-it style.\nThen we looked for repetitions to transfer several tests into parametrized tests with input and output by using the DataProviderRunner.\nAs last step we switched to [*JUnitQuickcheck*](https://github.com/pholser/junit-quickcheck) for running tests several times with random values produced by a custom generator.\nBig picture: Typically a developer starts with a hypothesis of the favored behavior of the system under test (SUT) and then tries inductively with TDD to prove the observation.\nIn contrast to this approach, a developer can also start with the observation of the SUT, find patterns how the system behaves, and then apply PBT deductively to generate a hypothesis of the SUT.\nThis means, that PBT can be seen as a complementary method to TDD to enhance the safety net and should not be used as its substitute.\n\n### Intro to concepts of Functional Programming (FP)\n\nThis session quickly showed the basic ideas in functional programming: No side effects, immutable data structures, first class functions, and higher-order functions, which take one or more functions as input and may return another function.\nFor instance, we focused on map with transformers, fold/reduce/accumulate with combiners, and filter with predicates.\nAs an easy example for monads (an abstract datatype) we learned about containers/boxes/collections, like lists, sets and multisets, maps, as well as vectors.\nWe also learned about the special Option/Some/Maybe monad/type, which can be created via a None or a Just/Some constructor.\nHence the return type of operations, that may fail, can be represented in a type safe matter so that operation chaining without throwing/checking for null reference/pointer exceptions is possible.\n\n## Workshop day\n\nSunday was reserved for longer workshops:\n\n* Code retreat with various sessions of the [Kata Game of Life](http://codingdojo.org/cgi-bin/index.pl?action=browse&diff=1&id=KataGameOfLife)\n* Agora platform development\n* Android app development\n* Integration testing without mocks\n\n## More than the usual conference!\n\n{% image blog/blog-socrates-group.jpg %}\n\nGiving feedback to session hosts, other participants, or the organization team was quite easy as well: Every attendee received Kudo Cards that they could freely distribute with remarks, why they liked a session, or other things.\nYet, the best part: The fully equipped conference hotel was located in a big beautiful national park, isolated by a forest from the surrounding world.\nThis is a huge opportunity to completely leave the daily business and escape into a surreal paradise for developers.\nHence, all participants also stayed together for the whole 4 days and nights, which allowed to establish close connections in a short period of time.\n\nBesides the technical talks there were a lot of soft topics about communication, such as:\n\n* How to communicate with management, sales or marketing\n* Company politics\n* Giving feedback\n* How to get your co-workers into a testing mindset?\n* Self-organization.\n\nFurthermore, we had plenty of entertaining morning/evening activities, including board games, PowerPoint karaoke, astrology walk, beach volleyball, martial arts, breathing exercises, wake-up running, and much more.\n\nIt was a great conference, we learned a lot, and had fun doing so!\n","source":"_posts/2016-09-01-socrates.md","raw":"---\nlayout: post\ntitle: \"SoCraTes 2016\"\ndate: \"2016-09-01 07:11:21\"\nimage: blog-header/craftsmanship.jpg\ncategories: events\nauthors: [\"Benjamin\", \"Oliver Z.\"]\n---\n\nFrom the 25th until the 28th of August 2016 the 6th International [Software Craftsmanship and Testing Conference (SoCraTes)](https://www.socrates-conference.de/) took place in Soltau, Germany.\nBoth of us were lucky to attend such a great event.\nAnd even one of the sponsors was [ePages](http://www.epages.com/en/).\nThis conference has a quite unique format and you can't really tell what you will get beforehand.\nHere's our wrap-up of 4 awesome days.\n\n## Warm-up\n\nHow do you get 226 people, software developers and non-developers alike, to show up at one place where you don't even have mobile coverage?\nObserving \"normal\" conferences, usually the most interesting slots are the coffee breaks where people connect, share inside knowledge, ideas, and inspiration.\nThe actual talks become a second thought.\nSo why not make a conference that is one big coffee break?\n\nRight after the initial kick-off meeting on Thursday evening we met in a [World Cafe](https://en.wikipedia.org/wiki/World_Caf%C3%A9_(conversational_process)).\nWe sat together in small groups with other people we did not know.\nWe introduced ourselves and explained what made us come here, which expectations we have, what we'd like to learn, and what sessions we could provide.\nAt the end of this ice breaker there was a pretty precise idea of what people are interested in, and what could be provided as conference sessions for the next two days.\n\n## Conference days\n\n{% image blog/blog-socrates.jpg 50% right %}\n\nFriday and Saturday were [open spaces](https://en.wikipedia.org/wiki/Open_Space_Technology).\nUpfront around 15 meeting locations with initially empty time schedules (6x1 hour slots) were prepared as a supportive sessions' frame by the organization team.\nThere was a \"marketplace\" every morning where people could pitch sessions and distribute those among the time slots and rooms.\nBeing an open space the \"Law of Two Feet\" applies: You can join or walk out of any session at any time.\nAt each day before dinner, everyone gathered in the hall again and shared what they had learned during the day.\n\nWe attended lots of those open spaces, so here's just an extract of some of them accompanied by our notes:\n\n### Deep dive into Git internals\n\n* How does Git store files and track changes internally?\n* Types of Git objects\n* Use of low-level \"plumbing\" commands. Git users normally just use the high-level \"porcelain\" commands.\n* Git does not store any diffs.\nThis is very ineffective on binary data.\n* The validation of hashes is disabled by default, so if you want to check the integrity of a repository you need to set a flag to validate (this is a huge performance impact in bigger projects).\n\n### Can monitoring be used for integration testing?\n\n* Using a test bot and monitoring to detect problems\n* Thresholds for monitoring are bad.\nBetter: track velocity or do a baseline comparison\n* Use an alert hierarchy/alert conditions/alert dependencies\n* Also test your monitoring.\n\n### Property-based testing in Java\n\nSolving the [FizzBuzz Kata](http://codingdojo.org/cgi-bin/index.pl?KataFizzBuzz) multiple times revealed the concepts of property-based testing (PBT) step by step.\nFirst we started writing normal unit tests in TDD-as-if-you-meant-it style.\nThen we looked for repetitions to transfer several tests into parametrized tests with input and output by using the DataProviderRunner.\nAs last step we switched to [*JUnitQuickcheck*](https://github.com/pholser/junit-quickcheck) for running tests several times with random values produced by a custom generator.\nBig picture: Typically a developer starts with a hypothesis of the favored behavior of the system under test (SUT) and then tries inductively with TDD to prove the observation.\nIn contrast to this approach, a developer can also start with the observation of the SUT, find patterns how the system behaves, and then apply PBT deductively to generate a hypothesis of the SUT.\nThis means, that PBT can be seen as a complementary method to TDD to enhance the safety net and should not be used as its substitute.\n\n### Intro to concepts of Functional Programming (FP)\n\nThis session quickly showed the basic ideas in functional programming: No side effects, immutable data structures, first class functions, and higher-order functions, which take one or more functions as input and may return another function.\nFor instance, we focused on map with transformers, fold/reduce/accumulate with combiners, and filter with predicates.\nAs an easy example for monads (an abstract datatype) we learned about containers/boxes/collections, like lists, sets and multisets, maps, as well as vectors.\nWe also learned about the special Option/Some/Maybe monad/type, which can be created via a None or a Just/Some constructor.\nHence the return type of operations, that may fail, can be represented in a type safe matter so that operation chaining without throwing/checking for null reference/pointer exceptions is possible.\n\n## Workshop day\n\nSunday was reserved for longer workshops:\n\n* Code retreat with various sessions of the [Kata Game of Life](http://codingdojo.org/cgi-bin/index.pl?action=browse&diff=1&id=KataGameOfLife)\n* Agora platform development\n* Android app development\n* Integration testing without mocks\n\n## More than the usual conference!\n\n{% image blog/blog-socrates-group.jpg %}\n\nGiving feedback to session hosts, other participants, or the organization team was quite easy as well: Every attendee received Kudo Cards that they could freely distribute with remarks, why they liked a session, or other things.\nYet, the best part: The fully equipped conference hotel was located in a big beautiful national park, isolated by a forest from the surrounding world.\nThis is a huge opportunity to completely leave the daily business and escape into a surreal paradise for developers.\nHence, all participants also stayed together for the whole 4 days and nights, which allowed to establish close connections in a short period of time.\n\nBesides the technical talks there were a lot of soft topics about communication, such as:\n\n* How to communicate with management, sales or marketing\n* Company politics\n* Giving feedback\n* How to get your co-workers into a testing mindset?\n* Self-organization.\n\nFurthermore, we had plenty of entertaining morning/evening activities, including board games, PowerPoint karaoke, astrology walk, beach volleyball, martial arts, breathing exercises, wake-up running, and much more.\n\nIt was a great conference, we learned a lot, and had fun doing so!\n","slug":"2016-09-01-socrates","published":1,"updated":"2016-09-20T14:31:48.000Z","comments":1,"photos":[],"link":"","_id":"ciu6nuha60036hqyxwyyx91dx","content":"<p>From the 25th until the 28th of August 2016 the 6th International <a href=\"https://www.socrates-conference.de/\" target=\"_blank\" rel=\"external\">Software Craftsmanship and Testing Conference (SoCraTes)</a> took place in Soltau, Germany.<br>Both of us were lucky to attend such a great event.<br>And even one of the sponsors was <a href=\"http://www.epages.com/en/\" target=\"_blank\" rel=\"external\">ePages</a>.<br>This conference has a quite unique format and you can’t really tell what you will get beforehand.<br>Here’s our wrap-up of 4 awesome days.</p>\n<h2 id=\"Warm-up\"><a href=\"#Warm-up\" class=\"headerlink\" title=\"Warm-up\"></a>Warm-up</h2><p>How do you get 226 people, software developers and non-developers alike, to show up at one place where you don’t even have mobile coverage?<br>Observing “normal” conferences, usually the most interesting slots are the coffee breaks where people connect, share inside knowledge, ideas, and inspiration.<br>The actual talks become a second thought.<br>So why not make a conference that is one big coffee break?</p>\n<p>Right after the initial kick-off meeting on Thursday evening we met in a <a href=\"https://en.wikipedia.org/wiki/World_Caf%C3%A9_(conversational_process\" target=\"_blank\" rel=\"external\">World Cafe</a>).<br>We sat together in small groups with other people we did not know.<br>We introduced ourselves and explained what made us come here, which expectations we have, what we’d like to learn, and what sessions we could provide.<br>At the end of this ice breaker there was a pretty precise idea of what people are interested in, and what could be provided as conference sessions for the next two days.</p>\n<h2 id=\"Conference-days\"><a href=\"#Conference-days\" class=\"headerlink\" title=\"Conference days\"></a>Conference days</h2><img class=\"blog/blog-socrates.jpg 50% right\">\n<p>Friday and Saturday were <a href=\"https://en.wikipedia.org/wiki/Open_Space_Technology\" target=\"_blank\" rel=\"external\">open spaces</a>.<br>Upfront around 15 meeting locations with initially empty time schedules (6x1 hour slots) were prepared as a supportive sessions’ frame by the organization team.<br>There was a “marketplace” every morning where people could pitch sessions and distribute those among the time slots and rooms.<br>Being an open space the “Law of Two Feet” applies: You can join or walk out of any session at any time.<br>At each day before dinner, everyone gathered in the hall again and shared what they had learned during the day.</p>\n<p>We attended lots of those open spaces, so here’s just an extract of some of them accompanied by our notes:</p>\n<h3 id=\"Deep-dive-into-Git-internals\"><a href=\"#Deep-dive-into-Git-internals\" class=\"headerlink\" title=\"Deep dive into Git internals\"></a>Deep dive into Git internals</h3><ul>\n<li>How does Git store files and track changes internally?</li>\n<li>Types of Git objects</li>\n<li>Use of low-level “plumbing” commands. Git users normally just use the high-level “porcelain” commands.</li>\n<li>Git does not store any diffs.<br>This is very ineffective on binary data.</li>\n<li>The validation of hashes is disabled by default, so if you want to check the integrity of a repository you need to set a flag to validate (this is a huge performance impact in bigger projects).</li>\n</ul>\n<h3 id=\"Can-monitoring-be-used-for-integration-testing\"><a href=\"#Can-monitoring-be-used-for-integration-testing\" class=\"headerlink\" title=\"Can monitoring be used for integration testing?\"></a>Can monitoring be used for integration testing?</h3><ul>\n<li>Using a test bot and monitoring to detect problems</li>\n<li>Thresholds for monitoring are bad.<br>Better: track velocity or do a baseline comparison</li>\n<li>Use an alert hierarchy/alert conditions/alert dependencies</li>\n<li>Also test your monitoring.</li>\n</ul>\n<h3 id=\"Property-based-testing-in-Java\"><a href=\"#Property-based-testing-in-Java\" class=\"headerlink\" title=\"Property-based testing in Java\"></a>Property-based testing in Java</h3><p>Solving the <a href=\"http://codingdojo.org/cgi-bin/index.pl?KataFizzBuzz\" target=\"_blank\" rel=\"external\">FizzBuzz Kata</a> multiple times revealed the concepts of property-based testing (PBT) step by step.<br>First we started writing normal unit tests in TDD-as-if-you-meant-it style.<br>Then we looked for repetitions to transfer several tests into parametrized tests with input and output by using the DataProviderRunner.<br>As last step we switched to <a href=\"https://github.com/pholser/junit-quickcheck\" target=\"_blank\" rel=\"external\"><em>JUnitQuickcheck</em></a> for running tests several times with random values produced by a custom generator.<br>Big picture: Typically a developer starts with a hypothesis of the favored behavior of the system under test (SUT) and then tries inductively with TDD to prove the observation.<br>In contrast to this approach, a developer can also start with the observation of the SUT, find patterns how the system behaves, and then apply PBT deductively to generate a hypothesis of the SUT.<br>This means, that PBT can be seen as a complementary method to TDD to enhance the safety net and should not be used as its substitute.</p>\n<h3 id=\"Intro-to-concepts-of-Functional-Programming-FP\"><a href=\"#Intro-to-concepts-of-Functional-Programming-FP\" class=\"headerlink\" title=\"Intro to concepts of Functional Programming (FP)\"></a>Intro to concepts of Functional Programming (FP)</h3><p>This session quickly showed the basic ideas in functional programming: No side effects, immutable data structures, first class functions, and higher-order functions, which take one or more functions as input and may return another function.<br>For instance, we focused on map with transformers, fold/reduce/accumulate with combiners, and filter with predicates.<br>As an easy example for monads (an abstract datatype) we learned about containers/boxes/collections, like lists, sets and multisets, maps, as well as vectors.<br>We also learned about the special Option/Some/Maybe monad/type, which can be created via a None or a Just/Some constructor.<br>Hence the return type of operations, that may fail, can be represented in a type safe matter so that operation chaining without throwing/checking for null reference/pointer exceptions is possible.</p>\n<h2 id=\"Workshop-day\"><a href=\"#Workshop-day\" class=\"headerlink\" title=\"Workshop day\"></a>Workshop day</h2><p>Sunday was reserved for longer workshops:</p>\n<ul>\n<li>Code retreat with various sessions of the <a href=\"http://codingdojo.org/cgi-bin/index.pl?action=browse&amp;diff=1&amp;id=KataGameOfLife\" target=\"_blank\" rel=\"external\">Kata Game of Life</a></li>\n<li>Agora platform development</li>\n<li>Android app development</li>\n<li>Integration testing without mocks</li>\n</ul>\n<h2 id=\"More-than-the-usual-conference\"><a href=\"#More-than-the-usual-conference\" class=\"headerlink\" title=\"More than the usual conference!\"></a>More than the usual conference!</h2><img class=\"blog/blog-socrates-group.jpg\">\n<p>Giving feedback to session hosts, other participants, or the organization team was quite easy as well: Every attendee received Kudo Cards that they could freely distribute with remarks, why they liked a session, or other things.<br>Yet, the best part: The fully equipped conference hotel was located in a big beautiful national park, isolated by a forest from the surrounding world.<br>This is a huge opportunity to completely leave the daily business and escape into a surreal paradise for developers.<br>Hence, all participants also stayed together for the whole 4 days and nights, which allowed to establish close connections in a short period of time.</p>\n<p>Besides the technical talks there were a lot of soft topics about communication, such as:</p>\n<ul>\n<li>How to communicate with management, sales or marketing</li>\n<li>Company politics</li>\n<li>Giving feedback</li>\n<li>How to get your co-workers into a testing mindset?</li>\n<li>Self-organization.</li>\n</ul>\n<p>Furthermore, we had plenty of entertaining morning/evening activities, including board games, PowerPoint karaoke, astrology walk, beach volleyball, martial arts, breathing exercises, wake-up running, and much more.</p>\n<p>It was a great conference, we learned a lot, and had fun doing so!</p>\n","excerpt":"","more":"<p>From the 25th until the 28th of August 2016 the 6th International <a href=\"https://www.socrates-conference.de/\">Software Craftsmanship and Testing Conference (SoCraTes)</a> took place in Soltau, Germany.<br>Both of us were lucky to attend such a great event.<br>And even one of the sponsors was <a href=\"http://www.epages.com/en/\">ePages</a>.<br>This conference has a quite unique format and you can’t really tell what you will get beforehand.<br>Here’s our wrap-up of 4 awesome days.</p>\n<h2 id=\"Warm-up\"><a href=\"#Warm-up\" class=\"headerlink\" title=\"Warm-up\"></a>Warm-up</h2><p>How do you get 226 people, software developers and non-developers alike, to show up at one place where you don’t even have mobile coverage?<br>Observing “normal” conferences, usually the most interesting slots are the coffee breaks where people connect, share inside knowledge, ideas, and inspiration.<br>The actual talks become a second thought.<br>So why not make a conference that is one big coffee break?</p>\n<p>Right after the initial kick-off meeting on Thursday evening we met in a <a href=\"https://en.wikipedia.org/wiki/World_Caf%C3%A9_(conversational_process\">World Cafe</a>).<br>We sat together in small groups with other people we did not know.<br>We introduced ourselves and explained what made us come here, which expectations we have, what we’d like to learn, and what sessions we could provide.<br>At the end of this ice breaker there was a pretty precise idea of what people are interested in, and what could be provided as conference sessions for the next two days.</p>\n<h2 id=\"Conference-days\"><a href=\"#Conference-days\" class=\"headerlink\" title=\"Conference days\"></a>Conference days</h2><img class=\"blog/blog-socrates.jpg 50% right\">\n<p>Friday and Saturday were <a href=\"https://en.wikipedia.org/wiki/Open_Space_Technology\">open spaces</a>.<br>Upfront around 15 meeting locations with initially empty time schedules (6x1 hour slots) were prepared as a supportive sessions’ frame by the organization team.<br>There was a “marketplace” every morning where people could pitch sessions and distribute those among the time slots and rooms.<br>Being an open space the “Law of Two Feet” applies: You can join or walk out of any session at any time.<br>At each day before dinner, everyone gathered in the hall again and shared what they had learned during the day.</p>\n<p>We attended lots of those open spaces, so here’s just an extract of some of them accompanied by our notes:</p>\n<h3 id=\"Deep-dive-into-Git-internals\"><a href=\"#Deep-dive-into-Git-internals\" class=\"headerlink\" title=\"Deep dive into Git internals\"></a>Deep dive into Git internals</h3><ul>\n<li>How does Git store files and track changes internally?</li>\n<li>Types of Git objects</li>\n<li>Use of low-level “plumbing” commands. Git users normally just use the high-level “porcelain” commands.</li>\n<li>Git does not store any diffs.<br>This is very ineffective on binary data.</li>\n<li>The validation of hashes is disabled by default, so if you want to check the integrity of a repository you need to set a flag to validate (this is a huge performance impact in bigger projects).</li>\n</ul>\n<h3 id=\"Can-monitoring-be-used-for-integration-testing\"><a href=\"#Can-monitoring-be-used-for-integration-testing\" class=\"headerlink\" title=\"Can monitoring be used for integration testing?\"></a>Can monitoring be used for integration testing?</h3><ul>\n<li>Using a test bot and monitoring to detect problems</li>\n<li>Thresholds for monitoring are bad.<br>Better: track velocity or do a baseline comparison</li>\n<li>Use an alert hierarchy/alert conditions/alert dependencies</li>\n<li>Also test your monitoring.</li>\n</ul>\n<h3 id=\"Property-based-testing-in-Java\"><a href=\"#Property-based-testing-in-Java\" class=\"headerlink\" title=\"Property-based testing in Java\"></a>Property-based testing in Java</h3><p>Solving the <a href=\"http://codingdojo.org/cgi-bin/index.pl?KataFizzBuzz\">FizzBuzz Kata</a> multiple times revealed the concepts of property-based testing (PBT) step by step.<br>First we started writing normal unit tests in TDD-as-if-you-meant-it style.<br>Then we looked for repetitions to transfer several tests into parametrized tests with input and output by using the DataProviderRunner.<br>As last step we switched to <a href=\"https://github.com/pholser/junit-quickcheck\"><em>JUnitQuickcheck</em></a> for running tests several times with random values produced by a custom generator.<br>Big picture: Typically a developer starts with a hypothesis of the favored behavior of the system under test (SUT) and then tries inductively with TDD to prove the observation.<br>In contrast to this approach, a developer can also start with the observation of the SUT, find patterns how the system behaves, and then apply PBT deductively to generate a hypothesis of the SUT.<br>This means, that PBT can be seen as a complementary method to TDD to enhance the safety net and should not be used as its substitute.</p>\n<h3 id=\"Intro-to-concepts-of-Functional-Programming-FP\"><a href=\"#Intro-to-concepts-of-Functional-Programming-FP\" class=\"headerlink\" title=\"Intro to concepts of Functional Programming (FP)\"></a>Intro to concepts of Functional Programming (FP)</h3><p>This session quickly showed the basic ideas in functional programming: No side effects, immutable data structures, first class functions, and higher-order functions, which take one or more functions as input and may return another function.<br>For instance, we focused on map with transformers, fold/reduce/accumulate with combiners, and filter with predicates.<br>As an easy example for monads (an abstract datatype) we learned about containers/boxes/collections, like lists, sets and multisets, maps, as well as vectors.<br>We also learned about the special Option/Some/Maybe monad/type, which can be created via a None or a Just/Some constructor.<br>Hence the return type of operations, that may fail, can be represented in a type safe matter so that operation chaining without throwing/checking for null reference/pointer exceptions is possible.</p>\n<h2 id=\"Workshop-day\"><a href=\"#Workshop-day\" class=\"headerlink\" title=\"Workshop day\"></a>Workshop day</h2><p>Sunday was reserved for longer workshops:</p>\n<ul>\n<li>Code retreat with various sessions of the <a href=\"http://codingdojo.org/cgi-bin/index.pl?action=browse&amp;diff=1&amp;id=KataGameOfLife\">Kata Game of Life</a></li>\n<li>Agora platform development</li>\n<li>Android app development</li>\n<li>Integration testing without mocks</li>\n</ul>\n<h2 id=\"More-than-the-usual-conference\"><a href=\"#More-than-the-usual-conference\" class=\"headerlink\" title=\"More than the usual conference!\"></a>More than the usual conference!</h2><img class=\"blog/blog-socrates-group.jpg\">\n<p>Giving feedback to session hosts, other participants, or the organization team was quite easy as well: Every attendee received Kudo Cards that they could freely distribute with remarks, why they liked a session, or other things.<br>Yet, the best part: The fully equipped conference hotel was located in a big beautiful national park, isolated by a forest from the surrounding world.<br>This is a huge opportunity to completely leave the daily business and escape into a surreal paradise for developers.<br>Hence, all participants also stayed together for the whole 4 days and nights, which allowed to establish close connections in a short period of time.</p>\n<p>Besides the technical talks there were a lot of soft topics about communication, such as:</p>\n<ul>\n<li>How to communicate with management, sales or marketing</li>\n<li>Company politics</li>\n<li>Giving feedback</li>\n<li>How to get your co-workers into a testing mindset?</li>\n<li>Self-organization.</li>\n</ul>\n<p>Furthermore, we had plenty of entertaining morning/evening activities, including board games, PowerPoint karaoke, astrology walk, beach volleyball, martial arts, breathing exercises, wake-up running, and much more.</p>\n<p>It was a great conference, we learned a lot, and had fun doing so!</p>\n"}],"PostAsset":[],"PostCategory":[{"post_id":"ciu6nuh7u0004hqyx5k293zvd","category_id":"ciu6nuh7q0002hqyx4znd0t21","_id":"ciu6nuh810008hqyxn86idwkv"},{"post_id":"ciu6nuh7i0000hqyx0ay5hen4","category_id":"ciu6nuh7q0002hqyx4znd0t21","_id":"ciu6nuh82000bhqyxqg0zrttz"},{"post_id":"ciu6nuh7x0005hqyx7r6s5r5d","category_id":"ciu6nuh7q0002hqyx4znd0t21","_id":"ciu6nuh83000dhqyxtl06rdxu"},{"post_id":"ciu6nuh7m0001hqyxg6k06pvg","category_id":"ciu6nuh7q0002hqyx4znd0t21","_id":"ciu6nuh87000ghqyxl5xhqebr"},{"post_id":"ciu6nuh810009hqyxzxk3d8e6","category_id":"ciu6nuh7q0002hqyx4znd0t21","_id":"ciu6nuh88000ihqyxwwr22z4d"},{"post_id":"ciu6nuh7s0003hqyxg45kkos5","category_id":"ciu6nuh82000ahqyxa8dkw4b8","_id":"ciu6nuh8a000lhqyx0qod0cm7"},{"post_id":"ciu6nuh87000hhqyxghnojy30","category_id":"ciu6nuh7q0002hqyx4znd0t21","_id":"ciu6nuh8j000nhqyx3i4bgfy8"},{"post_id":"ciu6nuh7z0007hqyxtjv269xl","category_id":"ciu6nuh86000fhqyxiud5memz","_id":"ciu6nuh8m000phqyxnzxs997a"},{"post_id":"ciu6nuh88000jhqyx9hab5vcq","category_id":"ciu6nuh82000ahqyxa8dkw4b8","_id":"ciu6nuh8r000shqyxngb9u38l"},{"post_id":"ciu6nuh8a000mhqyxi8fghv1s","category_id":"ciu6nuh7q0002hqyx4znd0t21","_id":"ciu6nuh8s000uhqyx587ze9f3"},{"post_id":"ciu6nuh82000chqyx4sxqlplz","category_id":"ciu6nuh8a000khqyxf8x9xhmi","_id":"ciu6nuh8t000whqyxwt91t8va"},{"post_id":"ciu6nuh8k000ohqyxs76hci8u","category_id":"ciu6nuh8a000khqyxf8x9xhmi","_id":"ciu6nuh8u000yhqyxgx4j7ov6"},{"post_id":"ciu6nuh8o000rhqyxpgr9j1uo","category_id":"ciu6nuh8a000khqyxf8x9xhmi","_id":"ciu6nuh8v0010hqyxzt0biyd4"},{"post_id":"ciu6nuh84000ehqyxmldl8y4y","category_id":"ciu6nuh8a000khqyxf8x9xhmi","_id":"ciu6nuh8w0012hqyxekke6l1p"},{"post_id":"ciu6nuh8r000thqyx0vmur6rt","category_id":"ciu6nuh7q0002hqyx4znd0t21","_id":"ciu6nuh8x0014hqyxxs2e31pc"},{"post_id":"ciu6nuh8s000vhqyxlrpcu3nb","category_id":"ciu6nuh86000fhqyxiud5memz","_id":"ciu6nuh8z0017hqyxo1udchwf"},{"post_id":"ciu6nuh8t000xhqyxovyj2jks","category_id":"ciu6nuh7q0002hqyx4znd0t21","_id":"ciu6nuh8z0019hqyxqz65hl5w"},{"post_id":"ciu6nuh8u000zhqyx7o78wana","category_id":"ciu6nuh8a000khqyxf8x9xhmi","_id":"ciu6nuh90001bhqyx20470tdn"},{"post_id":"ciu6nuh8v0011hqyxe5jsnoga","category_id":"ciu6nuh7q0002hqyx4znd0t21","_id":"ciu6nuh91001dhqyxaspt617y"},{"post_id":"ciu6nuh8y0015hqyxs4nm44zv","category_id":"ciu6nuh8a000khqyxf8x9xhmi","_id":"ciu6nuh93001fhqyx5zicrvfm"},{"post_id":"ciu6nuh8z0018hqyxlh478ilq","category_id":"ciu6nuh7q0002hqyx4znd0t21","_id":"ciu6nuh93001hhqyxy8rxxja6"},{"post_id":"ciu6nuh90001ahqyxviyljtf2","category_id":"ciu6nuh7q0002hqyx4znd0t21","_id":"ciu6nuh95001jhqyxykram184"},{"post_id":"ciu6nuh8w0013hqyx5p5iyy6c","category_id":"ciu6nuh8y0016hqyxlgmotg25","_id":"ciu6nuh96001lhqyxf1d70j5m"},{"post_id":"ciu6nuh91001chqyxzkvx9zyy","category_id":"ciu6nuh7q0002hqyx4znd0t21","_id":"ciu6nuh98001nhqyxin9dpunm"},{"post_id":"ciu6nuh91001ehqyxai2f80dx","category_id":"ciu6nuh8y0016hqyxlgmotg25","_id":"ciu6nuh99001phqyxlv5zlgad"},{"post_id":"ciu6nuh93001ghqyx3pv42aih","category_id":"ciu6nuh8y0016hqyxlgmotg25","_id":"ciu6nuh9a001rhqyxsu4coljs"},{"post_id":"ciu6nuh94001ihqyx6px89mgc","category_id":"ciu6nuh7q0002hqyx4znd0t21","_id":"ciu6nuh9e001thqyxclfxatdb"},{"post_id":"ciu6nuh95001khqyxf18ou0zf","category_id":"ciu6nuh7q0002hqyx4znd0t21","_id":"ciu6nuh9f001vhqyxvnfunqq8"},{"post_id":"ciu6nuh96001mhqyxuynhe2z8","category_id":"ciu6nuh7q0002hqyx4znd0t21","_id":"ciu6nuh9g001xhqyx7hiai3z3"},{"post_id":"ciu6nuh98001ohqyx705fzivk","category_id":"ciu6nuh7q0002hqyx4znd0t21","_id":"ciu6nuh9h001zhqyx4kz1tbdn"},{"post_id":"ciu6nuh99001qhqyxt5j0ws1j","category_id":"ciu6nuh8a000khqyxf8x9xhmi","_id":"ciu6nuh9j0021hqyx4dggjm9z"},{"post_id":"ciu6nuh9a001shqyxmkkg9f6g","category_id":"ciu6nuh8y0016hqyxlgmotg25","_id":"ciu6nuh9l0023hqyx2xngt2tn"},{"post_id":"ciu6nuh9e001uhqyxk2o9mjjl","category_id":"ciu6nuh7q0002hqyx4znd0t21","_id":"ciu6nuh9l0025hqyxp3tnp0r4"},{"post_id":"ciu6nuh9f001whqyxjo7xslxu","category_id":"ciu6nuh8y0016hqyxlgmotg25","_id":"ciu6nuh9m0027hqyxqt3ygkwp"},{"post_id":"ciu6nuh9g001yhqyx1phvxjry","category_id":"ciu6nuh8a000khqyxf8x9xhmi","_id":"ciu6nuh9n0029hqyxtfmzge3e"},{"post_id":"ciu6nuh9i0020hqyx322jtozl","category_id":"ciu6nuh7q0002hqyx4znd0t21","_id":"ciu6nuh9o002bhqyxc6y9b9kp"},{"post_id":"ciu6nuh9j0022hqyx5ahr8le2","category_id":"ciu6nuh86000fhqyxiud5memz","_id":"ciu6nuh9p002dhqyxioi7njpt"},{"post_id":"ciu6nuh9l0024hqyx10qivexa","category_id":"ciu6nuh8y0016hqyxlgmotg25","_id":"ciu6nuh9q002fhqyx3hmcbuxy"},{"post_id":"ciu6nuh9m0026hqyx1zvw00tg","category_id":"ciu6nuh8y0016hqyxlgmotg25","_id":"ciu6nuh9s002hhqyx9tazxufy"},{"post_id":"ciu6nuh9m0028hqyxvjdfutmo","category_id":"ciu6nuh7q0002hqyx4znd0t21","_id":"ciu6nuh9t002jhqyxcfmls4do"},{"post_id":"ciu6nuh9n002ahqyx0klopk22","category_id":"ciu6nuh7q0002hqyx4znd0t21","_id":"ciu6nuh9u002lhqyx174f3080"},{"post_id":"ciu6nuh9o002chqyxf6s5hgsz","category_id":"ciu6nuh7q0002hqyx4znd0t21","_id":"ciu6nuh9v002nhqyxh3n7u75z"},{"post_id":"ciu6nuh9p002ehqyxemm59zrg","category_id":"ciu6nuh7q0002hqyx4znd0t21","_id":"ciu6nuh9w002phqyxrrja0xvf"},{"post_id":"ciu6nuh9q002ghqyx5b0dy2p6","category_id":"ciu6nuh8a000khqyxf8x9xhmi","_id":"ciu6nuh9y002rhqyx655vb983"},{"post_id":"ciu6nuh9s002ihqyxjj35capj","category_id":"ciu6nuh7q0002hqyx4znd0t21","_id":"ciu6nuh9z002thqyxuryzoszz"},{"post_id":"ciu6nuh9t002khqyxdlh7eiy1","category_id":"ciu6nuh8a000khqyxf8x9xhmi","_id":"ciu6nuha1002vhqyxb5155q0b"},{"post_id":"ciu6nuh9u002mhqyxjhpqovvd","category_id":"ciu6nuh7q0002hqyx4znd0t21","_id":"ciu6nuha2002xhqyxhrxi84jw"},{"post_id":"ciu6nuh9v002ohqyxahvfxjan","category_id":"ciu6nuh7q0002hqyx4znd0t21","_id":"ciu6nuha2002zhqyx16s5gsgd"},{"post_id":"ciu6nuh9w002qhqyx6tmz9mg1","category_id":"ciu6nuh8a000khqyxf8x9xhmi","_id":"ciu6nuha30031hqyx7991d7co"},{"post_id":"ciu6nuh9y002shqyxtsi6hqem","category_id":"ciu6nuh7q0002hqyx4znd0t21","_id":"ciu6nuha50033hqyx1d6hwbx4"},{"post_id":"ciu6nuh9z002uhqyxenholys8","category_id":"ciu6nuh82000ahqyxa8dkw4b8","_id":"ciu6nuha60035hqyxxrb091ww"},{"post_id":"ciu6nuha1002whqyxcjqmhg2k","category_id":"ciu6nuh7q0002hqyx4znd0t21","_id":"ciu6nuha70037hqyx40bxe18e"},{"post_id":"ciu6nuha2002yhqyxe0oykkv5","category_id":"ciu6nuh8a000khqyxf8x9xhmi","_id":"ciu6nuha70038hqyxm6uu9ye9"},{"post_id":"ciu6nuha30030hqyxmv8pk6nu","category_id":"ciu6nuh8a000khqyxf8x9xhmi","_id":"ciu6nuha70039hqyx910jk8g5"},{"post_id":"ciu6nuha40032hqyx1woyelwy","category_id":"ciu6nuh86000fhqyxiud5memz","_id":"ciu6nuha7003ahqyx3onpjt0j"},{"post_id":"ciu6nuha50034hqyxrjwzqan5","category_id":"ciu6nuh7q0002hqyx4znd0t21","_id":"ciu6nuha7003bhqyxo082xusv"},{"post_id":"ciu6nuha60036hqyxwyyx91dx","category_id":"ciu6nuh7q0002hqyx4znd0t21","_id":"ciu6nuha7003chqyx39o6u4fy"}],"PostTag":[],"Tag":[]}}